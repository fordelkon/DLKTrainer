{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cc2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb68b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    def __init__(self, dim, n_embed, decay=0.99, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.n_embed = n_embed\n",
    "        self.decay = decay\n",
    "        self.eps = eps\n",
    "\n",
    "        embed = torch.randn(dim, n_embed)\n",
    "        self.register_buffer(\"embed\", embed)\n",
    "        self.register_buffer(\"cluster_size\", torch.zeros(n_embed))\n",
    "        self.register_buffer(\"embed_avg\", embed.clone())\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.embed = self.embed.to(input.device)\n",
    "        self.cluster_size = self.cluster_size.to(input.device)\n",
    "        \n",
    "        flatten = input.reshape(-1, self.dim)\n",
    "        dist = (\n",
    "            flatten.pow(2).sum(1, keepdim=True)\n",
    "            - 2 * flatten @ self.embed\n",
    "            + self.embed.pow(2).sum(0, keepdim=True)\n",
    "        )\n",
    "        _, embed_ind = (-dist).max(1)\n",
    "        embed_onehot = nn.functional.one_hot(embed_ind, self.n_embed).type(flatten.dtype)\n",
    "        embed_ind = embed_ind.view(*input.shape[:-1])\n",
    "        quantize = self.embed_code(embed_ind)\n",
    "\n",
    "        if self.training:\n",
    "            embed_onehot_sum = embed_onehot.sum(0)\n",
    "            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n",
    "\n",
    "            self.cluster_size.data.mul_(self.decay).add_(\n",
    "                embed_onehot_sum, alpha=1 - self.decay\n",
    "            )\n",
    "            self.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)\n",
    "            n = self.cluster_size.sum()\n",
    "            cluster_size = (\n",
    "                (self.cluster_size + self.eps) / (n + self.n_embed * self.eps) * n\n",
    "            )\n",
    "            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n",
    "            self.embed.data.copy_(embed_normalized)\n",
    "\n",
    "        diff = (quantize.detach() - input).pow(2).mean()\n",
    "        quantize = input + (quantize - input).detach()\n",
    "\n",
    "        return quantize, diff, embed_ind\n",
    "\n",
    "    def embed_code(self, embed_id):\n",
    "        return nn.functional.embedding(embed_id, self.embed.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f4a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channel, channel, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel, in_channel, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        out += input\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665a2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channel, channel, n_res_block, n_res_channel, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks = [\n",
    "                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 2, channel, 3, padding=1),\n",
    "            ]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876b98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channel, out_channel, channel, n_res_block, n_res_channel, stride\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = [nn.Conv2d(in_channel, channel, 3, padding=1)]\n",
    "\n",
    "        for i in range(n_res_block):\n",
    "            blocks.append(ResBlock(channel, n_res_channel))\n",
    "\n",
    "        blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        if stride == 4:\n",
    "            blocks.extend(\n",
    "                [\n",
    "                    nn.ConvTranspose2d(channel, channel // 2, 4, stride=2, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.ConvTranspose2d(\n",
    "                        channel // 2, out_channel, 4, stride=2, padding=1\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif stride == 2:\n",
    "            blocks.append(\n",
    "                nn.ConvTranspose2d(channel, out_channel, 4, stride=2, padding=1)\n",
    "            )\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.blocks(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f37c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=3,\n",
    "        channel=128,\n",
    "        n_res_block=2,\n",
    "        n_res_channel=32,\n",
    "        embed_dim=64,\n",
    "        n_embed=512,\n",
    "        decay=0.99,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_b = Encoder(in_channel, channel, n_res_block, n_res_channel, stride=4)\n",
    "        self.enc_t = Encoder(channel, channel, n_res_block, n_res_channel, stride=2)\n",
    "        self.quantize_conv_t = nn.Conv2d(channel, embed_dim, 1)\n",
    "        self.quantize_t = Quantize(embed_dim, n_embed, decay)\n",
    "        self.dec_t = Decoder(\n",
    "            embed_dim, embed_dim, channel, n_res_block, n_res_channel, stride=2\n",
    "        )\n",
    "        self.quantize_conv_b = nn.Conv2d(embed_dim + channel, embed_dim, 1)\n",
    "        self.quantize_b = Quantize(embed_dim, n_embed)\n",
    "        self.upsample_t = nn.ConvTranspose2d(\n",
    "            embed_dim, embed_dim, 4, stride=2, padding=1\n",
    "        )\n",
    "        self.dec = Decoder(\n",
    "            embed_dim + embed_dim,\n",
    "            in_channel,\n",
    "            channel,\n",
    "            n_res_block,\n",
    "            n_res_channel,\n",
    "            stride=4,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_t, quant_b, diff, _, _ = self.encode(input)\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return nn.functional.tanh(dec), diff\n",
    "\n",
    "    def encode(self, input):\n",
    "        enc_b = self.enc_b(input)\n",
    "        enc_t = self.enc_t(enc_b)\n",
    "\n",
    "        quant_t = self.quantize_conv_t(enc_t).permute(0, 2, 3, 1)\n",
    "        quant_t, diff_t, id_t = self.quantize_t(quant_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        diff_t = diff_t.unsqueeze(0)\n",
    "\n",
    "        dec_t = self.dec_t(quant_t)\n",
    "        enc_b = torch.cat([dec_t, enc_b], 1)\n",
    "\n",
    "        quant_b = self.quantize_conv_b(enc_b).permute(0, 2, 3, 1)\n",
    "        quant_b, diff_b, id_b = self.quantize_b(quant_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "        diff_b = diff_b.unsqueeze(0)\n",
    "\n",
    "        return quant_t, quant_b, diff_t + diff_b, id_t, id_b\n",
    "\n",
    "    def decode(self, quant_t, quant_b):\n",
    "        upsample_t = self.upsample_t(quant_t)\n",
    "        quant = torch.cat([upsample_t, quant_b], 1)\n",
    "        dec = self.dec(quant)\n",
    "\n",
    "        return dec\n",
    "\n",
    "    def decode_code(self, code_t, code_b):\n",
    "        quant_t = self.quantize_t.embed_code(code_t)\n",
    "        quant_t = quant_t.permute(0, 3, 1, 2)\n",
    "        quant_b = self.quantize_b.embed_code(code_b)\n",
    "        quant_b = quant_b.permute(0, 3, 1, 2)\n",
    "\n",
    "        dec = self.decode(quant_t, quant_b)\n",
    "\n",
    "        return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b51816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, image_num=-1):\n",
    "        # Collects image file paths from the root directory, limited to `image_num` images.\n",
    "        self.image_paths = sorted(\n",
    "            [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)\n",
    "             if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        )[:image_num]  # Limit to the first `image_num` images\n",
    "        self.transform = transform # Transformation to apply to images\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the number of images in the dataset.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Loads an image by index, converts it to RGB, and applies transformations if provided.\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Since no actual labels, return 0 as dummy labels\n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690ddade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pipeline for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    # Randomly applies a horizontal flip with 40% probability.\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ], p=0.4),  \n",
    "    transforms.ToTensor(), # Converts image to a PyTorch tensor.\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5)), # Normalizes using mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9aa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(root_dir=\"/datasets/delkon/dm_data\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b8d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae = VQVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9b6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2lightrainer.UnsupervisedLearning.VQVAEn.trainer_config import VQVAEnTrainerConfig\n",
    "from d2lightrainer.UnsupervisedLearning.VQVAEn.trainer import VQVAEnTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0aa249",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvaen_cfg = VQVAEnTrainerConfig()\n",
    "new_param_dict = {\"device\": 3, \"save_dir\": \"runs_vqvaen\", \"batch_size\": 16, \"nominal_batch_size\": 64}\n",
    "vqvaen_cfg.update(**new_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a94ec1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 10:55:10,428 - INFO - Using GPU: 3\n"
     ]
    }
   ],
   "source": [
    "vqvaen_trainer = VQVAEnTrainer(model=vqvae, dataset=dataset, cfg=vqvaen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f5dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 10:55:10,449 - INFO - 'optimizer:' Adam(lr=0.0003, momentum=0.937) with parameter groups 0 weight(decay=0.0), 0 weight(decay=1.0000000000000002e-06), 29 weight(decay=0.0001), 29 bias(decay=0.0)\n",
      "2025-09-10 10:55:10,558 - INFO - --------------------\n",
      "\n",
      "0/600: 100%|██████████| 216/216 [00:09<00:00, 23.08it/s]\n",
      "2025-09-10 10:55:20,008 - INFO - All types `lr` of epoch 0: {'lr/param_group0': np.float64(0.0005880555555555555), 'lr/param_group1': np.float64(1.1944444444444443e-05), 'lr/param_group2': np.float64(1.1944444444444443e-05), 'lr/param_group3': np.float64(1.1944444444444443e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:55:20,011 - INFO - epoch 0: train loss 0.30867565361162025\n",
      "2025-09-10 10:55:20,013 - INFO - 0 epochs completed!\n",
      "\n",
      "2025-09-10 10:55:20,014 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:55:20,016 - INFO - --------------------\n",
      "\n",
      "1/600: 100%|██████████| 216/216 [00:08<00:00, 25.16it/s]\n",
      "2025-09-10 10:55:28,780 - INFO - All types `lr` of epoch 1: {'lr/param_group0': np.float64(0.0005760540933420444), 'lr/param_group1': np.float64(2.3942982230933323e-05), 'lr/param_group2': np.float64(2.3942982230933323e-05), 'lr/param_group3': np.float64(2.3942982230933323e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:55:28,782 - INFO - epoch 1: train loss 0.30994721460673547\n",
      "2025-09-10 10:55:28,785 - INFO - 1 epochs completed!\n",
      "\n",
      "2025-09-10 10:55:28,786 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:55:28,787 - INFO - --------------------\n",
      "\n",
      "2/600: 100%|██████████| 216/216 [00:08<00:00, 24.99it/s]\n",
      "2025-09-10 10:55:37,604 - INFO - All types `lr` of epoch 2: {'lr/param_group0': np.float64(0.0005640467760308627), 'lr/param_group1': np.float64(3.5935664919751726e-05), 'lr/param_group2': np.float64(3.5935664919751726e-05), 'lr/param_group3': np.float64(3.5935664919751726e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:55:37,606 - INFO - epoch 2: train loss 0.3126891862463068\n",
      "2025-09-10 10:55:37,608 - INFO - 2 epochs completed!\n",
      "\n",
      "2025-09-10 10:55:37,609 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:55:37,610 - INFO - --------------------\n",
      "\n",
      "3/600: 100%|██████████| 216/216 [00:08<00:00, 25.36it/s]\n",
      "2025-09-10 10:55:46,301 - INFO - All types `lr` of epoch 3: {'lr/param_group0': np.float64(0.0005520292095130905), 'lr/param_group1': np.float64(4.791809840197939e-05), 'lr/param_group2': np.float64(4.791809840197939e-05), 'lr/param_group3': np.float64(4.791809840197939e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:55:46,302 - INFO - epoch 3: train loss 0.32451101516683895\n",
      "2025-09-10 10:55:46,304 - INFO - 3 epochs completed!\n",
      "\n",
      "2025-09-10 10:55:46,305 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:55:46,307 - INFO - --------------------\n",
      "\n",
      "4/600: 100%|██████████| 216/216 [00:08<00:00, 25.06it/s]\n",
      "2025-09-10 10:55:55,100 - INFO - All types `lr` of epoch 4: {'lr/param_group0': np.float64(0.0005399970036548434), 'lr/param_group1': np.float64(5.988589254373233e-05), 'lr/param_group2': np.float64(5.988589254373233e-05), 'lr/param_group3': np.float64(5.988589254373233e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:55:55,102 - INFO - epoch 4: train loss 0.40981077802953897\n",
      "2025-09-10 10:55:55,104 - INFO - 4 epochs completed!\n",
      "\n",
      "2025-09-10 10:55:55,106 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:55:55,107 - INFO - --------------------\n",
      "\n",
      "5/600: 100%|██████████| 216/216 [00:08<00:00, 24.87it/s]\n",
      "2025-09-10 10:56:03,961 - INFO - All types `lr` of epoch 5: {'lr/param_group0': np.float64(0.0005279457741031265), 'lr/param_group1': np.float64(7.183466299201544e-05), 'lr/param_group2': np.float64(7.183466299201544e-05), 'lr/param_group3': np.float64(7.183466299201544e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:03,963 - INFO - epoch 5: train loss 0.15064718029289334\n",
      "2025-09-10 10:56:03,965 - INFO - 5 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:03,967 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:03,968 - INFO - --------------------\n",
      "\n",
      "6/600: 100%|██████████| 216/216 [00:08<00:00, 25.04it/s]\n",
      "2025-09-10 10:56:12,765 - INFO - All types `lr` of epoch 6: {'lr/param_group0': np.float64(0.000515871144089725), 'lr/param_group1': np.float64(8.376003297861391e-05), 'lr/param_group2': np.float64(8.376003297861391e-05), 'lr/param_group3': np.float64(8.376003297861391e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:12,766 - INFO - epoch 6: train loss 0.07138180979355066\n",
      "2025-09-10 10:56:12,769 - INFO - 6 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:12,770 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:12,772 - INFO - --------------------\n",
      "\n",
      "7/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 10:56:21,676 - INFO - All types `lr` of epoch 7: {'lr/param_group0': np.float64(0.0005037687462325106), 'lr/param_group1': np.float64(9.565763512139956e-05), 'lr/param_group2': np.float64(9.565763512139956e-05), 'lr/param_group3': np.float64(9.565763512139956e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:21,679 - INFO - epoch 7: train loss 0.04908848826394037\n",
      "2025-09-10 10:56:21,682 - INFO - 7 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:21,684 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:21,685 - INFO - --------------------\n",
      "\n",
      "8/600: 100%|██████████| 216/216 [00:08<00:00, 25.01it/s]\n",
      "2025-09-10 10:56:30,499 - INFO - All types `lr` of epoch 8: {'lr/param_group0': np.float64(0.0004916342243335413), 'lr/param_group1': np.float64(0.00010752311322243027), 'lr/param_group2': np.float64(0.00010752311322243027), 'lr/param_group3': np.float64(0.00010752311322243027)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:30,500 - INFO - epoch 8: train loss 0.03154881917699068\n",
      "2025-09-10 10:56:30,502 - INFO - 8 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:30,504 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:30,505 - INFO - --------------------\n",
      "\n",
      "9/600: 100%|██████████| 216/216 [00:08<00:00, 24.26it/s]\n",
      "2025-09-10 10:56:39,583 - INFO - All types `lr` of epoch 9: {'lr/param_group0': np.float64(0.00047946323517333183), 'lr/param_group1': np.float64(0.00011935212406222075), 'lr/param_group2': np.float64(0.00011935212406222075), 'lr/param_group3': np.float64(0.00011935212406222075)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:39,585 - INFO - epoch 9: train loss 0.02338547920980663\n",
      "2025-09-10 10:56:39,587 - INFO - 9 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:39,588 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:39,590 - INFO - --------------------\n",
      "\n",
      "10/600: 100%|██████████| 216/216 [00:08<00:00, 25.07it/s]\n",
      "2025-09-10 10:56:48,373 - INFO - All types `lr` of epoch 10: {'lr/param_group0': np.float64(0.00046725145030067545), 'lr/param_group1': np.float64(0.00013114033918956437), 'lr/param_group2': np.float64(0.00013114033918956437), 'lr/param_group3': np.float64(0.00013114033918956437)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:48,375 - INFO - epoch 10: train loss 0.020454578334465623\n",
      "2025-09-10 10:56:48,376 - INFO - 10 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:48,377 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:48,378 - INFO - --------------------\n",
      "\n",
      "11/600: 100%|██████████| 216/216 [00:08<00:00, 25.23it/s]\n",
      "2025-09-10 10:56:57,101 - INFO - All types `lr` of epoch 11: {'lr/param_group0': np.float64(0.0004549945578173985), 'lr/param_group1': np.float64(0.00014288344670628747), 'lr/param_group2': np.float64(0.00014288344670628747), 'lr/param_group3': np.float64(0.00014288344670628747)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:56:57,103 - INFO - epoch 11: train loss 0.018790408848198475\n",
      "2025-09-10 10:56:57,105 - INFO - 11 epochs completed!\n",
      "\n",
      "2025-09-10 10:56:57,106 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:56:57,107 - INFO - --------------------\n",
      "\n",
      "12/600: 100%|██████████| 216/216 [00:08<00:00, 24.69it/s]\n",
      "2025-09-10 10:57:06,024 - INFO - All types `lr` of epoch 12: {'lr/param_group0': np.float64(0.0004426882641574298), 'lr/param_group1': np.float64(0.00015457715304631874), 'lr/param_group2': np.float64(0.00015457715304631874), 'lr/param_group3': np.float64(0.00015457715304631874)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:06,025 - INFO - epoch 12: train loss 0.01754584340206175\n",
      "2025-09-10 10:57:06,028 - INFO - 12 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:06,029 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:06,030 - INFO - --------------------\n",
      "\n",
      "13/600: 100%|██████████| 216/216 [00:08<00:00, 24.29it/s]\n",
      "2025-09-10 10:57:15,093 - INFO - All types `lr` of epoch 13: {'lr/param_group0': np.float64(0.00043032829585956943), 'lr/param_group1': np.float64(0.00016621718474845836), 'lr/param_group2': np.float64(0.00016621718474845836), 'lr/param_group3': np.float64(0.00016621718474845836)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:15,095 - INFO - epoch 13: train loss 0.016568766074703523\n",
      "2025-09-10 10:57:15,097 - INFO - 13 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:15,099 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:15,100 - INFO - --------------------\n",
      "\n",
      "14/600: 100%|██████████| 216/216 [00:08<00:00, 24.34it/s]\n",
      "2025-09-10 10:57:24,144 - INFO - All types `lr` of epoch 14: {'lr/param_group0': np.float64(0.00041791040133334456), 'lr/param_group1': np.float64(0.0001777992902222335), 'lr/param_group2': np.float64(0.0001777992902222335), 'lr/param_group3': np.float64(0.0001777992902222335)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:24,146 - INFO - epoch 14: train loss 0.015836215004566365\n",
      "2025-09-10 10:57:24,148 - INFO - 14 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:24,149 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:24,150 - INFO - --------------------\n",
      "\n",
      "15/600: 100%|██████████| 216/216 [00:08<00:00, 24.35it/s]\n",
      "2025-09-10 10:57:33,189 - INFO - All types `lr` of epoch 15: {'lr/param_group0': np.float64(0.00040543035261733976), 'lr/param_group1': np.float64(0.00018931924150622867), 'lr/param_group2': np.float64(0.00018931924150622867), 'lr/param_group3': np.float64(0.00018931924150622867)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:33,191 - INFO - epoch 15: train loss 0.015134029668169442\n",
      "2025-09-10 10:57:33,193 - INFO - 15 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:33,194 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:33,196 - INFO - --------------------\n",
      "\n",
      "16/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 10:57:42,048 - INFO - All types `lr` of epoch 16: {'lr/param_group0': np.float64(0.00039288394712939364), 'lr/param_group1': np.float64(0.00020077283601828256), 'lr/param_group2': np.float64(0.00020077283601828256), 'lr/param_group3': np.float64(0.00020077283601828256)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:42,049 - INFO - epoch 16: train loss 0.01393517823803618\n",
      "2025-09-10 10:57:42,051 - INFO - 16 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:42,053 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:42,055 - INFO - --------------------\n",
      "\n",
      "17/600: 100%|██████████| 216/216 [00:08<00:00, 25.07it/s]\n",
      "2025-09-10 10:57:50,840 - INFO - All types `lr` of epoch 17: {'lr/param_group0': np.float64(0.0003802670094080557), 'lr/param_group1': np.float64(0.00021215589829694462), 'lr/param_group2': np.float64(0.00021215589829694462), 'lr/param_group3': np.float64(0.00021215589829694462)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:50,842 - INFO - epoch 17: train loss 0.012998055602009926\n",
      "2025-09-10 10:57:50,844 - INFO - 17 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:50,845 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:50,847 - INFO - --------------------\n",
      "\n",
      "18/600: 100%|██████████| 216/216 [00:08<00:00, 25.51it/s]\n",
      "2025-09-10 10:57:59,488 - INFO - All types `lr` of epoch 18: {'lr/param_group0': np.float64(0.00036757539284469924), 'lr/param_group1': np.float64(0.00022346428173358813), 'lr/param_group2': np.float64(0.00022346428173358813), 'lr/param_group3': np.float64(0.00022346428173358813)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:57:59,490 - INFO - epoch 18: train loss 0.012518062790924753\n",
      "2025-09-10 10:57:59,492 - INFO - 18 epochs completed!\n",
      "\n",
      "2025-09-10 10:57:59,493 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:57:59,496 - INFO - --------------------\n",
      "\n",
      "19/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 10:58:08,369 - INFO - All types `lr` of epoch 19: {'lr/param_group0': np.float64(0.0003548049814056902), 'lr/param_group1': np.float64(0.0002346938702945791), 'lr/param_group2': np.float64(0.0002346938702945791), 'lr/param_group3': np.float64(0.0002346938702945791)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:08,370 - INFO - epoch 19: train loss 0.01211161906744733\n",
      "2025-09-10 10:58:08,372 - INFO - 19 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:08,374 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:08,375 - INFO - --------------------\n",
      "\n",
      "20/600: 100%|██████████| 216/216 [00:08<00:00, 24.46it/s]\n",
      "2025-09-10 10:58:17,381 - INFO - All types `lr` of epoch 20: {'lr/param_group0': np.float64(0.00034195169134401487), 'lr/param_group1': np.float64(0.00024584058023290376), 'lr/param_group2': np.float64(0.00024584058023290376), 'lr/param_group3': np.float64(0.00024584058023290376)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:17,383 - INFO - epoch 20: train loss 0.013065550627221388\n",
      "2025-09-10 10:58:17,385 - INFO - 20 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:17,387 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:17,388 - INFO - --------------------\n",
      "\n",
      "21/600: 100%|██████████| 216/216 [00:08<00:00, 25.08it/s]\n",
      "2025-09-10 10:58:26,179 - INFO - All types `lr` of epoch 21: {'lr/param_group0': np.float64(0.0003290114728997714), 'lr/param_group1': np.float64(0.0002569003617886603), 'lr/param_group2': np.float64(0.0002569003617886603), 'lr/param_group3': np.float64(0.0002569003617886603)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:26,181 - INFO - epoch 21: train loss 0.014624894682869868\n",
      "2025-09-10 10:58:26,183 - INFO - 21 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:26,185 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:26,186 - INFO - --------------------\n",
      "\n",
      "22/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 10:58:35,061 - INFO - All types `lr` of epoch 22: {'lr/param_group0': np.float64(0.0003159803119889356), 'lr/param_group1': np.float64(0.00026786920087782447), 'lr/param_group2': np.float64(0.00026786920087782447), 'lr/param_group3': np.float64(0.00026786920087782447)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:35,063 - INFO - epoch 22: train loss 0.011421703841295783\n",
      "2025-09-10 10:58:35,065 - INFO - 22 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:35,067 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:35,068 - INFO - --------------------\n",
      "\n",
      "23/600: 100%|██████████| 216/216 [00:08<00:00, 25.21it/s]\n",
      "2025-09-10 10:58:43,814 - INFO - All types `lr` of epoch 23: {'lr/param_group0': np.float64(0.0003028542318798136), 'lr/param_group1': np.float64(0.0002787431207687025), 'lr/param_group2': np.float64(0.0002787431207687025), 'lr/param_group3': np.float64(0.0002787431207687025)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:43,815 - INFO - epoch 23: train loss 0.011009799825303533\n",
      "2025-09-10 10:58:43,817 - INFO - 23 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:43,819 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:43,820 - INFO - --------------------\n",
      "\n",
      "24/600: 100%|██████████| 216/216 [00:08<00:00, 24.95it/s]\n",
      "2025-09-10 10:58:52,655 - INFO - All types `lr` of epoch 24: {'lr/param_group0': np.float64(0.00028962929485659895), 'lr/param_group1': np.float64(0.00028951818374548785), 'lr/param_group2': np.float64(0.00028951818374548785), 'lr/param_group3': np.float64(0.00028951818374548785)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:58:52,657 - INFO - epoch 24: train loss 0.010770201038448486\n",
      "2025-09-10 10:58:52,659 - INFO - 24 epochs completed!\n",
      "\n",
      "2025-09-10 10:58:52,661 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:58:52,662 - INFO - --------------------\n",
      "\n",
      "25/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 10:59:01,571 - INFO - All types `lr` of epoch 25: {'lr/param_group0': np.float64(0.00028869611057792606), 'lr/param_group1': np.float64(0.00028869611057792606), 'lr/param_group2': np.float64(0.00028869611057792606), 'lr/param_group3': np.float64(0.00028869611057792606)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:01,573 - INFO - epoch 25: train loss 0.010804337132463438\n",
      "2025-09-10 10:59:01,575 - INFO - 25 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:01,578 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:01,579 - INFO - --------------------\n",
      "\n",
      "26/600: 100%|██████████| 216/216 [00:08<00:00, 25.39it/s]\n",
      "2025-09-10 10:59:10,260 - INFO - All types `lr` of epoch 26: {'lr/param_group0': 0.00028778656191407115, 'lr/param_group1': 0.00028778656191407115, 'lr/param_group2': 0.00028778656191407115, 'lr/param_group3': 0.00028778656191407115}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:10,261 - INFO - epoch 26: train loss 0.010326764263919796\n",
      "2025-09-10 10:59:10,263 - INFO - 26 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:10,264 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:10,265 - INFO - --------------------\n",
      "\n",
      "27/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 10:59:19,168 - INFO - All types `lr` of epoch 27: {'lr/param_group0': 0.0002868433865803636, 'lr/param_group1': 0.0002868433865803636, 'lr/param_group2': 0.0002868433865803636, 'lr/param_group3': 0.0002868433865803636}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:19,169 - INFO - epoch 27: train loss 0.010060477624561085\n",
      "2025-09-10 10:59:19,171 - INFO - 27 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:19,172 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:19,173 - INFO - --------------------\n",
      "\n",
      "28/600: 100%|██████████| 216/216 [00:08<00:00, 25.48it/s]\n",
      "2025-09-10 10:59:27,817 - INFO - All types `lr` of epoch 28: {'lr/param_group0': 0.00028586681729120386, 'lr/param_group1': 0.00028586681729120386, 'lr/param_group2': 0.00028586681729120386, 'lr/param_group3': 0.00028586681729120386}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:27,819 - INFO - epoch 28: train loss 0.00986079641410874\n",
      "2025-09-10 10:59:27,822 - INFO - 28 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:27,824 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:27,825 - INFO - --------------------\n",
      "\n",
      "29/600: 100%|██████████| 216/216 [00:08<00:00, 24.90it/s]\n",
      "2025-09-10 10:59:36,672 - INFO - All types `lr` of epoch 29: {'lr/param_group0': 0.0002848570950004514, 'lr/param_group1': 0.0002848570950004514, 'lr/param_group2': 0.0002848570950004514, 'lr/param_group3': 0.0002848570950004514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:36,674 - INFO - epoch 29: train loss 0.009627076594538434\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.34it/s]\n",
      "2025-09-10 10:59:38,753 - INFO - epoch 29: val loss 0.009901148017012962\n",
      "2025-09-10 10:59:38,757 - INFO - 29 epoch vae reconstruct images complete!\n",
      "2025-09-10 10:59:38,823 - INFO - 29 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:38,824 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:38,825 - INFO - --------------------\n",
      "\n",
      "30/600: 100%|██████████| 216/216 [00:07<00:00, 28.32it/s]\n",
      "2025-09-10 10:59:46,626 - INFO - All types `lr` of epoch 30: {'lr/param_group0': 0.0002838144688419726, 'lr/param_group1': 0.0002838144688419726, 'lr/param_group2': 0.0002838144688419726, 'lr/param_group3': 0.0002838144688419726}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:46,628 - INFO - epoch 30: train loss 0.009536796452098147\n",
      "2025-09-10 10:59:46,631 - INFO - 30 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:46,633 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:46,634 - INFO - --------------------\n",
      "\n",
      "31/600: 100%|██████████| 216/216 [00:07<00:00, 27.98it/s]\n",
      "2025-09-10 10:59:54,516 - INFO - All types `lr` of epoch 31: {'lr/param_group0': 0.000282739196068171, 'lr/param_group1': 0.000282739196068171, 'lr/param_group2': 0.000282739196068171, 'lr/param_group3': 0.000282739196068171}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 10:59:54,518 - INFO - epoch 31: train loss 0.009288081088689741\n",
      "2025-09-10 10:59:54,520 - INFO - 31 epochs completed!\n",
      "\n",
      "2025-09-10 10:59:54,522 - INFO - --------------------\n",
      "\n",
      "2025-09-10 10:59:54,523 - INFO - --------------------\n",
      "\n",
      "32/600: 100%|██████████| 216/216 [00:08<00:00, 25.08it/s]\n",
      "2025-09-10 11:00:03,313 - INFO - All types `lr` of epoch 32: {'lr/param_group0': 0.00028163154198651373, 'lr/param_group1': 0.00028163154198651373, 'lr/param_group2': 0.00028163154198651373, 'lr/param_group3': 0.00028163154198651373}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:03,317 - INFO - epoch 32: train loss 0.009185654369907247\n",
      "2025-09-10 11:00:03,319 - INFO - 32 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:03,321 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:03,322 - INFO - --------------------\n",
      "\n",
      "33/600: 100%|██████████| 216/216 [00:08<00:00, 25.38it/s]\n",
      "2025-09-10 11:00:12,006 - INFO - All types `lr` of epoch 33: {'lr/param_group0': 0.00028049177989407137, 'lr/param_group1': 0.00028049177989407137, 'lr/param_group2': 0.00028049177989407137, 'lr/param_group3': 0.00028049177989407137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:12,009 - INFO - epoch 33: train loss 0.009126823921515434\n",
      "2025-09-10 11:00:12,011 - INFO - 33 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:12,012 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:12,015 - INFO - --------------------\n",
      "\n",
      "34/600: 100%|██████████| 216/216 [00:08<00:00, 25.02it/s]\n",
      "2025-09-10 11:00:20,820 - INFO - All types `lr` of epoch 34: {'lr/param_group0': 0.0002793201910100856, 'lr/param_group1': 0.0002793201910100856, 'lr/param_group2': 0.0002793201910100856, 'lr/param_group3': 0.0002793201910100856}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:20,822 - INFO - epoch 34: train loss 0.008925743062583799\n",
      "2025-09-10 11:00:20,824 - INFO - 34 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:20,826 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:20,827 - INFO - --------------------\n",
      "\n",
      "35/600: 100%|██████████| 216/216 [00:08<00:00, 25.11it/s]\n",
      "2025-09-10 11:00:29,615 - INFO - All types `lr` of epoch 35: {'lr/param_group0': 0.0002781170644065827, 'lr/param_group1': 0.0002781170644065827, 'lr/param_group2': 0.0002781170644065827, 'lr/param_group3': 0.0002781170644065827}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:29,617 - INFO - epoch 35: train loss 0.00887766656577932\n",
      "2025-09-10 11:00:29,619 - INFO - 35 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:29,620 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:29,621 - INFO - --------------------\n",
      "\n",
      "36/600: 100%|██████████| 216/216 [00:08<00:00, 25.00it/s]\n",
      "2025-09-10 11:00:38,431 - INFO - All types `lr` of epoch 36: {'lr/param_group0': 0.0002768826969370492, 'lr/param_group1': 0.0002768826969370492, 'lr/param_group2': 0.0002768826969370492, 'lr/param_group3': 0.0002768826969370492}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:38,435 - INFO - epoch 36: train loss 0.008818250796240237\n",
      "2025-09-10 11:00:38,438 - INFO - 36 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:38,439 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:38,441 - INFO - --------------------\n",
      "\n",
      "37/600: 100%|██████████| 216/216 [00:08<00:00, 25.07it/s]\n",
      "2025-09-10 11:00:47,224 - INFO - All types `lr` of epoch 37: {'lr/param_group0': 0.0002756173931631881, 'lr/param_group1': 0.0002756173931631881, 'lr/param_group2': 0.0002756173931631881, 'lr/param_group3': 0.0002756173931631881}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:47,226 - INFO - epoch 37: train loss 0.008834414134509172\n",
      "2025-09-10 11:00:47,228 - INFO - 37 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:47,230 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:47,231 - INFO - --------------------\n",
      "\n",
      "38/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 11:00:56,132 - INFO - All types `lr` of epoch 38: {'lr/param_group0': 0.0002743214652797724, 'lr/param_group1': 0.0002743214652797724, 'lr/param_group2': 0.0002743214652797724, 'lr/param_group3': 0.0002743214652797724}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:00:56,134 - INFO - epoch 38: train loss 0.00870225288801723\n",
      "2025-09-10 11:00:56,137 - INFO - 38 epochs completed!\n",
      "\n",
      "2025-09-10 11:00:56,139 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:00:56,141 - INFO - --------------------\n",
      "\n",
      "39/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:01:05,020 - INFO - All types `lr` of epoch 39: {'lr/param_group0': 0.00027299523303761595, 'lr/param_group1': 0.00027299523303761595, 'lr/param_group2': 0.00027299523303761595, 'lr/param_group3': 0.00027299523303761595}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:05,022 - INFO - epoch 39: train loss 0.008658277584429554\n",
      "2025-09-10 11:01:05,024 - INFO - 39 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:05,027 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:05,028 - INFO - --------------------\n",
      "\n",
      "40/600: 100%|██████████| 216/216 [00:07<00:00, 27.35it/s]\n",
      "2025-09-10 11:01:13,100 - INFO - All types `lr` of epoch 40: {'lr/param_group0': 0.00027163902366467965, 'lr/param_group1': 0.00027163902366467965, 'lr/param_group2': 0.00027163902366467965, 'lr/param_group3': 0.00027163902366467965}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:13,102 - INFO - epoch 40: train loss 0.008636177916303967\n",
      "2025-09-10 11:01:13,104 - INFO - 40 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:13,106 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:13,107 - INFO - --------------------\n",
      "\n",
      "41/600: 100%|██████████| 216/216 [00:07<00:00, 28.75it/s]\n",
      "2025-09-10 11:01:20,791 - INFO - All types `lr` of epoch 41: {'lr/param_group0': 0.00027025317178533295, 'lr/param_group1': 0.00027025317178533295, 'lr/param_group2': 0.00027025317178533295, 'lr/param_group3': 0.00027025317178533295}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:20,793 - INFO - epoch 41: train loss 0.008588115303104537\n",
      "2025-09-10 11:01:20,795 - INFO - 41 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:20,797 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:20,798 - INFO - --------------------\n",
      "\n",
      "42/600: 100%|██████████| 216/216 [00:07<00:00, 29.07it/s]\n",
      "2025-09-10 11:01:28,402 - INFO - All types `lr` of epoch 42: {'lr/param_group0': 0.00026883801933779, 'lr/param_group1': 0.00026883801933779, 'lr/param_group2': 0.00026883801933779, 'lr/param_group3': 0.00026883801933779}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:28,405 - INFO - epoch 42: train loss 0.008525171662094417\n",
      "2025-09-10 11:01:28,407 - INFO - 42 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:28,409 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:28,410 - INFO - --------------------\n",
      "\n",
      "43/600: 100%|██████████| 216/216 [00:07<00:00, 28.01it/s]\n",
      "2025-09-10 11:01:36,284 - INFO - All types `lr` of epoch 43: {'lr/param_group0': 0.00026739391548974195, 'lr/param_group1': 0.00026739391548974195, 'lr/param_group2': 0.00026739391548974195, 'lr/param_group3': 0.00026739391548974195}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:36,286 - INFO - epoch 43: train loss 0.008451222267467529\n",
      "2025-09-10 11:01:36,288 - INFO - 43 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:36,289 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:36,290 - INFO - --------------------\n",
      "\n",
      "44/600: 100%|██████████| 216/216 [00:07<00:00, 27.17it/s]\n",
      "2025-09-10 11:01:44,405 - INFO - All types `lr` of epoch 44: {'lr/param_group0': 0.0002659212165522047, 'lr/param_group1': 0.0002659212165522047, 'lr/param_group2': 0.0002659212165522047, 'lr/param_group3': 0.0002659212165522047}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:44,407 - INFO - epoch 44: train loss 0.008369079433140103\n",
      "2025-09-10 11:01:44,410 - INFO - 44 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:44,412 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:44,414 - INFO - --------------------\n",
      "\n",
      "45/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 11:01:52,509 - INFO - All types `lr` of epoch 45: {'lr/param_group0': 0.00026442028589160457, 'lr/param_group1': 0.00026442028589160457, 'lr/param_group2': 0.00026442028589160457, 'lr/param_group3': 0.00026442028589160457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:01:52,511 - INFO - epoch 45: train loss 0.00834253073790697\n",
      "2025-09-10 11:01:52,516 - INFO - 45 epochs completed!\n",
      "\n",
      "2025-09-10 11:01:52,518 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:01:52,519 - INFO - --------------------\n",
      "\n",
      "46/600: 100%|██████████| 216/216 [00:07<00:00, 27.18it/s]\n",
      "2025-09-10 11:02:00,637 - INFO - All types `lr` of epoch 46: {'lr/param_group0': 0.0002628914938401232, 'lr/param_group1': 0.0002628914938401232, 'lr/param_group2': 0.0002628914938401232, 'lr/param_group3': 0.0002628914938401232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:00,639 - INFO - epoch 46: train loss 0.008410723729024606\n",
      "2025-09-10 11:02:00,642 - INFO - 46 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:00,643 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:00,645 - INFO - --------------------\n",
      "\n",
      "47/600: 100%|██████████| 216/216 [00:07<00:00, 28.30it/s]\n",
      "2025-09-10 11:02:08,450 - INFO - All types `lr` of epoch 47: {'lr/param_group0': 0.0002613352176043235, 'lr/param_group1': 0.0002613352176043235, 'lr/param_group2': 0.0002613352176043235, 'lr/param_group3': 0.0002613352176043235}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:08,453 - INFO - epoch 47: train loss 0.00830915223384552\n",
      "2025-09-10 11:02:08,456 - INFO - 47 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:08,458 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:08,460 - INFO - --------------------\n",
      "\n",
      "48/600: 100%|██████████| 216/216 [00:07<00:00, 27.66it/s]\n",
      "2025-09-10 11:02:16,443 - INFO - All types `lr` of epoch 48: {'lr/param_group0': 0.0002597518411720796, 'lr/param_group1': 0.0002597518411720796, 'lr/param_group2': 0.0002597518411720796, 'lr/param_group3': 0.0002597518411720796}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:16,445 - INFO - epoch 48: train loss 0.008161602455570741\n",
      "2025-09-10 11:02:16,447 - INFO - 48 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:16,449 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:16,451 - INFO - --------------------\n",
      "\n",
      "49/600: 100%|██████████| 216/216 [00:07<00:00, 27.95it/s]\n",
      "2025-09-10 11:02:24,356 - INFO - All types `lr` of epoch 49: {'lr/param_group0': 0.0002581417552178335, 'lr/param_group1': 0.0002581417552178335, 'lr/param_group2': 0.0002581417552178335, 'lr/param_group3': 0.0002581417552178335}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:24,358 - INFO - epoch 49: train loss 0.008128321498925626\n",
      "2025-09-10 11:02:24,360 - INFO - 49 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:24,362 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:24,364 - INFO - --------------------\n",
      "\n",
      "50/600: 100%|██████████| 216/216 [00:07<00:00, 30.10it/s]\n",
      "2025-09-10 11:02:31,714 - INFO - All types `lr` of epoch 50: {'lr/param_group0': 0.0002565053570062023, 'lr/param_group1': 0.0002565053570062023, 'lr/param_group2': 0.0002565053570062023, 'lr/param_group3': 0.0002565053570062023}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:31,716 - INFO - epoch 50: train loss 0.008169223914457555\n",
      "2025-09-10 11:02:31,718 - INFO - 50 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:31,719 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:31,720 - INFO - --------------------\n",
      "\n",
      "51/600: 100%|██████████| 216/216 [00:08<00:00, 26.55it/s]\n",
      "2025-09-10 11:02:40,028 - INFO - All types `lr` of epoch 51: {'lr/param_group0': 0.00025484305029395865, 'lr/param_group1': 0.00025484305029395865, 'lr/param_group2': 0.00025484305029395865, 'lr/param_group3': 0.00025484305029395865}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:40,029 - INFO - epoch 51: train loss 0.00807699010948892\n",
      "2025-09-10 11:02:40,032 - INFO - 51 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:40,034 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:40,035 - INFO - --------------------\n",
      "\n",
      "52/600: 100%|██████████| 216/216 [00:08<00:00, 25.16it/s]\n",
      "2025-09-10 11:02:48,797 - INFO - All types `lr` of epoch 52: {'lr/param_group0': 0.0002531552452304102, 'lr/param_group1': 0.0002531552452304102, 'lr/param_group2': 0.0002531552452304102, 'lr/param_group3': 0.0002531552452304102}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:48,799 - INFO - epoch 52: train loss 0.008097535456289296\n",
      "2025-09-10 11:02:48,801 - INFO - 52 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:48,803 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:48,804 - INFO - --------------------\n",
      "\n",
      "53/600: 100%|██████████| 216/216 [00:08<00:00, 24.89it/s]\n",
      "2025-09-10 11:02:57,658 - INFO - All types `lr` of epoch 53: {'lr/param_group0': 0.00025144235825620134, 'lr/param_group1': 0.00025144235825620134, 'lr/param_group2': 0.00025144235825620134, 'lr/param_group3': 0.00025144235825620134}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:02:57,660 - INFO - epoch 53: train loss 0.008190757495834044\n",
      "2025-09-10 11:02:57,662 - INFO - 53 epochs completed!\n",
      "\n",
      "2025-09-10 11:02:57,664 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:02:57,666 - INFO - --------------------\n",
      "\n",
      "54/600: 100%|██████████| 216/216 [00:08<00:00, 26.59it/s]\n",
      "2025-09-10 11:03:05,963 - INFO - All types `lr` of epoch 54: {'lr/param_group0': 0.0002497048120005623, 'lr/param_group1': 0.0002497048120005623, 'lr/param_group2': 0.0002497048120005623, 'lr/param_group3': 0.0002497048120005623}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:05,965 - INFO - epoch 54: train loss 0.008067197560901858\n",
      "2025-09-10 11:03:05,968 - INFO - 54 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:05,969 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:05,971 - INFO - --------------------\n",
      "\n",
      "55/600: 100%|██████████| 216/216 [00:08<00:00, 24.71it/s]\n",
      "2025-09-10 11:03:14,888 - INFO - All types `lr` of epoch 55: {'lr/param_group0': 0.0002479430351770322, 'lr/param_group1': 0.0002479430351770322, 'lr/param_group2': 0.0002479430351770322, 'lr/param_group3': 0.0002479430351770322}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:14,891 - INFO - epoch 55: train loss 0.00812123621020604\n",
      "2025-09-10 11:03:14,894 - INFO - 55 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:14,896 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:14,898 - INFO - --------------------\n",
      "\n",
      "56/600: 100%|██████████| 216/216 [00:08<00:00, 25.53it/s]\n",
      "2025-09-10 11:03:23,538 - INFO - All types `lr` of epoch 56: {'lr/param_group0': 0.0002461574624776804, 'lr/param_group1': 0.0002461574624776804, 'lr/param_group2': 0.0002461574624776804, 'lr/param_group3': 0.0002461574624776804}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:23,539 - INFO - epoch 56: train loss 0.008156725289558785\n",
      "2025-09-10 11:03:23,541 - INFO - 56 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:23,542 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:23,544 - INFO - --------------------\n",
      "\n",
      "57/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 11:03:32,393 - INFO - All types `lr` of epoch 57: {'lr/param_group0': 0.0002443485344658522, 'lr/param_group1': 0.0002443485344658522, 'lr/param_group2': 0.0002443485344658522, 'lr/param_group3': 0.0002443485344658522}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:32,395 - INFO - epoch 57: train loss 0.008017815627951038\n",
      "2025-09-10 11:03:32,397 - INFO - 57 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:32,398 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:32,399 - INFO - --------------------\n",
      "\n",
      "58/600: 100%|██████████| 216/216 [00:08<00:00, 24.94it/s]\n",
      "2025-09-10 11:03:41,236 - INFO - All types `lr` of epoch 58: {'lr/param_group0': 0.000242516697467467, 'lr/param_group1': 0.000242516697467467, 'lr/param_group2': 0.000242516697467467, 'lr/param_group3': 0.000242516697467467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:41,238 - INFO - epoch 58: train loss 0.007956736434371796\n",
      "2025-09-10 11:03:41,240 - INFO - 58 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:41,242 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:41,244 - INFO - --------------------\n",
      "\n",
      "59/600: 100%|██████████| 216/216 [00:08<00:00, 24.97it/s]\n",
      "2025-09-10 11:03:50,070 - INFO - All types `lr` of epoch 59: {'lr/param_group0': 0.00024066240346089376, 'lr/param_group1': 0.00024066240346089376, 'lr/param_group2': 0.00024066240346089376, 'lr/param_group3': 0.00024066240346089376}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:03:50,073 - INFO - epoch 59: train loss 0.00801589335013112\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.71it/s]\n",
      "2025-09-10 11:03:52,130 - INFO - epoch 59: val loss 0.008200286809975902\n",
      "2025-09-10 11:03:52,134 - INFO - 59 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:03:52,189 - INFO - 59 epochs completed!\n",
      "\n",
      "2025-09-10 11:03:52,192 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:03:52,195 - INFO - --------------------\n",
      "\n",
      "60/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:04:01,144 - INFO - All types `lr` of epoch 60: {'lr/param_group0': 0.00023878610996543227, 'lr/param_group1': 0.00023878610996543227, 'lr/param_group2': 0.00023878610996543227, 'lr/param_group3': 0.00023878610996543227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:01,146 - INFO - epoch 60: train loss 0.007992014032357407\n",
      "2025-09-10 11:04:01,149 - INFO - 60 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:01,151 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:01,153 - INFO - --------------------\n",
      "\n",
      "61/600: 100%|██████████| 216/216 [00:07<00:00, 30.40it/s]\n",
      "2025-09-10 11:04:08,432 - INFO - All types `lr` of epoch 61: {'lr/param_group0': 0.00023688827992842683, 'lr/param_group1': 0.00023688827992842683, 'lr/param_group2': 0.00023688827992842683, 'lr/param_group3': 0.00023688827992842683}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:08,435 - INFO - epoch 61: train loss 0.008095863602917504\n",
      "2025-09-10 11:04:08,438 - INFO - 61 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:08,440 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:08,441 - INFO - --------------------\n",
      "\n",
      "62/600: 100%|██████████| 216/216 [00:07<00:00, 28.04it/s]\n",
      "2025-09-10 11:04:16,303 - INFO - All types `lr` of epoch 62: {'lr/param_group0': 0.00023496938161104137, 'lr/param_group1': 0.00023496938161104137, 'lr/param_group2': 0.00023496938161104137, 'lr/param_group3': 0.00023496938161104137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:16,305 - INFO - epoch 62: train loss 0.00803655170602724\n",
      "2025-09-10 11:04:16,307 - INFO - 62 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:16,309 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:16,311 - INFO - --------------------\n",
      "\n",
      "63/600: 100%|██████████| 216/216 [00:08<00:00, 25.09it/s]\n",
      "2025-09-10 11:04:25,100 - INFO - All types `lr` of epoch 63: {'lr/param_group0': 0.00023302988847272255, 'lr/param_group1': 0.00023302988847272255, 'lr/param_group2': 0.00023302988847272255, 'lr/param_group3': 0.00023302988847272255}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:25,103 - INFO - epoch 63: train loss 0.007959084746996976\n",
      "2025-09-10 11:04:25,105 - INFO - 63 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:25,107 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:25,109 - INFO - --------------------\n",
      "\n",
      "64/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:04:34,065 - INFO - All types `lr` of epoch 64: {'lr/param_group0': 0.00023107027905438097, 'lr/param_group1': 0.00023107027905438097, 'lr/param_group2': 0.00023107027905438097, 'lr/param_group3': 0.00023107027905438097}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:34,068 - INFO - epoch 64: train loss 0.007863861648797023\n",
      "2025-09-10 11:04:34,070 - INFO - 64 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:34,072 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:34,074 - INFO - --------------------\n",
      "\n",
      "65/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:04:42,962 - INFO - All types `lr` of epoch 65: {'lr/param_group0': 0.0002290910368603184, 'lr/param_group1': 0.0002290910368603184, 'lr/param_group2': 0.0002290910368603184, 'lr/param_group3': 0.0002290910368603184}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:42,964 - INFO - epoch 65: train loss 0.00788857787631935\n",
      "2025-09-10 11:04:42,966 - INFO - 65 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:42,968 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:42,970 - INFO - --------------------\n",
      "\n",
      "66/600: 100%|██████████| 216/216 [00:08<00:00, 25.12it/s]\n",
      "2025-09-10 11:04:51,745 - INFO - All types `lr` of epoch 66: {'lr/param_group0': 0.00022709265023893008, 'lr/param_group1': 0.00022709265023893008, 'lr/param_group2': 0.00022709265023893008, 'lr/param_group3': 0.00022709265023893008}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:04:51,747 - INFO - epoch 66: train loss 0.007927762892062741\n",
      "2025-09-10 11:04:51,750 - INFO - 66 epochs completed!\n",
      "\n",
      "2025-09-10 11:04:51,752 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:04:51,754 - INFO - --------------------\n",
      "\n",
      "67/600: 100%|██████████| 216/216 [00:08<00:00, 26.36it/s]\n",
      "2025-09-10 11:05:00,129 - INFO - All types `lr` of epoch 67: {'lr/param_group0': 0.0002250756122622125, 'lr/param_group1': 0.0002250756122622125, 'lr/param_group2': 0.0002250756122622125, 'lr/param_group3': 0.0002250756122622125}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:00,130 - INFO - epoch 67: train loss 0.007910002624460807\n",
      "2025-09-10 11:05:00,132 - INFO - 67 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:00,133 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:00,135 - INFO - --------------------\n",
      "\n",
      "68/600: 100%|██████████| 216/216 [00:08<00:00, 25.04it/s]\n",
      "2025-09-10 11:05:08,932 - INFO - All types `lr` of epoch 68: {'lr/param_group0': 0.00022304042060410467, 'lr/param_group1': 0.00022304042060410467, 'lr/param_group2': 0.00022304042060410467, 'lr/param_group3': 0.00022304042060410467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:08,934 - INFO - epoch 68: train loss 0.007892116787843406\n",
      "2025-09-10 11:05:08,936 - INFO - 68 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:08,937 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:08,939 - INFO - --------------------\n",
      "\n",
      "69/600: 100%|██████████| 216/216 [00:08<00:00, 24.79it/s]\n",
      "2025-09-10 11:05:17,820 - INFO - All types `lr` of epoch 69: {'lr/param_group0': 0.00022098757741769514, 'lr/param_group1': 0.00022098757741769514, 'lr/param_group2': 0.00022098757741769514, 'lr/param_group3': 0.00022098757741769514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:17,822 - INFO - epoch 69: train loss 0.007909907939999053\n",
      "2025-09-10 11:05:17,824 - INFO - 69 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:17,826 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:17,828 - INFO - --------------------\n",
      "\n",
      "70/600: 100%|██████████| 216/216 [00:08<00:00, 25.03it/s]\n",
      "2025-09-10 11:05:26,635 - INFO - All types `lr` of epoch 70: {'lr/param_group0': 0.0002189175892113227, 'lr/param_group1': 0.0002189175892113227, 'lr/param_group2': 0.0002189175892113227, 'lr/param_group3': 0.0002189175892113227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:26,638 - INFO - epoch 70: train loss 0.00973559600835735\n",
      "2025-09-10 11:05:26,640 - INFO - 70 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:26,642 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:26,645 - INFO - --------------------\n",
      "\n",
      "71/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:05:35,608 - INFO - All types `lr` of epoch 71: {'lr/param_group0': 0.00021683096672360337, 'lr/param_group1': 0.00021683096672360337, 'lr/param_group2': 0.00021683096672360337, 'lr/param_group3': 0.00021683096672360337}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:35,610 - INFO - epoch 71: train loss 0.009910873264608974\n",
      "2025-09-10 11:05:35,613 - INFO - 71 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:35,615 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:35,617 - INFO - --------------------\n",
      "\n",
      "72/600: 100%|██████████| 216/216 [00:08<00:00, 24.84it/s]\n",
      "2025-09-10 11:05:44,492 - INFO - All types `lr` of epoch 72: {'lr/param_group0': 0.00021472822479741326, 'lr/param_group1': 0.00021472822479741326, 'lr/param_group2': 0.00021472822479741326, 'lr/param_group3': 0.00021472822479741326}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:44,495 - INFO - epoch 72: train loss 0.007844249122879572\n",
      "2025-09-10 11:05:44,497 - INFO - 72 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:44,498 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:44,500 - INFO - --------------------\n",
      "\n",
      "73/600: 100%|██████████| 216/216 [00:08<00:00, 24.84it/s]\n",
      "2025-09-10 11:05:53,368 - INFO - All types `lr` of epoch 73: {'lr/param_group0': 0.00021260988225285863, 'lr/param_group1': 0.00021260988225285863, 'lr/param_group2': 0.00021260988225285863, 'lr/param_group3': 0.00021260988225285863}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:05:53,371 - INFO - epoch 73: train loss 0.007632785817366783\n",
      "2025-09-10 11:05:53,374 - INFO - 73 epochs completed!\n",
      "\n",
      "2025-09-10 11:05:53,376 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:05:53,378 - INFO - --------------------\n",
      "\n",
      "74/600: 100%|██████████| 216/216 [00:08<00:00, 24.76it/s]\n",
      "2025-09-10 11:06:02,273 - INFO - All types `lr` of epoch 74: {'lr/param_group0': 0.00021047646175926488, 'lr/param_group1': 0.00021047646175926488, 'lr/param_group2': 0.00021047646175926488, 'lr/param_group3': 0.00021047646175926488}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:02,276 - INFO - epoch 74: train loss 0.007564301121790238\n",
      "2025-09-10 11:06:02,279 - INFO - 74 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:02,282 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:02,284 - INFO - --------------------\n",
      "\n",
      "75/600: 100%|██████████| 216/216 [00:08<00:00, 24.54it/s]\n",
      "2025-09-10 11:06:11,264 - INFO - All types `lr` of epoch 75: {'lr/param_group0': 0.00020832848970621582, 'lr/param_group1': 0.00020832848970621582, 'lr/param_group2': 0.00020832848970621582, 'lr/param_group3': 0.00020832848970621582}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:11,266 - INFO - epoch 75: train loss 0.0075288727077552015\n",
      "2025-09-10 11:06:11,268 - INFO - 75 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:11,270 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:11,272 - INFO - --------------------\n",
      "\n",
      "76/600: 100%|██████████| 216/216 [00:08<00:00, 25.07it/s]\n",
      "2025-09-10 11:06:20,069 - INFO - All types `lr` of epoch 76: {'lr/param_group0': 0.0002061664960736747, 'lr/param_group1': 0.0002061664960736747, 'lr/param_group2': 0.0002061664960736747, 'lr/param_group3': 0.0002061664960736747}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:20,072 - INFO - epoch 76: train loss 0.007480463907726247\n",
      "2025-09-10 11:06:20,075 - INFO - 76 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:20,078 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:20,080 - INFO - --------------------\n",
      "\n",
      "77/600: 100%|██████████| 216/216 [00:08<00:00, 25.06it/s]\n",
      "2025-09-10 11:06:28,881 - INFO - All types `lr` of epoch 77: {'lr/param_group0': 0.00020399101430121968, 'lr/param_group1': 0.00020399101430121968, 'lr/param_group2': 0.00020399101430121968, 'lr/param_group3': 0.00020399101430121968}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:28,883 - INFO - epoch 77: train loss 0.0074762254543774935\n",
      "2025-09-10 11:06:28,886 - INFO - 77 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:28,887 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:28,889 - INFO - --------------------\n",
      "\n",
      "78/600: 100%|██████████| 216/216 [00:08<00:00, 24.98it/s]\n",
      "2025-09-10 11:06:37,713 - INFO - All types `lr` of epoch 78: {'lr/param_group0': 0.00020180258115642578, 'lr/param_group1': 0.00020180258115642578, 'lr/param_group2': 0.00020180258115642578, 'lr/param_group3': 0.00020180258115642578}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:37,716 - INFO - epoch 78: train loss 0.007480528792021451\n",
      "2025-09-10 11:06:37,719 - INFO - 78 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:37,720 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:37,722 - INFO - --------------------\n",
      "\n",
      "79/600: 100%|██████████| 216/216 [00:08<00:00, 25.08it/s]\n",
      "2025-09-10 11:06:46,514 - INFO - All types `lr` of epoch 79: {'lr/param_group0': 0.00019960173660242518, 'lr/param_group1': 0.00019960173660242518, 'lr/param_group2': 0.00019960173660242518, 'lr/param_group3': 0.00019960173660242518}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:46,516 - INFO - epoch 79: train loss 0.007546476071217546\n",
      "2025-09-10 11:06:46,519 - INFO - 79 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:46,521 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:46,523 - INFO - --------------------\n",
      "\n",
      "80/600: 100%|██████████| 216/216 [00:08<00:00, 24.85it/s]\n",
      "2025-09-10 11:06:55,385 - INFO - All types `lr` of epoch 80: {'lr/param_group0': 0.0001973890236646797, 'lr/param_group1': 0.0001973890236646797, 'lr/param_group2': 0.0001973890236646797, 'lr/param_group3': 0.0001973890236646797}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:06:55,387 - INFO - epoch 80: train loss 0.007442888208768434\n",
      "2025-09-10 11:06:55,390 - INFO - 80 epochs completed!\n",
      "\n",
      "2025-09-10 11:06:55,392 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:06:55,394 - INFO - --------------------\n",
      "\n",
      "81/600: 100%|██████████| 216/216 [00:08<00:00, 25.39it/s]\n",
      "2025-09-10 11:07:04,075 - INFO - All types `lr` of epoch 81: {'lr/param_group0': 0.0001951649882969971, 'lr/param_group1': 0.0001951649882969971, 'lr/param_group2': 0.0001951649882969971, 'lr/param_group3': 0.0001951649882969971}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:04,077 - INFO - epoch 81: train loss 0.0074457846155079705\n",
      "2025-09-10 11:07:04,080 - INFO - 81 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:04,082 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:04,084 - INFO - --------------------\n",
      "\n",
      "82/600: 100%|██████████| 216/216 [00:08<00:00, 24.81it/s]\n",
      "2025-09-10 11:07:12,967 - INFO - All types `lr` of epoch 82: {'lr/param_group0': 0.00019293017924682556, 'lr/param_group1': 0.00019293017924682556, 'lr/param_group2': 0.00019293017924682556, 'lr/param_group3': 0.00019293017924682556}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:12,969 - INFO - epoch 82: train loss 0.007475572045357829\n",
      "2025-09-10 11:07:12,972 - INFO - 82 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:12,974 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:12,976 - INFO - --------------------\n",
      "\n",
      "83/600: 100%|██████████| 216/216 [00:08<00:00, 24.97it/s]\n",
      "2025-09-10 11:07:21,800 - INFO - All types `lr` of epoch 83: {'lr/param_group0': 0.0001906851479198579, 'lr/param_group1': 0.0001906851479198579, 'lr/param_group2': 0.0001906851479198579, 'lr/param_group3': 0.0001906851479198579}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:21,803 - INFO - epoch 83: train loss 0.007685602090700909\n",
      "2025-09-10 11:07:21,805 - INFO - 83 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:21,807 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:21,809 - INFO - --------------------\n",
      "\n",
      "84/600: 100%|██████████| 216/216 [00:08<00:00, 24.84it/s]\n",
      "2025-09-10 11:07:30,681 - INFO - All types `lr` of epoch 84: {'lr/param_group0': 0.00018843044824398095, 'lr/param_group1': 0.00018843044824398095, 'lr/param_group2': 0.00018843044824398095, 'lr/param_group3': 0.00018843044824398095}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:30,683 - INFO - epoch 84: train loss 0.009094503973351998\n",
      "2025-09-10 11:07:30,685 - INFO - 84 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:30,686 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:30,688 - INFO - --------------------\n",
      "\n",
      "85/600: 100%|██████████| 216/216 [00:08<00:00, 25.17it/s]\n",
      "2025-09-10 11:07:39,440 - INFO - All types `lr` of epoch 85: {'lr/param_group0': 0.00018616663653260194, 'lr/param_group1': 0.00018616663653260194, 'lr/param_group2': 0.00018616663653260194, 'lr/param_group3': 0.00018616663653260194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:39,443 - INFO - epoch 85: train loss 0.008887278896980677\n",
      "2025-09-10 11:07:39,446 - INFO - 85 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:39,448 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:39,450 - INFO - --------------------\n",
      "\n",
      "86/600: 100%|██████████| 216/216 [00:08<00:00, 24.84it/s]\n",
      "2025-09-10 11:07:48,321 - INFO - All types `lr` of epoch 86: {'lr/param_group0': 0.00018389427134738657, 'lr/param_group1': 0.00018389427134738657, 'lr/param_group2': 0.00018389427134738657, 'lr/param_group3': 0.00018389427134738657}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:48,322 - INFO - epoch 86: train loss 0.007513882118035798\n",
      "2025-09-10 11:07:48,325 - INFO - 86 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:48,326 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:48,328 - INFO - --------------------\n",
      "\n",
      "87/600: 100%|██████████| 216/216 [00:08<00:00, 25.23it/s]\n",
      "2025-09-10 11:07:57,065 - INFO - All types `lr` of epoch 87: {'lr/param_group0': 0.00018161391336044209, 'lr/param_group1': 0.00018161391336044209, 'lr/param_group2': 0.00018161391336044209, 'lr/param_group3': 0.00018161391336044209}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:07:57,067 - INFO - epoch 87: train loss 0.007307121510772656\n",
      "2025-09-10 11:07:57,071 - INFO - 87 epochs completed!\n",
      "\n",
      "2025-09-10 11:07:57,073 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:07:57,075 - INFO - --------------------\n",
      "\n",
      "88/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:08:05,944 - INFO - All types `lr` of epoch 88: {'lr/param_group0': 0.0001793261252159801, 'lr/param_group1': 0.0001793261252159801, 'lr/param_group2': 0.0001793261252159801, 'lr/param_group3': 0.0001793261252159801}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:05,946 - INFO - epoch 88: train loss 0.007244886806734872\n",
      "2025-09-10 11:08:05,949 - INFO - 88 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:05,951 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:05,953 - INFO - --------------------\n",
      "\n",
      "89/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:08:14,915 - INFO - All types `lr` of epoch 89: {'lr/param_group0': 0.00017703147139149232, 'lr/param_group1': 0.00017703147139149232, 'lr/param_group2': 0.00017703147139149232, 'lr/param_group3': 0.00017703147139149232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:14,917 - INFO - epoch 89: train loss 0.007205439270129082\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.90it/s]\n",
      "2025-09-10 11:08:16,960 - INFO - epoch 89: val loss 0.00744686581849776\n",
      "2025-09-10 11:08:16,964 - INFO - 89 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:08:17,022 - INFO - 89 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:17,025 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:17,027 - INFO - --------------------\n",
      "\n",
      "90/600: 100%|██████████| 216/216 [00:08<00:00, 24.77it/s]\n",
      "2025-09-10 11:08:25,920 - INFO - All types `lr` of epoch 90: {'lr/param_group0': 0.00017473051805847427, 'lr/param_group1': 0.00017473051805847427, 'lr/param_group2': 0.00017473051805847427, 'lr/param_group3': 0.00017473051805847427}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:25,924 - INFO - epoch 90: train loss 0.007201393969201793\n",
      "2025-09-10 11:08:25,927 - INFO - 90 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:25,929 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:25,931 - INFO - --------------------\n",
      "\n",
      "91/600: 100%|██████████| 216/216 [00:08<00:00, 24.64it/s]\n",
      "2025-09-10 11:08:34,882 - INFO - All types `lr` of epoch 91: {'lr/param_group0': 0.00017242383294273098, 'lr/param_group1': 0.00017242383294273098, 'lr/param_group2': 0.00017242383294273098, 'lr/param_group3': 0.00017242383294273098}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:34,884 - INFO - epoch 91: train loss 0.007195264620585712\n",
      "2025-09-10 11:08:34,886 - INFO - 91 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:34,888 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:34,890 - INFO - --------------------\n",
      "\n",
      "92/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:08:43,813 - INFO - All types `lr` of epoch 92: {'lr/param_group0': 0.00017011198518429918, 'lr/param_group1': 0.00017011198518429918, 'lr/param_group2': 0.00017011198518429918, 'lr/param_group3': 0.00017011198518429918}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:43,815 - INFO - epoch 92: train loss 0.007212143601565104\n",
      "2025-09-10 11:08:43,818 - INFO - 92 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:43,820 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:43,822 - INFO - --------------------\n",
      "\n",
      "93/600: 100%|██████████| 216/216 [00:08<00:00, 25.11it/s]\n",
      "2025-09-10 11:08:52,607 - INFO - All types `lr` of epoch 93: {'lr/param_group0': 0.0001677955451970202, 'lr/param_group1': 0.0001677955451970202, 'lr/param_group2': 0.0001677955451970202, 'lr/param_group3': 0.0001677955451970202}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:08:52,609 - INFO - epoch 93: train loss 0.007229597723818626\n",
      "2025-09-10 11:08:52,612 - INFO - 93 epochs completed!\n",
      "\n",
      "2025-09-10 11:08:52,615 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:08:52,617 - INFO - --------------------\n",
      "\n",
      "94/600: 100%|██████████| 216/216 [00:08<00:00, 24.81it/s]\n",
      "2025-09-10 11:09:01,503 - INFO - All types `lr` of epoch 94: {'lr/param_group0': 0.00016547508452779942, 'lr/param_group1': 0.00016547508452779942, 'lr/param_group2': 0.00016547508452779942, 'lr/param_group3': 0.00016547508452779942}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:01,505 - INFO - epoch 94: train loss 0.007226545005795304\n",
      "2025-09-10 11:09:01,508 - INFO - 94 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:01,510 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:01,512 - INFO - --------------------\n",
      "\n",
      "95/600: 100%|██████████| 216/216 [00:08<00:00, 24.99it/s]\n",
      "2025-09-10 11:09:10,337 - INFO - All types `lr` of epoch 95: {'lr/param_group0': 0.00016315117571558496, 'lr/param_group1': 0.00016315117571558496, 'lr/param_group2': 0.00016315117571558496, 'lr/param_group3': 0.00016315117571558496}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:10,340 - INFO - epoch 95: train loss 0.007260954544310355\n",
      "2025-09-10 11:09:10,348 - INFO - 95 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:10,353 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:10,355 - INFO - --------------------\n",
      "\n",
      "96/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:09:19,316 - INFO - All types `lr` of epoch 96: {'lr/param_group0': 0.00016082439215010303, 'lr/param_group1': 0.00016082439215010303, 'lr/param_group2': 0.00016082439215010303, 'lr/param_group3': 0.00016082439215010303}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:19,318 - INFO - epoch 96: train loss 0.007241408888216096\n",
      "2025-09-10 11:09:19,321 - INFO - 96 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:19,323 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:19,325 - INFO - --------------------\n",
      "\n",
      "97/600: 100%|██████████| 216/216 [00:08<00:00, 24.77it/s]\n",
      "2025-09-10 11:09:28,225 - INFO - All types `lr` of epoch 97: {'lr/param_group0': 0.00015849530793038194, 'lr/param_group1': 0.00015849530793038194, 'lr/param_group2': 0.00015849530793038194, 'lr/param_group3': 0.00015849530793038194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:28,227 - INFO - epoch 97: train loss 0.007170398523427408\n",
      "2025-09-10 11:09:28,230 - INFO - 97 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:28,231 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:28,232 - INFO - --------------------\n",
      "\n",
      "98/600: 100%|██████████| 216/216 [00:08<00:00, 25.12it/s]\n",
      "2025-09-10 11:09:37,007 - INFO - All types `lr` of epoch 98: {'lr/param_group0': 0.00015616449772310208, 'lr/param_group1': 0.00015616449772310208, 'lr/param_group2': 0.00015616449772310208, 'lr/param_group3': 0.00015616449772310208}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:37,009 - INFO - epoch 98: train loss 0.00713389656825543\n",
      "2025-09-10 11:09:37,012 - INFO - 98 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:37,014 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:37,016 - INFO - --------------------\n",
      "\n",
      "99/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:09:45,924 - INFO - All types `lr` of epoch 99: {'lr/param_group0': 0.00015383253662080537, 'lr/param_group1': 0.00015383253662080537, 'lr/param_group2': 0.00015383253662080537, 'lr/param_group3': 0.00015383253662080537}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:45,926 - INFO - epoch 99: train loss 0.007117967610678601\n",
      "2025-09-10 11:09:45,929 - INFO - 99 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:45,930 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:45,932 - INFO - --------------------\n",
      "\n",
      "100/600: 100%|██████████| 216/216 [00:08<00:00, 24.64it/s]\n",
      "2025-09-10 11:09:54,882 - INFO - All types `lr` of epoch 100: {'lr/param_group0': 0.00015150000000000002, 'lr/param_group1': 0.00015150000000000002, 'lr/param_group2': 0.00015150000000000002, 'lr/param_group3': 0.00015150000000000002}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:09:54,884 - INFO - epoch 100: train loss 0.0071160459084677755\n",
      "2025-09-10 11:09:54,887 - INFO - 100 epochs completed!\n",
      "\n",
      "2025-09-10 11:09:54,889 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:09:54,891 - INFO - --------------------\n",
      "\n",
      "101/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:10:03,891 - INFO - All types `lr` of epoch 101: {'lr/param_group0': 0.00014916746337919465, 'lr/param_group1': 0.00014916746337919465, 'lr/param_group2': 0.00014916746337919465, 'lr/param_group3': 0.00014916746337919465}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:03,895 - INFO - epoch 101: train loss 0.007155748271745526\n",
      "2025-09-10 11:10:03,898 - INFO - 101 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:03,901 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:03,903 - INFO - --------------------\n",
      "\n",
      "102/600: 100%|██████████| 216/216 [00:08<00:00, 25.62it/s]\n",
      "2025-09-10 11:10:12,513 - INFO - All types `lr` of epoch 102: {'lr/param_group0': 0.00014683550227689794, 'lr/param_group1': 0.00014683550227689794, 'lr/param_group2': 0.00014683550227689794, 'lr/param_group3': 0.00014683550227689794}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:12,516 - INFO - epoch 102: train loss 0.007162694237194955\n",
      "2025-09-10 11:10:12,519 - INFO - 102 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:12,521 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:12,523 - INFO - --------------------\n",
      "\n",
      "103/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:10:21,495 - INFO - All types `lr` of epoch 103: {'lr/param_group0': 0.00014450469206961806, 'lr/param_group1': 0.00014450469206961806, 'lr/param_group2': 0.00014450469206961806, 'lr/param_group3': 0.00014450469206961806}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:21,498 - INFO - epoch 103: train loss 0.007146683053751649\n",
      "2025-09-10 11:10:21,501 - INFO - 103 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:21,503 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:21,505 - INFO - --------------------\n",
      "\n",
      "104/600: 100%|██████████| 216/216 [00:08<00:00, 24.54it/s]\n",
      "2025-09-10 11:10:30,480 - INFO - All types `lr` of epoch 104: {'lr/param_group0': 0.00014217560784989694, 'lr/param_group1': 0.00014217560784989694, 'lr/param_group2': 0.00014217560784989694, 'lr/param_group3': 0.00014217560784989694}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:30,482 - INFO - epoch 104: train loss 0.0071396529609854854\n",
      "2025-09-10 11:10:30,484 - INFO - 104 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:30,486 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:30,488 - INFO - --------------------\n",
      "\n",
      "105/600: 100%|██████████| 216/216 [00:08<00:00, 24.90it/s]\n",
      "2025-09-10 11:10:39,341 - INFO - All types `lr` of epoch 105: {'lr/param_group0': 0.000139848824284415, 'lr/param_group1': 0.000139848824284415, 'lr/param_group2': 0.000139848824284415, 'lr/param_group3': 0.000139848824284415}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:39,344 - INFO - epoch 105: train loss 0.007132549433865481\n",
      "2025-09-10 11:10:39,347 - INFO - 105 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:39,349 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:39,351 - INFO - --------------------\n",
      "\n",
      "106/600: 100%|██████████| 216/216 [00:07<00:00, 27.58it/s]\n",
      "2025-09-10 11:10:47,365 - INFO - All types `lr` of epoch 106: {'lr/param_group0': 0.0001375249154722006, 'lr/param_group1': 0.0001375249154722006, 'lr/param_group2': 0.0001375249154722006, 'lr/param_group3': 0.0001375249154722006}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:47,367 - INFO - epoch 106: train loss 0.007188515405653528\n",
      "2025-09-10 11:10:47,370 - INFO - 106 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:47,372 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:47,374 - INFO - --------------------\n",
      "\n",
      "107/600: 100%|██████████| 216/216 [00:07<00:00, 27.37it/s]\n",
      "2025-09-10 11:10:55,447 - INFO - All types `lr` of epoch 107: {'lr/param_group0': 0.0001352044548029798, 'lr/param_group1': 0.0001352044548029798, 'lr/param_group2': 0.0001352044548029798, 'lr/param_group3': 0.0001352044548029798}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:10:55,450 - INFO - epoch 107: train loss 0.008331998708416466\n",
      "2025-09-10 11:10:55,453 - INFO - 107 epochs completed!\n",
      "\n",
      "2025-09-10 11:10:55,455 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:10:55,457 - INFO - --------------------\n",
      "\n",
      "108/600: 100%|██████████| 216/216 [00:08<00:00, 25.16it/s]\n",
      "2025-09-10 11:11:04,220 - INFO - All types `lr` of epoch 108: {'lr/param_group0': 0.00013288801481570078, 'lr/param_group1': 0.00013288801481570078, 'lr/param_group2': 0.00013288801481570078, 'lr/param_group3': 0.00013288801481570078}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:04,223 - INFO - epoch 108: train loss 0.008932958279425899\n",
      "2025-09-10 11:11:04,226 - INFO - 108 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:04,228 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:04,230 - INFO - --------------------\n",
      "\n",
      "109/600: 100%|██████████| 216/216 [00:08<00:00, 24.92it/s]\n",
      "2025-09-10 11:11:13,078 - INFO - All types `lr` of epoch 109: {'lr/param_group0': 0.00013057616705726896, 'lr/param_group1': 0.00013057616705726896, 'lr/param_group2': 0.00013057616705726896, 'lr/param_group3': 0.00013057616705726896}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:13,082 - INFO - epoch 109: train loss 0.007290891301602608\n",
      "2025-09-10 11:11:13,085 - INFO - 109 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:13,087 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:13,090 - INFO - --------------------\n",
      "\n",
      "110/600: 100%|██████████| 216/216 [00:08<00:00, 24.40it/s]\n",
      "2025-09-10 11:11:22,125 - INFO - All types `lr` of epoch 110: {'lr/param_group0': 0.0001282694819415257, 'lr/param_group1': 0.0001282694819415257, 'lr/param_group2': 0.0001282694819415257, 'lr/param_group3': 0.0001282694819415257}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:22,127 - INFO - epoch 110: train loss 0.007101767569245702\n",
      "2025-09-10 11:11:22,130 - INFO - 110 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:22,132 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:22,134 - INFO - --------------------\n",
      "\n",
      "111/600: 100%|██████████| 216/216 [00:08<00:00, 24.95it/s]\n",
      "2025-09-10 11:11:30,968 - INFO - All types `lr` of epoch 111: {'lr/param_group0': 0.00012596852860850764, 'lr/param_group1': 0.00012596852860850764, 'lr/param_group2': 0.00012596852860850764, 'lr/param_group3': 0.00012596852860850764}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:30,971 - INFO - epoch 111: train loss 0.007063870585558039\n",
      "2025-09-10 11:11:30,975 - INFO - 111 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:30,977 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:30,979 - INFO - --------------------\n",
      "\n",
      "112/600: 100%|██████████| 216/216 [00:08<00:00, 24.96it/s]\n",
      "2025-09-10 11:11:39,814 - INFO - All types `lr` of epoch 112: {'lr/param_group0': 0.00012367387478401986, 'lr/param_group1': 0.00012367387478401986, 'lr/param_group2': 0.00012367387478401986, 'lr/param_group3': 0.00012367387478401986}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:39,818 - INFO - epoch 112: train loss 0.007062437387907671\n",
      "2025-09-10 11:11:39,826 - INFO - 112 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:39,834 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:39,836 - INFO - --------------------\n",
      "\n",
      "113/600: 100%|██████████| 216/216 [00:08<00:00, 24.93it/s]\n",
      "2025-09-10 11:11:48,676 - INFO - All types `lr` of epoch 113: {'lr/param_group0': 0.00012138608663955795, 'lr/param_group1': 0.00012138608663955795, 'lr/param_group2': 0.00012138608663955795, 'lr/param_group3': 0.00012138608663955795}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:48,679 - INFO - epoch 113: train loss 0.007052710355276725\n",
      "2025-09-10 11:11:48,682 - INFO - 113 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:48,684 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:48,686 - INFO - --------------------\n",
      "\n",
      "114/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:11:57,633 - INFO - All types `lr` of epoch 114: {'lr/param_group0': 0.00011910572865261347, 'lr/param_group1': 0.00011910572865261347, 'lr/param_group2': 0.00011910572865261347, 'lr/param_group3': 0.00011910572865261347}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:11:57,637 - INFO - epoch 114: train loss 0.0070627154351246575\n",
      "2025-09-10 11:11:57,640 - INFO - 114 epochs completed!\n",
      "\n",
      "2025-09-10 11:11:57,642 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:11:57,644 - INFO - --------------------\n",
      "\n",
      "115/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:12:06,557 - INFO - All types `lr` of epoch 115: {'lr/param_group0': 0.00011683336346739808, 'lr/param_group1': 0.00011683336346739808, 'lr/param_group2': 0.00011683336346739808, 'lr/param_group3': 0.00011683336346739808}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:06,560 - INFO - epoch 115: train loss 0.007052577193395269\n",
      "2025-09-10 11:12:06,563 - INFO - 115 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:06,565 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:06,567 - INFO - --------------------\n",
      "\n",
      "116/600: 100%|██████████| 216/216 [00:08<00:00, 24.96it/s]\n",
      "2025-09-10 11:12:15,402 - INFO - All types `lr` of epoch 116: {'lr/param_group0': 0.0001145695517560191, 'lr/param_group1': 0.0001145695517560191, 'lr/param_group2': 0.0001145695517560191, 'lr/param_group3': 0.0001145695517560191}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:15,404 - INFO - epoch 116: train loss 0.00707618985325098\n",
      "2025-09-10 11:12:15,407 - INFO - 116 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:15,409 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:15,412 - INFO - --------------------\n",
      "\n",
      "117/600: 100%|██████████| 216/216 [00:08<00:00, 25.31it/s]\n",
      "2025-09-10 11:12:24,137 - INFO - All types `lr` of epoch 117: {'lr/param_group0': 0.00011231485208014218, 'lr/param_group1': 0.00011231485208014218, 'lr/param_group2': 0.00011231485208014218, 'lr/param_group3': 0.00011231485208014218}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:24,145 - INFO - epoch 117: train loss 0.0070917382405174\n",
      "2025-09-10 11:12:24,153 - INFO - 117 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:24,155 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:24,157 - INFO - --------------------\n",
      "\n",
      "118/600: 100%|██████████| 216/216 [00:08<00:00, 25.47it/s]\n",
      "2025-09-10 11:12:32,817 - INFO - All types `lr` of epoch 118: {'lr/param_group0': 0.00011006982075317448, 'lr/param_group1': 0.00011006982075317448, 'lr/param_group2': 0.00011006982075317448, 'lr/param_group3': 0.00011006982075317448}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:32,819 - INFO - epoch 118: train loss 0.0070597180876777405\n",
      "2025-09-10 11:12:32,823 - INFO - 118 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:32,825 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:32,827 - INFO - --------------------\n",
      "\n",
      "119/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:12:41,709 - INFO - All types `lr` of epoch 119: {'lr/param_group0': 0.00010783501170300287, 'lr/param_group1': 0.00010783501170300287, 'lr/param_group2': 0.00010783501170300287, 'lr/param_group3': 0.00010783501170300287}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:41,712 - INFO - epoch 119: train loss 0.007082836939608333\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.84it/s]\n",
      "2025-09-10 11:12:43,764 - INFO - epoch 119: val loss 0.007304117506094001\n",
      "2025-09-10 11:12:43,769 - INFO - 119 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:12:43,821 - INFO - 119 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:43,823 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:43,826 - INFO - --------------------\n",
      "\n",
      "120/600: 100%|██████████| 216/216 [00:08<00:00, 24.94it/s]\n",
      "2025-09-10 11:12:52,670 - INFO - All types `lr` of epoch 120: {'lr/param_group0': 0.0001056109763353203, 'lr/param_group1': 0.0001056109763353203, 'lr/param_group2': 0.0001056109763353203, 'lr/param_group3': 0.0001056109763353203}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:52,678 - INFO - epoch 120: train loss 0.007058452131416372\n",
      "2025-09-10 11:12:52,681 - INFO - 120 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:52,683 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:52,685 - INFO - --------------------\n",
      "\n",
      "121/600: 100%|██████████| 216/216 [00:06<00:00, 32.05it/s]\n",
      "2025-09-10 11:12:59,605 - INFO - All types `lr` of epoch 121: {'lr/param_group0': 0.00010339826339757483, 'lr/param_group1': 0.00010339826339757483, 'lr/param_group2': 0.00010339826339757483, 'lr/param_group3': 0.00010339826339757483}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:12:59,613 - INFO - epoch 121: train loss 0.007045988929113028\n",
      "2025-09-10 11:12:59,620 - INFO - 121 epochs completed!\n",
      "\n",
      "2025-09-10 11:12:59,623 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:12:59,628 - INFO - --------------------\n",
      "\n",
      "122/600: 100%|██████████| 216/216 [00:08<00:00, 25.73it/s]\n",
      "2025-09-10 11:13:08,200 - INFO - All types `lr` of epoch 122: {'lr/param_group0': 0.00010119741884357424, 'lr/param_group1': 0.00010119741884357424, 'lr/param_group2': 0.00010119741884357424, 'lr/param_group3': 0.00010119741884357424}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:08,208 - INFO - epoch 122: train loss 0.007019119169045653\n",
      "2025-09-10 11:13:08,216 - INFO - 122 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:08,219 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:08,225 - INFO - --------------------\n",
      "\n",
      "123/600: 100%|██████████| 216/216 [00:08<00:00, 25.25it/s]\n",
      "2025-09-10 11:13:16,970 - INFO - All types `lr` of epoch 123: {'lr/param_group0': 9.900898569878033e-05, 'lr/param_group1': 9.900898569878033e-05, 'lr/param_group2': 9.900898569878033e-05, 'lr/param_group3': 9.900898569878033e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:16,973 - INFO - epoch 123: train loss 0.007019918427061013\n",
      "2025-09-10 11:13:16,981 - INFO - 123 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:16,988 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:16,991 - INFO - --------------------\n",
      "\n",
      "124/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 11:13:26,043 - INFO - All types `lr` of epoch 124: {'lr/param_group0': 9.683350392632531e-05, 'lr/param_group1': 9.683350392632531e-05, 'lr/param_group2': 9.683350392632531e-05, 'lr/param_group3': 9.683350392632531e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:26,053 - INFO - epoch 124: train loss 0.007033202195695291\n",
      "2025-09-10 11:13:26,056 - INFO - 124 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:26,062 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:26,068 - INFO - --------------------\n",
      "\n",
      "125/600: 100%|██████████| 216/216 [00:08<00:00, 24.27it/s]\n",
      "2025-09-10 11:13:35,139 - INFO - All types `lr` of epoch 125: {'lr/param_group0': 9.467151029378419e-05, 'lr/param_group1': 9.467151029378419e-05, 'lr/param_group2': 9.467151029378419e-05, 'lr/param_group3': 9.467151029378419e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:35,147 - INFO - epoch 125: train loss 0.007044777041301131\n",
      "2025-09-10 11:13:35,150 - INFO - 125 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:35,156 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:35,163 - INFO - --------------------\n",
      "\n",
      "126/600: 100%|██████████| 216/216 [00:08<00:00, 24.78it/s]\n",
      "2025-09-10 11:13:44,064 - INFO - All types `lr` of epoch 126: {'lr/param_group0': 9.25235382407351e-05, 'lr/param_group1': 9.25235382407351e-05, 'lr/param_group2': 9.25235382407351e-05, 'lr/param_group3': 9.25235382407351e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:44,074 - INFO - epoch 126: train loss 0.007045805978123099\n",
      "2025-09-10 11:13:44,078 - INFO - 126 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:44,086 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:44,094 - INFO - --------------------\n",
      "\n",
      "127/600: 100%|██████████| 216/216 [00:08<00:00, 24.51it/s]\n",
      "2025-09-10 11:13:53,089 - INFO - All types `lr` of epoch 127: {'lr/param_group0': 9.039011774714136e-05, 'lr/param_group1': 9.039011774714136e-05, 'lr/param_group2': 9.039011774714136e-05, 'lr/param_group3': 9.039011774714136e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:13:53,099 - INFO - epoch 127: train loss 0.007033115804747299\n",
      "2025-09-10 11:13:53,107 - INFO - 127 epochs completed!\n",
      "\n",
      "2025-09-10 11:13:53,110 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:13:53,117 - INFO - --------------------\n",
      "\n",
      "128/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:14:02,038 - INFO - All types `lr` of epoch 128: {'lr/param_group0': 8.827177520258669e-05, 'lr/param_group1': 8.827177520258669e-05, 'lr/param_group2': 8.827177520258669e-05, 'lr/param_group3': 8.827177520258669e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:02,045 - INFO - epoch 128: train loss 0.007016321111694668\n",
      "2025-09-10 11:14:02,048 - INFO - 128 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:02,054 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:02,061 - INFO - --------------------\n",
      "\n",
      "129/600: 100%|██████████| 216/216 [00:09<00:00, 23.52it/s]\n",
      "2025-09-10 11:14:11,428 - INFO - All types `lr` of epoch 129: {'lr/param_group0': 8.616903327639659e-05, 'lr/param_group1': 8.616903327639659e-05, 'lr/param_group2': 8.616903327639659e-05, 'lr/param_group3': 8.616903327639659e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:11,438 - INFO - epoch 129: train loss 0.007013103536640604\n",
      "2025-09-10 11:14:11,446 - INFO - 129 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:11,449 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:11,456 - INFO - --------------------\n",
      "\n",
      "130/600: 100%|██████████| 216/216 [00:08<00:00, 24.18it/s]\n",
      "2025-09-10 11:14:20,584 - INFO - All types `lr` of epoch 130: {'lr/param_group0': 8.408241078867731e-05, 'lr/param_group1': 8.408241078867731e-05, 'lr/param_group2': 8.408241078867731e-05, 'lr/param_group3': 8.408241078867731e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:20,587 - INFO - epoch 130: train loss 0.007015769311692566\n",
      "2025-09-10 11:14:20,595 - INFO - 130 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:20,602 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:20,604 - INFO - --------------------\n",
      "\n",
      "131/600: 100%|██████████| 216/216 [00:08<00:00, 24.21it/s]\n",
      "2025-09-10 11:14:29,708 - INFO - All types `lr` of epoch 131: {'lr/param_group0': 8.201242258230488e-05, 'lr/param_group1': 8.201242258230488e-05, 'lr/param_group2': 8.201242258230488e-05, 'lr/param_group3': 8.201242258230488e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:29,710 - INFO - epoch 131: train loss 0.0070052609791875714\n",
      "2025-09-10 11:14:29,721 - INFO - 131 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:29,729 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:29,736 - INFO - --------------------\n",
      "\n",
      "132/600: 100%|██████████| 216/216 [00:08<00:00, 24.30it/s]\n",
      "2025-09-10 11:14:38,811 - INFO - All types `lr` of epoch 132: {'lr/param_group0': 7.995957939589527e-05, 'lr/param_group1': 7.995957939589527e-05, 'lr/param_group2': 7.995957939589527e-05, 'lr/param_group3': 7.995957939589527e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:38,822 - INFO - epoch 132: train loss 0.006997621760496663\n",
      "2025-09-10 11:14:38,825 - INFO - 132 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:38,833 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:38,840 - INFO - --------------------\n",
      "\n",
      "133/600: 100%|██████████| 216/216 [00:08<00:00, 24.21it/s]\n",
      "2025-09-10 11:14:47,940 - INFO - All types `lr` of epoch 133: {'lr/param_group0': 7.792438773778747e-05, 'lr/param_group1': 7.792438773778747e-05, 'lr/param_group2': 7.792438773778747e-05, 'lr/param_group3': 7.792438773778747e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:47,942 - INFO - epoch 133: train loss 0.0069906808353995\n",
      "2025-09-10 11:14:47,948 - INFO - 133 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:47,950 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:47,956 - INFO - --------------------\n",
      "\n",
      "134/600: 100%|██████████| 216/216 [00:08<00:00, 24.20it/s]\n",
      "2025-09-10 11:14:57,074 - INFO - All types `lr` of epoch 134: {'lr/param_group0': 7.590734976106984e-05, 'lr/param_group1': 7.590734976106984e-05, 'lr/param_group2': 7.590734976106984e-05, 'lr/param_group3': 7.590734976106984e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:14:57,078 - INFO - epoch 134: train loss 0.00699882263843729\n",
      "2025-09-10 11:14:57,086 - INFO - 134 epochs completed!\n",
      "\n",
      "2025-09-10 11:14:57,094 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:14:57,100 - INFO - --------------------\n",
      "\n",
      "135/600: 100%|██████████| 216/216 [00:08<00:00, 24.09it/s]\n",
      "2025-09-10 11:15:06,245 - INFO - All types `lr` of epoch 135: {'lr/param_group0': 7.390896313968161e-05, 'lr/param_group1': 7.390896313968161e-05, 'lr/param_group2': 7.390896313968161e-05, 'lr/param_group3': 7.390896313968161e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:06,254 - INFO - epoch 135: train loss 0.006987404237777271\n",
      "2025-09-10 11:15:06,263 - INFO - 135 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:06,267 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:06,273 - INFO - --------------------\n",
      "\n",
      "136/600: 100%|██████████| 216/216 [00:08<00:00, 24.20it/s]\n",
      "2025-09-10 11:15:15,383 - INFO - All types `lr` of epoch 136: {'lr/param_group0': 7.192972094561893e-05, 'lr/param_group1': 7.192972094561893e-05, 'lr/param_group2': 7.192972094561893e-05, 'lr/param_group3': 7.192972094561893e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:15,392 - INFO - epoch 136: train loss 0.006994372158294061\n",
      "2025-09-10 11:15:15,396 - INFO - 136 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:15,404 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:15,411 - INFO - --------------------\n",
      "\n",
      "137/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:15:24,388 - INFO - All types `lr` of epoch 137: {'lr/param_group0': 6.997011152727743e-05, 'lr/param_group1': 6.997011152727743e-05, 'lr/param_group2': 6.997011152727743e-05, 'lr/param_group3': 6.997011152727743e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:24,391 - INFO - epoch 137: train loss 0.007023916310303051\n",
      "2025-09-10 11:15:24,399 - INFO - 137 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:24,406 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:24,409 - INFO - --------------------\n",
      "\n",
      "138/600: 100%|██████████| 216/216 [00:08<00:00, 24.08it/s]\n",
      "2025-09-10 11:15:33,554 - INFO - All types `lr` of epoch 138: {'lr/param_group0': 6.803061838895864e-05, 'lr/param_group1': 6.803061838895864e-05, 'lr/param_group2': 6.803061838895864e-05, 'lr/param_group3': 6.803061838895864e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:33,564 - INFO - epoch 138: train loss 0.007021107454353047\n",
      "2025-09-10 11:15:33,569 - INFO - 138 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:33,579 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:33,586 - INFO - --------------------\n",
      "\n",
      "139/600: 100%|██████████| 216/216 [00:08<00:00, 24.28it/s]\n",
      "2025-09-10 11:15:42,674 - INFO - All types `lr` of epoch 139: {'lr/param_group0': 6.611172007157319e-05, 'lr/param_group1': 6.611172007157319e-05, 'lr/param_group2': 6.611172007157319e-05, 'lr/param_group3': 6.611172007157319e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:42,677 - INFO - epoch 139: train loss 0.007035696967418685\n",
      "2025-09-10 11:15:42,685 - INFO - 139 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:42,688 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:42,695 - INFO - --------------------\n",
      "\n",
      "140/600: 100%|██████████| 216/216 [00:09<00:00, 23.75it/s]\n",
      "2025-09-10 11:15:51,980 - INFO - All types `lr` of epoch 140: {'lr/param_group0': 6.421389003456778e-05, 'lr/param_group1': 6.421389003456778e-05, 'lr/param_group2': 6.421389003456778e-05, 'lr/param_group3': 6.421389003456778e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:15:51,986 - INFO - epoch 140: train loss 0.007049106671561107\n",
      "2025-09-10 11:15:51,994 - INFO - 140 epochs completed!\n",
      "\n",
      "2025-09-10 11:15:52,002 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:15:52,005 - INFO - --------------------\n",
      "\n",
      "141/600: 100%|██████████| 216/216 [00:09<00:00, 23.50it/s]\n",
      "2025-09-10 11:16:01,381 - INFO - All types `lr` of epoch 141: {'lr/param_group0': 6.233759653910625e-05, 'lr/param_group1': 6.233759653910625e-05, 'lr/param_group2': 6.233759653910625e-05, 'lr/param_group3': 6.233759653910625e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:01,392 - INFO - epoch 141: train loss 0.007112360471014485\n",
      "2025-09-10 11:16:01,400 - INFO - 141 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:01,404 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:01,410 - INFO - --------------------\n",
      "\n",
      "142/600: 100%|██████████| 216/216 [00:09<00:00, 23.82it/s]\n",
      "2025-09-10 11:16:10,671 - INFO - All types `lr` of epoch 142: {'lr/param_group0': 6.048330253253304e-05, 'lr/param_group1': 6.048330253253304e-05, 'lr/param_group2': 6.048330253253304e-05, 'lr/param_group3': 6.048330253253304e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:10,675 - INFO - epoch 142: train loss 0.007283934706787544\n",
      "2025-09-10 11:16:10,684 - INFO - 142 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:10,688 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:10,694 - INFO - --------------------\n",
      "\n",
      "143/600: 100%|██████████| 216/216 [00:09<00:00, 23.63it/s]\n",
      "2025-09-10 11:16:20,022 - INFO - All types `lr` of epoch 143: {'lr/param_group0': 5.86514655341478e-05, 'lr/param_group1': 5.86514655341478e-05, 'lr/param_group2': 5.86514655341478e-05, 'lr/param_group3': 5.86514655341478e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:20,032 - INFO - epoch 143: train loss 0.008848548985379576\n",
      "2025-09-10 11:16:20,035 - INFO - 143 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:20,043 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:20,049 - INFO - --------------------\n",
      "\n",
      "144/600: 100%|██████████| 216/216 [00:09<00:00, 23.97it/s]\n",
      "2025-09-10 11:16:29,248 - INFO - All types `lr` of epoch 144: {'lr/param_group0': 5.6842537522319565e-05, 'lr/param_group1': 5.6842537522319565e-05, 'lr/param_group2': 5.6842537522319565e-05, 'lr/param_group3': 5.6842537522319565e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:29,252 - INFO - epoch 144: train loss 0.00788829239361264\n",
      "2025-09-10 11:16:29,262 - INFO - 144 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:29,265 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:29,272 - INFO - --------------------\n",
      "\n",
      "145/600: 100%|██████████| 216/216 [00:08<00:00, 24.26it/s]\n",
      "2025-09-10 11:16:38,376 - INFO - All types `lr` of epoch 145: {'lr/param_group0': 5.505696482296775e-05, 'lr/param_group1': 5.505696482296775e-05, 'lr/param_group2': 5.505696482296775e-05, 'lr/param_group3': 5.505696482296775e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:38,385 - INFO - epoch 145: train loss 0.007094177395898711\n",
      "2025-09-10 11:16:38,389 - INFO - 145 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:38,397 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:38,404 - INFO - --------------------\n",
      "\n",
      "146/600: 100%|██████████| 216/216 [00:07<00:00, 29.57it/s]\n",
      "2025-09-10 11:16:45,893 - INFO - All types `lr` of epoch 146: {'lr/param_group0': 5.3295187999437704e-05, 'lr/param_group1': 5.3295187999437704e-05, 'lr/param_group2': 5.3295187999437704e-05, 'lr/param_group3': 5.3295187999437704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:45,903 - INFO - epoch 146: train loss 0.006989505956880748\n",
      "2025-09-10 11:16:45,906 - INFO - 146 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:45,913 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:45,920 - INFO - --------------------\n",
      "\n",
      "147/600: 100%|██████████| 216/216 [00:07<00:00, 27.78it/s]\n",
      "2025-09-10 11:16:53,866 - INFO - All types `lr` of epoch 147: {'lr/param_group0': 5.1557641743798694e-05, 'lr/param_group1': 5.1557641743798694e-05, 'lr/param_group2': 5.1557641743798694e-05, 'lr/param_group3': 5.1557641743798694e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:16:53,875 - INFO - epoch 147: train loss 0.0069677418537644874\n",
      "2025-09-10 11:16:53,878 - INFO - 147 epochs completed!\n",
      "\n",
      "2025-09-10 11:16:53,885 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:16:53,891 - INFO - --------------------\n",
      "\n",
      "148/600: 100%|██████████| 216/216 [00:07<00:00, 27.51it/s]\n",
      "2025-09-10 11:17:01,913 - INFO - All types `lr` of epoch 148: {'lr/param_group0': 4.984475476958972e-05, 'lr/param_group1': 4.984475476958972e-05, 'lr/param_group2': 4.984475476958972e-05, 'lr/param_group3': 4.984475476958972e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:01,923 - INFO - epoch 148: train loss 0.006951879841465227\n",
      "2025-09-10 11:17:01,927 - INFO - 148 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:01,934 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:01,941 - INFO - --------------------\n",
      "\n",
      "149/600: 100%|██████████| 216/216 [00:07<00:00, 27.63it/s]\n",
      "2025-09-10 11:17:09,942 - INFO - All types `lr` of epoch 149: {'lr/param_group0': 4.815694970604134e-05, 'lr/param_group1': 4.815694970604134e-05, 'lr/param_group2': 4.815694970604134e-05, 'lr/param_group3': 4.815694970604134e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:09,952 - INFO - epoch 149: train loss 0.006947549918011107\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.39it/s]\n",
      "2025-09-10 11:17:11,858 - INFO - epoch 149: val loss 0.007203669166537347\n",
      "2025-09-10 11:17:11,867 - INFO - 149 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:17:11,913 - INFO - 149 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:11,916 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:11,922 - INFO - --------------------\n",
      "\n",
      "150/600: 100%|██████████| 216/216 [00:08<00:00, 26.79it/s]\n",
      "2025-09-10 11:17:20,171 - INFO - All types `lr` of epoch 150: {'lr/param_group0': 4.6494642993797704e-05, 'lr/param_group1': 4.6494642993797704e-05, 'lr/param_group2': 4.6494642993797704e-05, 'lr/param_group3': 4.6494642993797704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:20,178 - INFO - epoch 150: train loss 0.00694551001328768\n",
      "2025-09-10 11:17:20,182 - INFO - 150 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:20,189 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:20,196 - INFO - --------------------\n",
      "\n",
      "151/600: 100%|██████████| 216/216 [00:08<00:00, 24.56it/s]\n",
      "2025-09-10 11:17:29,157 - INFO - All types `lr` of epoch 151: {'lr/param_group0': 4.485824478216651e-05, 'lr/param_group1': 4.485824478216651e-05, 'lr/param_group2': 4.485824478216651e-05, 'lr/param_group3': 4.485824478216651e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:29,163 - INFO - epoch 151: train loss 0.006942413473519048\n",
      "2025-09-10 11:17:29,167 - INFO - 151 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:29,173 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:29,179 - INFO - --------------------\n",
      "\n",
      "152/600: 100%|██████████| 216/216 [00:08<00:00, 24.99it/s]\n",
      "2025-09-10 11:17:38,012 - INFO - All types `lr` of epoch 152: {'lr/param_group0': 4.324815882792043e-05, 'lr/param_group1': 4.324815882792043e-05, 'lr/param_group2': 4.324815882792043e-05, 'lr/param_group3': 4.324815882792043e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:38,021 - INFO - epoch 152: train loss 0.006938073486607108\n",
      "2025-09-10 11:17:38,030 - INFO - 152 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:38,033 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:38,040 - INFO - --------------------\n",
      "\n",
      "153/600: 100%|██████████| 216/216 [00:09<00:00, 23.88it/s]\n",
      "2025-09-10 11:17:47,272 - INFO - All types `lr` of epoch 153: {'lr/param_group0': 4.1664782395676444e-05, 'lr/param_group1': 4.1664782395676444e-05, 'lr/param_group2': 4.1664782395676444e-05, 'lr/param_group3': 4.1664782395676444e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:47,282 - INFO - epoch 153: train loss 0.006942950887605548\n",
      "2025-09-10 11:17:47,286 - INFO - 153 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:47,294 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:47,302 - INFO - --------------------\n",
      "\n",
      "154/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:17:56,283 - INFO - All types `lr` of epoch 154: {'lr/param_group0': 4.0108506159876744e-05, 'lr/param_group1': 4.0108506159876744e-05, 'lr/param_group2': 4.0108506159876744e-05, 'lr/param_group3': 4.0108506159876744e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:17:56,293 - INFO - epoch 154: train loss 0.006945014196120341\n",
      "2025-09-10 11:17:56,297 - INFO - 154 epochs completed!\n",
      "\n",
      "2025-09-10 11:17:56,304 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:17:56,312 - INFO - --------------------\n",
      "\n",
      "155/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:18:05,181 - INFO - All types `lr` of epoch 155: {'lr/param_group0': 3.8579714108395387e-05, 'lr/param_group1': 3.8579714108395387e-05, 'lr/param_group2': 3.8579714108395387e-05, 'lr/param_group3': 3.8579714108395387e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:05,190 - INFO - epoch 155: train loss 0.006946210745135667\n",
      "2025-09-10 11:18:05,193 - INFO - 155 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:05,201 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:05,208 - INFO - --------------------\n",
      "\n",
      "156/600: 100%|██████████| 216/216 [00:08<00:00, 24.81it/s]\n",
      "2025-09-10 11:18:14,099 - INFO - All types `lr` of epoch 156: {'lr/param_group0': 3.707878344779533e-05, 'lr/param_group1': 3.707878344779533e-05, 'lr/param_group2': 3.707878344779533e-05, 'lr/param_group3': 3.707878344779533e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:14,103 - INFO - epoch 156: train loss 0.00694634711706183\n",
      "2025-09-10 11:18:14,114 - INFO - 156 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:14,122 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:14,125 - INFO - --------------------\n",
      "\n",
      "157/600: 100%|██████████| 216/216 [00:08<00:00, 25.66it/s]\n",
      "2025-09-10 11:18:22,739 - INFO - All types `lr` of epoch 157: {'lr/param_group0': 3.5606084510258035e-05, 'lr/param_group1': 3.5606084510258035e-05, 'lr/param_group2': 3.5606084510258035e-05, 'lr/param_group3': 3.5606084510258035e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:22,750 - INFO - epoch 157: train loss 0.006946917015334798\n",
      "2025-09-10 11:18:22,759 - INFO - 157 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:22,762 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:22,769 - INFO - --------------------\n",
      "\n",
      "158/600: 100%|██████████| 216/216 [00:09<00:00, 23.44it/s]\n",
      "2025-09-10 11:18:32,181 - INFO - All types `lr` of epoch 158: {'lr/param_group0': 3.416198066220997e-05, 'lr/param_group1': 3.416198066220997e-05, 'lr/param_group2': 3.416198066220997e-05, 'lr/param_group3': 3.416198066220997e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:32,183 - INFO - epoch 158: train loss 0.006948690859307708\n",
      "2025-09-10 11:18:32,187 - INFO - 158 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:32,197 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:32,207 - INFO - --------------------\n",
      "\n",
      "159/600: 100%|██████████| 216/216 [00:09<00:00, 23.84it/s]\n",
      "2025-09-10 11:18:41,463 - INFO - All types `lr` of epoch 159: {'lr/param_group0': 3.274682821466704e-05, 'lr/param_group1': 3.274682821466704e-05, 'lr/param_group2': 3.274682821466704e-05, 'lr/param_group3': 3.274682821466704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:41,470 - INFO - epoch 159: train loss 0.006953753380070406\n",
      "2025-09-10 11:18:41,479 - INFO - 159 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:41,487 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:41,490 - INFO - --------------------\n",
      "\n",
      "160/600: 100%|██████████| 216/216 [00:09<00:00, 23.78it/s]\n",
      "2025-09-10 11:18:50,758 - INFO - All types `lr` of epoch 160: {'lr/param_group0': 3.13609763353203e-05, 'lr/param_group1': 3.13609763353203e-05, 'lr/param_group2': 3.13609763353203e-05, 'lr/param_group3': 3.13609763353203e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:50,769 - INFO - epoch 160: train loss 0.006943731090157396\n",
      "2025-09-10 11:18:50,773 - INFO - 160 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:50,781 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:50,789 - INFO - --------------------\n",
      "\n",
      "161/600: 100%|██████████| 216/216 [00:07<00:00, 27.39it/s]\n",
      "2025-09-10 11:18:58,863 - INFO - All types `lr` of epoch 161: {'lr/param_group0': 3.0004766962383986e-05, 'lr/param_group1': 3.0004766962383986e-05, 'lr/param_group2': 3.0004766962383986e-05, 'lr/param_group3': 3.0004766962383986e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:18:58,873 - INFO - epoch 161: train loss 0.006953511391421435\n",
      "2025-09-10 11:18:58,877 - INFO - 161 epochs completed!\n",
      "\n",
      "2025-09-10 11:18:58,884 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:18:58,891 - INFO - --------------------\n",
      "\n",
      "162/600: 100%|██████████| 216/216 [00:08<00:00, 25.01it/s]\n",
      "2025-09-10 11:19:07,724 - INFO - All types `lr` of epoch 162: {'lr/param_group0': 2.8678534720227554e-05, 'lr/param_group1': 2.8678534720227554e-05, 'lr/param_group2': 2.8678534720227554e-05, 'lr/param_group3': 2.8678534720227554e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:07,728 - INFO - epoch 162: train loss 0.00695163375240992\n",
      "2025-09-10 11:19:07,737 - INFO - 162 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:07,745 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:07,749 - INFO - --------------------\n",
      "\n",
      "163/600: 100%|██████████| 216/216 [00:09<00:00, 23.96it/s]\n",
      "2025-09-10 11:19:16,956 - INFO - All types `lr` of epoch 163: {'lr/param_group0': 2.7382606836811927e-05, 'lr/param_group1': 2.7382606836811927e-05, 'lr/param_group2': 2.7382606836811927e-05, 'lr/param_group3': 2.7382606836811927e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:16,968 - INFO - epoch 163: train loss 0.006960057532759728\n",
      "2025-09-10 11:19:16,977 - INFO - 163 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:16,985 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:16,991 - INFO - --------------------\n",
      "\n",
      "164/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:19:25,925 - INFO - All types `lr` of epoch 164: {'lr/param_group0': 2.61173030629508e-05, 'lr/param_group1': 2.61173030629508e-05, 'lr/param_group2': 2.61173030629508e-05, 'lr/param_group3': 2.61173030629508e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:25,936 - INFO - epoch 164: train loss 0.006952326421418952\n",
      "2025-09-10 11:19:25,939 - INFO - 164 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:25,941 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:25,950 - INFO - --------------------\n",
      "\n",
      "165/600: 100%|██████████| 216/216 [00:08<00:00, 25.21it/s]\n",
      "2025-09-10 11:19:34,712 - INFO - All types `lr` of epoch 165: {'lr/param_group0': 2.4882935593417308e-05, 'lr/param_group1': 2.4882935593417308e-05, 'lr/param_group2': 2.4882935593417308e-05, 'lr/param_group3': 2.4882935593417308e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:34,716 - INFO - epoch 165: train loss 0.006981511423536749\n",
      "2025-09-10 11:19:34,725 - INFO - 165 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:34,733 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:34,736 - INFO - --------------------\n",
      "\n",
      "166/600: 100%|██████████| 216/216 [00:09<00:00, 23.71it/s]\n",
      "2025-09-10 11:19:44,036 - INFO - All types `lr` of epoch 166: {'lr/param_group0': 2.3679808989914373e-05, 'lr/param_group1': 2.3679808989914373e-05, 'lr/param_group2': 2.3679808989914373e-05, 'lr/param_group3': 2.3679808989914373e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:44,047 - INFO - epoch 166: train loss 0.007019309406772394\n",
      "2025-09-10 11:19:44,056 - INFO - 166 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:44,063 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:44,069 - INFO - --------------------\n",
      "\n",
      "167/600: 100%|██████████| 216/216 [00:08<00:00, 24.06it/s]\n",
      "2025-09-10 11:19:53,241 - INFO - All types `lr` of epoch 167: {'lr/param_group0': 2.250822010592862e-05, 'lr/param_group1': 2.250822010592862e-05, 'lr/param_group2': 2.250822010592862e-05, 'lr/param_group3': 2.250822010592862e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:19:53,251 - INFO - epoch 167: train loss 0.007085810066200793\n",
      "2025-09-10 11:19:53,259 - INFO - 167 epochs completed!\n",
      "\n",
      "2025-09-10 11:19:53,262 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:19:53,269 - INFO - --------------------\n",
      "\n",
      "168/600: 100%|██████████| 216/216 [00:08<00:00, 25.76it/s]\n",
      "2025-09-10 11:20:01,845 - INFO - All types `lr` of epoch 168: {'lr/param_group0': 2.1368458013486268e-05, 'lr/param_group1': 2.1368458013486268e-05, 'lr/param_group2': 2.1368458013486268e-05, 'lr/param_group3': 2.1368458013486268e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:01,848 - INFO - epoch 168: train loss 0.007236185449141043\n",
      "2025-09-10 11:20:01,851 - INFO - 168 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:01,860 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:01,864 - INFO - --------------------\n",
      "\n",
      "169/600: 100%|██████████| 216/216 [00:08<00:00, 26.53it/s]\n",
      "2025-09-10 11:20:10,190 - INFO - All types `lr` of epoch 169: {'lr/param_group0': 2.0260803931829005e-05, 'lr/param_group1': 2.0260803931829005e-05, 'lr/param_group2': 2.0260803931829005e-05, 'lr/param_group3': 2.0260803931829005e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:10,200 - INFO - epoch 169: train loss 0.007393284702966748\n",
      "2025-09-10 11:20:10,203 - INFO - 169 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:10,211 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:10,218 - INFO - --------------------\n",
      "\n",
      "170/600: 100%|██████████| 216/216 [00:08<00:00, 26.39it/s]\n",
      "2025-09-10 11:20:18,585 - INFO - All types `lr` of epoch 170: {'lr/param_group0': 1.918553115802738e-05, 'lr/param_group1': 1.918553115802738e-05, 'lr/param_group2': 1.918553115802738e-05, 'lr/param_group3': 1.918553115802738e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:18,596 - INFO - epoch 170: train loss 0.007435741603667675\n",
      "2025-09-10 11:20:18,600 - INFO - 170 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:18,608 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:18,616 - INFO - --------------------\n",
      "\n",
      "171/600: 100%|██████████| 216/216 [00:07<00:00, 27.04it/s]\n",
      "2025-09-10 11:20:26,794 - INFO - All types `lr` of epoch 171: {'lr/param_group0': 1.814290499954858e-05, 'lr/param_group1': 1.814290499954858e-05, 'lr/param_group2': 1.814290499954858e-05, 'lr/param_group3': 1.814290499954858e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:26,798 - INFO - epoch 171: train loss 0.007330268082484879\n",
      "2025-09-10 11:20:26,808 - INFO - 171 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:26,811 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:26,818 - INFO - --------------------\n",
      "\n",
      "172/600: 100%|██████████| 216/216 [00:08<00:00, 25.92it/s]\n",
      "2025-09-10 11:20:35,342 - INFO - All types `lr` of epoch 172: {'lr/param_group0': 1.713318270879612e-05, 'lr/param_group1': 1.713318270879612e-05, 'lr/param_group2': 1.713318270879612e-05, 'lr/param_group3': 1.713318270879612e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:35,353 - INFO - epoch 172: train loss 0.007167217595485487\n",
      "2025-09-10 11:20:35,356 - INFO - 172 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:35,358 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:35,367 - INFO - --------------------\n",
      "\n",
      "173/600: 100%|██████████| 216/216 [00:08<00:00, 26.98it/s]\n",
      "2025-09-10 11:20:43,550 - INFO - All types `lr` of epoch 173: {'lr/param_group0': 1.6156613419636378e-05, 'lr/param_group1': 1.6156613419636378e-05, 'lr/param_group2': 1.6156613419636378e-05, 'lr/param_group3': 1.6156613419636378e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:43,558 - INFO - epoch 173: train loss 0.00705742052566536\n",
      "2025-09-10 11:20:43,561 - INFO - 173 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:43,569 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:43,577 - INFO - --------------------\n",
      "\n",
      "174/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:20:52,501 - INFO - All types `lr` of epoch 174: {'lr/param_group0': 1.5213438085928809e-05, 'lr/param_group1': 1.5213438085928809e-05, 'lr/param_group2': 1.5213438085928809e-05, 'lr/param_group3': 1.5213438085928809e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:20:52,511 - INFO - epoch 174: train loss 0.0069951083644776155\n",
      "2025-09-10 11:20:52,515 - INFO - 174 epochs completed!\n",
      "\n",
      "2025-09-10 11:20:52,523 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:20:52,530 - INFO - --------------------\n",
      "\n",
      "175/600: 100%|██████████| 216/216 [00:08<00:00, 24.93it/s]\n",
      "2025-09-10 11:21:01,387 - INFO - All types `lr` of epoch 175: {'lr/param_group0': 1.4303889422073933e-05, 'lr/param_group1': 1.4303889422073933e-05, 'lr/param_group2': 1.4303889422073933e-05, 'lr/param_group3': 1.4303889422073933e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:01,390 - INFO - epoch 175: train loss 0.00696617495527284\n",
      "2025-09-10 11:21:01,398 - INFO - 175 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:01,406 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:01,408 - INFO - --------------------\n",
      "\n",
      "176/600: 100%|██████████| 216/216 [00:09<00:00, 23.61it/s]\n",
      "2025-09-10 11:21:10,744 - INFO - All types `lr` of epoch 176: {'lr/param_group0': 1.3428191845594682e-05, 'lr/param_group1': 1.3428191845594682e-05, 'lr/param_group2': 1.3428191845594682e-05, 'lr/param_group3': 1.3428191845594682e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:10,747 - INFO - epoch 176: train loss 0.006950043730386015\n",
      "2025-09-10 11:21:10,750 - INFO - 176 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:10,760 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:10,770 - INFO - --------------------\n",
      "\n",
      "177/600: 100%|██████████| 216/216 [00:09<00:00, 23.59it/s]\n",
      "2025-09-10 11:21:20,121 - INFO - All types `lr` of epoch 177: {'lr/param_group0': 1.2586561421764697e-05, 'lr/param_group1': 1.2586561421764697e-05, 'lr/param_group2': 1.2586561421764697e-05, 'lr/param_group3': 1.2586561421764697e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:20,131 - INFO - epoch 177: train loss 0.0069409105646492985\n",
      "2025-09-10 11:21:20,139 - INFO - 177 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:20,143 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:20,149 - INFO - --------------------\n",
      "\n",
      "178/600: 100%|██████████| 216/216 [00:09<00:00, 23.47it/s]\n",
      "2025-09-10 11:21:29,544 - INFO - All types `lr` of epoch 178: {'lr/param_group0': 1.1779205810297499e-05, 'lr/param_group1': 1.1779205810297499e-05, 'lr/param_group2': 1.1779205810297499e-05, 'lr/param_group3': 1.1779205810297499e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:29,554 - INFO - epoch 178: train loss 0.006935244245040748\n",
      "2025-09-10 11:21:29,562 - INFO - 178 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:29,565 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:29,573 - INFO - --------------------\n",
      "\n",
      "179/600: 100%|██████████| 216/216 [00:09<00:00, 23.54it/s]\n",
      "2025-09-10 11:21:38,928 - INFO - All types `lr` of epoch 179: {'lr/param_group0': 1.1006324214109518e-05, 'lr/param_group1': 1.1006324214109518e-05, 'lr/param_group2': 1.1006324214109518e-05, 'lr/param_group3': 1.1006324214109518e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:38,936 - INFO - epoch 179: train loss 0.006934516052111845\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.48it/s]\n",
      "2025-09-10 11:21:41,025 - INFO - epoch 179: val loss 0.0071891870487619325\n",
      "2025-09-10 11:21:41,031 - INFO - 179 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:21:41,081 - INFO - 179 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:41,083 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:41,086 - INFO - --------------------\n",
      "\n",
      "180/600: 100%|██████████| 216/216 [00:08<00:00, 26.55it/s]\n",
      "2025-09-10 11:21:49,415 - INFO - All types `lr` of epoch 180: {'lr/param_group0': 1.0268107330169672e-05, 'lr/param_group1': 1.0268107330169672e-05, 'lr/param_group2': 1.0268107330169672e-05, 'lr/param_group3': 1.0268107330169672e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:49,424 - INFO - epoch 180: train loss 0.006936281783661495\n",
      "2025-09-10 11:21:49,428 - INFO - 180 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:49,437 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:49,445 - INFO - --------------------\n",
      "\n",
      "181/600: 100%|██████████| 216/216 [00:08<00:00, 25.13it/s]\n",
      "2025-09-10 11:21:58,235 - INFO - All types `lr` of epoch 181: {'lr/param_group0': 9.564737302448001e-06, 'lr/param_group1': 9.564737302448001e-06, 'lr/param_group2': 9.564737302448001e-06, 'lr/param_group3': 9.564737302448001e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:21:58,240 - INFO - epoch 181: train loss 0.006936619150952471\n",
      "2025-09-10 11:21:58,250 - INFO - 181 epochs completed!\n",
      "\n",
      "2025-09-10 11:21:58,258 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:21:58,261 - INFO - --------------------\n",
      "\n",
      "182/600: 100%|██████████| 216/216 [00:09<00:00, 23.82it/s]\n",
      "2025-09-10 11:22:07,523 - INFO - All types `lr` of epoch 182: {'lr/param_group0': 8.896387676973949e-06, 'lr/param_group1': 8.896387676973949e-06, 'lr/param_group2': 8.896387676973949e-06, 'lr/param_group3': 8.896387676973949e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:07,534 - INFO - epoch 182: train loss 0.006934887893428957\n",
      "2025-09-10 11:22:07,538 - INFO - 182 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:07,547 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:07,550 - INFO - --------------------\n",
      "\n",
      "183/600: 100%|██████████| 216/216 [00:09<00:00, 23.64it/s]\n",
      "2025-09-10 11:22:16,880 - INFO - All types `lr` of epoch 183: {'lr/param_group0': 8.26322335901699e-06, 'lr/param_group1': 8.26322335901699e-06, 'lr/param_group2': 8.26322335901699e-06, 'lr/param_group3': 8.26322335901699e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:16,893 - INFO - epoch 183: train loss 0.006932559408057757\n",
      "2025-09-10 11:22:16,902 - INFO - 183 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:16,905 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:16,913 - INFO - --------------------\n",
      "\n",
      "184/600: 100%|██████████| 216/216 [00:09<00:00, 23.52it/s]\n",
      "2025-09-10 11:22:26,294 - INFO - All types `lr` of epoch 184: {'lr/param_group0': 7.665400572398272e-06, 'lr/param_group1': 7.665400572398272e-06, 'lr/param_group2': 7.665400572398272e-06, 'lr/param_group3': 7.665400572398272e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:26,303 - INFO - epoch 184: train loss 0.006934051509705131\n",
      "2025-09-10 11:22:26,312 - INFO - 184 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:26,316 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:26,323 - INFO - --------------------\n",
      "\n",
      "185/600: 100%|██████████| 216/216 [00:09<00:00, 23.55it/s]\n",
      "2025-09-10 11:22:35,689 - INFO - All types `lr` of epoch 185: {'lr/param_group0': 7.103066820945047e-06, 'lr/param_group1': 7.103066820945047e-06, 'lr/param_group2': 7.103066820945047e-06, 'lr/param_group3': 7.103066820945047e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:35,700 - INFO - epoch 185: train loss 0.006936568111457207\n",
      "2025-09-10 11:22:35,704 - INFO - 185 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:35,714 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:35,722 - INFO - --------------------\n",
      "\n",
      "186/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:22:44,683 - INFO - All types `lr` of epoch 186: {'lr/param_group0': 6.576360852096019e-06, 'lr/param_group1': 6.576360852096019e-06, 'lr/param_group2': 6.576360852096019e-06, 'lr/param_group3': 6.576360852096019e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:44,695 - INFO - epoch 186: train loss 0.006931574793135816\n",
      "2025-09-10 11:22:44,705 - INFO - 186 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:44,708 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:44,716 - INFO - --------------------\n",
      "\n",
      "187/600: 100%|██████████| 216/216 [00:09<00:00, 23.65it/s]\n",
      "2025-09-10 11:22:54,042 - INFO - All types `lr` of epoch 187: {'lr/param_group0': 6.085412622667795e-06, 'lr/param_group1': 6.085412622667795e-06, 'lr/param_group2': 6.085412622667795e-06, 'lr/param_group3': 6.085412622667795e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:22:54,045 - INFO - epoch 187: train loss 0.006934424439721086\n",
      "2025-09-10 11:22:54,048 - INFO - 187 epochs completed!\n",
      "\n",
      "2025-09-10 11:22:54,060 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:22:54,068 - INFO - --------------------\n",
      "\n",
      "188/600: 100%|██████████| 216/216 [00:08<00:00, 24.14it/s]\n",
      "2025-09-10 11:23:03,206 - INFO - All types `lr` of epoch 188: {'lr/param_group0': 5.630343266789739e-06, 'lr/param_group1': 5.630343266789739e-06, 'lr/param_group2': 5.630343266789739e-06, 'lr/param_group3': 5.630343266789739e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:03,216 - INFO - epoch 188: train loss 0.006932391992045773\n",
      "2025-09-10 11:23:03,225 - INFO - 188 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:03,228 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:03,235 - INFO - --------------------\n",
      "\n",
      "189/600: 100%|██████████| 216/216 [00:08<00:00, 24.14it/s]\n",
      "2025-09-10 11:23:12,378 - INFO - All types `lr` of epoch 189: {'lr/param_group0': 5.211265066016068e-06, 'lr/param_group1': 5.211265066016068e-06, 'lr/param_group2': 5.211265066016068e-06, 'lr/param_group3': 5.211265066016068e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:12,389 - INFO - epoch 189: train loss 0.006931523384992033\n",
      "2025-09-10 11:23:12,392 - INFO - 189 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:12,395 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:12,405 - INFO - --------------------\n",
      "\n",
      "190/600: 100%|██████████| 216/216 [00:08<00:00, 24.12it/s]\n",
      "2025-09-10 11:23:21,558 - INFO - All types `lr` of epoch 190: {'lr/param_group0': 4.8282814216220265e-06, 'lr/param_group1': 4.8282814216220265e-06, 'lr/param_group2': 4.8282814216220265e-06, 'lr/param_group3': 4.8282814216220265e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:21,562 - INFO - epoch 190: train loss 0.00693184803283118\n",
      "2025-09-10 11:23:21,571 - INFO - 190 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:21,574 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:21,582 - INFO - --------------------\n",
      "\n",
      "191/600: 100%|██████████| 216/216 [00:08<00:00, 24.29it/s]\n",
      "2025-09-10 11:23:30,668 - INFO - All types `lr` of epoch 191: {'lr/param_group0': 4.4814868290912184e-06, 'lr/param_group1': 4.4814868290912184e-06, 'lr/param_group2': 4.4814868290912184e-06, 'lr/param_group3': 4.4814868290912184e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:30,681 - INFO - epoch 191: train loss 0.006931338472188347\n",
      "2025-09-10 11:23:30,685 - INFO - 191 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:30,687 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:30,697 - INFO - --------------------\n",
      "\n",
      "192/600: 100%|██████████| 216/216 [00:08<00:00, 24.33it/s]\n",
      "2025-09-10 11:23:39,763 - INFO - All types `lr` of epoch 192: {'lr/param_group0': 4.170966854800062e-06, 'lr/param_group1': 4.170966854800062e-06, 'lr/param_group2': 4.170966854800062e-06, 'lr/param_group3': 4.170966854800062e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:39,773 - INFO - epoch 192: train loss 0.006933144621413063\n",
      "2025-09-10 11:23:39,783 - INFO - 192 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:39,786 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:39,794 - INFO - --------------------\n",
      "\n",
      "193/600: 100%|██████████| 216/216 [00:09<00:00, 23.34it/s]\n",
      "2025-09-10 11:23:49,235 - INFO - All types `lr` of epoch 193: {'lr/param_group0': 3.896798114905841e-06, 'lr/param_group1': 3.896798114905841e-06, 'lr/param_group2': 3.896798114905841e-06, 'lr/param_group3': 3.896798114905841e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:49,247 - INFO - epoch 193: train loss 0.006932927547798802\n",
      "2025-09-10 11:23:49,252 - INFO - 193 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:49,261 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:49,271 - INFO - --------------------\n",
      "\n",
      "194/600: 100%|██████████| 216/216 [00:09<00:00, 23.21it/s]\n",
      "2025-09-10 11:23:58,770 - INFO - All types `lr` of epoch 194: {'lr/param_group0': 3.6590482564426316e-06, 'lr/param_group1': 3.6590482564426316e-06, 'lr/param_group2': 3.6590482564426316e-06, 'lr/param_group3': 3.6590482564426316e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:23:58,781 - INFO - epoch 194: train loss 0.006932568318141556\n",
      "2025-09-10 11:23:58,786 - INFO - 194 epochs completed!\n",
      "\n",
      "2025-09-10 11:23:58,794 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:23:58,802 - INFO - --------------------\n",
      "\n",
      "195/600: 100%|██████████| 216/216 [00:08<00:00, 24.58it/s]\n",
      "2025-09-10 11:24:07,779 - INFO - All types `lr` of epoch 195: {'lr/param_group0': 3.4577759406304806e-06, 'lr/param_group1': 3.4577759406304806e-06, 'lr/param_group2': 3.4577759406304806e-06, 'lr/param_group3': 3.4577759406304806e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:07,792 - INFO - epoch 195: train loss 0.006933164405550256\n",
      "2025-09-10 11:24:07,802 - INFO - 195 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:07,810 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:07,818 - INFO - --------------------\n",
      "\n",
      "196/600: 100%|██████████| 216/216 [00:09<00:00, 23.27it/s]\n",
      "2025-09-10 11:24:17,298 - INFO - All types `lr` of epoch 196: {'lr/param_group0': 3.293030828401688e-06, 'lr/param_group1': 3.293030828401688e-06, 'lr/param_group2': 3.293030828401688e-06, 'lr/param_group3': 3.293030828401688e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:17,309 - INFO - epoch 196: train loss 0.006934020215541952\n",
      "2025-09-10 11:24:17,312 - INFO - 196 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:17,315 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:17,324 - INFO - --------------------\n",
      "\n",
      "197/600: 100%|██████████| 216/216 [00:08<00:00, 24.03it/s]\n",
      "2025-09-10 11:24:26,496 - INFO - All types `lr` of epoch 197: {'lr/param_group0': 3.164853568147474e-06, 'lr/param_group1': 3.164853568147474e-06, 'lr/param_group2': 3.164853568147474e-06, 'lr/param_group3': 3.164853568147474e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:26,504 - INFO - epoch 197: train loss 0.006934487368670051\n",
      "2025-09-10 11:24:26,513 - INFO - 197 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:26,517 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:26,525 - INFO - --------------------\n",
      "\n",
      "198/600: 100%|██████████| 216/216 [00:09<00:00, 23.47it/s]\n",
      "2025-09-10 11:24:35,931 - INFO - All types `lr` of epoch 198: {'lr/param_group0': 3.073275785688867e-06, 'lr/param_group1': 3.073275785688867e-06, 'lr/param_group2': 3.073275785688867e-06, 'lr/param_group3': 3.073275785688867e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:35,944 - INFO - epoch 198: train loss 0.006933495732179533\n",
      "2025-09-10 11:24:35,954 - INFO - 198 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:35,962 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:35,970 - INFO - --------------------\n",
      "\n",
      "199/600: 100%|██████████| 216/216 [00:08<00:00, 24.44it/s]\n",
      "2025-09-10 11:24:45,006 - INFO - All types `lr` of epoch 199: {'lr/param_group0': 3.0183200764734126e-06, 'lr/param_group1': 3.0183200764734126e-06, 'lr/param_group2': 3.0183200764734126e-06, 'lr/param_group3': 3.0183200764734126e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:45,011 - INFO - epoch 199: train loss 0.006934917853127613\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.89it/s]\n",
      "2025-09-10 11:24:47,011 - INFO - epoch 199: val loss 0.007181311759200913\n",
      "2025-09-10 11:24:47,024 - INFO - 199 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:24:47,121 - INFO - epoch 199 has been saved\n",
      "2025-09-10 11:24:47,199 - INFO - 199 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:47,203 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:47,214 - INFO - --------------------\n",
      "\n",
      "200/600: 100%|██████████| 216/216 [00:08<00:00, 24.40it/s]\n",
      "2025-09-10 11:24:56,257 - INFO - All types `lr` of epoch 200: {'lr/param_group0': 0.0003, 'lr/param_group1': 0.0003, 'lr/param_group2': 0.0003, 'lr/param_group3': 0.0003}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:24:56,260 - INFO - epoch 200: train loss 0.0418327801162377\n",
      "2025-09-10 11:24:56,263 - INFO - 200 epochs completed!\n",
      "\n",
      "2025-09-10 11:24:56,266 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:24:56,269 - INFO - --------------------\n",
      "\n",
      "201/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:25:05,185 - INFO - All types `lr` of epoch 201: {'lr/param_group0': 0.00029998167992352655, 'lr/param_group1': 0.00029998167992352655, 'lr/param_group2': 0.00029998167992352655, 'lr/param_group3': 0.00029998167992352655}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:05,188 - INFO - epoch 201: train loss 0.014227189201240739\n",
      "2025-09-10 11:25:05,192 - INFO - 201 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:05,195 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:05,198 - INFO - --------------------\n",
      "\n",
      "202/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 11:25:14,070 - INFO - All types `lr` of epoch 202: {'lr/param_group0': 0.00029992672421431113, 'lr/param_group1': 0.00029992672421431113, 'lr/param_group2': 0.00029992672421431113, 'lr/param_group3': 0.00029992672421431113}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:14,074 - INFO - epoch 202: train loss 0.011345472589945766\n",
      "2025-09-10 11:25:14,077 - INFO - 202 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:14,080 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:14,083 - INFO - --------------------\n",
      "\n",
      "203/600: 100%|██████████| 216/216 [00:08<00:00, 24.67it/s]\n",
      "2025-09-10 11:25:23,030 - INFO - All types `lr` of epoch 203: {'lr/param_group0': 0.0002998351464318525, 'lr/param_group1': 0.0002998351464318525, 'lr/param_group2': 0.0002998351464318525, 'lr/param_group3': 0.0002998351464318525}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:23,034 - INFO - epoch 203: train loss 0.00905607965843821\n",
      "2025-09-10 11:25:23,037 - INFO - 203 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:23,040 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:23,043 - INFO - --------------------\n",
      "\n",
      "204/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 11:25:31,928 - INFO - All types `lr` of epoch 204: {'lr/param_group0': 0.0002997069691715983, 'lr/param_group1': 0.0002997069691715983, 'lr/param_group2': 0.0002997069691715983, 'lr/param_group3': 0.0002997069691715983}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:31,931 - INFO - epoch 204: train loss 0.008463888383832656\n",
      "2025-09-10 11:25:31,934 - INFO - 204 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:31,936 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:31,938 - INFO - --------------------\n",
      "\n",
      "205/600: 100%|██████████| 216/216 [00:08<00:00, 24.93it/s]\n",
      "2025-09-10 11:25:40,786 - INFO - All types `lr` of epoch 205: {'lr/param_group0': 0.00029954222405936945, 'lr/param_group1': 0.00029954222405936945, 'lr/param_group2': 0.00029954222405936945, 'lr/param_group3': 0.00029954222405936945}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:40,790 - INFO - epoch 205: train loss 0.008128824096207542\n",
      "2025-09-10 11:25:40,794 - INFO - 205 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:40,797 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:40,800 - INFO - --------------------\n",
      "\n",
      "206/600: 100%|██████████| 216/216 [00:08<00:00, 24.66it/s]\n",
      "2025-09-10 11:25:49,750 - INFO - All types `lr` of epoch 206: {'lr/param_group0': 0.00029934095174355733, 'lr/param_group1': 0.00029934095174355733, 'lr/param_group2': 0.00029934095174355733, 'lr/param_group3': 0.00029934095174355733}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:49,753 - INFO - epoch 206: train loss 0.00789277632807002\n",
      "2025-09-10 11:25:49,758 - INFO - 206 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:49,761 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:49,764 - INFO - --------------------\n",
      "\n",
      "207/600: 100%|██████████| 216/216 [00:08<00:00, 24.78it/s]\n",
      "2025-09-10 11:25:58,668 - INFO - All types `lr` of epoch 207: {'lr/param_group0': 0.00029910320188509414, 'lr/param_group1': 0.00029910320188509414, 'lr/param_group2': 0.00029910320188509414, 'lr/param_group3': 0.00029910320188509414}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:25:58,672 - INFO - epoch 207: train loss 0.0077061711905386165\n",
      "2025-09-10 11:25:58,676 - INFO - 207 epochs completed!\n",
      "\n",
      "2025-09-10 11:25:58,680 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:25:58,684 - INFO - --------------------\n",
      "\n",
      "208/600: 100%|██████████| 216/216 [00:08<00:00, 24.87it/s]\n",
      "2025-09-10 11:26:07,565 - INFO - All types `lr` of epoch 208: {'lr/param_group0': 0.00029882903314519993, 'lr/param_group1': 0.00029882903314519993, 'lr/param_group2': 0.00029882903314519993, 'lr/param_group3': 0.00029882903314519993}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:07,567 - INFO - epoch 208: train loss 0.007583260475830348\n",
      "2025-09-10 11:26:07,570 - INFO - 208 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:07,572 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:07,575 - INFO - --------------------\n",
      "\n",
      "209/600: 100%|██████████| 216/216 [00:08<00:00, 24.64it/s]\n",
      "2025-09-10 11:26:16,524 - INFO - All types `lr` of epoch 209: {'lr/param_group0': 0.00029851851317090877, 'lr/param_group1': 0.00029851851317090877, 'lr/param_group2': 0.00029851851317090877, 'lr/param_group3': 0.00029851851317090877}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:16,528 - INFO - epoch 209: train loss 0.007497030700539687\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.47it/s]\n",
      "2025-09-10 11:26:18,548 - INFO - epoch 209: val loss 0.007669266227080866\n",
      "2025-09-10 11:26:18,553 - INFO - 209 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:26:18,605 - INFO - 209 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:18,608 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:18,611 - INFO - --------------------\n",
      "\n",
      "210/600: 100%|██████████| 216/216 [00:08<00:00, 24.58it/s]\n",
      "2025-09-10 11:26:27,584 - INFO - All types `lr` of epoch 210: {'lr/param_group0': 0.0002981717185783779, 'lr/param_group1': 0.0002981717185783779, 'lr/param_group2': 0.0002981717185783779, 'lr/param_group3': 0.0002981717185783779}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:27,588 - INFO - epoch 210: train loss 0.007398291706555971\n",
      "2025-09-10 11:26:27,592 - INFO - 210 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:27,595 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:27,598 - INFO - --------------------\n",
      "\n",
      "211/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:26:36,520 - INFO - All types `lr` of epoch 211: {'lr/param_group0': 0.0002977887349339839, 'lr/param_group1': 0.0002977887349339839, 'lr/param_group2': 0.0002977887349339839, 'lr/param_group3': 0.0002977887349339839}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:36,523 - INFO - epoch 211: train loss 0.007345944345514808\n",
      "2025-09-10 11:26:36,527 - INFO - 211 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:36,530 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:36,533 - INFO - --------------------\n",
      "\n",
      "212/600: 100%|██████████| 216/216 [00:06<00:00, 31.26it/s]\n",
      "2025-09-10 11:26:43,637 - INFO - All types `lr` of epoch 212: {'lr/param_group0': 0.00029736965673321026, 'lr/param_group1': 0.00029736965673321026, 'lr/param_group2': 0.00029736965673321026, 'lr/param_group3': 0.00029736965673321026}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:43,640 - INFO - epoch 212: train loss 0.007298152285834981\n",
      "2025-09-10 11:26:43,643 - INFO - 212 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:43,646 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:43,649 - INFO - --------------------\n",
      "\n",
      "213/600: 100%|██████████| 216/216 [00:07<00:00, 28.11it/s]\n",
      "2025-09-10 11:26:51,512 - INFO - All types `lr` of epoch 213: {'lr/param_group0': 0.00029691458737733217, 'lr/param_group1': 0.00029691458737733217, 'lr/param_group2': 0.00029691458737733217, 'lr/param_group3': 0.00029691458737733217}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:51,516 - INFO - epoch 213: train loss 0.007229986518655938\n",
      "2025-09-10 11:26:51,519 - INFO - 213 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:51,522 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:51,525 - INFO - --------------------\n",
      "\n",
      "214/600: 100%|██████████| 216/216 [00:07<00:00, 27.57it/s]\n",
      "2025-09-10 11:26:59,540 - INFO - All types `lr` of epoch 214: {'lr/param_group0': 0.00029642363914790396, 'lr/param_group1': 0.00029642363914790396, 'lr/param_group2': 0.00029642363914790396, 'lr/param_group3': 0.00029642363914790396}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:26:59,543 - INFO - epoch 214: train loss 0.007193502172379306\n",
      "2025-09-10 11:26:59,547 - INFO - 214 epochs completed!\n",
      "\n",
      "2025-09-10 11:26:59,550 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:26:59,553 - INFO - --------------------\n",
      "\n",
      "215/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 11:27:07,667 - INFO - All types `lr` of epoch 215: {'lr/param_group0': 0.00029589693317905494, 'lr/param_group1': 0.00029589693317905494, 'lr/param_group2': 0.00029589693317905494, 'lr/param_group3': 0.00029589693317905494}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:07,670 - INFO - epoch 215: train loss 0.00715079830735232\n",
      "2025-09-10 11:27:07,673 - INFO - 215 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:07,677 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:07,680 - INFO - --------------------\n",
      "\n",
      "216/600: 100%|██████████| 216/216 [00:08<00:00, 26.09it/s]\n",
      "2025-09-10 11:27:16,147 - INFO - All types `lr` of epoch 216: {'lr/param_group0': 0.0002953345994276017, 'lr/param_group1': 0.0002953345994276017, 'lr/param_group2': 0.0002953345994276017, 'lr/param_group3': 0.0002953345994276017}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:16,151 - INFO - epoch 216: train loss 0.0071114280036892056\n",
      "2025-09-10 11:27:16,155 - INFO - 216 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:16,158 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:16,161 - INFO - --------------------\n",
      "\n",
      "217/600: 100%|██████████| 216/216 [00:08<00:00, 24.76it/s]\n",
      "2025-09-10 11:27:25,083 - INFO - All types `lr` of epoch 217: {'lr/param_group0': 0.000294736776640983, 'lr/param_group1': 0.000294736776640983, 'lr/param_group2': 0.000294736776640983, 'lr/param_group3': 0.000294736776640983}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:25,086 - INFO - epoch 217: train loss 0.007092512958614087\n",
      "2025-09-10 11:27:25,090 - INFO - 217 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:25,094 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:25,097 - INFO - --------------------\n",
      "\n",
      "218/600: 100%|██████████| 216/216 [00:08<00:00, 24.89it/s]\n",
      "2025-09-10 11:27:33,977 - INFO - All types `lr` of epoch 218: {'lr/param_group0': 0.00029410361232302604, 'lr/param_group1': 0.00029410361232302604, 'lr/param_group2': 0.00029410361232302604, 'lr/param_group3': 0.00029410361232302604}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:33,980 - INFO - epoch 218: train loss 0.007079349425448863\n",
      "2025-09-10 11:27:33,984 - INFO - 218 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:33,987 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:33,990 - INFO - --------------------\n",
      "\n",
      "219/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:27:42,987 - INFO - All types `lr` of epoch 219: {'lr/param_group0': 0.000293435262697552, 'lr/param_group1': 0.000293435262697552, 'lr/param_group2': 0.000293435262697552, 'lr/param_group3': 0.000293435262697552}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:42,990 - INFO - epoch 219: train loss 0.00703542812347964\n",
      "2025-09-10 11:27:42,994 - INFO - 219 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:42,997 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:43,000 - INFO - --------------------\n",
      "\n",
      "220/600: 100%|██████████| 216/216 [00:08<00:00, 24.90it/s]\n",
      "2025-09-10 11:27:51,868 - INFO - All types `lr` of epoch 220: {'lr/param_group0': 0.00029273189266983027, 'lr/param_group1': 0.00029273189266983027, 'lr/param_group2': 0.00029273189266983027, 'lr/param_group3': 0.00029273189266983027}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:27:51,871 - INFO - epoch 220: train loss 0.007017004161348773\n",
      "2025-09-10 11:27:51,875 - INFO - 220 epochs completed!\n",
      "\n",
      "2025-09-10 11:27:51,878 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:27:51,881 - INFO - --------------------\n",
      "\n",
      "221/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 11:28:00,778 - INFO - All types `lr` of epoch 221: {'lr/param_group0': 0.00029199367578589046, 'lr/param_group1': 0.00029199367578589046, 'lr/param_group2': 0.00029199367578589046, 'lr/param_group3': 0.00029199367578589046}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:00,782 - INFO - epoch 221: train loss 0.0070013135145590814\n",
      "2025-09-10 11:28:00,786 - INFO - 221 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:00,790 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:00,793 - INFO - --------------------\n",
      "\n",
      "222/600: 100%|██████████| 216/216 [00:08<00:00, 24.65it/s]\n",
      "2025-09-10 11:28:09,756 - INFO - All types `lr` of epoch 222: {'lr/param_group0': 0.00029122079418970247, 'lr/param_group1': 0.00029122079418970247, 'lr/param_group2': 0.00029122079418970247, 'lr/param_group3': 0.00029122079418970247}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:09,759 - INFO - epoch 222: train loss 0.006966723021361287\n",
      "2025-09-10 11:28:09,763 - INFO - 222 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:09,766 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:09,770 - INFO - --------------------\n",
      "\n",
      "223/600: 100%|██████████| 216/216 [00:08<00:00, 24.84it/s]\n",
      "2025-09-10 11:28:18,663 - INFO - All types `lr` of epoch 223: {'lr/param_group0': 0.0002904134385782353, 'lr/param_group1': 0.0002904134385782353, 'lr/param_group2': 0.0002904134385782353, 'lr/param_group3': 0.0002904134385782353}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:18,666 - INFO - epoch 223: train loss 0.006953330091804404\n",
      "2025-09-10 11:28:18,670 - INFO - 223 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:18,673 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:18,676 - INFO - --------------------\n",
      "\n",
      "224/600: 100%|██████████| 216/216 [00:08<00:00, 24.78it/s]\n",
      "2025-09-10 11:28:27,584 - INFO - All types `lr` of epoch 224: {'lr/param_group0': 0.00028957180815440534, 'lr/param_group1': 0.00028957180815440534, 'lr/param_group2': 0.00028957180815440534, 'lr/param_group3': 0.00028957180815440534}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:27,587 - INFO - epoch 224: train loss 0.006956379711886661\n",
      "2025-09-10 11:28:27,590 - INFO - 224 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:27,593 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:27,596 - INFO - --------------------\n",
      "\n",
      "225/600: 100%|██████████| 216/216 [00:08<00:00, 24.18it/s]\n",
      "2025-09-10 11:28:36,720 - INFO - All types `lr` of epoch 225: {'lr/param_group0': 0.00028869611057792606, 'lr/param_group1': 0.00028869611057792606, 'lr/param_group2': 0.00028869611057792606, 'lr/param_group3': 0.00028869611057792606}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:36,723 - INFO - epoch 225: train loss 0.00691632294587584\n",
      "2025-09-10 11:28:36,727 - INFO - 225 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:36,730 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:36,733 - INFO - --------------------\n",
      "\n",
      "226/600: 100%|██████████| 216/216 [00:08<00:00, 24.68it/s]\n",
      "2025-09-10 11:28:45,683 - INFO - All types `lr` of epoch 226: {'lr/param_group0': 0.00028778656191407115, 'lr/param_group1': 0.00028778656191407115, 'lr/param_group2': 0.00028778656191407115, 'lr/param_group3': 0.00028778656191407115}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:45,687 - INFO - epoch 226: train loss 0.0068929801669178736\n",
      "2025-09-10 11:28:45,691 - INFO - 226 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:45,693 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:45,697 - INFO - --------------------\n",
      "\n",
      "227/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:28:54,701 - INFO - All types `lr` of epoch 227: {'lr/param_group0': 0.0002868433865803636, 'lr/param_group1': 0.0002868433865803636, 'lr/param_group2': 0.0002868433865803636, 'lr/param_group3': 0.0002868433865803636}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:28:54,705 - INFO - epoch 227: train loss 0.006952720608010336\n",
      "2025-09-10 11:28:54,708 - INFO - 227 epochs completed!\n",
      "\n",
      "2025-09-10 11:28:54,710 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:28:54,713 - INFO - --------------------\n",
      "\n",
      "228/600: 100%|██████████| 216/216 [00:08<00:00, 24.34it/s]\n",
      "2025-09-10 11:29:03,773 - INFO - All types `lr` of epoch 228: {'lr/param_group0': 0.00028586681729120386, 'lr/param_group1': 0.00028586681729120386, 'lr/param_group2': 0.00028586681729120386, 'lr/param_group3': 0.00028586681729120386}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:03,776 - INFO - epoch 228: train loss 0.007101510466007447\n",
      "2025-09-10 11:29:03,780 - INFO - 228 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:03,783 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:03,786 - INFO - --------------------\n",
      "\n",
      "229/600: 100%|██████████| 216/216 [00:08<00:00, 25.25it/s]\n",
      "2025-09-10 11:29:12,531 - INFO - All types `lr` of epoch 229: {'lr/param_group0': 0.0002848570950004514, 'lr/param_group1': 0.0002848570950004514, 'lr/param_group2': 0.0002848570950004514, 'lr/param_group3': 0.0002848570950004514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:12,535 - INFO - epoch 229: train loss 0.007166822326662777\n",
      "2025-09-10 11:29:12,539 - INFO - 229 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:12,542 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:12,545 - INFO - --------------------\n",
      "\n",
      "230/600: 100%|██████████| 216/216 [00:08<00:00, 24.54it/s]\n",
      "2025-09-10 11:29:21,540 - INFO - All types `lr` of epoch 230: {'lr/param_group0': 0.0002838144688419726, 'lr/param_group1': 0.0002838144688419726, 'lr/param_group2': 0.0002838144688419726, 'lr/param_group3': 0.0002838144688419726}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:21,543 - INFO - epoch 230: train loss 0.006851890671963769\n",
      "2025-09-10 11:29:21,547 - INFO - 230 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:21,550 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:21,553 - INFO - --------------------\n",
      "\n",
      "231/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 11:29:30,616 - INFO - All types `lr` of epoch 231: {'lr/param_group0': 0.000282739196068171, 'lr/param_group1': 0.000282739196068171, 'lr/param_group2': 0.000282739196068171, 'lr/param_group3': 0.000282739196068171}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:30,619 - INFO - epoch 231: train loss 0.006812667041904879\n",
      "2025-09-10 11:29:30,623 - INFO - 231 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:30,626 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:30,630 - INFO - --------------------\n",
      "\n",
      "232/600: 100%|██████████| 216/216 [00:08<00:00, 24.56it/s]\n",
      "2025-09-10 11:29:39,620 - INFO - All types `lr` of epoch 232: {'lr/param_group0': 0.00028163154198651373, 'lr/param_group1': 0.00028163154198651373, 'lr/param_group2': 0.00028163154198651373, 'lr/param_group3': 0.00028163154198651373}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:39,625 - INFO - epoch 232: train loss 0.006807360507082194\n",
      "2025-09-10 11:29:39,628 - INFO - 232 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:39,631 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:39,633 - INFO - --------------------\n",
      "\n",
      "233/600: 100%|██████████| 216/216 [00:08<00:00, 24.12it/s]\n",
      "2025-09-10 11:29:48,776 - INFO - All types `lr` of epoch 233: {'lr/param_group0': 0.00028049177989407137, 'lr/param_group1': 0.00028049177989407137, 'lr/param_group2': 0.00028049177989407137, 'lr/param_group3': 0.00028049177989407137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:48,780 - INFO - epoch 233: train loss 0.0067940587328781405\n",
      "2025-09-10 11:29:48,783 - INFO - 233 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:48,787 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:48,790 - INFO - --------------------\n",
      "\n",
      "234/600: 100%|██████████| 216/216 [00:08<00:00, 24.91it/s]\n",
      "2025-09-10 11:29:57,658 - INFO - All types `lr` of epoch 234: {'lr/param_group0': 0.0002793201910100856, 'lr/param_group1': 0.0002793201910100856, 'lr/param_group2': 0.0002793201910100856, 'lr/param_group3': 0.0002793201910100856}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:29:57,663 - INFO - epoch 234: train loss 0.006774297546750556\n",
      "2025-09-10 11:29:57,667 - INFO - 234 epochs completed!\n",
      "\n",
      "2025-09-10 11:29:57,670 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:29:57,673 - INFO - --------------------\n",
      "\n",
      "235/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:30:06,559 - INFO - All types `lr` of epoch 235: {'lr/param_group0': 0.0002781170644065827, 'lr/param_group1': 0.0002781170644065827, 'lr/param_group2': 0.0002781170644065827, 'lr/param_group3': 0.0002781170644065827}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:06,562 - INFO - epoch 235: train loss 0.006742244482868248\n",
      "2025-09-10 11:30:06,566 - INFO - 235 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:06,569 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:06,572 - INFO - --------------------\n",
      "\n",
      "236/600: 100%|██████████| 216/216 [00:08<00:00, 24.85it/s]\n",
      "2025-09-10 11:30:15,461 - INFO - All types `lr` of epoch 236: {'lr/param_group0': 0.0002768826969370492, 'lr/param_group1': 0.0002768826969370492, 'lr/param_group2': 0.0002768826969370492, 'lr/param_group3': 0.0002768826969370492}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:15,465 - INFO - epoch 236: train loss 0.0067285501454197975\n",
      "2025-09-10 11:30:15,469 - INFO - 236 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:15,473 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:15,476 - INFO - --------------------\n",
      "\n",
      "237/600: 100%|██████████| 216/216 [00:08<00:00, 24.41it/s]\n",
      "2025-09-10 11:30:24,521 - INFO - All types `lr` of epoch 237: {'lr/param_group0': 0.0002756173931631881, 'lr/param_group1': 0.0002756173931631881, 'lr/param_group2': 0.0002756173931631881, 'lr/param_group3': 0.0002756173931631881}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:24,525 - INFO - epoch 237: train loss 0.006717078454568292\n",
      "2025-09-10 11:30:24,529 - INFO - 237 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:24,533 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:24,536 - INFO - --------------------\n",
      "\n",
      "238/600: 100%|██████████| 216/216 [00:08<00:00, 24.56it/s]\n",
      "2025-09-10 11:30:33,527 - INFO - All types `lr` of epoch 238: {'lr/param_group0': 0.0002743214652797724, 'lr/param_group1': 0.0002743214652797724, 'lr/param_group2': 0.0002743214652797724, 'lr/param_group3': 0.0002743214652797724}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:33,530 - INFO - epoch 238: train loss 0.006688034073535905\n",
      "2025-09-10 11:30:33,534 - INFO - 238 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:33,537 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:33,540 - INFO - --------------------\n",
      "\n",
      "239/600: 100%|██████████| 216/216 [00:08<00:00, 24.62it/s]\n",
      "2025-09-10 11:30:42,508 - INFO - All types `lr` of epoch 239: {'lr/param_group0': 0.00027299523303761595, 'lr/param_group1': 0.00027299523303761595, 'lr/param_group2': 0.00027299523303761595, 'lr/param_group3': 0.00027299523303761595}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:42,511 - INFO - epoch 239: train loss 0.006676156951235262\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.45it/s]\n",
      "2025-09-10 11:30:44,422 - INFO - epoch 239: val loss 0.006922846297836966\n",
      "2025-09-10 11:30:44,427 - INFO - 239 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:30:44,479 - INFO - 239 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:44,482 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:44,485 - INFO - --------------------\n",
      "\n",
      "240/600: 100%|██████████| 216/216 [00:08<00:00, 24.56it/s]\n",
      "2025-09-10 11:30:53,468 - INFO - All types `lr` of epoch 240: {'lr/param_group0': 0.00027163902366467965, 'lr/param_group1': 0.00027163902366467965, 'lr/param_group2': 0.00027163902366467965, 'lr/param_group3': 0.00027163902366467965}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:30:53,472 - INFO - epoch 240: train loss 0.006672233843279106\n",
      "2025-09-10 11:30:53,476 - INFO - 240 epochs completed!\n",
      "\n",
      "2025-09-10 11:30:53,479 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:30:53,482 - INFO - --------------------\n",
      "\n",
      "241/600: 100%|██████████| 216/216 [00:08<00:00, 24.35it/s]\n",
      "2025-09-10 11:31:02,545 - INFO - All types `lr` of epoch 241: {'lr/param_group0': 0.00027025317178533295, 'lr/param_group1': 0.00027025317178533295, 'lr/param_group2': 0.00027025317178533295, 'lr/param_group3': 0.00027025317178533295}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:02,548 - INFO - epoch 241: train loss 0.0066452209872228125\n",
      "2025-09-10 11:31:02,552 - INFO - 241 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:02,555 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:02,558 - INFO - --------------------\n",
      "\n",
      "242/600: 100%|██████████| 216/216 [00:08<00:00, 24.43it/s]\n",
      "2025-09-10 11:31:11,588 - INFO - All types `lr` of epoch 242: {'lr/param_group0': 0.00026883801933779, 'lr/param_group1': 0.00026883801933779, 'lr/param_group2': 0.00026883801933779, 'lr/param_group3': 0.00026883801933779}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:11,592 - INFO - epoch 242: train loss 0.0066228003038472875\n",
      "2025-09-10 11:31:11,596 - INFO - 242 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:11,599 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:11,603 - INFO - --------------------\n",
      "\n",
      "243/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 11:31:20,490 - INFO - All types `lr` of epoch 243: {'lr/param_group0': 0.00026739391548974195, 'lr/param_group1': 0.00026739391548974195, 'lr/param_group2': 0.00026739391548974195, 'lr/param_group3': 0.00026739391548974195}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:20,493 - INFO - epoch 243: train loss 0.006611882399603793\n",
      "2025-09-10 11:31:20,496 - INFO - 243 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:20,499 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:20,501 - INFO - --------------------\n",
      "\n",
      "244/600: 100%|██████████| 216/216 [00:07<00:00, 30.12it/s]\n",
      "2025-09-10 11:31:27,858 - INFO - All types `lr` of epoch 244: {'lr/param_group0': 0.0002659212165522047, 'lr/param_group1': 0.0002659212165522047, 'lr/param_group2': 0.0002659212165522047, 'lr/param_group3': 0.0002659212165522047}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:27,862 - INFO - epoch 244: train loss 0.0065941927001673594\n",
      "2025-09-10 11:31:27,866 - INFO - 244 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:27,869 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:27,872 - INFO - --------------------\n",
      "\n",
      "245/600: 100%|██████████| 216/216 [00:07<00:00, 27.16it/s]\n",
      "2025-09-10 11:31:36,016 - INFO - All types `lr` of epoch 245: {'lr/param_group0': 0.00026442028589160457, 'lr/param_group1': 0.00026442028589160457, 'lr/param_group2': 0.00026442028589160457, 'lr/param_group3': 0.00026442028589160457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:36,019 - INFO - epoch 245: train loss 0.006597758201813257\n",
      "2025-09-10 11:31:36,023 - INFO - 245 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:36,025 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:36,028 - INFO - --------------------\n",
      "\n",
      "246/600: 100%|██████████| 216/216 [00:08<00:00, 25.55it/s]\n",
      "2025-09-10 11:31:44,669 - INFO - All types `lr` of epoch 246: {'lr/param_group0': 0.0002628914938401232, 'lr/param_group1': 0.0002628914938401232, 'lr/param_group2': 0.0002628914938401232, 'lr/param_group3': 0.0002628914938401232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:44,672 - INFO - epoch 246: train loss 0.006600309340110807\n",
      "2025-09-10 11:31:44,676 - INFO - 246 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:44,680 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:44,683 - INFO - --------------------\n",
      "\n",
      "247/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 11:31:53,556 - INFO - All types `lr` of epoch 247: {'lr/param_group0': 0.0002613352176043235, 'lr/param_group1': 0.0002613352176043235, 'lr/param_group2': 0.0002613352176043235, 'lr/param_group3': 0.0002613352176043235}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:31:53,560 - INFO - epoch 247: train loss 0.006598497471444447\n",
      "2025-09-10 11:31:53,563 - INFO - 247 epochs completed!\n",
      "\n",
      "2025-09-10 11:31:53,566 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:31:53,569 - INFO - --------------------\n",
      "\n",
      "248/600: 100%|██████████| 216/216 [00:08<00:00, 24.69it/s]\n",
      "2025-09-10 11:32:02,507 - INFO - All types `lr` of epoch 248: {'lr/param_group0': 0.0002597518411720796, 'lr/param_group1': 0.0002597518411720796, 'lr/param_group2': 0.0002597518411720796, 'lr/param_group3': 0.0002597518411720796}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:02,510 - INFO - epoch 248: train loss 0.006548894204940923\n",
      "2025-09-10 11:32:02,514 - INFO - 248 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:02,517 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:02,520 - INFO - --------------------\n",
      "\n",
      "249/600: 100%|██████████| 216/216 [00:08<00:00, 24.93it/s]\n",
      "2025-09-10 11:32:11,380 - INFO - All types `lr` of epoch 249: {'lr/param_group0': 0.0002581417552178335, 'lr/param_group1': 0.0002581417552178335, 'lr/param_group2': 0.0002581417552178335, 'lr/param_group3': 0.0002581417552178335}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:11,383 - INFO - epoch 249: train loss 0.00654208713374963\n",
      "2025-09-10 11:32:11,387 - INFO - 249 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:11,390 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:11,393 - INFO - --------------------\n",
      "\n",
      "250/600: 100%|██████████| 216/216 [00:08<00:00, 25.05it/s]\n",
      "2025-09-10 11:32:20,204 - INFO - All types `lr` of epoch 250: {'lr/param_group0': 0.0002565053570062023, 'lr/param_group1': 0.0002565053570062023, 'lr/param_group2': 0.0002565053570062023, 'lr/param_group3': 0.0002565053570062023}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:20,207 - INFO - epoch 250: train loss 0.0065606792987738215\n",
      "2025-09-10 11:32:20,211 - INFO - 250 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:20,214 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:20,217 - INFO - --------------------\n",
      "\n",
      "251/600: 100%|██████████| 216/216 [00:08<00:00, 25.04it/s]\n",
      "2025-09-10 11:32:29,033 - INFO - All types `lr` of epoch 251: {'lr/param_group0': 0.00025484305029395865, 'lr/param_group1': 0.00025484305029395865, 'lr/param_group2': 0.00025484305029395865, 'lr/param_group3': 0.00025484305029395865}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:29,037 - INFO - epoch 251: train loss 0.006557531033953031\n",
      "2025-09-10 11:32:29,041 - INFO - 251 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:29,044 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:29,047 - INFO - --------------------\n",
      "\n",
      "252/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:32:37,946 - INFO - All types `lr` of epoch 252: {'lr/param_group0': 0.0002531552452304102, 'lr/param_group1': 0.0002531552452304102, 'lr/param_group2': 0.0002531552452304102, 'lr/param_group3': 0.0002531552452304102}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:37,949 - INFO - epoch 252: train loss 0.006513951186746083\n",
      "2025-09-10 11:32:37,952 - INFO - 252 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:37,955 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:37,958 - INFO - --------------------\n",
      "\n",
      "253/600: 100%|██████████| 216/216 [00:08<00:00, 24.90it/s]\n",
      "2025-09-10 11:32:46,816 - INFO - All types `lr` of epoch 253: {'lr/param_group0': 0.00025144235825620134, 'lr/param_group1': 0.00025144235825620134, 'lr/param_group2': 0.00025144235825620134, 'lr/param_group3': 0.00025144235825620134}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:46,820 - INFO - epoch 253: train loss 0.0065129191218013015\n",
      "2025-09-10 11:32:46,824 - INFO - 253 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:46,827 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:46,830 - INFO - --------------------\n",
      "\n",
      "254/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:32:55,838 - INFO - All types `lr` of epoch 254: {'lr/param_group0': 0.0002497048120005623, 'lr/param_group1': 0.0002497048120005623, 'lr/param_group2': 0.0002497048120005623, 'lr/param_group3': 0.0002497048120005623}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:32:55,843 - INFO - epoch 254: train loss 0.006525993138051557\n",
      "2025-09-10 11:32:55,847 - INFO - 254 epochs completed!\n",
      "\n",
      "2025-09-10 11:32:55,850 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:32:55,853 - INFO - --------------------\n",
      "\n",
      "255/600: 100%|██████████| 216/216 [00:08<00:00, 24.71it/s]\n",
      "2025-09-10 11:33:04,782 - INFO - All types `lr` of epoch 255: {'lr/param_group0': 0.0002479430351770322, 'lr/param_group1': 0.0002479430351770322, 'lr/param_group2': 0.0002479430351770322, 'lr/param_group3': 0.0002479430351770322}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:04,785 - INFO - epoch 255: train loss 0.006509193865996268\n",
      "2025-09-10 11:33:04,789 - INFO - 255 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:04,792 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:04,795 - INFO - --------------------\n",
      "\n",
      "256/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:33:13,803 - INFO - All types `lr` of epoch 256: {'lr/param_group0': 0.0002461574624776804, 'lr/param_group1': 0.0002461574624776804, 'lr/param_group2': 0.0002461574624776804, 'lr/param_group3': 0.0002461574624776804}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:13,806 - INFO - epoch 256: train loss 0.006497111124055529\n",
      "2025-09-10 11:33:13,810 - INFO - 256 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:13,813 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:13,817 - INFO - --------------------\n",
      "\n",
      "257/600: 100%|██████████| 216/216 [00:08<00:00, 24.42it/s]\n",
      "2025-09-10 11:33:22,851 - INFO - All types `lr` of epoch 257: {'lr/param_group0': 0.0002443485344658522, 'lr/param_group1': 0.0002443485344658522, 'lr/param_group2': 0.0002443485344658522, 'lr/param_group3': 0.0002443485344658522}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:22,854 - INFO - epoch 257: train loss 0.006478403839368925\n",
      "2025-09-10 11:33:22,858 - INFO - 257 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:22,861 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:22,865 - INFO - --------------------\n",
      "\n",
      "258/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:33:31,782 - INFO - All types `lr` of epoch 258: {'lr/param_group0': 0.000242516697467467, 'lr/param_group1': 0.000242516697467467, 'lr/param_group2': 0.000242516697467467, 'lr/param_group3': 0.000242516697467467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:31,785 - INFO - epoch 258: train loss 0.006485531522668208\n",
      "2025-09-10 11:33:31,789 - INFO - 258 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:31,793 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:31,796 - INFO - --------------------\n",
      "\n",
      "259/600: 100%|██████████| 216/216 [00:08<00:00, 25.02it/s]\n",
      "2025-09-10 11:33:40,620 - INFO - All types `lr` of epoch 259: {'lr/param_group0': 0.00024066240346089376, 'lr/param_group1': 0.00024066240346089376, 'lr/param_group2': 0.00024066240346089376, 'lr/param_group3': 0.00024066240346089376}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:40,624 - INFO - epoch 259: train loss 0.006446025435623058\n",
      "2025-09-10 11:33:40,628 - INFO - 259 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:40,631 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:40,634 - INFO - --------------------\n",
      "\n",
      "260/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:33:49,561 - INFO - All types `lr` of epoch 260: {'lr/param_group0': 0.00023878610996543227, 'lr/param_group1': 0.00023878610996543227, 'lr/param_group2': 0.00023878610996543227, 'lr/param_group3': 0.00023878610996543227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:49,565 - INFO - epoch 260: train loss 0.006551787416726627\n",
      "2025-09-10 11:33:49,568 - INFO - 260 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:49,571 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:49,574 - INFO - --------------------\n",
      "\n",
      "261/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:33:58,572 - INFO - All types `lr` of epoch 261: {'lr/param_group0': 0.00023688827992842683, 'lr/param_group1': 0.00023688827992842683, 'lr/param_group2': 0.00023688827992842683, 'lr/param_group3': 0.00023688827992842683}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:33:58,576 - INFO - epoch 261: train loss 0.006566265285342794\n",
      "2025-09-10 11:33:58,579 - INFO - 261 epochs completed!\n",
      "\n",
      "2025-09-10 11:33:58,583 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:33:58,586 - INFO - --------------------\n",
      "\n",
      "262/600: 100%|██████████| 216/216 [00:08<00:00, 24.82it/s]\n",
      "2025-09-10 11:34:07,479 - INFO - All types `lr` of epoch 262: {'lr/param_group0': 0.00023496938161104137, 'lr/param_group1': 0.00023496938161104137, 'lr/param_group2': 0.00023496938161104137, 'lr/param_group3': 0.00023496938161104137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:07,482 - INFO - epoch 262: train loss 0.006484588414120178\n",
      "2025-09-10 11:34:07,486 - INFO - 262 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:07,489 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:07,492 - INFO - --------------------\n",
      "\n",
      "263/600: 100%|██████████| 216/216 [00:08<00:00, 24.62it/s]\n",
      "2025-09-10 11:34:16,452 - INFO - All types `lr` of epoch 263: {'lr/param_group0': 0.00023302988847272255, 'lr/param_group1': 0.00023302988847272255, 'lr/param_group2': 0.00023302988847272255, 'lr/param_group3': 0.00023302988847272255}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:16,456 - INFO - epoch 263: train loss 0.006441482143364502\n",
      "2025-09-10 11:34:16,460 - INFO - 263 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:16,463 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:16,467 - INFO - --------------------\n",
      "\n",
      "264/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:34:25,348 - INFO - All types `lr` of epoch 264: {'lr/param_group0': 0.00023107027905438097, 'lr/param_group1': 0.00023107027905438097, 'lr/param_group2': 0.00023107027905438097, 'lr/param_group3': 0.00023107027905438097}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:25,351 - INFO - epoch 264: train loss 0.006429396873702192\n",
      "2025-09-10 11:34:25,355 - INFO - 264 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:25,359 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:25,363 - INFO - --------------------\n",
      "\n",
      "265/600: 100%|██████████| 216/216 [00:09<00:00, 23.99it/s]\n",
      "2025-09-10 11:34:34,560 - INFO - All types `lr` of epoch 265: {'lr/param_group0': 0.0002290910368603184, 'lr/param_group1': 0.0002290910368603184, 'lr/param_group2': 0.0002290910368603184, 'lr/param_group3': 0.0002290910368603184}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:34,567 - INFO - epoch 265: train loss 0.006431037642027217\n",
      "2025-09-10 11:34:34,571 - INFO - 265 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:34,576 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:34,579 - INFO - --------------------\n",
      "\n",
      "266/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:34:43,554 - INFO - All types `lr` of epoch 266: {'lr/param_group0': 0.00022709265023893008, 'lr/param_group1': 0.00022709265023893008, 'lr/param_group2': 0.00022709265023893008, 'lr/param_group3': 0.00022709265023893008}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:43,558 - INFO - epoch 266: train loss 0.006488947074912075\n",
      "2025-09-10 11:34:43,562 - INFO - 266 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:43,565 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:43,568 - INFO - --------------------\n",
      "\n",
      "267/600: 100%|██████████| 216/216 [00:06<00:00, 33.89it/s]\n",
      "2025-09-10 11:34:50,133 - INFO - All types `lr` of epoch 267: {'lr/param_group0': 0.0002250756122622125, 'lr/param_group1': 0.0002250756122622125, 'lr/param_group2': 0.0002250756122622125, 'lr/param_group3': 0.0002250756122622125}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:50,136 - INFO - epoch 267: train loss 0.006502956768532318\n",
      "2025-09-10 11:34:50,140 - INFO - 267 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:50,143 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:50,146 - INFO - --------------------\n",
      "\n",
      "268/600: 100%|██████████| 216/216 [00:07<00:00, 28.98it/s]\n",
      "2025-09-10 11:34:57,769 - INFO - All types `lr` of epoch 268: {'lr/param_group0': 0.00022304042060410467, 'lr/param_group1': 0.00022304042060410467, 'lr/param_group2': 0.00022304042060410467, 'lr/param_group3': 0.00022304042060410467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:34:57,773 - INFO - epoch 268: train loss 0.006467695009497994\n",
      "2025-09-10 11:34:57,777 - INFO - 268 epochs completed!\n",
      "\n",
      "2025-09-10 11:34:57,780 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:34:57,783 - INFO - --------------------\n",
      "\n",
      "269/600: 100%|██████████| 216/216 [00:07<00:00, 30.04it/s]\n",
      "2025-09-10 11:35:05,155 - INFO - All types `lr` of epoch 269: {'lr/param_group0': 0.00022098757741769514, 'lr/param_group1': 0.00022098757741769514, 'lr/param_group2': 0.00022098757741769514, 'lr/param_group3': 0.00022098757741769514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:05,159 - INFO - epoch 269: train loss 0.00648817634727392\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.35it/s]\n",
      "2025-09-10 11:35:07,131 - INFO - epoch 269: val loss 0.006708006667732088\n",
      "2025-09-10 11:35:07,136 - INFO - 269 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:35:07,184 - INFO - 269 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:07,187 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:07,190 - INFO - --------------------\n",
      "\n",
      "270/600: 100%|██████████| 216/216 [00:08<00:00, 25.03it/s]\n",
      "2025-09-10 11:35:16,013 - INFO - All types `lr` of epoch 270: {'lr/param_group0': 0.0002189175892113227, 'lr/param_group1': 0.0002189175892113227, 'lr/param_group2': 0.0002189175892113227, 'lr/param_group3': 0.0002189175892113227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:16,017 - INFO - epoch 270: train loss 0.006400389799468771\n",
      "2025-09-10 11:35:16,021 - INFO - 270 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:16,025 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:16,028 - INFO - --------------------\n",
      "\n",
      "271/600: 100%|██████████| 216/216 [00:08<00:00, 24.85it/s]\n",
      "2025-09-10 11:35:24,920 - INFO - All types `lr` of epoch 271: {'lr/param_group0': 0.00021683096672360337, 'lr/param_group1': 0.00021683096672360337, 'lr/param_group2': 0.00021683096672360337, 'lr/param_group3': 0.00021683096672360337}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:24,924 - INFO - epoch 271: train loss 0.006367350255863534\n",
      "2025-09-10 11:35:24,928 - INFO - 271 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:24,932 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:24,935 - INFO - --------------------\n",
      "\n",
      "272/600: 100%|██████████| 216/216 [00:08<00:00, 25.51it/s]\n",
      "2025-09-10 11:35:33,603 - INFO - All types `lr` of epoch 272: {'lr/param_group0': 0.00021472822479741326, 'lr/param_group1': 0.00021472822479741326, 'lr/param_group2': 0.00021472822479741326, 'lr/param_group3': 0.00021472822479741326}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:33,606 - INFO - epoch 272: train loss 0.006389820207712344\n",
      "2025-09-10 11:35:33,611 - INFO - 272 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:33,614 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:33,618 - INFO - --------------------\n",
      "\n",
      "273/600: 100%|██████████| 216/216 [00:08<00:00, 24.32it/s]\n",
      "2025-09-10 11:35:42,704 - INFO - All types `lr` of epoch 273: {'lr/param_group0': 0.00021260988225285863, 'lr/param_group1': 0.00021260988225285863, 'lr/param_group2': 0.00021260988225285863, 'lr/param_group3': 0.00021260988225285863}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:42,707 - INFO - epoch 273: train loss 0.0063957492195725165\n",
      "2025-09-10 11:35:42,711 - INFO - 273 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:42,715 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:42,718 - INFO - --------------------\n",
      "\n",
      "274/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:35:51,606 - INFO - All types `lr` of epoch 274: {'lr/param_group0': 0.00021047646175926488, 'lr/param_group1': 0.00021047646175926488, 'lr/param_group2': 0.00021047646175926488, 'lr/param_group3': 0.00021047646175926488}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:35:51,611 - INFO - epoch 274: train loss 0.006489166332391539\n",
      "2025-09-10 11:35:51,615 - INFO - 274 epochs completed!\n",
      "\n",
      "2025-09-10 11:35:51,619 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:35:51,623 - INFO - --------------------\n",
      "\n",
      "275/600: 100%|██████████| 216/216 [00:08<00:00, 25.21it/s]\n",
      "2025-09-10 11:36:00,388 - INFO - All types `lr` of epoch 275: {'lr/param_group0': 0.00020832848970621582, 'lr/param_group1': 0.00020832848970621582, 'lr/param_group2': 0.00020832848970621582, 'lr/param_group3': 0.00020832848970621582}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:00,392 - INFO - epoch 275: train loss 0.006452462416038745\n",
      "2025-09-10 11:36:00,396 - INFO - 275 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:00,399 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:00,402 - INFO - --------------------\n",
      "\n",
      "276/600: 100%|██████████| 216/216 [00:08<00:00, 24.99it/s]\n",
      "2025-09-10 11:36:09,234 - INFO - All types `lr` of epoch 276: {'lr/param_group0': 0.0002061664960736747, 'lr/param_group1': 0.0002061664960736747, 'lr/param_group2': 0.0002061664960736747, 'lr/param_group3': 0.0002061664960736747}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:09,237 - INFO - epoch 276: train loss 0.006347572120527427\n",
      "2025-09-10 11:36:09,241 - INFO - 276 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:09,245 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:09,248 - INFO - --------------------\n",
      "\n",
      "277/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:36:18,207 - INFO - All types `lr` of epoch 277: {'lr/param_group0': 0.00020399101430121968, 'lr/param_group1': 0.00020399101430121968, 'lr/param_group2': 0.00020399101430121968, 'lr/param_group3': 0.00020399101430121968}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:18,211 - INFO - epoch 277: train loss 0.006340056942361925\n",
      "2025-09-10 11:36:18,215 - INFO - 277 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:18,218 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:18,222 - INFO - --------------------\n",
      "\n",
      "278/600: 100%|██████████| 216/216 [00:08<00:00, 26.19it/s]\n",
      "2025-09-10 11:36:26,662 - INFO - All types `lr` of epoch 278: {'lr/param_group0': 0.00020180258115642578, 'lr/param_group1': 0.00020180258115642578, 'lr/param_group2': 0.00020180258115642578, 'lr/param_group3': 0.00020180258115642578}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:26,667 - INFO - epoch 278: train loss 0.006422748278257334\n",
      "2025-09-10 11:36:26,671 - INFO - 278 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:26,674 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:26,677 - INFO - --------------------\n",
      "\n",
      "279/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:36:35,614 - INFO - All types `lr` of epoch 279: {'lr/param_group0': 0.00019960173660242518, 'lr/param_group1': 0.00019960173660242518, 'lr/param_group2': 0.00019960173660242518, 'lr/param_group3': 0.00019960173660242518}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:35,617 - INFO - epoch 279: train loss 0.0064200769303608\n",
      "2025-09-10 11:36:35,621 - INFO - 279 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:35,624 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:35,628 - INFO - --------------------\n",
      "\n",
      "280/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 11:36:44,549 - INFO - All types `lr` of epoch 280: {'lr/param_group0': 0.0001973890236646797, 'lr/param_group1': 0.0001973890236646797, 'lr/param_group2': 0.0001973890236646797, 'lr/param_group3': 0.0001973890236646797}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:44,553 - INFO - epoch 280: train loss 0.006437264587643936\n",
      "2025-09-10 11:36:44,557 - INFO - 280 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:44,560 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:44,564 - INFO - --------------------\n",
      "\n",
      "281/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:36:53,566 - INFO - All types `lr` of epoch 281: {'lr/param_group0': 0.0001951649882969971, 'lr/param_group1': 0.0001951649882969971, 'lr/param_group2': 0.0001951649882969971, 'lr/param_group3': 0.0001951649882969971}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:36:53,569 - INFO - epoch 281: train loss 0.006388368268273081\n",
      "2025-09-10 11:36:53,574 - INFO - 281 epochs completed!\n",
      "\n",
      "2025-09-10 11:36:53,577 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:36:53,580 - INFO - --------------------\n",
      "\n",
      "282/600: 100%|██████████| 216/216 [00:08<00:00, 24.25it/s]\n",
      "2025-09-10 11:37:02,686 - INFO - All types `lr` of epoch 282: {'lr/param_group0': 0.00019293017924682556, 'lr/param_group1': 0.00019293017924682556, 'lr/param_group2': 0.00019293017924682556, 'lr/param_group3': 0.00019293017924682556}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:02,691 - INFO - epoch 282: train loss 0.00637930589598707\n",
      "2025-09-10 11:37:02,695 - INFO - 282 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:02,698 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:02,702 - INFO - --------------------\n",
      "\n",
      "283/600: 100%|██████████| 216/216 [00:08<00:00, 24.71it/s]\n",
      "2025-09-10 11:37:11,642 - INFO - All types `lr` of epoch 283: {'lr/param_group0': 0.0001906851479198579, 'lr/param_group1': 0.0001906851479198579, 'lr/param_group2': 0.0001906851479198579, 'lr/param_group3': 0.0001906851479198579}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:11,645 - INFO - epoch 283: train loss 0.0063433173323843494\n",
      "2025-09-10 11:37:11,650 - INFO - 283 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:11,653 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:11,657 - INFO - --------------------\n",
      "\n",
      "284/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:37:20,577 - INFO - All types `lr` of epoch 284: {'lr/param_group0': 0.00018843044824398095, 'lr/param_group1': 0.00018843044824398095, 'lr/param_group2': 0.00018843044824398095, 'lr/param_group3': 0.00018843044824398095}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:20,581 - INFO - epoch 284: train loss 0.006381135584821028\n",
      "2025-09-10 11:37:20,585 - INFO - 284 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:20,589 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:20,592 - INFO - --------------------\n",
      "\n",
      "285/600: 100%|██████████| 216/216 [00:08<00:00, 26.10it/s]\n",
      "2025-09-10 11:37:29,064 - INFO - All types `lr` of epoch 285: {'lr/param_group0': 0.00018616663653260194, 'lr/param_group1': 0.00018616663653260194, 'lr/param_group2': 0.00018616663653260194, 'lr/param_group3': 0.00018616663653260194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:29,068 - INFO - epoch 285: train loss 0.006385900211710207\n",
      "2025-09-10 11:37:29,072 - INFO - 285 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:29,076 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:29,079 - INFO - --------------------\n",
      "\n",
      "286/600: 100%|██████████| 216/216 [00:08<00:00, 25.09it/s]\n",
      "2025-09-10 11:37:37,886 - INFO - All types `lr` of epoch 286: {'lr/param_group0': 0.00018389427134738657, 'lr/param_group1': 0.00018389427134738657, 'lr/param_group2': 0.00018389427134738657, 'lr/param_group3': 0.00018389427134738657}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:37,891 - INFO - epoch 286: train loss 0.00633725860690767\n",
      "2025-09-10 11:37:37,896 - INFO - 286 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:37,900 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:37,903 - INFO - --------------------\n",
      "\n",
      "287/600: 100%|██████████| 216/216 [00:07<00:00, 27.88it/s]\n",
      "2025-09-10 11:37:45,857 - INFO - All types `lr` of epoch 287: {'lr/param_group0': 0.00018161391336044209, 'lr/param_group1': 0.00018161391336044209, 'lr/param_group2': 0.00018161391336044209, 'lr/param_group3': 0.00018161391336044209}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:45,861 - INFO - epoch 287: train loss 0.006319782711755208\n",
      "2025-09-10 11:37:45,865 - INFO - 287 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:45,868 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:45,872 - INFO - --------------------\n",
      "\n",
      "288/600: 100%|██████████| 216/216 [00:08<00:00, 24.70it/s]\n",
      "2025-09-10 11:37:54,814 - INFO - All types `lr` of epoch 288: {'lr/param_group0': 0.0001793261252159801, 'lr/param_group1': 0.0001793261252159801, 'lr/param_group2': 0.0001793261252159801, 'lr/param_group3': 0.0001793261252159801}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:37:54,818 - INFO - epoch 288: train loss 0.006325131383534797\n",
      "2025-09-10 11:37:54,823 - INFO - 288 epochs completed!\n",
      "\n",
      "2025-09-10 11:37:54,826 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:37:54,830 - INFO - --------------------\n",
      "\n",
      "289/600: 100%|██████████| 216/216 [00:08<00:00, 26.12it/s]\n",
      "2025-09-10 11:38:03,292 - INFO - All types `lr` of epoch 289: {'lr/param_group0': 0.00017703147139149232, 'lr/param_group1': 0.00017703147139149232, 'lr/param_group2': 0.00017703147139149232, 'lr/param_group3': 0.00017703147139149232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:03,296 - INFO - epoch 289: train loss 0.006342413895590989\n",
      "2025-09-10 11:38:03,299 - INFO - 289 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:03,302 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:03,305 - INFO - --------------------\n",
      "\n",
      "290/600: 100%|██████████| 216/216 [00:08<00:00, 25.57it/s]\n",
      "2025-09-10 11:38:11,948 - INFO - All types `lr` of epoch 290: {'lr/param_group0': 0.00017473051805847427, 'lr/param_group1': 0.00017473051805847427, 'lr/param_group2': 0.00017473051805847427, 'lr/param_group3': 0.00017473051805847427}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:11,951 - INFO - epoch 290: train loss 0.006364287250175106\n",
      "2025-09-10 11:38:11,956 - INFO - 290 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:11,960 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:11,963 - INFO - --------------------\n",
      "\n",
      "291/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 11:38:20,890 - INFO - All types `lr` of epoch 291: {'lr/param_group0': 0.00017242383294273098, 'lr/param_group1': 0.00017242383294273098, 'lr/param_group2': 0.00017242383294273098, 'lr/param_group3': 0.00017242383294273098}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:20,894 - INFO - epoch 291: train loss 0.006312107195198122\n",
      "2025-09-10 11:38:20,898 - INFO - 291 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:20,902 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:20,905 - INFO - --------------------\n",
      "\n",
      "292/600: 100%|██████████| 216/216 [00:08<00:00, 25.37it/s]\n",
      "2025-09-10 11:38:29,612 - INFO - All types `lr` of epoch 292: {'lr/param_group0': 0.00017011198518429918, 'lr/param_group1': 0.00017011198518429918, 'lr/param_group2': 0.00017011198518429918, 'lr/param_group3': 0.00017011198518429918}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:29,616 - INFO - epoch 292: train loss 0.006313496649791314\n",
      "2025-09-10 11:38:29,620 - INFO - 292 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:29,624 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:29,627 - INFO - --------------------\n",
      "\n",
      "293/600: 100%|██████████| 216/216 [00:06<00:00, 32.21it/s]\n",
      "2025-09-10 11:38:36,527 - INFO - All types `lr` of epoch 293: {'lr/param_group0': 0.0001677955451970202, 'lr/param_group1': 0.0001677955451970202, 'lr/param_group2': 0.0001677955451970202, 'lr/param_group3': 0.0001677955451970202}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:36,532 - INFO - epoch 293: train loss 0.006349000314474796\n",
      "2025-09-10 11:38:36,537 - INFO - 293 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:36,540 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:36,544 - INFO - --------------------\n",
      "\n",
      "294/600: 100%|██████████| 216/216 [00:06<00:00, 31.60it/s]\n",
      "2025-09-10 11:38:43,572 - INFO - All types `lr` of epoch 294: {'lr/param_group0': 0.00016547508452779942, 'lr/param_group1': 0.00016547508452779942, 'lr/param_group2': 0.00016547508452779942, 'lr/param_group3': 0.00016547508452779942}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:43,575 - INFO - epoch 294: train loss 0.006340589436823157\n",
      "2025-09-10 11:38:43,580 - INFO - 294 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:43,583 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:43,587 - INFO - --------------------\n",
      "\n",
      "295/600: 100%|██████████| 216/216 [00:07<00:00, 28.19it/s]\n",
      "2025-09-10 11:38:51,421 - INFO - All types `lr` of epoch 295: {'lr/param_group0': 0.00016315117571558496, 'lr/param_group1': 0.00016315117571558496, 'lr/param_group2': 0.00016315117571558496, 'lr/param_group3': 0.00016315117571558496}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:51,426 - INFO - epoch 295: train loss 0.006319549046801748\n",
      "2025-09-10 11:38:51,430 - INFO - 295 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:51,434 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:51,438 - INFO - --------------------\n",
      "\n",
      "296/600: 100%|██████████| 216/216 [00:08<00:00, 26.40it/s]\n",
      "2025-09-10 11:38:59,817 - INFO - All types `lr` of epoch 296: {'lr/param_group0': 0.00016082439215010303, 'lr/param_group1': 0.00016082439215010303, 'lr/param_group2': 0.00016082439215010303, 'lr/param_group3': 0.00016082439215010303}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:38:59,821 - INFO - epoch 296: train loss 0.006302636470300732\n",
      "2025-09-10 11:38:59,825 - INFO - 296 epochs completed!\n",
      "\n",
      "2025-09-10 11:38:59,829 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:38:59,832 - INFO - --------------------\n",
      "\n",
      "297/600: 100%|██████████| 216/216 [00:08<00:00, 24.39it/s]\n",
      "2025-09-10 11:39:08,882 - INFO - All types `lr` of epoch 297: {'lr/param_group0': 0.00015849530793038194, 'lr/param_group1': 0.00015849530793038194, 'lr/param_group2': 0.00015849530793038194, 'lr/param_group3': 0.00015849530793038194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:08,886 - INFO - epoch 297: train loss 0.00632239218921987\n",
      "2025-09-10 11:39:08,890 - INFO - 297 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:08,894 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:08,898 - INFO - --------------------\n",
      "\n",
      "298/600: 100%|██████████| 216/216 [00:07<00:00, 27.26it/s]\n",
      "2025-09-10 11:39:17,020 - INFO - All types `lr` of epoch 298: {'lr/param_group0': 0.00015616449772310208, 'lr/param_group1': 0.00015616449772310208, 'lr/param_group2': 0.00015616449772310208, 'lr/param_group3': 0.00015616449772310208}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:17,024 - INFO - epoch 298: train loss 0.00633785622172851\n",
      "2025-09-10 11:39:17,028 - INFO - 298 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:17,032 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:17,035 - INFO - --------------------\n",
      "\n",
      "299/600: 100%|██████████| 216/216 [00:08<00:00, 24.43it/s]\n",
      "2025-09-10 11:39:26,073 - INFO - All types `lr` of epoch 299: {'lr/param_group0': 0.00015383253662080537, 'lr/param_group1': 0.00015383253662080537, 'lr/param_group2': 0.00015383253662080537, 'lr/param_group3': 0.00015383253662080537}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:26,079 - INFO - epoch 299: train loss 0.006503177882189414\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.59it/s]\n",
      "2025-09-10 11:39:28,099 - INFO - epoch 299: val loss 0.007130158728816443\n",
      "2025-09-10 11:39:28,105 - INFO - 299 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:39:28,155 - INFO - 299 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:28,159 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:28,162 - INFO - --------------------\n",
      "\n",
      "300/600: 100%|██████████| 216/216 [00:07<00:00, 28.05it/s]\n",
      "2025-09-10 11:39:36,057 - INFO - All types `lr` of epoch 300: {'lr/param_group0': 0.00015150000000000002, 'lr/param_group1': 0.00015150000000000002, 'lr/param_group2': 0.00015150000000000002, 'lr/param_group3': 0.00015150000000000002}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:36,062 - INFO - epoch 300: train loss 0.007468691061216372\n",
      "2025-09-10 11:39:36,066 - INFO - 300 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:36,070 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:36,073 - INFO - --------------------\n",
      "\n",
      "301/600: 100%|██████████| 216/216 [00:08<00:00, 24.93it/s]\n",
      "2025-09-10 11:39:44,930 - INFO - All types `lr` of epoch 301: {'lr/param_group0': 0.00014916746337919465, 'lr/param_group1': 0.00014916746337919465, 'lr/param_group2': 0.00014916746337919465, 'lr/param_group3': 0.00014916746337919465}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:44,935 - INFO - epoch 301: train loss 0.007780461925668297\n",
      "2025-09-10 11:39:44,940 - INFO - 301 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:44,943 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:44,946 - INFO - --------------------\n",
      "\n",
      "302/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:39:53,913 - INFO - All types `lr` of epoch 302: {'lr/param_group0': 0.00014683550227689794, 'lr/param_group1': 0.00014683550227689794, 'lr/param_group2': 0.00014683550227689794, 'lr/param_group3': 0.00014683550227689794}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:39:53,917 - INFO - epoch 302: train loss 0.006509433858338054\n",
      "2025-09-10 11:39:53,921 - INFO - 302 epochs completed!\n",
      "\n",
      "2025-09-10 11:39:53,925 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:39:53,928 - INFO - --------------------\n",
      "\n",
      "303/600: 100%|██████████| 216/216 [00:08<00:00, 24.45it/s]\n",
      "2025-09-10 11:40:02,961 - INFO - All types `lr` of epoch 303: {'lr/param_group0': 0.00014450469206961806, 'lr/param_group1': 0.00014450469206961806, 'lr/param_group2': 0.00014450469206961806, 'lr/param_group3': 0.00014450469206961806}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:02,965 - INFO - epoch 303: train loss 0.006293380260036362\n",
      "2025-09-10 11:40:02,970 - INFO - 303 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:02,973 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:02,977 - INFO - --------------------\n",
      "\n",
      "304/600: 100%|██████████| 216/216 [00:08<00:00, 24.46it/s]\n",
      "2025-09-10 11:40:12,006 - INFO - All types `lr` of epoch 304: {'lr/param_group0': 0.00014217560784989694, 'lr/param_group1': 0.00014217560784989694, 'lr/param_group2': 0.00014217560784989694, 'lr/param_group3': 0.00014217560784989694}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:12,009 - INFO - epoch 304: train loss 0.006259331699564225\n",
      "2025-09-10 11:40:12,013 - INFO - 304 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:12,016 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:12,019 - INFO - --------------------\n",
      "\n",
      "305/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 11:40:20,147 - INFO - All types `lr` of epoch 305: {'lr/param_group0': 0.000139848824284415, 'lr/param_group1': 0.000139848824284415, 'lr/param_group2': 0.000139848824284415, 'lr/param_group3': 0.000139848824284415}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:20,151 - INFO - epoch 305: train loss 0.00625133501900429\n",
      "2025-09-10 11:40:20,155 - INFO - 305 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:20,160 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:20,163 - INFO - --------------------\n",
      "\n",
      "306/600: 100%|██████████| 216/216 [00:07<00:00, 28.36it/s]\n",
      "2025-09-10 11:40:27,976 - INFO - All types `lr` of epoch 306: {'lr/param_group0': 0.0001375249154722006, 'lr/param_group1': 0.0001375249154722006, 'lr/param_group2': 0.0001375249154722006, 'lr/param_group3': 0.0001375249154722006}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:27,980 - INFO - epoch 306: train loss 0.006245853527043773\n",
      "2025-09-10 11:40:27,984 - INFO - 306 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:27,988 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:27,992 - INFO - --------------------\n",
      "\n",
      "307/600: 100%|██████████| 216/216 [00:08<00:00, 24.23it/s]\n",
      "2025-09-10 11:40:37,110 - INFO - All types `lr` of epoch 307: {'lr/param_group0': 0.0001352044548029798, 'lr/param_group1': 0.0001352044548029798, 'lr/param_group2': 0.0001352044548029798, 'lr/param_group3': 0.0001352044548029798}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:37,114 - INFO - epoch 307: train loss 0.00624746059205521\n",
      "2025-09-10 11:40:37,118 - INFO - 307 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:37,123 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:37,126 - INFO - --------------------\n",
      "\n",
      "308/600: 100%|██████████| 216/216 [00:07<00:00, 28.08it/s]\n",
      "2025-09-10 11:40:45,029 - INFO - All types `lr` of epoch 308: {'lr/param_group0': 0.00013288801481570078, 'lr/param_group1': 0.00013288801481570078, 'lr/param_group2': 0.00013288801481570078, 'lr/param_group3': 0.00013288801481570078}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:45,033 - INFO - epoch 308: train loss 0.006248000922992274\n",
      "2025-09-10 11:40:45,037 - INFO - 308 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:45,041 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:45,045 - INFO - --------------------\n",
      "\n",
      "309/600: 100%|██████████| 216/216 [00:08<00:00, 25.41it/s]\n",
      "2025-09-10 11:40:53,748 - INFO - All types `lr` of epoch 309: {'lr/param_group0': 0.00013057616705726896, 'lr/param_group1': 0.00013057616705726896, 'lr/param_group2': 0.00013057616705726896, 'lr/param_group3': 0.00013057616705726896}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:40:53,752 - INFO - epoch 309: train loss 0.006258184788748622\n",
      "2025-09-10 11:40:53,756 - INFO - 309 epochs completed!\n",
      "\n",
      "2025-09-10 11:40:53,760 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:40:53,763 - INFO - --------------------\n",
      "\n",
      "310/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:41:02,739 - INFO - All types `lr` of epoch 310: {'lr/param_group0': 0.0001282694819415257, 'lr/param_group1': 0.0001282694819415257, 'lr/param_group2': 0.0001282694819415257, 'lr/param_group3': 0.0001282694819415257}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:02,744 - INFO - epoch 310: train loss 0.006261395174078643\n",
      "2025-09-10 11:41:02,749 - INFO - 310 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:02,752 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:02,756 - INFO - --------------------\n",
      "\n",
      "311/600: 100%|██████████| 216/216 [00:08<00:00, 24.92it/s]\n",
      "2025-09-10 11:41:11,621 - INFO - All types `lr` of epoch 311: {'lr/param_group0': 0.00012596852860850764, 'lr/param_group1': 0.00012596852860850764, 'lr/param_group2': 0.00012596852860850764, 'lr/param_group3': 0.00012596852860850764}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:11,625 - INFO - epoch 311: train loss 0.0063017970845706895\n",
      "2025-09-10 11:41:11,630 - INFO - 311 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:11,633 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:11,637 - INFO - --------------------\n",
      "\n",
      "312/600: 100%|██████████| 216/216 [00:08<00:00, 24.27it/s]\n",
      "2025-09-10 11:41:20,748 - INFO - All types `lr` of epoch 312: {'lr/param_group0': 0.00012367387478401986, 'lr/param_group1': 0.00012367387478401986, 'lr/param_group2': 0.00012367387478401986, 'lr/param_group3': 0.00012367387478401986}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:20,752 - INFO - epoch 312: train loss 0.006855978186380256\n",
      "2025-09-10 11:41:20,756 - INFO - 312 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:20,760 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:20,763 - INFO - --------------------\n",
      "\n",
      "313/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:41:29,748 - INFO - All types `lr` of epoch 313: {'lr/param_group0': 0.00012138608663955795, 'lr/param_group1': 0.00012138608663955795, 'lr/param_group2': 0.00012138608663955795, 'lr/param_group3': 0.00012138608663955795}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:29,751 - INFO - epoch 313: train loss 0.007650261550831298\n",
      "2025-09-10 11:41:29,755 - INFO - 313 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:29,758 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:29,761 - INFO - --------------------\n",
      "\n",
      "314/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 11:41:38,689 - INFO - All types `lr` of epoch 314: {'lr/param_group0': 0.00011910572865261347, 'lr/param_group1': 0.00011910572865261347, 'lr/param_group2': 0.00011910572865261347, 'lr/param_group3': 0.00011910572865261347}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:38,693 - INFO - epoch 314: train loss 0.006534868612005893\n",
      "2025-09-10 11:41:38,698 - INFO - 314 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:38,702 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:38,706 - INFO - --------------------\n",
      "\n",
      "315/600: 100%|██████████| 216/216 [00:08<00:00, 25.24it/s]\n",
      "2025-09-10 11:41:47,462 - INFO - All types `lr` of epoch 315: {'lr/param_group0': 0.00011683336346739808, 'lr/param_group1': 0.00011683336346739808, 'lr/param_group2': 0.00011683336346739808, 'lr/param_group3': 0.00011683336346739808}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:47,466 - INFO - epoch 315: train loss 0.006299481045937649\n",
      "2025-09-10 11:41:47,471 - INFO - 315 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:47,474 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:47,478 - INFO - --------------------\n",
      "\n",
      "316/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:41:56,406 - INFO - All types `lr` of epoch 316: {'lr/param_group0': 0.0001145695517560191, 'lr/param_group1': 0.0001145695517560191, 'lr/param_group2': 0.0001145695517560191, 'lr/param_group3': 0.0001145695517560191}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:41:56,409 - INFO - epoch 316: train loss 0.006234788422093347\n",
      "2025-09-10 11:41:56,414 - INFO - 316 epochs completed!\n",
      "\n",
      "2025-09-10 11:41:56,417 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:41:56,421 - INFO - --------------------\n",
      "\n",
      "317/600: 100%|██████████| 216/216 [00:08<00:00, 24.66it/s]\n",
      "2025-09-10 11:42:05,376 - INFO - All types `lr` of epoch 317: {'lr/param_group0': 0.00011231485208014218, 'lr/param_group1': 0.00011231485208014218, 'lr/param_group2': 0.00011231485208014218, 'lr/param_group3': 0.00011231485208014218}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:05,382 - INFO - epoch 317: train loss 0.006227700507561503\n",
      "2025-09-10 11:42:05,386 - INFO - 317 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:05,390 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:05,393 - INFO - --------------------\n",
      "\n",
      "318/600: 100%|██████████| 216/216 [00:08<00:00, 24.38it/s]\n",
      "2025-09-10 11:42:14,450 - INFO - All types `lr` of epoch 318: {'lr/param_group0': 0.00011006982075317448, 'lr/param_group1': 0.00011006982075317448, 'lr/param_group2': 0.00011006982075317448, 'lr/param_group3': 0.00011006982075317448}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:14,453 - INFO - epoch 318: train loss 0.006220057723112404\n",
      "2025-09-10 11:42:14,457 - INFO - 318 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:14,460 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:14,463 - INFO - --------------------\n",
      "\n",
      "319/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:42:23,443 - INFO - All types `lr` of epoch 319: {'lr/param_group0': 0.00010783501170300287, 'lr/param_group1': 0.00010783501170300287, 'lr/param_group2': 0.00010783501170300287, 'lr/param_group3': 0.00010783501170300287}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:23,448 - INFO - epoch 319: train loss 0.006226767207004337\n",
      "2025-09-10 11:42:23,452 - INFO - 319 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:23,456 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:23,459 - INFO - --------------------\n",
      "\n",
      "320/600: 100%|██████████| 216/216 [00:08<00:00, 24.92it/s]\n",
      "2025-09-10 11:42:32,325 - INFO - All types `lr` of epoch 320: {'lr/param_group0': 0.0001056109763353203, 'lr/param_group1': 0.0001056109763353203, 'lr/param_group2': 0.0001056109763353203, 'lr/param_group3': 0.0001056109763353203}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:32,330 - INFO - epoch 320: train loss 0.006234824302804622\n",
      "2025-09-10 11:42:32,335 - INFO - 320 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:32,338 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:32,342 - INFO - --------------------\n",
      "\n",
      "321/600: 100%|██████████| 216/216 [00:08<00:00, 24.78it/s]\n",
      "2025-09-10 11:42:41,259 - INFO - All types `lr` of epoch 321: {'lr/param_group0': 0.00010339826339757483, 'lr/param_group1': 0.00010339826339757483, 'lr/param_group2': 0.00010339826339757483, 'lr/param_group3': 0.00010339826339757483}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:41,263 - INFO - epoch 321: train loss 0.006297392604648377\n",
      "2025-09-10 11:42:41,266 - INFO - 321 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:41,270 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:41,273 - INFO - --------------------\n",
      "\n",
      "322/600: 100%|██████████| 216/216 [00:08<00:00, 24.67it/s]\n",
      "2025-09-10 11:42:50,224 - INFO - All types `lr` of epoch 322: {'lr/param_group0': 0.00010119741884357424, 'lr/param_group1': 0.00010119741884357424, 'lr/param_group2': 0.00010119741884357424, 'lr/param_group3': 0.00010119741884357424}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:50,229 - INFO - epoch 322: train loss 0.0071740671604250865\n",
      "2025-09-10 11:42:50,233 - INFO - 322 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:50,236 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:50,240 - INFO - --------------------\n",
      "\n",
      "323/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:42:59,258 - INFO - All types `lr` of epoch 323: {'lr/param_group0': 9.900898569878033e-05, 'lr/param_group1': 9.900898569878033e-05, 'lr/param_group2': 9.900898569878033e-05, 'lr/param_group3': 9.900898569878033e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:42:59,262 - INFO - epoch 323: train loss 0.007364975363964698\n",
      "2025-09-10 11:42:59,267 - INFO - 323 epochs completed!\n",
      "\n",
      "2025-09-10 11:42:59,271 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:42:59,274 - INFO - --------------------\n",
      "\n",
      "324/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:43:08,250 - INFO - All types `lr` of epoch 324: {'lr/param_group0': 9.683350392632531e-05, 'lr/param_group1': 9.683350392632531e-05, 'lr/param_group2': 9.683350392632531e-05, 'lr/param_group3': 9.683350392632531e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:08,254 - INFO - epoch 324: train loss 0.006401916951829291\n",
      "2025-09-10 11:43:08,258 - INFO - 324 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:08,261 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:08,264 - INFO - --------------------\n",
      "\n",
      "325/600: 100%|██████████| 216/216 [00:08<00:00, 24.40it/s]\n",
      "2025-09-10 11:43:17,310 - INFO - All types `lr` of epoch 325: {'lr/param_group0': 9.467151029378419e-05, 'lr/param_group1': 9.467151029378419e-05, 'lr/param_group2': 9.467151029378419e-05, 'lr/param_group3': 9.467151029378419e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:17,315 - INFO - epoch 325: train loss 0.006260045181045792\n",
      "2025-09-10 11:43:17,319 - INFO - 325 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:17,322 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:17,325 - INFO - --------------------\n",
      "\n",
      "326/600: 100%|██████████| 216/216 [00:08<00:00, 24.65it/s]\n",
      "2025-09-10 11:43:26,283 - INFO - All types `lr` of epoch 326: {'lr/param_group0': 9.25235382407351e-05, 'lr/param_group1': 9.25235382407351e-05, 'lr/param_group2': 9.25235382407351e-05, 'lr/param_group3': 9.25235382407351e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:26,288 - INFO - epoch 326: train loss 0.006217133439214969\n",
      "2025-09-10 11:43:26,292 - INFO - 326 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:26,296 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:26,300 - INFO - --------------------\n",
      "\n",
      "327/600: 100%|██████████| 216/216 [00:08<00:00, 24.46it/s]\n",
      "2025-09-10 11:43:35,328 - INFO - All types `lr` of epoch 327: {'lr/param_group0': 9.039011774714136e-05, 'lr/param_group1': 9.039011774714136e-05, 'lr/param_group2': 9.039011774714136e-05, 'lr/param_group3': 9.039011774714136e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:35,332 - INFO - epoch 327: train loss 0.006210673587500221\n",
      "2025-09-10 11:43:35,337 - INFO - 327 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:35,340 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:35,344 - INFO - --------------------\n",
      "\n",
      "328/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:43:44,364 - INFO - All types `lr` of epoch 328: {'lr/param_group0': 8.827177520258669e-05, 'lr/param_group1': 8.827177520258669e-05, 'lr/param_group2': 8.827177520258669e-05, 'lr/param_group3': 8.827177520258669e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:44,369 - INFO - epoch 328: train loss 0.006209792964876181\n",
      "2025-09-10 11:43:44,372 - INFO - 328 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:44,375 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:44,378 - INFO - --------------------\n",
      "\n",
      "329/600: 100%|██████████| 216/216 [00:08<00:00, 24.46it/s]\n",
      "2025-09-10 11:43:53,406 - INFO - All types `lr` of epoch 329: {'lr/param_group0': 8.616903327639659e-05, 'lr/param_group1': 8.616903327639659e-05, 'lr/param_group2': 8.616903327639659e-05, 'lr/param_group3': 8.616903327639659e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:43:53,410 - INFO - epoch 329: train loss 0.0062109762867395245\n",
      "100%|██████████| 54/54 [00:01<00:00, 29.03it/s]\n",
      "2025-09-10 11:43:55,468 - INFO - epoch 329: val loss 0.006449206628733211\n",
      "2025-09-10 11:43:55,475 - INFO - 329 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:43:55,525 - INFO - 329 epochs completed!\n",
      "\n",
      "2025-09-10 11:43:55,529 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:43:55,532 - INFO - --------------------\n",
      "\n",
      "330/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 11:44:04,596 - INFO - All types `lr` of epoch 330: {'lr/param_group0': 8.408241078867731e-05, 'lr/param_group1': 8.408241078867731e-05, 'lr/param_group2': 8.408241078867731e-05, 'lr/param_group3': 8.408241078867731e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:04,599 - INFO - epoch 330: train loss 0.006208076135307137\n",
      "2025-09-10 11:44:04,604 - INFO - 330 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:04,607 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:04,610 - INFO - --------------------\n",
      "\n",
      "331/600: 100%|██████████| 216/216 [00:08<00:00, 24.39it/s]\n",
      "2025-09-10 11:44:13,659 - INFO - All types `lr` of epoch 331: {'lr/param_group0': 8.201242258230488e-05, 'lr/param_group1': 8.201242258230488e-05, 'lr/param_group2': 8.201242258230488e-05, 'lr/param_group3': 8.201242258230488e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:13,664 - INFO - epoch 331: train loss 0.006214945629903081\n",
      "2025-09-10 11:44:13,668 - INFO - 331 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:13,672 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:13,676 - INFO - --------------------\n",
      "\n",
      "332/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:44:22,605 - INFO - All types `lr` of epoch 332: {'lr/param_group0': 7.995957939589527e-05, 'lr/param_group1': 7.995957939589527e-05, 'lr/param_group2': 7.995957939589527e-05, 'lr/param_group3': 7.995957939589527e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:22,610 - INFO - epoch 332: train loss 0.006234601397645073\n",
      "2025-09-10 11:44:22,615 - INFO - 332 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:22,619 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:22,622 - INFO - --------------------\n",
      "\n",
      "333/600: 100%|██████████| 216/216 [00:08<00:00, 24.57it/s]\n",
      "2025-09-10 11:44:31,613 - INFO - All types `lr` of epoch 333: {'lr/param_group0': 7.792438773778747e-05, 'lr/param_group1': 7.792438773778747e-05, 'lr/param_group2': 7.792438773778747e-05, 'lr/param_group3': 7.792438773778747e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:31,619 - INFO - epoch 333: train loss 0.006497778736822376\n",
      "2025-09-10 11:44:31,624 - INFO - 333 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:31,628 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:31,632 - INFO - --------------------\n",
      "\n",
      "334/600: 100%|██████████| 216/216 [00:08<00:00, 24.58it/s]\n",
      "2025-09-10 11:44:40,624 - INFO - All types `lr` of epoch 334: {'lr/param_group0': 7.590734976106984e-05, 'lr/param_group1': 7.590734976106984e-05, 'lr/param_group2': 7.590734976106984e-05, 'lr/param_group3': 7.590734976106984e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:40,628 - INFO - epoch 334: train loss 0.0073199817259726975\n",
      "2025-09-10 11:44:40,632 - INFO - 334 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:40,635 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:40,638 - INFO - --------------------\n",
      "\n",
      "335/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:44:49,644 - INFO - All types `lr` of epoch 335: {'lr/param_group0': 7.390896313968161e-05, 'lr/param_group1': 7.390896313968161e-05, 'lr/param_group2': 7.390896313968161e-05, 'lr/param_group3': 7.390896313968161e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:49,649 - INFO - epoch 335: train loss 0.006690890420469697\n",
      "2025-09-10 11:44:49,653 - INFO - 335 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:49,657 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:49,661 - INFO - --------------------\n",
      "\n",
      "336/600: 100%|██████████| 216/216 [00:08<00:00, 24.24it/s]\n",
      "2025-09-10 11:44:58,773 - INFO - All types `lr` of epoch 336: {'lr/param_group0': 7.192972094561893e-05, 'lr/param_group1': 7.192972094561893e-05, 'lr/param_group2': 7.192972094561893e-05, 'lr/param_group3': 7.192972094561893e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:44:58,779 - INFO - epoch 336: train loss 0.006300873059512081\n",
      "2025-09-10 11:44:58,784 - INFO - 336 epochs completed!\n",
      "\n",
      "2025-09-10 11:44:58,787 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:44:58,791 - INFO - --------------------\n",
      "\n",
      "337/600: 100%|██████████| 216/216 [00:08<00:00, 25.54it/s]\n",
      "2025-09-10 11:45:07,449 - INFO - All types `lr` of epoch 337: {'lr/param_group0': 6.997011152727743e-05, 'lr/param_group1': 6.997011152727743e-05, 'lr/param_group2': 6.997011152727743e-05, 'lr/param_group3': 6.997011152727743e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:07,453 - INFO - epoch 337: train loss 0.006219029311237305\n",
      "2025-09-10 11:45:07,458 - INFO - 337 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:07,461 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:07,465 - INFO - --------------------\n",
      "\n",
      "338/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:45:16,434 - INFO - All types `lr` of epoch 338: {'lr/param_group0': 6.803061838895864e-05, 'lr/param_group1': 6.803061838895864e-05, 'lr/param_group2': 6.803061838895864e-05, 'lr/param_group3': 6.803061838895864e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:16,440 - INFO - epoch 338: train loss 0.006196870369388274\n",
      "2025-09-10 11:45:16,444 - INFO - 338 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:16,448 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:16,452 - INFO - --------------------\n",
      "\n",
      "339/600: 100%|██████████| 216/216 [00:08<00:00, 24.37it/s]\n",
      "2025-09-10 11:45:25,514 - INFO - All types `lr` of epoch 339: {'lr/param_group0': 6.611172007157319e-05, 'lr/param_group1': 6.611172007157319e-05, 'lr/param_group2': 6.611172007157319e-05, 'lr/param_group3': 6.611172007157319e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:25,519 - INFO - epoch 339: train loss 0.006187167650312875\n",
      "2025-09-10 11:45:25,523 - INFO - 339 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:25,526 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:25,529 - INFO - --------------------\n",
      "\n",
      "340/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:45:34,524 - INFO - All types `lr` of epoch 340: {'lr/param_group0': 6.421389003456778e-05, 'lr/param_group1': 6.421389003456778e-05, 'lr/param_group2': 6.421389003456778e-05, 'lr/param_group3': 6.421389003456778e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:34,529 - INFO - epoch 340: train loss 0.006186259966516109\n",
      "2025-09-10 11:45:34,533 - INFO - 340 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:34,537 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:34,540 - INFO - --------------------\n",
      "\n",
      "341/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:45:43,448 - INFO - All types `lr` of epoch 341: {'lr/param_group0': 6.233759653910625e-05, 'lr/param_group1': 6.233759653910625e-05, 'lr/param_group2': 6.233759653910625e-05, 'lr/param_group3': 6.233759653910625e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:43,454 - INFO - epoch 341: train loss 0.006190248466467623\n",
      "2025-09-10 11:45:43,458 - INFO - 341 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:43,462 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:43,466 - INFO - --------------------\n",
      "\n",
      "342/600: 100%|██████████| 216/216 [00:08<00:00, 24.77it/s]\n",
      "2025-09-10 11:45:52,383 - INFO - All types `lr` of epoch 342: {'lr/param_group0': 6.048330253253304e-05, 'lr/param_group1': 6.048330253253304e-05, 'lr/param_group2': 6.048330253253304e-05, 'lr/param_group3': 6.048330253253304e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:45:52,387 - INFO - epoch 342: train loss 0.006197533997086187\n",
      "2025-09-10 11:45:52,391 - INFO - 342 epochs completed!\n",
      "\n",
      "2025-09-10 11:45:52,395 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:45:52,399 - INFO - --------------------\n",
      "\n",
      "343/600: 100%|██████████| 216/216 [00:08<00:00, 24.35it/s]\n",
      "2025-09-10 11:46:01,470 - INFO - All types `lr` of epoch 343: {'lr/param_group0': 5.86514655341478e-05, 'lr/param_group1': 5.86514655341478e-05, 'lr/param_group2': 5.86514655341478e-05, 'lr/param_group3': 5.86514655341478e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:01,475 - INFO - epoch 343: train loss 0.0062870598199811795\n",
      "2025-09-10 11:46:01,479 - INFO - 343 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:01,483 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:01,487 - INFO - --------------------\n",
      "\n",
      "344/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:46:10,469 - INFO - All types `lr` of epoch 344: {'lr/param_group0': 5.6842537522319565e-05, 'lr/param_group1': 5.6842537522319565e-05, 'lr/param_group2': 5.6842537522319565e-05, 'lr/param_group3': 5.6842537522319565e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:10,473 - INFO - epoch 344: train loss 0.0067704918587373365\n",
      "2025-09-10 11:46:10,477 - INFO - 344 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:10,481 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:10,484 - INFO - --------------------\n",
      "\n",
      "345/600: 100%|██████████| 216/216 [00:08<00:00, 24.47it/s]\n",
      "2025-09-10 11:46:19,515 - INFO - All types `lr` of epoch 345: {'lr/param_group0': 5.505696482296775e-05, 'lr/param_group1': 5.505696482296775e-05, 'lr/param_group2': 5.505696482296775e-05, 'lr/param_group3': 5.505696482296775e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:19,520 - INFO - epoch 345: train loss 0.0067857598597011355\n",
      "2025-09-10 11:46:19,525 - INFO - 345 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:19,529 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:19,533 - INFO - --------------------\n",
      "\n",
      "346/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:46:28,469 - INFO - All types `lr` of epoch 346: {'lr/param_group0': 5.3295187999437704e-05, 'lr/param_group1': 5.3295187999437704e-05, 'lr/param_group2': 5.3295187999437704e-05, 'lr/param_group3': 5.3295187999437704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:28,473 - INFO - epoch 346: train loss 0.006499521779241385\n",
      "2025-09-10 11:46:28,477 - INFO - 346 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:28,480 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:28,483 - INFO - --------------------\n",
      "\n",
      "347/600: 100%|██████████| 216/216 [00:08<00:00, 25.91it/s]\n",
      "2025-09-10 11:46:37,018 - INFO - All types `lr` of epoch 347: {'lr/param_group0': 5.1557641743798694e-05, 'lr/param_group1': 5.1557641743798694e-05, 'lr/param_group2': 5.1557641743798694e-05, 'lr/param_group3': 5.1557641743798694e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:37,023 - INFO - epoch 347: train loss 0.006312720457100551\n",
      "2025-09-10 11:46:37,027 - INFO - 347 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:37,031 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:37,035 - INFO - --------------------\n",
      "\n",
      "348/600: 100%|██████████| 216/216 [00:08<00:00, 24.62it/s]\n",
      "2025-09-10 11:46:46,027 - INFO - All types `lr` of epoch 348: {'lr/param_group0': 4.984475476958972e-05, 'lr/param_group1': 4.984475476958972e-05, 'lr/param_group2': 4.984475476958972e-05, 'lr/param_group3': 4.984475476958972e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:46,033 - INFO - epoch 348: train loss 0.006252918207017636\n",
      "2025-09-10 11:46:46,037 - INFO - 348 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:46,042 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:46,046 - INFO - --------------------\n",
      "\n",
      "349/600: 100%|██████████| 216/216 [00:08<00:00, 24.99it/s]\n",
      "2025-09-10 11:46:54,890 - INFO - All types `lr` of epoch 349: {'lr/param_group0': 4.815694970604134e-05, 'lr/param_group1': 4.815694970604134e-05, 'lr/param_group2': 4.815694970604134e-05, 'lr/param_group3': 4.815694970604134e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:46:54,895 - INFO - epoch 349: train loss 0.006231245692577903\n",
      "2025-09-10 11:46:54,900 - INFO - 349 epochs completed!\n",
      "\n",
      "2025-09-10 11:46:54,904 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:46:54,908 - INFO - --------------------\n",
      "\n",
      "350/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:47:03,892 - INFO - All types `lr` of epoch 350: {'lr/param_group0': 4.6494642993797704e-05, 'lr/param_group1': 4.6494642993797704e-05, 'lr/param_group2': 4.6494642993797704e-05, 'lr/param_group3': 4.6494642993797704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:03,897 - INFO - epoch 350: train loss 0.006217269167623103\n",
      "2025-09-10 11:47:03,902 - INFO - 350 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:03,906 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:03,910 - INFO - --------------------\n",
      "\n",
      "351/600: 100%|██████████| 216/216 [00:08<00:00, 24.64it/s]\n",
      "2025-09-10 11:47:12,880 - INFO - All types `lr` of epoch 351: {'lr/param_group0': 4.485824478216651e-05, 'lr/param_group1': 4.485824478216651e-05, 'lr/param_group2': 4.485824478216651e-05, 'lr/param_group3': 4.485824478216651e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:12,884 - INFO - epoch 351: train loss 0.0062359095576943625\n",
      "2025-09-10 11:47:12,888 - INFO - 351 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:12,893 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:12,896 - INFO - --------------------\n",
      "\n",
      "352/600: 100%|██████████| 216/216 [00:08<00:00, 24.11it/s]\n",
      "2025-09-10 11:47:22,059 - INFO - All types `lr` of epoch 352: {'lr/param_group0': 4.324815882792043e-05, 'lr/param_group1': 4.324815882792043e-05, 'lr/param_group2': 4.324815882792043e-05, 'lr/param_group3': 4.324815882792043e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:22,064 - INFO - epoch 352: train loss 0.00627263362252119\n",
      "2025-09-10 11:47:22,068 - INFO - 352 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:22,072 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:22,076 - INFO - --------------------\n",
      "\n",
      "353/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:47:31,080 - INFO - All types `lr` of epoch 353: {'lr/param_group0': 4.1664782395676444e-05, 'lr/param_group1': 4.1664782395676444e-05, 'lr/param_group2': 4.1664782395676444e-05, 'lr/param_group3': 4.1664782395676444e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:31,084 - INFO - epoch 353: train loss 0.006323887746677631\n",
      "2025-09-10 11:47:31,088 - INFO - 353 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:31,091 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:31,095 - INFO - --------------------\n",
      "\n",
      "354/600: 100%|██████████| 216/216 [00:08<00:00, 24.30it/s]\n",
      "2025-09-10 11:47:40,185 - INFO - All types `lr` of epoch 354: {'lr/param_group0': 4.0108506159876744e-05, 'lr/param_group1': 4.0108506159876744e-05, 'lr/param_group2': 4.0108506159876744e-05, 'lr/param_group3': 4.0108506159876744e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:40,189 - INFO - epoch 354: train loss 0.006418904625914163\n",
      "2025-09-10 11:47:40,194 - INFO - 354 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:40,198 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:40,202 - INFO - --------------------\n",
      "\n",
      "355/600: 100%|██████████| 216/216 [00:08<00:00, 24.63it/s]\n",
      "2025-09-10 11:47:49,171 - INFO - All types `lr` of epoch 355: {'lr/param_group0': 3.8579714108395387e-05, 'lr/param_group1': 3.8579714108395387e-05, 'lr/param_group2': 3.8579714108395387e-05, 'lr/param_group3': 3.8579714108395387e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:49,175 - INFO - epoch 355: train loss 0.006332664996282094\n",
      "2025-09-10 11:47:49,181 - INFO - 355 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:49,185 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:49,188 - INFO - --------------------\n",
      "\n",
      "356/600: 100%|██████████| 216/216 [00:08<00:00, 24.68it/s]\n",
      "2025-09-10 11:47:58,129 - INFO - All types `lr` of epoch 356: {'lr/param_group0': 3.707878344779533e-05, 'lr/param_group1': 3.707878344779533e-05, 'lr/param_group2': 3.707878344779533e-05, 'lr/param_group3': 3.707878344779533e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:47:58,135 - INFO - epoch 356: train loss 0.006349330316340827\n",
      "2025-09-10 11:47:58,139 - INFO - 356 epochs completed!\n",
      "\n",
      "2025-09-10 11:47:58,143 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:47:58,146 - INFO - --------------------\n",
      "\n",
      "357/600: 100%|██████████| 216/216 [00:08<00:00, 24.67it/s]\n",
      "2025-09-10 11:48:07,102 - INFO - All types `lr` of epoch 357: {'lr/param_group0': 3.5606084510258035e-05, 'lr/param_group1': 3.5606084510258035e-05, 'lr/param_group2': 3.5606084510258035e-05, 'lr/param_group3': 3.5606084510258035e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:07,110 - INFO - epoch 357: train loss 0.0063161346263735105\n",
      "2025-09-10 11:48:07,115 - INFO - 357 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:07,119 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:07,123 - INFO - --------------------\n",
      "\n",
      "358/600: 100%|██████████| 216/216 [00:08<00:00, 24.42it/s]\n",
      "2025-09-10 11:48:16,171 - INFO - All types `lr` of epoch 358: {'lr/param_group0': 3.416198066220997e-05, 'lr/param_group1': 3.416198066220997e-05, 'lr/param_group2': 3.416198066220997e-05, 'lr/param_group3': 3.416198066220997e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:16,176 - INFO - epoch 358: train loss 0.006280968286942139\n",
      "2025-09-10 11:48:16,179 - INFO - 358 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:16,183 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:16,186 - INFO - --------------------\n",
      "\n",
      "359/600: 100%|██████████| 216/216 [00:08<00:00, 24.05it/s]\n",
      "2025-09-10 11:48:25,370 - INFO - All types `lr` of epoch 359: {'lr/param_group0': 3.274682821466704e-05, 'lr/param_group1': 3.274682821466704e-05, 'lr/param_group2': 3.274682821466704e-05, 'lr/param_group3': 3.274682821466704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:25,374 - INFO - epoch 359: train loss 0.006268707876895658\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.32it/s]\n",
      "2025-09-10 11:48:27,299 - INFO - epoch 359: val loss 0.006520919260327463\n",
      "2025-09-10 11:48:27,306 - INFO - 359 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:48:27,357 - INFO - 359 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:27,360 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:27,364 - INFO - --------------------\n",
      "\n",
      "360/600: 100%|██████████| 216/216 [00:08<00:00, 24.95it/s]\n",
      "2025-09-10 11:48:36,219 - INFO - All types `lr` of epoch 360: {'lr/param_group0': 3.13609763353203e-05, 'lr/param_group1': 3.13609763353203e-05, 'lr/param_group2': 3.13609763353203e-05, 'lr/param_group3': 3.13609763353203e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:36,224 - INFO - epoch 360: train loss 0.006265908136912104\n",
      "2025-09-10 11:48:36,229 - INFO - 360 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:36,233 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:36,237 - INFO - --------------------\n",
      "\n",
      "361/600: 100%|██████████| 216/216 [00:09<00:00, 23.99it/s]\n",
      "2025-09-10 11:48:45,446 - INFO - All types `lr` of epoch 361: {'lr/param_group0': 3.0004766962383986e-05, 'lr/param_group1': 3.0004766962383986e-05, 'lr/param_group2': 3.0004766962383986e-05, 'lr/param_group3': 3.0004766962383986e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:45,450 - INFO - epoch 361: train loss 0.00625160933446346\n",
      "2025-09-10 11:48:45,454 - INFO - 361 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:45,458 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:45,462 - INFO - --------------------\n",
      "\n",
      "362/600: 100%|██████████| 216/216 [00:08<00:00, 24.31it/s]\n",
      "2025-09-10 11:48:54,550 - INFO - All types `lr` of epoch 362: {'lr/param_group0': 2.8678534720227554e-05, 'lr/param_group1': 2.8678534720227554e-05, 'lr/param_group2': 2.8678534720227554e-05, 'lr/param_group3': 2.8678534720227554e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:48:54,555 - INFO - epoch 362: train loss 0.006255756546225812\n",
      "2025-09-10 11:48:54,559 - INFO - 362 epochs completed!\n",
      "\n",
      "2025-09-10 11:48:54,563 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:48:54,567 - INFO - --------------------\n",
      "\n",
      "363/600: 100%|██████████| 216/216 [00:08<00:00, 24.13it/s]\n",
      "2025-09-10 11:49:03,725 - INFO - All types `lr` of epoch 363: {'lr/param_group0': 2.7382606836811927e-05, 'lr/param_group1': 2.7382606836811927e-05, 'lr/param_group2': 2.7382606836811927e-05, 'lr/param_group3': 2.7382606836811927e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:03,730 - INFO - epoch 363: train loss 0.0062616499845818095\n",
      "2025-09-10 11:49:03,734 - INFO - 363 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:03,739 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:03,742 - INFO - --------------------\n",
      "\n",
      "364/600: 100%|██████████| 216/216 [00:08<00:00, 24.78it/s]\n",
      "2025-09-10 11:49:12,665 - INFO - All types `lr` of epoch 364: {'lr/param_group0': 2.61173030629508e-05, 'lr/param_group1': 2.61173030629508e-05, 'lr/param_group2': 2.61173030629508e-05, 'lr/param_group3': 2.61173030629508e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:12,669 - INFO - epoch 364: train loss 0.006275706864134581\n",
      "2025-09-10 11:49:12,674 - INFO - 364 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:12,678 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:12,682 - INFO - --------------------\n",
      "\n",
      "365/600: 100%|██████████| 216/216 [00:08<00:00, 24.96it/s]\n",
      "2025-09-10 11:49:21,556 - INFO - All types `lr` of epoch 365: {'lr/param_group0': 2.4882935593417308e-05, 'lr/param_group1': 2.4882935593417308e-05, 'lr/param_group2': 2.4882935593417308e-05, 'lr/param_group3': 2.4882935593417308e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:21,560 - INFO - epoch 365: train loss 0.0062709041220067\n",
      "2025-09-10 11:49:21,565 - INFO - 365 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:21,570 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:21,574 - INFO - --------------------\n",
      "\n",
      "366/600: 100%|██████████| 216/216 [00:09<00:00, 23.93it/s]\n",
      "2025-09-10 11:49:30,816 - INFO - All types `lr` of epoch 366: {'lr/param_group0': 2.3679808989914373e-05, 'lr/param_group1': 2.3679808989914373e-05, 'lr/param_group2': 2.3679808989914373e-05, 'lr/param_group3': 2.3679808989914373e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:30,821 - INFO - epoch 366: train loss 0.0062797517802445565\n",
      "2025-09-10 11:49:30,825 - INFO - 366 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:30,830 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:30,834 - INFO - --------------------\n",
      "\n",
      "367/600: 100%|██████████| 216/216 [00:09<00:00, 23.94it/s]\n",
      "2025-09-10 11:49:40,067 - INFO - All types `lr` of epoch 367: {'lr/param_group0': 2.250822010592862e-05, 'lr/param_group1': 2.250822010592862e-05, 'lr/param_group2': 2.250822010592862e-05, 'lr/param_group3': 2.250822010592862e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:40,072 - INFO - epoch 367: train loss 0.006268652657228004\n",
      "2025-09-10 11:49:40,077 - INFO - 367 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:40,081 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:40,085 - INFO - --------------------\n",
      "\n",
      "368/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:49:49,077 - INFO - All types `lr` of epoch 368: {'lr/param_group0': 2.1368458013486268e-05, 'lr/param_group1': 2.1368458013486268e-05, 'lr/param_group2': 2.1368458013486268e-05, 'lr/param_group3': 2.1368458013486268e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:49,083 - INFO - epoch 368: train loss 0.006259044317563099\n",
      "2025-09-10 11:49:49,087 - INFO - 368 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:49,091 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:49,095 - INFO - --------------------\n",
      "\n",
      "369/600: 100%|██████████| 216/216 [00:08<00:00, 24.34it/s]\n",
      "2025-09-10 11:49:58,176 - INFO - All types `lr` of epoch 369: {'lr/param_group0': 2.0260803931829005e-05, 'lr/param_group1': 2.0260803931829005e-05, 'lr/param_group2': 2.0260803931829005e-05, 'lr/param_group3': 2.0260803931829005e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:49:58,181 - INFO - epoch 369: train loss 0.006241466850042343\n",
      "2025-09-10 11:49:58,185 - INFO - 369 epochs completed!\n",
      "\n",
      "2025-09-10 11:49:58,190 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:49:58,193 - INFO - --------------------\n",
      "\n",
      "370/600: 100%|██████████| 216/216 [00:08<00:00, 24.26it/s]\n",
      "2025-09-10 11:50:07,302 - INFO - All types `lr` of epoch 370: {'lr/param_group0': 1.918553115802738e-05, 'lr/param_group1': 1.918553115802738e-05, 'lr/param_group2': 1.918553115802738e-05, 'lr/param_group3': 1.918553115802738e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:07,307 - INFO - epoch 370: train loss 0.006240210642486259\n",
      "2025-09-10 11:50:07,312 - INFO - 370 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:07,316 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:07,320 - INFO - --------------------\n",
      "\n",
      "371/600: 100%|██████████| 216/216 [00:08<00:00, 24.38it/s]\n",
      "2025-09-10 11:50:16,385 - INFO - All types `lr` of epoch 371: {'lr/param_group0': 1.814290499954858e-05, 'lr/param_group1': 1.814290499954858e-05, 'lr/param_group2': 1.814290499954858e-05, 'lr/param_group3': 1.814290499954858e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:16,389 - INFO - epoch 371: train loss 0.006231913406669197\n",
      "2025-09-10 11:50:16,393 - INFO - 371 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:16,397 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:16,400 - INFO - --------------------\n",
      "\n",
      "372/600: 100%|██████████| 216/216 [00:08<00:00, 24.57it/s]\n",
      "2025-09-10 11:50:25,399 - INFO - All types `lr` of epoch 372: {'lr/param_group0': 1.713318270879612e-05, 'lr/param_group1': 1.713318270879612e-05, 'lr/param_group2': 1.713318270879612e-05, 'lr/param_group3': 1.713318270879612e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:25,403 - INFO - epoch 372: train loss 0.006213817570824176\n",
      "2025-09-10 11:50:25,408 - INFO - 372 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:25,412 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:25,416 - INFO - --------------------\n",
      "\n",
      "373/600: 100%|██████████| 216/216 [00:08<00:00, 24.40it/s]\n",
      "2025-09-10 11:50:34,474 - INFO - All types `lr` of epoch 373: {'lr/param_group0': 1.6156613419636378e-05, 'lr/param_group1': 1.6156613419636378e-05, 'lr/param_group2': 1.6156613419636378e-05, 'lr/param_group3': 1.6156613419636378e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:34,478 - INFO - epoch 373: train loss 0.0062075491554828156\n",
      "2025-09-10 11:50:34,483 - INFO - 373 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:34,487 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:34,492 - INFO - --------------------\n",
      "\n",
      "374/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:50:43,471 - INFO - All types `lr` of epoch 374: {'lr/param_group0': 1.5213438085928809e-05, 'lr/param_group1': 1.5213438085928809e-05, 'lr/param_group2': 1.5213438085928809e-05, 'lr/param_group3': 1.5213438085928809e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:43,477 - INFO - epoch 374: train loss 0.006197219166939182\n",
      "2025-09-10 11:50:43,482 - INFO - 374 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:43,486 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:43,491 - INFO - --------------------\n",
      "\n",
      "375/600: 100%|██████████| 216/216 [00:08<00:00, 24.58it/s]\n",
      "2025-09-10 11:50:52,482 - INFO - All types `lr` of epoch 375: {'lr/param_group0': 1.4303889422073933e-05, 'lr/param_group1': 1.4303889422073933e-05, 'lr/param_group2': 1.4303889422073933e-05, 'lr/param_group3': 1.4303889422073933e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:50:52,487 - INFO - epoch 375: train loss 0.006198153382650128\n",
      "2025-09-10 11:50:52,492 - INFO - 375 epochs completed!\n",
      "\n",
      "2025-09-10 11:50:52,496 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:50:52,500 - INFO - --------------------\n",
      "\n",
      "376/600: 100%|██████████| 216/216 [00:08<00:00, 25.31it/s]\n",
      "2025-09-10 11:51:01,254 - INFO - All types `lr` of epoch 376: {'lr/param_group0': 1.3428191845594682e-05, 'lr/param_group1': 1.3428191845594682e-05, 'lr/param_group2': 1.3428191845594682e-05, 'lr/param_group3': 1.3428191845594682e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:01,259 - INFO - epoch 376: train loss 0.006196906255489147\n",
      "2025-09-10 11:51:01,263 - INFO - 376 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:01,267 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:01,271 - INFO - --------------------\n",
      "\n",
      "377/600: 100%|██████████| 216/216 [00:06<00:00, 34.94it/s]\n",
      "2025-09-10 11:51:07,654 - INFO - All types `lr` of epoch 377: {'lr/param_group0': 1.2586561421764697e-05, 'lr/param_group1': 1.2586561421764697e-05, 'lr/param_group2': 1.2586561421764697e-05, 'lr/param_group3': 1.2586561421764697e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:07,659 - INFO - epoch 377: train loss 0.006203740938670105\n",
      "2025-09-10 11:51:07,665 - INFO - 377 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:07,668 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:07,672 - INFO - --------------------\n",
      "\n",
      "378/600: 100%|██████████| 216/216 [00:08<00:00, 26.14it/s]\n",
      "2025-09-10 11:51:16,138 - INFO - All types `lr` of epoch 378: {'lr/param_group0': 1.1779205810297499e-05, 'lr/param_group1': 1.1779205810297499e-05, 'lr/param_group2': 1.1779205810297499e-05, 'lr/param_group3': 1.1779205810297499e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:16,143 - INFO - epoch 378: train loss 0.006205094852096711\n",
      "2025-09-10 11:51:16,147 - INFO - 378 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:16,151 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:16,155 - INFO - --------------------\n",
      "\n",
      "379/600: 100%|██████████| 216/216 [00:08<00:00, 24.76it/s]\n",
      "2025-09-10 11:51:25,079 - INFO - All types `lr` of epoch 379: {'lr/param_group0': 1.1006324214109518e-05, 'lr/param_group1': 1.1006324214109518e-05, 'lr/param_group2': 1.1006324214109518e-05, 'lr/param_group3': 1.1006324214109518e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:25,083 - INFO - epoch 379: train loss 0.006201079936646339\n",
      "2025-09-10 11:51:25,088 - INFO - 379 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:25,092 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:25,096 - INFO - --------------------\n",
      "\n",
      "380/600: 100%|██████████| 216/216 [00:07<00:00, 27.72it/s]\n",
      "2025-09-10 11:51:33,097 - INFO - All types `lr` of epoch 380: {'lr/param_group0': 1.0268107330169672e-05, 'lr/param_group1': 1.0268107330169672e-05, 'lr/param_group2': 1.0268107330169672e-05, 'lr/param_group3': 1.0268107330169672e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:33,102 - INFO - epoch 380: train loss 0.006202261998421616\n",
      "2025-09-10 11:51:33,107 - INFO - 380 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:33,111 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:33,115 - INFO - --------------------\n",
      "\n",
      "381/600: 100%|██████████| 216/216 [00:08<00:00, 26.15it/s]\n",
      "2025-09-10 11:51:41,574 - INFO - All types `lr` of epoch 381: {'lr/param_group0': 9.564737302448001e-06, 'lr/param_group1': 9.564737302448001e-06, 'lr/param_group2': 9.564737302448001e-06, 'lr/param_group3': 9.564737302448001e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:41,580 - INFO - epoch 381: train loss 0.006199348427967548\n",
      "2025-09-10 11:51:41,584 - INFO - 381 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:41,588 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:41,591 - INFO - --------------------\n",
      "\n",
      "382/600: 100%|██████████| 216/216 [00:08<00:00, 26.13it/s]\n",
      "2025-09-10 11:51:50,059 - INFO - All types `lr` of epoch 382: {'lr/param_group0': 8.896387676973949e-06, 'lr/param_group1': 8.896387676973949e-06, 'lr/param_group2': 8.896387676973949e-06, 'lr/param_group3': 8.896387676973949e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:50,065 - INFO - epoch 382: train loss 0.006196030687230329\n",
      "2025-09-10 11:51:50,070 - INFO - 382 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:50,074 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:50,079 - INFO - --------------------\n",
      "\n",
      "383/600: 100%|██████████| 216/216 [00:08<00:00, 24.73it/s]\n",
      "2025-09-10 11:51:59,021 - INFO - All types `lr` of epoch 383: {'lr/param_group0': 8.26322335901699e-06, 'lr/param_group1': 8.26322335901699e-06, 'lr/param_group2': 8.26322335901699e-06, 'lr/param_group3': 8.26322335901699e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:51:59,025 - INFO - epoch 383: train loss 0.006190603555835507\n",
      "2025-09-10 11:51:59,030 - INFO - 383 epochs completed!\n",
      "\n",
      "2025-09-10 11:51:59,034 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:51:59,038 - INFO - --------------------\n",
      "\n",
      "384/600: 100%|██████████| 216/216 [00:08<00:00, 25.20it/s]\n",
      "2025-09-10 11:52:07,819 - INFO - All types `lr` of epoch 384: {'lr/param_group0': 7.665400572398272e-06, 'lr/param_group1': 7.665400572398272e-06, 'lr/param_group2': 7.665400572398272e-06, 'lr/param_group3': 7.665400572398272e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:07,823 - INFO - epoch 384: train loss 0.006191353639156592\n",
      "2025-09-10 11:52:07,828 - INFO - 384 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:07,833 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:07,837 - INFO - --------------------\n",
      "\n",
      "385/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:52:16,850 - INFO - All types `lr` of epoch 385: {'lr/param_group0': 7.103066820945047e-06, 'lr/param_group1': 7.103066820945047e-06, 'lr/param_group2': 7.103066820945047e-06, 'lr/param_group3': 7.103066820945047e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:16,855 - INFO - epoch 385: train loss 0.006191501072694168\n",
      "2025-09-10 11:52:16,860 - INFO - 385 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:16,864 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:16,868 - INFO - --------------------\n",
      "\n",
      "386/600: 100%|██████████| 216/216 [00:08<00:00, 24.48it/s]\n",
      "2025-09-10 11:52:25,899 - INFO - All types `lr` of epoch 386: {'lr/param_group0': 6.576360852096019e-06, 'lr/param_group1': 6.576360852096019e-06, 'lr/param_group2': 6.576360852096019e-06, 'lr/param_group3': 6.576360852096019e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:25,904 - INFO - epoch 386: train loss 0.006191182142140827\n",
      "2025-09-10 11:52:25,909 - INFO - 386 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:25,913 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:25,918 - INFO - --------------------\n",
      "\n",
      "387/600: 100%|██████████| 216/216 [00:08<00:00, 24.21it/s]\n",
      "2025-09-10 11:52:35,046 - INFO - All types `lr` of epoch 387: {'lr/param_group0': 6.085412622667795e-06, 'lr/param_group1': 6.085412622667795e-06, 'lr/param_group2': 6.085412622667795e-06, 'lr/param_group3': 6.085412622667795e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:35,051 - INFO - epoch 387: train loss 0.006190302352748673\n",
      "2025-09-10 11:52:35,056 - INFO - 387 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:35,061 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:35,065 - INFO - --------------------\n",
      "\n",
      "388/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:52:44,071 - INFO - All types `lr` of epoch 388: {'lr/param_group0': 5.630343266789739e-06, 'lr/param_group1': 5.630343266789739e-06, 'lr/param_group2': 5.630343266789739e-06, 'lr/param_group3': 5.630343266789739e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:44,075 - INFO - epoch 388: train loss 0.006187505474641781\n",
      "2025-09-10 11:52:44,080 - INFO - 388 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:44,084 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:44,088 - INFO - --------------------\n",
      "\n",
      "389/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:52:53,102 - INFO - All types `lr` of epoch 389: {'lr/param_group0': 5.211265066016068e-06, 'lr/param_group1': 5.211265066016068e-06, 'lr/param_group2': 5.211265066016068e-06, 'lr/param_group3': 5.211265066016068e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:52:53,108 - INFO - epoch 389: train loss 0.0061838266868747905\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.08it/s]\n",
      "2025-09-10 11:52:55,052 - INFO - epoch 389: val loss 0.006416185845241502\n",
      "2025-09-10 11:52:55,058 - INFO - 389 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:52:55,107 - INFO - 389 epochs completed!\n",
      "\n",
      "2025-09-10 11:52:55,111 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:52:55,115 - INFO - --------------------\n",
      "\n",
      "390/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:53:04,130 - INFO - All types `lr` of epoch 390: {'lr/param_group0': 4.8282814216220265e-06, 'lr/param_group1': 4.8282814216220265e-06, 'lr/param_group2': 4.8282814216220265e-06, 'lr/param_group3': 4.8282814216220265e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:04,135 - INFO - epoch 390: train loss 0.006183181228590439\n",
      "2025-09-10 11:53:04,140 - INFO - 390 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:04,144 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:04,148 - INFO - --------------------\n",
      "\n",
      "391/600: 100%|██████████| 216/216 [00:08<00:00, 24.07it/s]\n",
      "2025-09-10 11:53:13,326 - INFO - All types `lr` of epoch 391: {'lr/param_group0': 4.4814868290912184e-06, 'lr/param_group1': 4.4814868290912184e-06, 'lr/param_group2': 4.4814868290912184e-06, 'lr/param_group3': 4.4814868290912184e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:13,332 - INFO - epoch 391: train loss 0.0061829734240072196\n",
      "2025-09-10 11:53:13,338 - INFO - 391 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:13,343 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:13,347 - INFO - --------------------\n",
      "\n",
      "392/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 11:53:22,428 - INFO - All types `lr` of epoch 392: {'lr/param_group0': 4.170966854800062e-06, 'lr/param_group1': 4.170966854800062e-06, 'lr/param_group2': 4.170966854800062e-06, 'lr/param_group3': 4.170966854800062e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:22,433 - INFO - epoch 392: train loss 0.006184633019276791\n",
      "2025-09-10 11:53:22,438 - INFO - 392 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:22,442 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:22,447 - INFO - --------------------\n",
      "\n",
      "393/600: 100%|██████████| 216/216 [00:08<00:00, 24.75it/s]\n",
      "2025-09-10 11:53:31,382 - INFO - All types `lr` of epoch 393: {'lr/param_group0': 3.896798114905841e-06, 'lr/param_group1': 3.896798114905841e-06, 'lr/param_group2': 3.896798114905841e-06, 'lr/param_group3': 3.896798114905841e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:31,387 - INFO - epoch 393: train loss 0.0061843062468580215\n",
      "2025-09-10 11:53:31,393 - INFO - 393 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:31,398 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:31,402 - INFO - --------------------\n",
      "\n",
      "394/600: 100%|██████████| 216/216 [00:08<00:00, 24.55it/s]\n",
      "2025-09-10 11:53:40,412 - INFO - All types `lr` of epoch 394: {'lr/param_group0': 3.6590482564426316e-06, 'lr/param_group1': 3.6590482564426316e-06, 'lr/param_group2': 3.6590482564426316e-06, 'lr/param_group3': 3.6590482564426316e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:40,418 - INFO - epoch 394: train loss 0.006184330606764114\n",
      "2025-09-10 11:53:40,423 - INFO - 394 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:40,428 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:40,432 - INFO - --------------------\n",
      "\n",
      "395/600: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s]\n",
      "2025-09-10 11:53:49,458 - INFO - All types `lr` of epoch 395: {'lr/param_group0': 3.4577759406304806e-06, 'lr/param_group1': 3.4577759406304806e-06, 'lr/param_group2': 3.4577759406304806e-06, 'lr/param_group3': 3.4577759406304806e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:49,463 - INFO - epoch 395: train loss 0.006185225869692793\n",
      "2025-09-10 11:53:49,469 - INFO - 395 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:49,473 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:49,477 - INFO - --------------------\n",
      "\n",
      "396/600: 100%|██████████| 216/216 [00:08<00:00, 24.09it/s]\n",
      "2025-09-10 11:53:58,642 - INFO - All types `lr` of epoch 396: {'lr/param_group0': 3.293030828401688e-06, 'lr/param_group1': 3.293030828401688e-06, 'lr/param_group2': 3.293030828401688e-06, 'lr/param_group3': 3.293030828401688e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:53:58,647 - INFO - epoch 396: train loss 0.006185602112155821\n",
      "2025-09-10 11:53:58,652 - INFO - 396 epochs completed!\n",
      "\n",
      "2025-09-10 11:53:58,656 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:53:58,659 - INFO - --------------------\n",
      "\n",
      "397/600: 100%|██████████| 216/216 [00:08<00:00, 25.00it/s]\n",
      "2025-09-10 11:54:07,505 - INFO - All types `lr` of epoch 397: {'lr/param_group0': 3.164853568147474e-06, 'lr/param_group1': 3.164853568147474e-06, 'lr/param_group2': 3.164853568147474e-06, 'lr/param_group3': 3.164853568147474e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:07,510 - INFO - epoch 397: train loss 0.006184715574986681\n",
      "2025-09-10 11:54:07,515 - INFO - 397 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:07,519 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:07,523 - INFO - --------------------\n",
      "\n",
      "398/600: 100%|██████████| 216/216 [00:08<00:00, 24.59it/s]\n",
      "2025-09-10 11:54:16,514 - INFO - All types `lr` of epoch 398: {'lr/param_group0': 3.073275785688867e-06, 'lr/param_group1': 3.073275785688867e-06, 'lr/param_group2': 3.073275785688867e-06, 'lr/param_group3': 3.073275785688867e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:16,519 - INFO - epoch 398: train loss 0.006185417735078199\n",
      "2025-09-10 11:54:16,524 - INFO - 398 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:16,528 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:16,532 - INFO - --------------------\n",
      "\n",
      "399/600: 100%|██████████| 216/216 [00:08<00:00, 24.90it/s]\n",
      "2025-09-10 11:54:25,410 - INFO - All types `lr` of epoch 399: {'lr/param_group0': 3.0183200764734126e-06, 'lr/param_group1': 3.0183200764734126e-06, 'lr/param_group2': 3.0183200764734126e-06, 'lr/param_group3': 3.0183200764734126e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:25,414 - INFO - epoch 399: train loss 0.00618488885919322\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.10it/s]\n",
      "2025-09-10 11:54:27,355 - INFO - epoch 399: val loss 0.006423992898177217\n",
      "2025-09-10 11:54:27,363 - INFO - 399 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:54:27,436 - INFO - epoch 399 has been saved\n",
      "2025-09-10 11:54:27,543 - INFO - 399 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:27,548 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:27,554 - INFO - --------------------\n",
      "\n",
      "400/600: 100%|██████████| 216/216 [00:08<00:00, 24.52it/s]\n",
      "2025-09-10 11:54:36,579 - INFO - All types `lr` of epoch 400: {'lr/param_group0': 0.0003, 'lr/param_group1': 0.0003, 'lr/param_group2': 0.0003, 'lr/param_group3': 0.0003}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:36,584 - INFO - epoch 400: train loss 0.028943863636986526\n",
      "2025-09-10 11:54:36,588 - INFO - 400 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:36,592 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:36,596 - INFO - --------------------\n",
      "\n",
      "401/600: 100%|██████████| 216/216 [00:08<00:00, 24.64it/s]\n",
      "2025-09-10 11:54:45,577 - INFO - All types `lr` of epoch 401: {'lr/param_group0': 0.00029998167992352655, 'lr/param_group1': 0.00029998167992352655, 'lr/param_group2': 0.00029998167992352655, 'lr/param_group3': 0.00029998167992352655}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:45,583 - INFO - epoch 401: train loss 0.01084023712987632\n",
      "2025-09-10 11:54:45,588 - INFO - 401 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:45,591 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:45,595 - INFO - --------------------\n",
      "\n",
      "402/600: 100%|██████████| 216/216 [00:08<00:00, 24.95it/s]\n",
      "2025-09-10 11:54:54,464 - INFO - All types `lr` of epoch 402: {'lr/param_group0': 0.00029992672421431113, 'lr/param_group1': 0.00029992672421431113, 'lr/param_group2': 0.00029992672421431113, 'lr/param_group3': 0.00029992672421431113}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:54:54,469 - INFO - epoch 402: train loss 0.008561264986551746\n",
      "2025-09-10 11:54:54,474 - INFO - 402 epochs completed!\n",
      "\n",
      "2025-09-10 11:54:54,478 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:54:54,481 - INFO - --------------------\n",
      "\n",
      "403/600: 100%|██████████| 216/216 [00:08<00:00, 25.16it/s]\n",
      "2025-09-10 11:55:03,269 - INFO - All types `lr` of epoch 403: {'lr/param_group0': 0.0002998351464318525, 'lr/param_group1': 0.0002998351464318525, 'lr/param_group2': 0.0002998351464318525, 'lr/param_group3': 0.0002998351464318525}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:03,274 - INFO - epoch 403: train loss 0.007828021605274882\n",
      "2025-09-10 11:55:03,279 - INFO - 403 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:03,284 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:03,288 - INFO - --------------------\n",
      "\n",
      "404/600: 100%|██████████| 216/216 [00:08<00:00, 24.45it/s]\n",
      "2025-09-10 11:55:12,332 - INFO - All types `lr` of epoch 404: {'lr/param_group0': 0.0002997069691715983, 'lr/param_group1': 0.0002997069691715983, 'lr/param_group2': 0.0002997069691715983, 'lr/param_group3': 0.0002997069691715983}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:12,338 - INFO - epoch 404: train loss 0.007528656774579927\n",
      "2025-09-10 11:55:12,342 - INFO - 404 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:12,346 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:12,350 - INFO - --------------------\n",
      "\n",
      "405/600: 100%|██████████| 216/216 [00:08<00:00, 24.48it/s]\n",
      "2025-09-10 11:55:21,375 - INFO - All types `lr` of epoch 405: {'lr/param_group0': 0.00029954222405936945, 'lr/param_group1': 0.00029954222405936945, 'lr/param_group2': 0.00029954222405936945, 'lr/param_group3': 0.00029954222405936945}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:21,379 - INFO - epoch 405: train loss 0.007321066104513766\n",
      "2025-09-10 11:55:21,385 - INFO - 405 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:21,389 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:21,393 - INFO - --------------------\n",
      "\n",
      "406/600: 100%|██████████| 216/216 [00:08<00:00, 24.58it/s]\n",
      "2025-09-10 11:55:30,390 - INFO - All types `lr` of epoch 406: {'lr/param_group0': 0.00029934095174355733, 'lr/param_group1': 0.00029934095174355733, 'lr/param_group2': 0.00029934095174355733, 'lr/param_group3': 0.00029934095174355733}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:30,395 - INFO - epoch 406: train loss 0.0072396153290928515\n",
      "2025-09-10 11:55:30,400 - INFO - 406 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:30,404 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:30,409 - INFO - --------------------\n",
      "\n",
      "407/600: 100%|██████████| 216/216 [00:08<00:00, 24.79it/s]\n",
      "2025-09-10 11:55:39,330 - INFO - All types `lr` of epoch 407: {'lr/param_group0': 0.00029910320188509414, 'lr/param_group1': 0.00029910320188509414, 'lr/param_group2': 0.00029910320188509414, 'lr/param_group3': 0.00029910320188509414}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:39,335 - INFO - epoch 407: train loss 0.007057148665707145\n",
      "2025-09-10 11:55:39,340 - INFO - 407 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:39,344 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:39,348 - INFO - --------------------\n",
      "\n",
      "408/600: 100%|██████████| 216/216 [00:08<00:00, 24.32it/s]\n",
      "2025-09-10 11:55:48,436 - INFO - All types `lr` of epoch 408: {'lr/param_group0': 0.00029882903314519993, 'lr/param_group1': 0.00029882903314519993, 'lr/param_group2': 0.00029882903314519993, 'lr/param_group3': 0.00029882903314519993}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:48,441 - INFO - epoch 408: train loss 0.007031145315893271\n",
      "2025-09-10 11:55:48,446 - INFO - 408 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:48,449 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:48,453 - INFO - --------------------\n",
      "\n",
      "409/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:55:57,436 - INFO - All types `lr` of epoch 409: {'lr/param_group0': 0.00029851851317090877, 'lr/param_group1': 0.00029851851317090877, 'lr/param_group2': 0.00029851851317090877, 'lr/param_group3': 0.00029851851317090877}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:55:57,441 - INFO - epoch 409: train loss 0.00690108196835758\n",
      "2025-09-10 11:55:57,447 - INFO - 409 epochs completed!\n",
      "\n",
      "2025-09-10 11:55:57,450 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:55:57,454 - INFO - --------------------\n",
      "\n",
      "410/600: 100%|██████████| 216/216 [00:08<00:00, 24.12it/s]\n",
      "2025-09-10 11:56:06,616 - INFO - All types `lr` of epoch 410: {'lr/param_group0': 0.0002981717185783779, 'lr/param_group1': 0.0002981717185783779, 'lr/param_group2': 0.0002981717185783779, 'lr/param_group3': 0.0002981717185783779}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:06,620 - INFO - epoch 410: train loss 0.006740622884266217\n",
      "2025-09-10 11:56:06,624 - INFO - 410 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:06,628 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:06,632 - INFO - --------------------\n",
      "\n",
      "411/600: 100%|██████████| 216/216 [00:08<00:00, 24.32it/s]\n",
      "2025-09-10 11:56:15,715 - INFO - All types `lr` of epoch 411: {'lr/param_group0': 0.0002977887349339839, 'lr/param_group1': 0.0002977887349339839, 'lr/param_group2': 0.0002977887349339839, 'lr/param_group3': 0.0002977887349339839}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:15,719 - INFO - epoch 411: train loss 0.006702351845214488\n",
      "2025-09-10 11:56:15,724 - INFO - 411 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:15,728 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:15,732 - INFO - --------------------\n",
      "\n",
      "412/600: 100%|██████████| 216/216 [00:08<00:00, 24.80it/s]\n",
      "2025-09-10 11:56:24,649 - INFO - All types `lr` of epoch 412: {'lr/param_group0': 0.00029736965673321026, 'lr/param_group1': 0.00029736965673321026, 'lr/param_group2': 0.00029736965673321026, 'lr/param_group3': 0.00029736965673321026}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:24,656 - INFO - epoch 412: train loss 0.006622798755954675\n",
      "2025-09-10 11:56:24,661 - INFO - 412 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:24,665 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:24,670 - INFO - --------------------\n",
      "\n",
      "413/600: 100%|██████████| 216/216 [00:08<00:00, 24.74it/s]\n",
      "2025-09-10 11:56:33,617 - INFO - All types `lr` of epoch 413: {'lr/param_group0': 0.00029691458737733217, 'lr/param_group1': 0.00029691458737733217, 'lr/param_group2': 0.00029691458737733217, 'lr/param_group3': 0.00029691458737733217}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:33,622 - INFO - epoch 413: train loss 0.006579219042409763\n",
      "2025-09-10 11:56:33,627 - INFO - 413 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:33,632 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:33,636 - INFO - --------------------\n",
      "\n",
      "414/600: 100%|██████████| 216/216 [00:08<00:00, 24.72it/s]\n",
      "2025-09-10 11:56:42,581 - INFO - All types `lr` of epoch 414: {'lr/param_group0': 0.00029642363914790396, 'lr/param_group1': 0.00029642363914790396, 'lr/param_group2': 0.00029642363914790396, 'lr/param_group3': 0.00029642363914790396}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:42,586 - INFO - epoch 414: train loss 0.0065606059334068385\n",
      "2025-09-10 11:56:42,591 - INFO - 414 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:42,595 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:42,599 - INFO - --------------------\n",
      "\n",
      "415/600: 100%|██████████| 216/216 [00:08<00:00, 24.18it/s]\n",
      "2025-09-10 11:56:51,735 - INFO - All types `lr` of epoch 415: {'lr/param_group0': 0.00029589693317905494, 'lr/param_group1': 0.00029589693317905494, 'lr/param_group2': 0.00029589693317905494, 'lr/param_group3': 0.00029589693317905494}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:56:51,741 - INFO - epoch 415: train loss 0.006480790494673851\n",
      "2025-09-10 11:56:51,746 - INFO - 415 epochs completed!\n",
      "\n",
      "2025-09-10 11:56:51,750 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:56:51,755 - INFO - --------------------\n",
      "\n",
      "416/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 11:57:00,644 - INFO - All types `lr` of epoch 416: {'lr/param_group0': 0.0002953345994276017, 'lr/param_group1': 0.0002953345994276017, 'lr/param_group2': 0.0002953345994276017, 'lr/param_group3': 0.0002953345994276017}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:00,648 - INFO - epoch 416: train loss 0.006469213037268707\n",
      "2025-09-10 11:57:00,653 - INFO - 416 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:00,657 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:00,662 - INFO - --------------------\n",
      "\n",
      "417/600: 100%|██████████| 216/216 [00:08<00:00, 24.39it/s]\n",
      "2025-09-10 11:57:09,722 - INFO - All types `lr` of epoch 417: {'lr/param_group0': 0.000294736776640983, 'lr/param_group1': 0.000294736776640983, 'lr/param_group2': 0.000294736776640983, 'lr/param_group3': 0.000294736776640983}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:09,727 - INFO - epoch 417: train loss 0.0065178449246256305\n",
      "2025-09-10 11:57:09,731 - INFO - 417 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:09,735 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:09,739 - INFO - --------------------\n",
      "\n",
      "418/600: 100%|██████████| 216/216 [00:08<00:00, 24.26it/s]\n",
      "2025-09-10 11:57:18,845 - INFO - All types `lr` of epoch 418: {'lr/param_group0': 0.00029410361232302604, 'lr/param_group1': 0.00029410361232302604, 'lr/param_group2': 0.00029410361232302604, 'lr/param_group3': 0.00029410361232302604}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:18,850 - INFO - epoch 418: train loss 0.00651354256896647\n",
      "2025-09-10 11:57:18,855 - INFO - 418 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:18,860 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:18,864 - INFO - --------------------\n",
      "\n",
      "419/600: 100%|██████████| 216/216 [00:08<00:00, 24.57it/s]\n",
      "2025-09-10 11:57:27,863 - INFO - All types `lr` of epoch 419: {'lr/param_group0': 0.000293435262697552, 'lr/param_group1': 0.000293435262697552, 'lr/param_group2': 0.000293435262697552, 'lr/param_group3': 0.000293435262697552}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:27,868 - INFO - epoch 419: train loss 0.006479148220495079\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.75it/s]\n",
      "2025-09-10 11:57:29,788 - INFO - epoch 419: val loss 0.00673969702243253\n",
      "2025-09-10 11:57:29,795 - INFO - 419 epoch vae reconstruct images complete!\n",
      "2025-09-10 11:57:29,846 - INFO - 419 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:29,850 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:29,854 - INFO - --------------------\n",
      "\n",
      "420/600: 100%|██████████| 216/216 [00:08<00:00, 24.50it/s]\n",
      "2025-09-10 11:57:38,869 - INFO - All types `lr` of epoch 420: {'lr/param_group0': 0.00029273189266983027, 'lr/param_group1': 0.00029273189266983027, 'lr/param_group2': 0.00029273189266983027, 'lr/param_group3': 0.00029273189266983027}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:38,873 - INFO - epoch 420: train loss 0.006449600778675328\n",
      "2025-09-10 11:57:38,877 - INFO - 420 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:38,880 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:38,883 - INFO - --------------------\n",
      "\n",
      "421/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 11:57:46,970 - INFO - All types `lr` of epoch 421: {'lr/param_group0': 0.00029199367578589046, 'lr/param_group1': 0.00029199367578589046, 'lr/param_group2': 0.00029199367578589046, 'lr/param_group3': 0.00029199367578589046}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:46,974 - INFO - epoch 421: train loss 0.006417503746450637\n",
      "2025-09-10 11:57:46,977 - INFO - 421 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:46,980 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:46,983 - INFO - --------------------\n",
      "\n",
      "422/600: 100%|██████████| 216/216 [00:08<00:00, 24.86it/s]\n",
      "2025-09-10 11:57:55,834 - INFO - All types `lr` of epoch 422: {'lr/param_group0': 0.00029122079418970247, 'lr/param_group1': 0.00029122079418970247, 'lr/param_group2': 0.00029122079418970247, 'lr/param_group3': 0.00029122079418970247}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:57:55,840 - INFO - epoch 422: train loss 0.006551722075393492\n",
      "2025-09-10 11:57:55,846 - INFO - 422 epochs completed!\n",
      "\n",
      "2025-09-10 11:57:55,851 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:57:55,855 - INFO - --------------------\n",
      "\n",
      "423/600: 100%|██████████| 216/216 [00:08<00:00, 24.88it/s]\n",
      "2025-09-10 11:58:04,739 - INFO - All types `lr` of epoch 423: {'lr/param_group0': 0.0002904134385782353, 'lr/param_group1': 0.0002904134385782353, 'lr/param_group2': 0.0002904134385782353, 'lr/param_group3': 0.0002904134385782353}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:04,744 - INFO - epoch 423: train loss 0.008360610037386694\n",
      "2025-09-10 11:58:04,751 - INFO - 423 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:04,755 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:04,759 - INFO - --------------------\n",
      "\n",
      "424/600: 100%|██████████| 216/216 [00:08<00:00, 24.43it/s]\n",
      "2025-09-10 11:58:13,803 - INFO - All types `lr` of epoch 424: {'lr/param_group0': 0.00028957180815440534, 'lr/param_group1': 0.00028957180815440534, 'lr/param_group2': 0.00028957180815440534, 'lr/param_group3': 0.00028957180815440534}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:13,809 - INFO - epoch 424: train loss 0.0071393846344478705\n",
      "2025-09-10 11:58:13,814 - INFO - 424 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:13,818 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:13,822 - INFO - --------------------\n",
      "\n",
      "425/600: 100%|██████████| 216/216 [00:09<00:00, 23.91it/s]\n",
      "2025-09-10 11:58:23,059 - INFO - All types `lr` of epoch 425: {'lr/param_group0': 0.00028869611057792606, 'lr/param_group1': 0.00028869611057792606, 'lr/param_group2': 0.00028869611057792606, 'lr/param_group3': 0.00028869611057792606}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:23,064 - INFO - epoch 425: train loss 0.0065009392457324325\n",
      "2025-09-10 11:58:23,069 - INFO - 425 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:23,073 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:23,077 - INFO - --------------------\n",
      "\n",
      "426/600: 100%|██████████| 216/216 [00:07<00:00, 27.79it/s]\n",
      "2025-09-10 11:58:31,061 - INFO - All types `lr` of epoch 426: {'lr/param_group0': 0.00028778656191407115, 'lr/param_group1': 0.00028778656191407115, 'lr/param_group2': 0.00028778656191407115, 'lr/param_group3': 0.00028778656191407115}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:31,065 - INFO - epoch 426: train loss 0.006451795047959658\n",
      "2025-09-10 11:58:31,069 - INFO - 426 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:31,072 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:31,076 - INFO - --------------------\n",
      "\n",
      "427/600: 100%|██████████| 216/216 [00:08<00:00, 24.92it/s]\n",
      "2025-09-10 11:58:39,945 - INFO - All types `lr` of epoch 427: {'lr/param_group0': 0.0002868433865803636, 'lr/param_group1': 0.0002868433865803636, 'lr/param_group2': 0.0002868433865803636, 'lr/param_group3': 0.0002868433865803636}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:39,949 - INFO - epoch 427: train loss 0.006537941670372944\n",
      "2025-09-10 11:58:39,953 - INFO - 427 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:39,956 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:39,959 - INFO - --------------------\n",
      "\n",
      "428/600: 100%|██████████| 216/216 [00:07<00:00, 27.29it/s]\n",
      "2025-09-10 11:58:48,034 - INFO - All types `lr` of epoch 428: {'lr/param_group0': 0.00028586681729120386, 'lr/param_group1': 0.00028586681729120386, 'lr/param_group2': 0.00028586681729120386, 'lr/param_group3': 0.00028586681729120386}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:48,038 - INFO - epoch 428: train loss 0.007664564274751616\n",
      "2025-09-10 11:58:48,042 - INFO - 428 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:48,045 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:48,048 - INFO - --------------------\n",
      "\n",
      "429/600: 100%|██████████| 216/216 [00:08<00:00, 25.34it/s]\n",
      "2025-09-10 11:58:56,735 - INFO - All types `lr` of epoch 429: {'lr/param_group0': 0.0002848570950004514, 'lr/param_group1': 0.0002848570950004514, 'lr/param_group2': 0.0002848570950004514, 'lr/param_group3': 0.0002848570950004514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:58:56,740 - INFO - epoch 429: train loss 0.007524186659052416\n",
      "2025-09-10 11:58:56,746 - INFO - 429 epochs completed!\n",
      "\n",
      "2025-09-10 11:58:56,751 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:58:56,755 - INFO - --------------------\n",
      "\n",
      "430/600: 100%|██████████| 216/216 [00:08<00:00, 24.69it/s]\n",
      "2025-09-10 11:59:05,713 - INFO - All types `lr` of epoch 430: {'lr/param_group0': 0.0002838144688419726, 'lr/param_group1': 0.0002838144688419726, 'lr/param_group2': 0.0002838144688419726, 'lr/param_group3': 0.0002838144688419726}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:05,718 - INFO - epoch 430: train loss 0.006524426569403322\n",
      "2025-09-10 11:59:05,723 - INFO - 430 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:05,728 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:05,732 - INFO - --------------------\n",
      "\n",
      "431/600: 100%|██████████| 216/216 [00:08<00:00, 24.60it/s]\n",
      "2025-09-10 11:59:14,714 - INFO - All types `lr` of epoch 431: {'lr/param_group0': 0.000282739196068171, 'lr/param_group1': 0.000282739196068171, 'lr/param_group2': 0.000282739196068171, 'lr/param_group3': 0.000282739196068171}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:14,720 - INFO - epoch 431: train loss 0.0063088934047199376\n",
      "2025-09-10 11:59:14,725 - INFO - 431 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:14,730 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:14,734 - INFO - --------------------\n",
      "\n",
      "432/600: 100%|██████████| 216/216 [00:08<00:00, 24.29it/s]\n",
      "2025-09-10 11:59:23,831 - INFO - All types `lr` of epoch 432: {'lr/param_group0': 0.00028163154198651373, 'lr/param_group1': 0.00028163154198651373, 'lr/param_group2': 0.00028163154198651373, 'lr/param_group3': 0.00028163154198651373}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:23,836 - INFO - epoch 432: train loss 0.006283461584071456\n",
      "2025-09-10 11:59:23,841 - INFO - 432 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:23,846 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:23,851 - INFO - --------------------\n",
      "\n",
      "433/600: 100%|██████████| 216/216 [00:08<00:00, 24.44it/s]\n",
      "2025-09-10 11:59:32,895 - INFO - All types `lr` of epoch 433: {'lr/param_group0': 0.00028049177989407137, 'lr/param_group1': 0.00028049177989407137, 'lr/param_group2': 0.00028049177989407137, 'lr/param_group3': 0.00028049177989407137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:32,900 - INFO - epoch 433: train loss 0.006293840819529982\n",
      "2025-09-10 11:59:32,905 - INFO - 433 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:32,910 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:32,914 - INFO - --------------------\n",
      "\n",
      "434/600: 100%|██████████| 216/216 [00:08<00:00, 24.61it/s]\n",
      "2025-09-10 11:59:41,898 - INFO - All types `lr` of epoch 434: {'lr/param_group0': 0.0002793201910100856, 'lr/param_group1': 0.0002793201910100856, 'lr/param_group2': 0.0002793201910100856, 'lr/param_group3': 0.0002793201910100856}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:41,903 - INFO - epoch 434: train loss 0.007121102591217668\n",
      "2025-09-10 11:59:41,909 - INFO - 434 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:41,914 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:41,918 - INFO - --------------------\n",
      "\n",
      "435/600: 100%|██████████| 216/216 [00:08<00:00, 26.95it/s]\n",
      "2025-09-10 11:59:50,149 - INFO - All types `lr` of epoch 435: {'lr/param_group0': 0.0002781170644065827, 'lr/param_group1': 0.0002781170644065827, 'lr/param_group2': 0.0002781170644065827, 'lr/param_group3': 0.0002781170644065827}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:50,152 - INFO - epoch 435: train loss 0.007610119821038097\n",
      "2025-09-10 11:59:50,156 - INFO - 435 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:50,160 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:50,163 - INFO - --------------------\n",
      "\n",
      "436/600: 100%|██████████| 216/216 [00:08<00:00, 25.32it/s]\n",
      "2025-09-10 11:59:58,862 - INFO - All types `lr` of epoch 436: {'lr/param_group0': 0.0002768826969370492, 'lr/param_group1': 0.0002768826969370492, 'lr/param_group2': 0.0002768826969370492, 'lr/param_group3': 0.0002768826969370492}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 11:59:58,868 - INFO - epoch 436: train loss 0.006371749485239248\n",
      "2025-09-10 11:59:58,874 - INFO - 436 epochs completed!\n",
      "\n",
      "2025-09-10 11:59:58,879 - INFO - --------------------\n",
      "\n",
      "2025-09-10 11:59:58,883 - INFO - --------------------\n",
      "\n",
      "437/600: 100%|██████████| 216/216 [00:08<00:00, 25.10it/s]\n",
      "2025-09-10 12:00:07,707 - INFO - All types `lr` of epoch 437: {'lr/param_group0': 0.0002756173931631881, 'lr/param_group1': 0.0002756173931631881, 'lr/param_group2': 0.0002756173931631881, 'lr/param_group3': 0.0002756173931631881}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:07,712 - INFO - epoch 437: train loss 0.0062311168660892655\n",
      "2025-09-10 12:00:07,718 - INFO - 437 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:07,722 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:07,727 - INFO - --------------------\n",
      "\n",
      "438/600: 100%|██████████| 216/216 [00:08<00:00, 25.96it/s]\n",
      "2025-09-10 12:00:16,253 - INFO - All types `lr` of epoch 438: {'lr/param_group0': 0.0002743214652797724, 'lr/param_group1': 0.0002743214652797724, 'lr/param_group2': 0.0002743214652797724, 'lr/param_group3': 0.0002743214652797724}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:16,258 - INFO - epoch 438: train loss 0.006210849028623973\n",
      "2025-09-10 12:00:16,264 - INFO - 438 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:16,269 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:16,273 - INFO - --------------------\n",
      "\n",
      "439/600: 100%|██████████| 216/216 [00:08<00:00, 24.79it/s]\n",
      "2025-09-10 12:00:25,202 - INFO - All types `lr` of epoch 439: {'lr/param_group0': 0.00027299523303761595, 'lr/param_group1': 0.00027299523303761595, 'lr/param_group2': 0.00027299523303761595, 'lr/param_group3': 0.00027299523303761595}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:25,208 - INFO - epoch 439: train loss 0.006204616676162307\n",
      "2025-09-10 12:00:25,213 - INFO - 439 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:25,218 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:25,222 - INFO - --------------------\n",
      "\n",
      "440/600: 100%|██████████| 216/216 [00:08<00:00, 25.92it/s]\n",
      "2025-09-10 12:00:33,751 - INFO - All types `lr` of epoch 440: {'lr/param_group0': 0.00027163902366467965, 'lr/param_group1': 0.00027163902366467965, 'lr/param_group2': 0.00027163902366467965, 'lr/param_group3': 0.00027163902366467965}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:33,756 - INFO - epoch 440: train loss 0.006201354908558575\n",
      "2025-09-10 12:00:33,761 - INFO - 440 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:33,766 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:33,770 - INFO - --------------------\n",
      "\n",
      "441/600: 100%|██████████| 216/216 [00:08<00:00, 26.00it/s]\n",
      "2025-09-10 12:00:42,284 - INFO - All types `lr` of epoch 441: {'lr/param_group0': 0.00027025317178533295, 'lr/param_group1': 0.00027025317178533295, 'lr/param_group2': 0.00027025317178533295, 'lr/param_group3': 0.00027025317178533295}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:42,287 - INFO - epoch 441: train loss 0.006208690742453284\n",
      "2025-09-10 12:00:42,290 - INFO - 441 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:42,292 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:42,294 - INFO - --------------------\n",
      "\n",
      "442/600: 100%|██████████| 216/216 [00:07<00:00, 27.03it/s]\n",
      "2025-09-10 12:00:50,445 - INFO - All types `lr` of epoch 442: {'lr/param_group0': 0.00026883801933779, 'lr/param_group1': 0.00026883801933779, 'lr/param_group2': 0.00026883801933779, 'lr/param_group3': 0.00026883801933779}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:50,449 - INFO - epoch 442: train loss 0.006212020994603841\n",
      "2025-09-10 12:00:50,453 - INFO - 442 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:50,457 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:50,460 - INFO - --------------------\n",
      "\n",
      "443/600: 100%|██████████| 216/216 [00:08<00:00, 25.09it/s]\n",
      "2025-09-10 12:00:59,274 - INFO - All types `lr` of epoch 443: {'lr/param_group0': 0.00026739391548974195, 'lr/param_group1': 0.00026739391548974195, 'lr/param_group2': 0.00026739391548974195, 'lr/param_group3': 0.00026739391548974195}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:00:59,280 - INFO - epoch 443: train loss 0.0064133827841875175\n",
      "2025-09-10 12:00:59,285 - INFO - 443 epochs completed!\n",
      "\n",
      "2025-09-10 12:00:59,290 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:00:59,295 - INFO - --------------------\n",
      "\n",
      "444/600: 100%|██████████| 216/216 [00:08<00:00, 24.81it/s]\n",
      "2025-09-10 12:01:08,206 - INFO - All types `lr` of epoch 444: {'lr/param_group0': 0.0002659212165522047, 'lr/param_group1': 0.0002659212165522047, 'lr/param_group2': 0.0002659212165522047, 'lr/param_group3': 0.0002659212165522047}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:08,211 - INFO - epoch 444: train loss 0.007938174379955011\n",
      "2025-09-10 12:01:08,216 - INFO - 444 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:08,220 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:08,225 - INFO - --------------------\n",
      "\n",
      "445/600: 100%|██████████| 216/216 [00:08<00:00, 24.95it/s]\n",
      "2025-09-10 12:01:17,091 - INFO - All types `lr` of epoch 445: {'lr/param_group0': 0.00026442028589160457, 'lr/param_group1': 0.00026442028589160457, 'lr/param_group2': 0.00026442028589160457, 'lr/param_group3': 0.00026442028589160457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:17,095 - INFO - epoch 445: train loss 0.006391818890632648\n",
      "2025-09-10 12:01:17,100 - INFO - 445 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:17,103 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:17,107 - INFO - --------------------\n",
      "\n",
      "446/600: 100%|██████████| 216/216 [00:08<00:00, 25.15it/s]\n",
      "2025-09-10 12:01:25,899 - INFO - All types `lr` of epoch 446: {'lr/param_group0': 0.0002628914938401232, 'lr/param_group1': 0.0002628914938401232, 'lr/param_group2': 0.0002628914938401232, 'lr/param_group3': 0.0002628914938401232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:25,906 - INFO - epoch 446: train loss 0.006183363745178751\n",
      "2025-09-10 12:01:25,911 - INFO - 446 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:25,916 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:25,920 - INFO - --------------------\n",
      "\n",
      "447/600: 100%|██████████| 216/216 [00:08<00:00, 25.14it/s]\n",
      "2025-09-10 12:01:34,726 - INFO - All types `lr` of epoch 447: {'lr/param_group0': 0.0002613352176043235, 'lr/param_group1': 0.0002613352176043235, 'lr/param_group2': 0.0002613352176043235, 'lr/param_group3': 0.0002613352176043235}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:34,732 - INFO - epoch 447: train loss 0.006166183221567836\n",
      "2025-09-10 12:01:34,737 - INFO - 447 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:34,741 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:34,746 - INFO - --------------------\n",
      "\n",
      "448/600: 100%|██████████| 216/216 [00:08<00:00, 26.85it/s]\n",
      "2025-09-10 12:01:43,001 - INFO - All types `lr` of epoch 448: {'lr/param_group0': 0.0002597518411720796, 'lr/param_group1': 0.0002597518411720796, 'lr/param_group2': 0.0002597518411720796, 'lr/param_group3': 0.0002597518411720796}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:43,004 - INFO - epoch 448: train loss 0.00614615854445017\n",
      "2025-09-10 12:01:43,007 - INFO - 448 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:43,011 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:43,014 - INFO - --------------------\n",
      "\n",
      "449/600: 100%|██████████| 216/216 [00:08<00:00, 26.65it/s]\n",
      "2025-09-10 12:01:51,281 - INFO - All types `lr` of epoch 449: {'lr/param_group0': 0.0002581417552178335, 'lr/param_group1': 0.0002581417552178335, 'lr/param_group2': 0.0002581417552178335, 'lr/param_group3': 0.0002581417552178335}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:01:51,287 - INFO - epoch 449: train loss 0.00614627833581633\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.54it/s]\n",
      "2025-09-10 12:01:53,266 - INFO - epoch 449: val loss 0.0063803138349343225\n",
      "2025-09-10 12:01:53,272 - INFO - 449 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:01:53,320 - INFO - 449 epochs completed!\n",
      "\n",
      "2025-09-10 12:01:53,323 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:01:53,328 - INFO - --------------------\n",
      "\n",
      "450/600: 100%|██████████| 216/216 [00:08<00:00, 25.31it/s]\n",
      "2025-09-10 12:02:02,069 - INFO - All types `lr` of epoch 450: {'lr/param_group0': 0.0002565053570062023, 'lr/param_group1': 0.0002565053570062023, 'lr/param_group2': 0.0002565053570062023, 'lr/param_group3': 0.0002565053570062023}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:02,075 - INFO - epoch 450: train loss 0.006158083047786796\n",
      "2025-09-10 12:02:02,080 - INFO - 450 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:02,085 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:02,090 - INFO - --------------------\n",
      "\n",
      "451/600: 100%|██████████| 216/216 [00:08<00:00, 24.28it/s]\n",
      "2025-09-10 12:02:11,199 - INFO - All types `lr` of epoch 451: {'lr/param_group0': 0.00025484305029395865, 'lr/param_group1': 0.00025484305029395865, 'lr/param_group2': 0.00025484305029395865, 'lr/param_group3': 0.00025484305029395865}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:11,205 - INFO - epoch 451: train loss 0.0062647064936485275\n",
      "2025-09-10 12:02:11,210 - INFO - 451 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:11,215 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:11,220 - INFO - --------------------\n",
      "\n",
      "452/600: 100%|██████████| 216/216 [00:09<00:00, 23.99it/s]\n",
      "2025-09-10 12:02:20,425 - INFO - All types `lr` of epoch 452: {'lr/param_group0': 0.0002531552452304102, 'lr/param_group1': 0.0002531552452304102, 'lr/param_group2': 0.0002531552452304102, 'lr/param_group3': 0.0002531552452304102}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:20,430 - INFO - epoch 452: train loss 0.007438987480579979\n",
      "2025-09-10 12:02:20,436 - INFO - 452 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:20,440 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:20,444 - INFO - --------------------\n",
      "\n",
      "453/600: 100%|██████████| 216/216 [00:08<00:00, 25.06it/s]\n",
      "2025-09-10 12:02:29,271 - INFO - All types `lr` of epoch 453: {'lr/param_group0': 0.00025144235825620134, 'lr/param_group1': 0.00025144235825620134, 'lr/param_group2': 0.00025144235825620134, 'lr/param_group3': 0.00025144235825620134}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:29,276 - INFO - epoch 453: train loss 0.006761191289923672\n",
      "2025-09-10 12:02:29,281 - INFO - 453 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:29,286 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:29,290 - INFO - --------------------\n",
      "\n",
      "454/600: 100%|██████████| 216/216 [00:08<00:00, 24.35it/s]\n",
      "2025-09-10 12:02:38,368 - INFO - All types `lr` of epoch 454: {'lr/param_group0': 0.0002497048120005623, 'lr/param_group1': 0.0002497048120005623, 'lr/param_group2': 0.0002497048120005623, 'lr/param_group3': 0.0002497048120005623}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:38,376 - INFO - epoch 454: train loss 0.006186131149728748\n",
      "2025-09-10 12:02:38,381 - INFO - 454 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:38,386 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:38,390 - INFO - --------------------\n",
      "\n",
      "455/600: 100%|██████████| 216/216 [00:08<00:00, 26.62it/s]\n",
      "2025-09-10 12:02:46,730 - INFO - All types `lr` of epoch 455: {'lr/param_group0': 0.0002479430351770322, 'lr/param_group1': 0.0002479430351770322, 'lr/param_group2': 0.0002479430351770322, 'lr/param_group3': 0.0002479430351770322}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:46,734 - INFO - epoch 455: train loss 0.006142602357107939\n",
      "2025-09-10 12:02:46,738 - INFO - 455 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:46,741 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:46,744 - INFO - --------------------\n",
      "\n",
      "456/600: 100%|██████████| 216/216 [00:08<00:00, 25.79it/s]\n",
      "2025-09-10 12:02:55,283 - INFO - All types `lr` of epoch 456: {'lr/param_group0': 0.0002461574624776804, 'lr/param_group1': 0.0002461574624776804, 'lr/param_group2': 0.0002461574624776804, 'lr/param_group3': 0.0002461574624776804}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:02:55,288 - INFO - epoch 456: train loss 0.006140877321336625\n",
      "2025-09-10 12:02:55,292 - INFO - 456 epochs completed!\n",
      "\n",
      "2025-09-10 12:02:55,296 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:02:55,300 - INFO - --------------------\n",
      "\n",
      "457/600: 100%|██████████| 216/216 [00:08<00:00, 25.14it/s]\n",
      "2025-09-10 12:03:04,098 - INFO - All types `lr` of epoch 457: {'lr/param_group0': 0.0002443485344658522, 'lr/param_group1': 0.0002443485344658522, 'lr/param_group2': 0.0002443485344658522, 'lr/param_group3': 0.0002443485344658522}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:04,104 - INFO - epoch 457: train loss 0.006365009059663862\n",
      "2025-09-10 12:03:04,110 - INFO - 457 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:04,115 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:04,119 - INFO - --------------------\n",
      "\n",
      "458/600: 100%|██████████| 216/216 [00:08<00:00, 24.32it/s]\n",
      "2025-09-10 12:03:13,210 - INFO - All types `lr` of epoch 458: {'lr/param_group0': 0.000242516697467467, 'lr/param_group1': 0.000242516697467467, 'lr/param_group2': 0.000242516697467467, 'lr/param_group3': 0.000242516697467467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:13,216 - INFO - epoch 458: train loss 0.007412911155606034\n",
      "2025-09-10 12:03:13,221 - INFO - 458 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:13,226 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:13,230 - INFO - --------------------\n",
      "\n",
      "459/600: 100%|██████████| 216/216 [00:08<00:00, 24.83it/s]\n",
      "2025-09-10 12:03:22,144 - INFO - All types `lr` of epoch 459: {'lr/param_group0': 0.00024066240346089376, 'lr/param_group1': 0.00024066240346089376, 'lr/param_group2': 0.00024066240346089376, 'lr/param_group3': 0.00024066240346089376}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:22,151 - INFO - epoch 459: train loss 0.006406809207638381\n",
      "2025-09-10 12:03:22,156 - INFO - 459 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:22,160 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:22,165 - INFO - --------------------\n",
      "\n",
      "460/600: 100%|██████████| 216/216 [00:08<00:00, 24.43it/s]\n",
      "2025-09-10 12:03:31,213 - INFO - All types `lr` of epoch 460: {'lr/param_group0': 0.00023878610996543227, 'lr/param_group1': 0.00023878610996543227, 'lr/param_group2': 0.00023878610996543227, 'lr/param_group3': 0.00023878610996543227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:31,219 - INFO - epoch 460: train loss 0.006128955044981989\n",
      "2025-09-10 12:03:31,224 - INFO - 460 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:31,228 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:31,233 - INFO - --------------------\n",
      "\n",
      "461/600: 100%|██████████| 216/216 [00:08<00:00, 24.57it/s]\n",
      "2025-09-10 12:03:40,232 - INFO - All types `lr` of epoch 461: {'lr/param_group0': 0.00023688827992842683, 'lr/param_group1': 0.00023688827992842683, 'lr/param_group2': 0.00023688827992842683, 'lr/param_group3': 0.00023688827992842683}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:40,236 - INFO - epoch 461: train loss 0.006111676473800024\n",
      "2025-09-10 12:03:40,240 - INFO - 461 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:40,243 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:40,246 - INFO - --------------------\n",
      "\n",
      "462/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 12:03:48,334 - INFO - All types `lr` of epoch 462: {'lr/param_group0': 0.00023496938161104137, 'lr/param_group1': 0.00023496938161104137, 'lr/param_group2': 0.00023496938161104137, 'lr/param_group3': 0.00023496938161104137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:48,336 - INFO - epoch 462: train loss 0.006098512387662022\n",
      "2025-09-10 12:03:48,339 - INFO - 462 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:48,341 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:48,344 - INFO - --------------------\n",
      "\n",
      "463/600: 100%|██████████| 216/216 [00:08<00:00, 24.87it/s]\n",
      "2025-09-10 12:03:57,197 - INFO - All types `lr` of epoch 463: {'lr/param_group0': 0.00023302988847272255, 'lr/param_group1': 0.00023302988847272255, 'lr/param_group2': 0.00023302988847272255, 'lr/param_group3': 0.00023302988847272255}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:03:57,202 - INFO - epoch 463: train loss 0.006107260107657769\n",
      "2025-09-10 12:03:57,208 - INFO - 463 epochs completed!\n",
      "\n",
      "2025-09-10 12:03:57,213 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:03:57,217 - INFO - --------------------\n",
      "\n",
      "464/600: 100%|██████████| 216/216 [00:08<00:00, 24.30it/s]\n",
      "2025-09-10 12:04:06,319 - INFO - All types `lr` of epoch 464: {'lr/param_group0': 0.00023107027905438097, 'lr/param_group1': 0.00023107027905438097, 'lr/param_group2': 0.00023107027905438097, 'lr/param_group3': 0.00023107027905438097}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:06,324 - INFO - epoch 464: train loss 0.00628448186951034\n",
      "2025-09-10 12:04:06,329 - INFO - 464 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:06,333 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:06,337 - INFO - --------------------\n",
      "\n",
      "465/600: 100%|██████████| 216/216 [00:08<00:00, 25.28it/s]\n",
      "2025-09-10 12:04:15,082 - INFO - All types `lr` of epoch 465: {'lr/param_group0': 0.0002290910368603184, 'lr/param_group1': 0.0002290910368603184, 'lr/param_group2': 0.0002290910368603184, 'lr/param_group3': 0.0002290910368603184}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:15,088 - INFO - epoch 465: train loss 0.007179992896487453\n",
      "2025-09-10 12:04:15,093 - INFO - 465 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:15,098 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:15,102 - INFO - --------------------\n",
      "\n",
      "466/600: 100%|██████████| 216/216 [00:08<00:00, 26.90it/s]\n",
      "2025-09-10 12:04:23,340 - INFO - All types `lr` of epoch 466: {'lr/param_group0': 0.00022709265023893008, 'lr/param_group1': 0.00022709265023893008, 'lr/param_group2': 0.00022709265023893008, 'lr/param_group3': 0.00022709265023893008}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:23,347 - INFO - epoch 466: train loss 0.006254306849937334\n",
      "2025-09-10 12:04:23,352 - INFO - 466 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:23,356 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:23,361 - INFO - --------------------\n",
      "\n",
      "467/600: 100%|██████████| 216/216 [00:08<00:00, 24.26it/s]\n",
      "2025-09-10 12:04:32,471 - INFO - All types `lr` of epoch 467: {'lr/param_group0': 0.0002250756122622125, 'lr/param_group1': 0.0002250756122622125, 'lr/param_group2': 0.0002250756122622125, 'lr/param_group3': 0.0002250756122622125}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:32,477 - INFO - epoch 467: train loss 0.006086221495125856\n",
      "2025-09-10 12:04:32,483 - INFO - 467 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:32,487 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:32,491 - INFO - --------------------\n",
      "\n",
      "468/600: 100%|██████████| 216/216 [00:08<00:00, 25.06it/s]\n",
      "2025-09-10 12:04:41,310 - INFO - All types `lr` of epoch 468: {'lr/param_group0': 0.00022304042060410467, 'lr/param_group1': 0.00022304042060410467, 'lr/param_group2': 0.00022304042060410467, 'lr/param_group3': 0.00022304042060410467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:41,314 - INFO - epoch 468: train loss 0.006081775279232749\n",
      "2025-09-10 12:04:41,318 - INFO - 468 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:41,321 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:41,324 - INFO - --------------------\n",
      "\n",
      "469/600: 100%|██████████| 216/216 [00:07<00:00, 27.25it/s]\n",
      "2025-09-10 12:04:49,415 - INFO - All types `lr` of epoch 469: {'lr/param_group0': 0.00022098757741769514, 'lr/param_group1': 0.00022098757741769514, 'lr/param_group2': 0.00022098757741769514, 'lr/param_group3': 0.00022098757741769514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:49,419 - INFO - epoch 469: train loss 0.006100507552252599\n",
      "2025-09-10 12:04:49,422 - INFO - 469 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:49,427 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:49,430 - INFO - --------------------\n",
      "\n",
      "470/600: 100%|██████████| 216/216 [00:08<00:00, 24.30it/s]\n",
      "2025-09-10 12:04:58,484 - INFO - All types `lr` of epoch 470: {'lr/param_group0': 0.0002189175892113227, 'lr/param_group1': 0.0002189175892113227, 'lr/param_group2': 0.0002189175892113227, 'lr/param_group3': 0.0002189175892113227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:04:58,490 - INFO - epoch 470: train loss 0.006629379207475318\n",
      "2025-09-10 12:04:58,494 - INFO - 470 epochs completed!\n",
      "\n",
      "2025-09-10 12:04:58,498 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:04:58,502 - INFO - --------------------\n",
      "\n",
      "471/600: 100%|██████████| 216/216 [00:08<00:00, 24.54it/s]\n",
      "2025-09-10 12:05:07,511 - INFO - All types `lr` of epoch 471: {'lr/param_group0': 0.00021683096672360337, 'lr/param_group1': 0.00021683096672360337, 'lr/param_group2': 0.00021683096672360337, 'lr/param_group3': 0.00021683096672360337}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:07,516 - INFO - epoch 471: train loss 0.006851270052181833\n",
      "2025-09-10 12:05:07,521 - INFO - 471 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:07,526 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:07,530 - INFO - --------------------\n",
      "\n",
      "472/600: 100%|██████████| 216/216 [00:08<00:00, 24.29it/s]\n",
      "2025-09-10 12:05:16,628 - INFO - All types `lr` of epoch 472: {'lr/param_group0': 0.00021472822479741326, 'lr/param_group1': 0.00021472822479741326, 'lr/param_group2': 0.00021472822479741326, 'lr/param_group3': 0.00021472822479741326}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:16,632 - INFO - epoch 472: train loss 0.006166553429836684\n",
      "2025-09-10 12:05:16,637 - INFO - 472 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:16,641 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:16,644 - INFO - --------------------\n",
      "\n",
      "473/600: 100%|██████████| 216/216 [00:08<00:00, 24.31it/s]\n",
      "2025-09-10 12:05:25,727 - INFO - All types `lr` of epoch 473: {'lr/param_group0': 0.00021260988225285863, 'lr/param_group1': 0.00021260988225285863, 'lr/param_group2': 0.00021260988225285863, 'lr/param_group3': 0.00021260988225285863}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:25,732 - INFO - epoch 473: train loss 0.0060753243526926745\n",
      "2025-09-10 12:05:25,736 - INFO - 473 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:25,740 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:25,744 - INFO - --------------------\n",
      "\n",
      "474/600: 100%|██████████| 216/216 [00:08<00:00, 24.24it/s]\n",
      "2025-09-10 12:05:34,870 - INFO - All types `lr` of epoch 474: {'lr/param_group0': 0.00021047646175926488, 'lr/param_group1': 0.00021047646175926488, 'lr/param_group2': 0.00021047646175926488, 'lr/param_group3': 0.00021047646175926488}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:34,876 - INFO - epoch 474: train loss 0.00607532836147584\n",
      "2025-09-10 12:05:34,882 - INFO - 474 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:34,888 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:34,892 - INFO - --------------------\n",
      "\n",
      "475/600: 100%|██████████| 216/216 [00:08<00:00, 26.27it/s]\n",
      "2025-09-10 12:05:43,321 - INFO - All types `lr` of epoch 475: {'lr/param_group0': 0.00020832848970621582, 'lr/param_group1': 0.00020832848970621582, 'lr/param_group2': 0.00020832848970621582, 'lr/param_group3': 0.00020832848970621582}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:43,325 - INFO - epoch 475: train loss 0.006162826819086654\n",
      "2025-09-10 12:05:43,329 - INFO - 475 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:43,333 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:43,336 - INFO - --------------------\n",
      "\n",
      "476/600: 100%|██████████| 216/216 [00:07<00:00, 28.77it/s]\n",
      "2025-09-10 12:05:51,030 - INFO - All types `lr` of epoch 476: {'lr/param_group0': 0.0002061664960736747, 'lr/param_group1': 0.0002061664960736747, 'lr/param_group2': 0.0002061664960736747, 'lr/param_group3': 0.0002061664960736747}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:51,036 - INFO - epoch 476: train loss 0.006791201941841455\n",
      "2025-09-10 12:05:51,041 - INFO - 476 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:51,046 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:51,051 - INFO - --------------------\n",
      "\n",
      "477/600: 100%|██████████| 216/216 [00:08<00:00, 25.62it/s]\n",
      "2025-09-10 12:05:59,686 - INFO - All types `lr` of epoch 477: {'lr/param_group0': 0.00020399101430121968, 'lr/param_group1': 0.00020399101430121968, 'lr/param_group2': 0.00020399101430121968, 'lr/param_group3': 0.00020399101430121968}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:05:59,691 - INFO - epoch 477: train loss 0.006374190702680843\n",
      "2025-09-10 12:05:59,697 - INFO - 477 epochs completed!\n",
      "\n",
      "2025-09-10 12:05:59,701 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:05:59,706 - INFO - --------------------\n",
      "\n",
      "478/600: 100%|██████████| 216/216 [00:08<00:00, 24.38it/s]\n",
      "2025-09-10 12:06:08,769 - INFO - All types `lr` of epoch 478: {'lr/param_group0': 0.00020180258115642578, 'lr/param_group1': 0.00020180258115642578, 'lr/param_group2': 0.00020180258115642578, 'lr/param_group3': 0.00020180258115642578}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:08,775 - INFO - epoch 478: train loss 0.006259654195875757\n",
      "2025-09-10 12:06:08,780 - INFO - 478 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:08,785 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:08,790 - INFO - --------------------\n",
      "\n",
      "479/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 12:06:17,874 - INFO - All types `lr` of epoch 479: {'lr/param_group0': 0.00019960173660242518, 'lr/param_group1': 0.00019960173660242518, 'lr/param_group2': 0.00019960173660242518, 'lr/param_group3': 0.00019960173660242518}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:17,880 - INFO - epoch 479: train loss 0.006259605141908482\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.90it/s]\n",
      "2025-09-10 12:06:19,782 - INFO - epoch 479: val loss 0.006577653663784817\n",
      "2025-09-10 12:06:19,788 - INFO - 479 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:06:19,836 - INFO - 479 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:19,841 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:19,845 - INFO - --------------------\n",
      "\n",
      "480/600: 100%|██████████| 216/216 [00:08<00:00, 24.03it/s]\n",
      "2025-09-10 12:06:29,039 - INFO - All types `lr` of epoch 480: {'lr/param_group0': 0.0001973890236646797, 'lr/param_group1': 0.0001973890236646797, 'lr/param_group2': 0.0001973890236646797, 'lr/param_group3': 0.0001973890236646797}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:29,044 - INFO - epoch 480: train loss 0.006409215692353125\n",
      "2025-09-10 12:06:29,050 - INFO - 480 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:29,054 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:29,059 - INFO - --------------------\n",
      "\n",
      "481/600: 100%|██████████| 216/216 [00:08<00:00, 24.04it/s]\n",
      "2025-09-10 12:06:38,255 - INFO - All types `lr` of epoch 481: {'lr/param_group0': 0.0001951649882969971, 'lr/param_group1': 0.0001951649882969971, 'lr/param_group2': 0.0001951649882969971, 'lr/param_group3': 0.0001951649882969971}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:38,260 - INFO - epoch 481: train loss 0.006491917232913828\n",
      "2025-09-10 12:06:38,267 - INFO - 481 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:38,271 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:38,276 - INFO - --------------------\n",
      "\n",
      "482/600: 100%|██████████| 216/216 [00:08<00:00, 26.97it/s]\n",
      "2025-09-10 12:06:46,508 - INFO - All types `lr` of epoch 482: {'lr/param_group0': 0.00019293017924682556, 'lr/param_group1': 0.00019293017924682556, 'lr/param_group2': 0.00019293017924682556, 'lr/param_group3': 0.00019293017924682556}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:46,512 - INFO - epoch 482: train loss 0.006378456460812164\n",
      "2025-09-10 12:06:46,516 - INFO - 482 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:46,519 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:46,523 - INFO - --------------------\n",
      "\n",
      "483/600: 100%|██████████| 216/216 [00:08<00:00, 25.90it/s]\n",
      "2025-09-10 12:06:55,027 - INFO - All types `lr` of epoch 483: {'lr/param_group0': 0.0001906851479198579, 'lr/param_group1': 0.0001906851479198579, 'lr/param_group2': 0.0001906851479198579, 'lr/param_group3': 0.0001906851479198579}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:06:55,032 - INFO - epoch 483: train loss 0.006264016638009774\n",
      "2025-09-10 12:06:55,037 - INFO - 483 epochs completed!\n",
      "\n",
      "2025-09-10 12:06:55,041 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:06:55,045 - INFO - --------------------\n",
      "\n",
      "484/600: 100%|██████████| 216/216 [00:08<00:00, 24.34it/s]\n",
      "2025-09-10 12:07:04,122 - INFO - All types `lr` of epoch 484: {'lr/param_group0': 0.00018843044824398095, 'lr/param_group1': 0.00018843044824398095, 'lr/param_group2': 0.00018843044824398095, 'lr/param_group3': 0.00018843044824398095}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:04,128 - INFO - epoch 484: train loss 0.006240769229070456\n",
      "2025-09-10 12:07:04,135 - INFO - 484 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:04,139 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:04,143 - INFO - --------------------\n",
      "\n",
      "485/600: 100%|██████████| 216/216 [00:08<00:00, 24.56it/s]\n",
      "2025-09-10 12:07:13,144 - INFO - All types `lr` of epoch 485: {'lr/param_group0': 0.00018616663653260194, 'lr/param_group1': 0.00018616663653260194, 'lr/param_group2': 0.00018616663653260194, 'lr/param_group3': 0.00018616663653260194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:13,150 - INFO - epoch 485: train loss 0.006256813747178832\n",
      "2025-09-10 12:07:13,155 - INFO - 485 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:13,159 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:13,162 - INFO - --------------------\n",
      "\n",
      "486/600: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s]\n",
      "2025-09-10 12:07:22,232 - INFO - All types `lr` of epoch 486: {'lr/param_group0': 0.00018389427134738657, 'lr/param_group1': 0.00018389427134738657, 'lr/param_group2': 0.00018389427134738657, 'lr/param_group3': 0.00018389427134738657}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:22,239 - INFO - epoch 486: train loss 0.006375771330635029\n",
      "2025-09-10 12:07:22,245 - INFO - 486 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:22,250 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:22,255 - INFO - --------------------\n",
      "\n",
      "487/600: 100%|██████████| 216/216 [00:08<00:00, 24.20it/s]\n",
      "2025-09-10 12:07:31,391 - INFO - All types `lr` of epoch 487: {'lr/param_group0': 0.00018161391336044209, 'lr/param_group1': 0.00018161391336044209, 'lr/param_group2': 0.00018161391336044209, 'lr/param_group3': 0.00018161391336044209}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:31,396 - INFO - epoch 487: train loss 0.00634458452825331\n",
      "2025-09-10 12:07:31,401 - INFO - 487 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:31,406 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:31,410 - INFO - --------------------\n",
      "\n",
      "488/600: 100%|██████████| 216/216 [00:08<00:00, 25.10it/s]\n",
      "2025-09-10 12:07:40,217 - INFO - All types `lr` of epoch 488: {'lr/param_group0': 0.0001793261252159801, 'lr/param_group1': 0.0001793261252159801, 'lr/param_group2': 0.0001793261252159801, 'lr/param_group3': 0.0001793261252159801}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:40,221 - INFO - epoch 488: train loss 0.0062618088311326035\n",
      "2025-09-10 12:07:40,225 - INFO - 488 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:40,230 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:40,233 - INFO - --------------------\n",
      "\n",
      "489/600: 100%|██████████| 216/216 [00:07<00:00, 27.02it/s]\n",
      "2025-09-10 12:07:48,391 - INFO - All types `lr` of epoch 489: {'lr/param_group0': 0.00017703147139149232, 'lr/param_group1': 0.00017703147139149232, 'lr/param_group2': 0.00017703147139149232, 'lr/param_group3': 0.00017703147139149232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:48,395 - INFO - epoch 489: train loss 0.006285281711758149\n",
      "2025-09-10 12:07:48,399 - INFO - 489 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:48,403 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:48,406 - INFO - --------------------\n",
      "\n",
      "490/600: 100%|██████████| 216/216 [00:08<00:00, 24.94it/s]\n",
      "2025-09-10 12:07:57,235 - INFO - All types `lr` of epoch 490: {'lr/param_group0': 0.00017473051805847427, 'lr/param_group1': 0.00017473051805847427, 'lr/param_group2': 0.00017473051805847427, 'lr/param_group3': 0.00017473051805847427}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:07:57,240 - INFO - epoch 490: train loss 0.006242376404029697\n",
      "2025-09-10 12:07:57,245 - INFO - 490 epochs completed!\n",
      "\n",
      "2025-09-10 12:07:57,249 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:07:57,253 - INFO - --------------------\n",
      "\n",
      "491/600: 100%|██████████| 216/216 [00:08<00:00, 25.60it/s]\n",
      "2025-09-10 12:08:05,926 - INFO - All types `lr` of epoch 491: {'lr/param_group0': 0.00017242383294273098, 'lr/param_group1': 0.00017242383294273098, 'lr/param_group2': 0.00017242383294273098, 'lr/param_group3': 0.00017242383294273098}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:08:05,944 - INFO - epoch 491: train loss 0.006242974484511824\n",
      "2025-09-10 12:08:05,962 - INFO - 491 epochs completed!\n",
      "\n",
      "2025-09-10 12:08:05,970 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:08:05,987 - INFO - --------------------\n",
      "\n",
      "492/600: 100%|██████████| 216/216 [00:11<00:00, 18.98it/s]\n",
      "2025-09-10 12:08:17,621 - INFO - All types `lr` of epoch 492: {'lr/param_group0': 0.00017011198518429918, 'lr/param_group1': 0.00017011198518429918, 'lr/param_group2': 0.00017011198518429918, 'lr/param_group3': 0.00017011198518429918}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:08:17,639 - INFO - epoch 492: train loss 0.006240593368635961\n",
      "2025-09-10 12:08:17,647 - INFO - 492 epochs completed!\n",
      "\n",
      "2025-09-10 12:08:17,664 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:08:17,681 - INFO - --------------------\n",
      "\n",
      "493/600: 100%|██████████| 216/216 [00:11<00:00, 19.23it/s]\n",
      "2025-09-10 12:08:29,147 - INFO - All types `lr` of epoch 493: {'lr/param_group0': 0.0001677955451970202, 'lr/param_group1': 0.0001677955451970202, 'lr/param_group2': 0.0001677955451970202, 'lr/param_group3': 0.0001677955451970202}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:08:29,165 - INFO - epoch 493: train loss 0.006226418139973517\n",
      "2025-09-10 12:08:29,183 - INFO - 493 epochs completed!\n",
      "\n",
      "2025-09-10 12:08:29,190 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:08:29,207 - INFO - --------------------\n",
      "\n",
      "494/600: 100%|██████████| 216/216 [00:10<00:00, 20.03it/s]\n",
      "2025-09-10 12:08:40,233 - INFO - All types `lr` of epoch 494: {'lr/param_group0': 0.00016547508452779942, 'lr/param_group1': 0.00016547508452779942, 'lr/param_group2': 0.00016547508452779942, 'lr/param_group3': 0.00016547508452779942}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:08:40,247 - INFO - epoch 494: train loss 0.006237032445992723\n",
      "2025-09-10 12:08:40,258 - INFO - 494 epochs completed!\n",
      "\n",
      "2025-09-10 12:08:40,262 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:08:40,274 - INFO - --------------------\n",
      "\n",
      "495/600: 100%|██████████| 216/216 [00:08<00:00, 24.04it/s]\n",
      "2025-09-10 12:08:49,468 - INFO - All types `lr` of epoch 495: {'lr/param_group0': 0.00016315117571558496, 'lr/param_group1': 0.00016315117571558496, 'lr/param_group2': 0.00016315117571558496, 'lr/param_group3': 0.00016315117571558496}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:08:49,477 - INFO - epoch 495: train loss 0.006247310409822536\n",
      "2025-09-10 12:08:49,494 - INFO - 495 epochs completed!\n",
      "\n",
      "2025-09-10 12:08:49,511 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:08:49,519 - INFO - --------------------\n",
      "\n",
      "496/600: 100%|██████████| 216/216 [00:11<00:00, 18.54it/s]\n",
      "2025-09-10 12:09:01,417 - INFO - All types `lr` of epoch 496: {'lr/param_group0': 0.00016082439215010303, 'lr/param_group1': 0.00016082439215010303, 'lr/param_group2': 0.00016082439215010303, 'lr/param_group3': 0.00016082439215010303}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:01,437 - INFO - epoch 496: train loss 0.006244698608363116\n",
      "2025-09-10 12:09:01,456 - INFO - 496 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:01,463 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:01,479 - INFO - --------------------\n",
      "\n",
      "497/600: 100%|██████████| 216/216 [00:11<00:00, 18.80it/s]\n",
      "2025-09-10 12:09:13,235 - INFO - All types `lr` of epoch 497: {'lr/param_group0': 0.00015849530793038194, 'lr/param_group1': 0.00015849530793038194, 'lr/param_group2': 0.00015849530793038194, 'lr/param_group3': 0.00015849530793038194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:13,243 - INFO - epoch 497: train loss 0.006225501229184576\n",
      "2025-09-10 12:09:13,261 - INFO - 497 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:13,266 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:13,283 - INFO - --------------------\n",
      "\n",
      "498/600: 100%|██████████| 216/216 [00:11<00:00, 18.85it/s]\n",
      "2025-09-10 12:09:24,998 - INFO - All types `lr` of epoch 498: {'lr/param_group0': 0.00015616449772310208, 'lr/param_group1': 0.00015616449772310208, 'lr/param_group2': 0.00015616449772310208, 'lr/param_group3': 0.00015616449772310208}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:25,017 - INFO - epoch 498: train loss 0.006188675401197678\n",
      "2025-09-10 12:09:25,024 - INFO - 498 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:25,042 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:25,060 - INFO - --------------------\n",
      "\n",
      "499/600: 100%|██████████| 216/216 [00:11<00:00, 18.63it/s]\n",
      "2025-09-10 12:09:36,907 - INFO - All types `lr` of epoch 499: {'lr/param_group0': 0.00015383253662080537, 'lr/param_group1': 0.00015383253662080537, 'lr/param_group2': 0.00015383253662080537, 'lr/param_group3': 0.00015383253662080537}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:36,914 - INFO - epoch 499: train loss 0.006196751417721518\n",
      "2025-09-10 12:09:36,932 - INFO - 499 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:36,938 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:36,955 - INFO - --------------------\n",
      "\n",
      "500/600: 100%|██████████| 216/216 [00:09<00:00, 23.23it/s]\n",
      "2025-09-10 12:09:46,517 - INFO - All types `lr` of epoch 500: {'lr/param_group0': 0.00015150000000000002, 'lr/param_group1': 0.00015150000000000002, 'lr/param_group2': 0.00015150000000000002, 'lr/param_group3': 0.00015150000000000002}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:46,531 - INFO - epoch 500: train loss 0.006171950664052188\n",
      "2025-09-10 12:09:46,543 - INFO - 500 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:46,547 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:46,558 - INFO - --------------------\n",
      "\n",
      "501/600: 100%|██████████| 216/216 [00:09<00:00, 22.38it/s]\n",
      "2025-09-10 12:09:56,413 - INFO - All types `lr` of epoch 501: {'lr/param_group0': 0.00014916746337919465, 'lr/param_group1': 0.00014916746337919465, 'lr/param_group2': 0.00014916746337919465, 'lr/param_group3': 0.00014916746337919465}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:09:56,418 - INFO - epoch 501: train loss 0.00616374441974417\n",
      "2025-09-10 12:09:56,432 - INFO - 501 epochs completed!\n",
      "\n",
      "2025-09-10 12:09:56,445 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:09:56,450 - INFO - --------------------\n",
      "\n",
      "502/600: 100%|██████████| 216/216 [00:09<00:00, 23.25it/s]\n",
      "2025-09-10 12:10:05,983 - INFO - All types `lr` of epoch 502: {'lr/param_group0': 0.00014683550227689794, 'lr/param_group1': 0.00014683550227689794, 'lr/param_group2': 0.00014683550227689794, 'lr/param_group3': 0.00014683550227689794}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:10:06,003 - INFO - epoch 502: train loss 0.006181919306982309\n",
      "2025-09-10 12:10:06,021 - INFO - 502 epochs completed!\n",
      "\n",
      "2025-09-10 12:10:06,039 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:10:06,055 - INFO - --------------------\n",
      "\n",
      "503/600: 100%|██████████| 216/216 [00:11<00:00, 19.52it/s]\n",
      "2025-09-10 12:10:17,376 - INFO - All types `lr` of epoch 503: {'lr/param_group0': 0.00014450469206961806, 'lr/param_group1': 0.00014450469206961806, 'lr/param_group2': 0.00014450469206961806, 'lr/param_group3': 0.00014450469206961806}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:10:17,393 - INFO - epoch 503: train loss 0.006165993538969714\n",
      "2025-09-10 12:10:17,399 - INFO - 503 epochs completed!\n",
      "\n",
      "2025-09-10 12:10:17,415 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:10:17,432 - INFO - --------------------\n",
      "\n",
      "504/600: 100%|██████████| 216/216 [00:11<00:00, 19.49it/s]\n",
      "2025-09-10 12:10:28,752 - INFO - All types `lr` of epoch 504: {'lr/param_group0': 0.00014217560784989694, 'lr/param_group1': 0.00014217560784989694, 'lr/param_group2': 0.00014217560784989694, 'lr/param_group3': 0.00014217560784989694}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:10:28,771 - INFO - epoch 504: train loss 0.006179934428978918\n",
      "2025-09-10 12:10:28,777 - INFO - 504 epochs completed!\n",
      "\n",
      "2025-09-10 12:10:28,793 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:10:28,810 - INFO - --------------------\n",
      "\n",
      "505/600: 100%|██████████| 216/216 [00:11<00:00, 18.86it/s]\n",
      "2025-09-10 12:10:40,502 - INFO - All types `lr` of epoch 505: {'lr/param_group0': 0.000139848824284415, 'lr/param_group1': 0.000139848824284415, 'lr/param_group2': 0.000139848824284415, 'lr/param_group3': 0.000139848824284415}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:10:40,523 - INFO - epoch 505: train loss 0.006158987073124283\n",
      "2025-09-10 12:10:40,530 - INFO - 505 epochs completed!\n",
      "\n",
      "2025-09-10 12:10:40,547 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:10:40,564 - INFO - --------------------\n",
      "\n",
      "506/600: 100%|██████████| 216/216 [00:11<00:00, 19.20it/s]\n",
      "2025-09-10 12:10:52,054 - INFO - All types `lr` of epoch 506: {'lr/param_group0': 0.0001375249154722006, 'lr/param_group1': 0.0001375249154722006, 'lr/param_group2': 0.0001375249154722006, 'lr/param_group3': 0.0001375249154722006}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:10:52,074 - INFO - epoch 506: train loss 0.006130171015953507\n",
      "2025-09-10 12:10:52,081 - INFO - 506 epochs completed!\n",
      "\n",
      "2025-09-10 12:10:52,098 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:10:52,116 - INFO - --------------------\n",
      "\n",
      "507/600: 100%|██████████| 216/216 [00:11<00:00, 18.54it/s]\n",
      "2025-09-10 12:11:04,004 - INFO - All types `lr` of epoch 507: {'lr/param_group0': 0.0001352044548029798, 'lr/param_group1': 0.0001352044548029798, 'lr/param_group2': 0.0001352044548029798, 'lr/param_group3': 0.0001352044548029798}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:11:04,025 - INFO - epoch 507: train loss 0.006155383764524703\n",
      "2025-09-10 12:11:04,045 - INFO - 507 epochs completed!\n",
      "\n",
      "2025-09-10 12:11:04,062 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:11:04,078 - INFO - --------------------\n",
      "\n",
      "508/600: 100%|██████████| 216/216 [00:11<00:00, 18.85it/s]\n",
      "2025-09-10 12:11:15,790 - INFO - All types `lr` of epoch 508: {'lr/param_group0': 0.00013288801481570078, 'lr/param_group1': 0.00013288801481570078, 'lr/param_group2': 0.00013288801481570078, 'lr/param_group3': 0.00013288801481570078}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:11:15,809 - INFO - epoch 508: train loss 0.006161027512495854\n",
      "2025-09-10 12:11:15,816 - INFO - 508 epochs completed!\n",
      "\n",
      "2025-09-10 12:11:15,833 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:11:15,851 - INFO - --------------------\n",
      "\n",
      "509/600: 100%|██████████| 216/216 [00:11<00:00, 18.91it/s]\n",
      "2025-09-10 12:11:27,513 - INFO - All types `lr` of epoch 509: {'lr/param_group0': 0.00013057616705726896, 'lr/param_group1': 0.00013057616705726896, 'lr/param_group2': 0.00013057616705726896, 'lr/param_group3': 0.00013057616705726896}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:11:27,531 - INFO - epoch 509: train loss 0.006141916100642885\n",
      "100%|██████████| 54/54 [00:01<00:00, 31.28it/s]\n",
      "2025-09-10 12:11:29,488 - INFO - epoch 509: val loss 0.006384526448393309\n",
      "2025-09-10 12:11:29,507 - INFO - 509 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:11:29,554 - INFO - 509 epochs completed!\n",
      "\n",
      "2025-09-10 12:11:29,564 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:11:29,581 - INFO - --------------------\n",
      "\n",
      "510/600: 100%|██████████| 216/216 [00:10<00:00, 20.95it/s]\n",
      "2025-09-10 12:11:40,123 - INFO - All types `lr` of epoch 510: {'lr/param_group0': 0.0001282694819415257, 'lr/param_group1': 0.0001282694819415257, 'lr/param_group2': 0.0001282694819415257, 'lr/param_group3': 0.0001282694819415257}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:11:40,142 - INFO - epoch 510: train loss 0.006125563426865955\n",
      "2025-09-10 12:11:40,149 - INFO - 510 epochs completed!\n",
      "\n",
      "2025-09-10 12:11:40,166 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:11:40,184 - INFO - --------------------\n",
      "\n",
      "511/600: 100%|██████████| 216/216 [00:11<00:00, 18.50it/s]\n",
      "2025-09-10 12:11:52,104 - INFO - All types `lr` of epoch 511: {'lr/param_group0': 0.00012596852860850764, 'lr/param_group1': 0.00012596852860850764, 'lr/param_group2': 0.00012596852860850764, 'lr/param_group3': 0.00012596852860850764}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:11:52,125 - INFO - epoch 511: train loss 0.006114963588684246\n",
      "2025-09-10 12:11:52,144 - INFO - 511 epochs completed!\n",
      "\n",
      "2025-09-10 12:11:52,161 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:11:52,177 - INFO - --------------------\n",
      "\n",
      "512/600: 100%|██████████| 216/216 [00:11<00:00, 18.79it/s]\n",
      "2025-09-10 12:12:03,930 - INFO - All types `lr` of epoch 512: {'lr/param_group0': 0.00012367387478401986, 'lr/param_group1': 0.00012367387478401986, 'lr/param_group2': 0.00012367387478401986, 'lr/param_group3': 0.00012367387478401986}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:12:03,948 - INFO - epoch 512: train loss 0.0061156349342868285\n",
      "2025-09-10 12:12:03,966 - INFO - 512 epochs completed!\n",
      "\n",
      "2025-09-10 12:12:03,973 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:12:03,990 - INFO - --------------------\n",
      "\n",
      "513/600: 100%|██████████| 216/216 [00:11<00:00, 19.23it/s]\n",
      "2025-09-10 12:12:15,472 - INFO - All types `lr` of epoch 513: {'lr/param_group0': 0.00012138608663955795, 'lr/param_group1': 0.00012138608663955795, 'lr/param_group2': 0.00012138608663955795, 'lr/param_group3': 0.00012138608663955795}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:12:15,490 - INFO - epoch 513: train loss 0.0061426357111755625\n",
      "2025-09-10 12:12:15,508 - INFO - 513 epochs completed!\n",
      "\n",
      "2025-09-10 12:12:15,515 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:12:15,531 - INFO - --------------------\n",
      "\n",
      "514/600: 100%|██████████| 216/216 [00:10<00:00, 20.82it/s]\n",
      "2025-09-10 12:12:26,156 - INFO - All types `lr` of epoch 514: {'lr/param_group0': 0.00011910572865261347, 'lr/param_group1': 0.00011910572865261347, 'lr/param_group2': 0.00011910572865261347, 'lr/param_group3': 0.00011910572865261347}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:12:26,176 - INFO - epoch 514: train loss 0.006139758165874001\n",
      "2025-09-10 12:12:26,195 - INFO - 514 epochs completed!\n",
      "\n",
      "2025-09-10 12:12:26,202 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:12:26,219 - INFO - --------------------\n",
      "\n",
      "515/600: 100%|██████████| 216/216 [00:11<00:00, 18.34it/s]\n",
      "2025-09-10 12:12:38,277 - INFO - All types `lr` of epoch 515: {'lr/param_group0': 0.00011683336346739808, 'lr/param_group1': 0.00011683336346739808, 'lr/param_group2': 0.00011683336346739808, 'lr/param_group3': 0.00011683336346739808}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:12:38,285 - INFO - epoch 515: train loss 0.006154609848400233\n",
      "2025-09-10 12:12:38,302 - INFO - 515 epochs completed!\n",
      "\n",
      "2025-09-10 12:12:38,323 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:12:38,341 - INFO - --------------------\n",
      "\n",
      "516/600: 100%|██████████| 216/216 [00:11<00:00, 18.14it/s]\n",
      "2025-09-10 12:12:50,502 - INFO - All types `lr` of epoch 516: {'lr/param_group0': 0.0001145695517560191, 'lr/param_group1': 0.0001145695517560191, 'lr/param_group2': 0.0001145695517560191, 'lr/param_group3': 0.0001145695517560191}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:12:50,521 - INFO - epoch 516: train loss 0.0060997969164789\n",
      "2025-09-10 12:12:50,529 - INFO - 516 epochs completed!\n",
      "\n",
      "2025-09-10 12:12:50,547 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:12:50,565 - INFO - --------------------\n",
      "\n",
      "517/600: 100%|██████████| 216/216 [00:11<00:00, 18.63it/s]\n",
      "2025-09-10 12:13:02,410 - INFO - All types `lr` of epoch 517: {'lr/param_group0': 0.00011231485208014218, 'lr/param_group1': 0.00011231485208014218, 'lr/param_group2': 0.00011231485208014218, 'lr/param_group3': 0.00011231485208014218}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:13:02,417 - INFO - epoch 517: train loss 0.006070735222979069\n",
      "2025-09-10 12:13:02,434 - INFO - 517 epochs completed!\n",
      "\n",
      "2025-09-10 12:13:02,440 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:13:02,456 - INFO - --------------------\n",
      "\n",
      "518/600: 100%|██████████| 216/216 [00:11<00:00, 18.74it/s]\n",
      "2025-09-10 12:13:14,234 - INFO - All types `lr` of epoch 518: {'lr/param_group0': 0.00011006982075317448, 'lr/param_group1': 0.00011006982075317448, 'lr/param_group2': 0.00011006982075317448, 'lr/param_group3': 0.00011006982075317448}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:13:14,253 - INFO - epoch 518: train loss 0.006076851654884026\n",
      "2025-09-10 12:13:14,260 - INFO - 518 epochs completed!\n",
      "\n",
      "2025-09-10 12:13:14,277 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:13:14,295 - INFO - --------------------\n",
      "\n",
      "519/600: 100%|██████████| 216/216 [00:10<00:00, 19.78it/s]\n",
      "2025-09-10 12:13:25,460 - INFO - All types `lr` of epoch 519: {'lr/param_group0': 0.00010783501170300287, 'lr/param_group1': 0.00010783501170300287, 'lr/param_group2': 0.00010783501170300287, 'lr/param_group3': 0.00010783501170300287}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:13:25,468 - INFO - epoch 519: train loss 0.006086687074491271\n",
      "2025-09-10 12:13:25,485 - INFO - 519 epochs completed!\n",
      "\n",
      "2025-09-10 12:13:25,502 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:13:25,508 - INFO - --------------------\n",
      "\n",
      "520/600: 100%|██████████| 216/216 [00:11<00:00, 19.20it/s]\n",
      "2025-09-10 12:13:37,026 - INFO - All types `lr` of epoch 520: {'lr/param_group0': 0.0001056109763353203, 'lr/param_group1': 0.0001056109763353203, 'lr/param_group2': 0.0001056109763353203, 'lr/param_group3': 0.0001056109763353203}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:13:37,035 - INFO - epoch 520: train loss 0.006090996405368464\n",
      "2025-09-10 12:13:37,054 - INFO - 520 epochs completed!\n",
      "\n",
      "2025-09-10 12:13:37,073 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:13:37,080 - INFO - --------------------\n",
      "\n",
      "521/600: 100%|██████████| 216/216 [00:11<00:00, 18.55it/s]\n",
      "2025-09-10 12:13:48,987 - INFO - All types `lr` of epoch 521: {'lr/param_group0': 0.00010339826339757483, 'lr/param_group1': 0.00010339826339757483, 'lr/param_group2': 0.00010339826339757483, 'lr/param_group3': 0.00010339826339757483}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:13:48,995 - INFO - epoch 521: train loss 0.006096497029324787\n",
      "2025-09-10 12:13:49,013 - INFO - 521 epochs completed!\n",
      "\n",
      "2025-09-10 12:13:49,019 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:13:49,035 - INFO - --------------------\n",
      "\n",
      "522/600: 100%|██████████| 216/216 [00:10<00:00, 20.06it/s]\n",
      "2025-09-10 12:14:00,067 - INFO - All types `lr` of epoch 522: {'lr/param_group0': 0.00010119741884357424, 'lr/param_group1': 0.00010119741884357424, 'lr/param_group2': 0.00010119741884357424, 'lr/param_group3': 0.00010119741884357424}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:00,074 - INFO - epoch 522: train loss 0.006092841146272366\n",
      "2025-09-10 12:14:00,092 - INFO - 522 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:00,110 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:00,116 - INFO - --------------------\n",
      "\n",
      "523/600: 100%|██████████| 216/216 [00:11<00:00, 18.54it/s]\n",
      "2025-09-10 12:14:12,024 - INFO - All types `lr` of epoch 523: {'lr/param_group0': 9.900898569878033e-05, 'lr/param_group1': 9.900898569878033e-05, 'lr/param_group2': 9.900898569878033e-05, 'lr/param_group3': 9.900898569878033e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:12,030 - INFO - epoch 523: train loss 0.006073436148990704\n",
      "2025-09-10 12:14:12,048 - INFO - 523 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:12,065 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:12,072 - INFO - --------------------\n",
      "\n",
      "524/600: 100%|██████████| 216/216 [00:11<00:00, 18.53it/s]\n",
      "2025-09-10 12:14:23,992 - INFO - All types `lr` of epoch 524: {'lr/param_group0': 9.683350392632531e-05, 'lr/param_group1': 9.683350392632531e-05, 'lr/param_group2': 9.683350392632531e-05, 'lr/param_group3': 9.683350392632531e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:23,999 - INFO - epoch 524: train loss 0.006080646863362442\n",
      "2025-09-10 12:14:24,016 - INFO - 524 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:24,034 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:24,041 - INFO - --------------------\n",
      "\n",
      "525/600: 100%|██████████| 216/216 [00:10<00:00, 20.44it/s]\n",
      "2025-09-10 12:14:34,870 - INFO - All types `lr` of epoch 525: {'lr/param_group0': 9.467151029378419e-05, 'lr/param_group1': 9.467151029378419e-05, 'lr/param_group2': 9.467151029378419e-05, 'lr/param_group3': 9.467151029378419e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:34,877 - INFO - epoch 525: train loss 0.006090808262039597\n",
      "2025-09-10 12:14:34,895 - INFO - 525 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:34,913 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:34,920 - INFO - --------------------\n",
      "\n",
      "526/600: 100%|██████████| 216/216 [00:11<00:00, 18.45it/s]\n",
      "2025-09-10 12:14:46,875 - INFO - All types `lr` of epoch 526: {'lr/param_group0': 9.25235382407351e-05, 'lr/param_group1': 9.25235382407351e-05, 'lr/param_group2': 9.25235382407351e-05, 'lr/param_group3': 9.25235382407351e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:46,897 - INFO - epoch 526: train loss 0.006064721599816241\n",
      "2025-09-10 12:14:46,917 - INFO - 526 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:46,937 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:46,954 - INFO - --------------------\n",
      "\n",
      "527/600: 100%|██████████| 216/216 [00:11<00:00, 18.06it/s]\n",
      "2025-09-10 12:14:59,175 - INFO - All types `lr` of epoch 527: {'lr/param_group0': 9.039011774714136e-05, 'lr/param_group1': 9.039011774714136e-05, 'lr/param_group2': 9.039011774714136e-05, 'lr/param_group3': 9.039011774714136e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:14:59,194 - INFO - epoch 527: train loss 0.006059204101027852\n",
      "2025-09-10 12:14:59,202 - INFO - 527 epochs completed!\n",
      "\n",
      "2025-09-10 12:14:59,220 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:14:59,238 - INFO - --------------------\n",
      "\n",
      "528/600: 100%|██████████| 216/216 [00:11<00:00, 18.92it/s]\n",
      "2025-09-10 12:15:10,903 - INFO - All types `lr` of epoch 528: {'lr/param_group0': 8.827177520258669e-05, 'lr/param_group1': 8.827177520258669e-05, 'lr/param_group2': 8.827177520258669e-05, 'lr/param_group3': 8.827177520258669e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:15:10,910 - INFO - epoch 528: train loss 0.006061222458137544\n",
      "2025-09-10 12:15:10,928 - INFO - 528 epochs completed!\n",
      "\n",
      "2025-09-10 12:15:10,934 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:15:10,950 - INFO - --------------------\n",
      "\n",
      "529/600: 100%|██████████| 216/216 [00:11<00:00, 18.57it/s]\n",
      "2025-09-10 12:15:22,846 - INFO - All types `lr` of epoch 529: {'lr/param_group0': 8.616903327639659e-05, 'lr/param_group1': 8.616903327639659e-05, 'lr/param_group2': 8.616903327639659e-05, 'lr/param_group3': 8.616903327639659e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:15:22,865 - INFO - epoch 529: train loss 0.006049219995340401\n",
      "2025-09-10 12:15:22,873 - INFO - 529 epochs completed!\n",
      "\n",
      "2025-09-10 12:15:22,890 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:15:22,907 - INFO - --------------------\n",
      "\n",
      "530/600: 100%|██████████| 216/216 [00:10<00:00, 21.57it/s]\n",
      "2025-09-10 12:15:33,158 - INFO - All types `lr` of epoch 530: {'lr/param_group0': 8.408241078867731e-05, 'lr/param_group1': 8.408241078867731e-05, 'lr/param_group2': 8.408241078867731e-05, 'lr/param_group3': 8.408241078867731e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:15:33,179 - INFO - epoch 530: train loss 0.006054862914391345\n",
      "2025-09-10 12:15:33,185 - INFO - 530 epochs completed!\n",
      "\n",
      "2025-09-10 12:15:33,202 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:15:33,222 - INFO - --------------------\n",
      "\n",
      "531/600: 100%|██████████| 216/216 [00:11<00:00, 18.79it/s]\n",
      "2025-09-10 12:15:44,959 - INFO - All types `lr` of epoch 531: {'lr/param_group0': 8.201242258230488e-05, 'lr/param_group1': 8.201242258230488e-05, 'lr/param_group2': 8.201242258230488e-05, 'lr/param_group3': 8.201242258230488e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:15:44,978 - INFO - epoch 531: train loss 0.0060398739243046964\n",
      "2025-09-10 12:15:44,985 - INFO - 531 epochs completed!\n",
      "\n",
      "2025-09-10 12:15:45,004 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:15:45,021 - INFO - --------------------\n",
      "\n",
      "532/600: 100%|██████████| 216/216 [00:11<00:00, 18.35it/s]\n",
      "2025-09-10 12:15:57,034 - INFO - All types `lr` of epoch 532: {'lr/param_group0': 7.995957939589527e-05, 'lr/param_group1': 7.995957939589527e-05, 'lr/param_group2': 7.995957939589527e-05, 'lr/param_group3': 7.995957939589527e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:15:57,053 - INFO - epoch 532: train loss 0.006020522264642986\n",
      "2025-09-10 12:15:57,059 - INFO - 532 epochs completed!\n",
      "\n",
      "2025-09-10 12:15:57,077 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:15:57,097 - INFO - --------------------\n",
      "\n",
      "533/600: 100%|██████████| 216/216 [00:11<00:00, 18.50it/s]\n",
      "2025-09-10 12:16:09,010 - INFO - All types `lr` of epoch 533: {'lr/param_group0': 7.792438773778747e-05, 'lr/param_group1': 7.792438773778747e-05, 'lr/param_group2': 7.792438773778747e-05, 'lr/param_group3': 7.792438773778747e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:09,030 - INFO - epoch 533: train loss 0.006023268204579061\n",
      "2025-09-10 12:16:09,037 - INFO - 533 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:09,055 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:09,073 - INFO - --------------------\n",
      "\n",
      "534/600: 100%|██████████| 216/216 [00:11<00:00, 18.50it/s]\n",
      "2025-09-10 12:16:20,987 - INFO - All types `lr` of epoch 534: {'lr/param_group0': 7.590734976106984e-05, 'lr/param_group1': 7.590734976106984e-05, 'lr/param_group2': 7.590734976106984e-05, 'lr/param_group3': 7.590734976106984e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:21,007 - INFO - epoch 534: train loss 0.006040418193960149\n",
      "2025-09-10 12:16:21,028 - INFO - 534 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:21,048 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:21,066 - INFO - --------------------\n",
      "\n",
      "535/600: 100%|██████████| 216/216 [00:11<00:00, 18.27it/s]\n",
      "2025-09-10 12:16:33,138 - INFO - All types `lr` of epoch 535: {'lr/param_group0': 7.390896313968161e-05, 'lr/param_group1': 7.390896313968161e-05, 'lr/param_group2': 7.390896313968161e-05, 'lr/param_group3': 7.390896313968161e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:33,160 - INFO - epoch 535: train loss 0.006034898793721503\n",
      "2025-09-10 12:16:33,168 - INFO - 535 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:33,186 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:33,205 - INFO - --------------------\n",
      "\n",
      "536/600: 100%|██████████| 216/216 [00:08<00:00, 25.95it/s]\n",
      "2025-09-10 12:16:41,778 - INFO - All types `lr` of epoch 536: {'lr/param_group0': 7.192972094561893e-05, 'lr/param_group1': 7.192972094561893e-05, 'lr/param_group2': 7.192972094561893e-05, 'lr/param_group3': 7.192972094561893e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:41,783 - INFO - epoch 536: train loss 0.0060466976385753326\n",
      "2025-09-10 12:16:41,793 - INFO - 536 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:41,796 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:41,806 - INFO - --------------------\n",
      "\n",
      "537/600: 100%|██████████| 216/216 [00:08<00:00, 25.26it/s]\n",
      "2025-09-10 12:16:50,517 - INFO - All types `lr` of epoch 537: {'lr/param_group0': 6.997011152727743e-05, 'lr/param_group1': 6.997011152727743e-05, 'lr/param_group2': 6.997011152727743e-05, 'lr/param_group3': 6.997011152727743e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:50,531 - INFO - epoch 537: train loss 0.006035943381936738\n",
      "2025-09-10 12:16:50,536 - INFO - 537 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:50,546 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:50,556 - INFO - --------------------\n",
      "\n",
      "538/600: 100%|██████████| 216/216 [00:08<00:00, 25.65it/s]\n",
      "2025-09-10 12:16:59,125 - INFO - All types `lr` of epoch 538: {'lr/param_group0': 6.803061838895864e-05, 'lr/param_group1': 6.803061838895864e-05, 'lr/param_group2': 6.803061838895864e-05, 'lr/param_group3': 6.803061838895864e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:16:59,140 - INFO - epoch 538: train loss 0.006041332708533715\n",
      "2025-09-10 12:16:59,145 - INFO - 538 epochs completed!\n",
      "\n",
      "2025-09-10 12:16:59,155 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:16:59,165 - INFO - --------------------\n",
      "\n",
      "539/600: 100%|██████████| 216/216 [00:08<00:00, 25.09it/s]\n",
      "2025-09-10 12:17:07,938 - INFO - All types `lr` of epoch 539: {'lr/param_group0': 6.611172007157319e-05, 'lr/param_group1': 6.611172007157319e-05, 'lr/param_group2': 6.611172007157319e-05, 'lr/param_group3': 6.611172007157319e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:17:07,943 - INFO - epoch 539: train loss 0.006049300225977613\n",
      "100%|██████████| 54/54 [00:01<00:00, 32.76it/s]\n",
      "2025-09-10 12:17:09,743 - INFO - epoch 539: val loss 0.00624366585786144\n",
      "2025-09-10 12:17:09,756 - INFO - 539 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:17:09,791 - INFO - 539 epochs completed!\n",
      "\n",
      "2025-09-10 12:17:09,795 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:17:09,804 - INFO - --------------------\n",
      "\n",
      "540/600: 100%|██████████| 216/216 [00:09<00:00, 23.72it/s]\n",
      "2025-09-10 12:17:19,077 - INFO - All types `lr` of epoch 540: {'lr/param_group0': 6.421389003456778e-05, 'lr/param_group1': 6.421389003456778e-05, 'lr/param_group2': 6.421389003456778e-05, 'lr/param_group3': 6.421389003456778e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:17:19,096 - INFO - epoch 540: train loss 0.00602154727783744\n",
      "2025-09-10 12:17:19,116 - INFO - 540 epochs completed!\n",
      "\n",
      "2025-09-10 12:17:19,123 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:17:19,140 - INFO - --------------------\n",
      "\n",
      "541/600: 100%|██████████| 216/216 [00:11<00:00, 18.17it/s]\n",
      "2025-09-10 12:17:31,294 - INFO - All types `lr` of epoch 541: {'lr/param_group0': 6.233759653910625e-05, 'lr/param_group1': 6.233759653910625e-05, 'lr/param_group2': 6.233759653910625e-05, 'lr/param_group3': 6.233759653910625e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:17:31,302 - INFO - epoch 541: train loss 0.006013612437527627\n",
      "2025-09-10 12:17:31,321 - INFO - 541 epochs completed!\n",
      "\n",
      "2025-09-10 12:17:31,341 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:17:31,348 - INFO - --------------------\n",
      "\n",
      "542/600: 100%|██████████| 216/216 [00:11<00:00, 18.28it/s]\n",
      "2025-09-10 12:17:43,418 - INFO - All types `lr` of epoch 542: {'lr/param_group0': 6.048330253253304e-05, 'lr/param_group1': 6.048330253253304e-05, 'lr/param_group2': 6.048330253253304e-05, 'lr/param_group3': 6.048330253253304e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:17:43,437 - INFO - epoch 542: train loss 0.006002486665103653\n",
      "2025-09-10 12:17:43,443 - INFO - 542 epochs completed!\n",
      "\n",
      "2025-09-10 12:17:43,462 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:17:43,482 - INFO - --------------------\n",
      "\n",
      "543/600: 100%|██████████| 216/216 [00:11<00:00, 18.31it/s]\n",
      "2025-09-10 12:17:55,531 - INFO - All types `lr` of epoch 543: {'lr/param_group0': 5.86514655341478e-05, 'lr/param_group1': 5.86514655341478e-05, 'lr/param_group2': 5.86514655341478e-05, 'lr/param_group3': 5.86514655341478e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:17:55,538 - INFO - epoch 543: train loss 0.0060033412139293635\n",
      "2025-09-10 12:17:55,557 - INFO - 543 epochs completed!\n",
      "\n",
      "2025-09-10 12:17:55,577 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:17:55,584 - INFO - --------------------\n",
      "\n",
      "544/600: 100%|██████████| 216/216 [00:11<00:00, 18.46it/s]\n",
      "2025-09-10 12:18:07,540 - INFO - All types `lr` of epoch 544: {'lr/param_group0': 5.6842537522319565e-05, 'lr/param_group1': 5.6842537522319565e-05, 'lr/param_group2': 5.6842537522319565e-05, 'lr/param_group3': 5.6842537522319565e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:18:07,559 - INFO - epoch 544: train loss 0.006006782246037835\n",
      "2025-09-10 12:18:07,564 - INFO - 544 epochs completed!\n",
      "\n",
      "2025-09-10 12:18:07,581 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:18:07,601 - INFO - --------------------\n",
      "\n",
      "545/600: 100%|██████████| 216/216 [00:11<00:00, 18.32it/s]\n",
      "2025-09-10 12:18:19,622 - INFO - All types `lr` of epoch 545: {'lr/param_group0': 5.505696482296775e-05, 'lr/param_group1': 5.505696482296775e-05, 'lr/param_group2': 5.505696482296775e-05, 'lr/param_group3': 5.505696482296775e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:18:19,643 - INFO - epoch 545: train loss 0.006008600328910958\n",
      "2025-09-10 12:18:19,650 - INFO - 545 epochs completed!\n",
      "\n",
      "2025-09-10 12:18:19,669 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:18:19,688 - INFO - --------------------\n",
      "\n",
      "546/600: 100%|██████████| 216/216 [00:11<00:00, 18.16it/s]\n",
      "2025-09-10 12:18:31,822 - INFO - All types `lr` of epoch 546: {'lr/param_group0': 5.3295187999437704e-05, 'lr/param_group1': 5.3295187999437704e-05, 'lr/param_group2': 5.3295187999437704e-05, 'lr/param_group3': 5.3295187999437704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:18:31,844 - INFO - epoch 546: train loss 0.006014800902145605\n",
      "2025-09-10 12:18:31,864 - INFO - 546 epochs completed!\n",
      "\n",
      "2025-09-10 12:18:31,872 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:18:31,890 - INFO - --------------------\n",
      "\n",
      "547/600: 100%|██████████| 216/216 [00:11<00:00, 19.09it/s]\n",
      "2025-09-10 12:18:43,463 - INFO - All types `lr` of epoch 547: {'lr/param_group0': 5.1557641743798694e-05, 'lr/param_group1': 5.1557641743798694e-05, 'lr/param_group2': 5.1557641743798694e-05, 'lr/param_group3': 5.1557641743798694e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:18:43,483 - INFO - epoch 547: train loss 0.006020364193116418\n",
      "2025-09-10 12:18:43,490 - INFO - 547 epochs completed!\n",
      "\n",
      "2025-09-10 12:18:43,508 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:18:43,526 - INFO - --------------------\n",
      "\n",
      "548/600: 100%|██████████| 216/216 [00:11<00:00, 18.41it/s]\n",
      "2025-09-10 12:18:55,491 - INFO - All types `lr` of epoch 548: {'lr/param_group0': 4.984475476958972e-05, 'lr/param_group1': 4.984475476958972e-05, 'lr/param_group2': 4.984475476958972e-05, 'lr/param_group3': 4.984475476958972e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:18:55,510 - INFO - epoch 548: train loss 0.006018983525724185\n",
      "2025-09-10 12:18:55,529 - INFO - 548 epochs completed!\n",
      "\n",
      "2025-09-10 12:18:55,536 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:18:55,554 - INFO - --------------------\n",
      "\n",
      "549/600: 100%|██████████| 216/216 [00:11<00:00, 18.44it/s]\n",
      "2025-09-10 12:19:07,500 - INFO - All types `lr` of epoch 549: {'lr/param_group0': 4.815694970604134e-05, 'lr/param_group1': 4.815694970604134e-05, 'lr/param_group2': 4.815694970604134e-05, 'lr/param_group3': 4.815694970604134e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:19:07,519 - INFO - epoch 549: train loss 0.006010064698919585\n",
      "2025-09-10 12:19:07,526 - INFO - 549 epochs completed!\n",
      "\n",
      "2025-09-10 12:19:07,544 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:19:07,562 - INFO - --------------------\n",
      "\n",
      "550/600: 100%|██████████| 216/216 [00:11<00:00, 18.60it/s]\n",
      "2025-09-10 12:19:19,412 - INFO - All types `lr` of epoch 550: {'lr/param_group0': 4.6494642993797704e-05, 'lr/param_group1': 4.6494642993797704e-05, 'lr/param_group2': 4.6494642993797704e-05, 'lr/param_group3': 4.6494642993797704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:19:19,435 - INFO - epoch 550: train loss 0.006004944443702698\n",
      "2025-09-10 12:19:19,456 - INFO - 550 epochs completed!\n",
      "\n",
      "2025-09-10 12:19:19,475 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:19:19,493 - INFO - --------------------\n",
      "\n",
      "551/600: 100%|██████████| 216/216 [00:12<00:00, 17.72it/s]\n",
      "2025-09-10 12:19:31,949 - INFO - All types `lr` of epoch 551: {'lr/param_group0': 4.485824478216651e-05, 'lr/param_group1': 4.485824478216651e-05, 'lr/param_group2': 4.485824478216651e-05, 'lr/param_group3': 4.485824478216651e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:19:31,968 - INFO - epoch 551: train loss 0.00600232696591842\n",
      "2025-09-10 12:19:31,988 - INFO - 551 epochs completed!\n",
      "\n",
      "2025-09-10 12:19:31,996 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:19:32,014 - INFO - --------------------\n",
      "\n",
      "552/600: 100%|██████████| 216/216 [00:11<00:00, 18.11it/s]\n",
      "2025-09-10 12:19:44,220 - INFO - All types `lr` of epoch 552: {'lr/param_group0': 4.324815882792043e-05, 'lr/param_group1': 4.324815882792043e-05, 'lr/param_group2': 4.324815882792043e-05, 'lr/param_group3': 4.324815882792043e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:19:44,228 - INFO - epoch 552: train loss 0.005992668978352513\n",
      "2025-09-10 12:19:44,247 - INFO - 552 epochs completed!\n",
      "\n",
      "2025-09-10 12:19:44,252 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:19:44,271 - INFO - --------------------\n",
      "\n",
      "553/600: 100%|██████████| 216/216 [00:11<00:00, 18.24it/s]\n",
      "2025-09-10 12:19:56,387 - INFO - All types `lr` of epoch 553: {'lr/param_group0': 4.1664782395676444e-05, 'lr/param_group1': 4.1664782395676444e-05, 'lr/param_group2': 4.1664782395676444e-05, 'lr/param_group3': 4.1664782395676444e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:19:56,396 - INFO - epoch 553: train loss 0.005994620792248666\n",
      "2025-09-10 12:19:56,416 - INFO - 553 epochs completed!\n",
      "\n",
      "2025-09-10 12:19:56,435 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:19:56,443 - INFO - --------------------\n",
      "\n",
      "554/600: 100%|██████████| 216/216 [00:11<00:00, 18.12it/s]\n",
      "2025-09-10 12:20:08,634 - INFO - All types `lr` of epoch 554: {'lr/param_group0': 4.0108506159876744e-05, 'lr/param_group1': 4.0108506159876744e-05, 'lr/param_group2': 4.0108506159876744e-05, 'lr/param_group3': 4.0108506159876744e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:20:08,642 - INFO - epoch 554: train loss 0.005997064843541011\n",
      "2025-09-10 12:20:08,661 - INFO - 554 epochs completed!\n",
      "\n",
      "2025-09-10 12:20:08,681 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:20:08,688 - INFO - --------------------\n",
      "\n",
      "555/600: 100%|██████████| 216/216 [00:11<00:00, 18.27it/s]\n",
      "2025-09-10 12:20:20,769 - INFO - All types `lr` of epoch 555: {'lr/param_group0': 3.8579714108395387e-05, 'lr/param_group1': 3.8579714108395387e-05, 'lr/param_group2': 3.8579714108395387e-05, 'lr/param_group3': 3.8579714108395387e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:20:20,790 - INFO - epoch 555: train loss 0.006001790286973119\n",
      "2025-09-10 12:20:20,809 - INFO - 555 epochs completed!\n",
      "\n",
      "2025-09-10 12:20:20,817 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:20:20,836 - INFO - --------------------\n",
      "\n",
      "556/600: 100%|██████████| 216/216 [00:11<00:00, 18.03it/s]\n",
      "2025-09-10 12:20:33,082 - INFO - All types `lr` of epoch 556: {'lr/param_group0': 3.707878344779533e-05, 'lr/param_group1': 3.707878344779533e-05, 'lr/param_group2': 3.707878344779533e-05, 'lr/param_group3': 3.707878344779533e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:20:33,101 - INFO - epoch 556: train loss 0.006004264883274489\n",
      "2025-09-10 12:20:33,121 - INFO - 556 epochs completed!\n",
      "\n",
      "2025-09-10 12:20:33,129 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:20:33,148 - INFO - --------------------\n",
      "\n",
      "557/600: 100%|██████████| 216/216 [00:12<00:00, 17.86it/s]\n",
      "2025-09-10 12:20:45,508 - INFO - All types `lr` of epoch 557: {'lr/param_group0': 3.5606084510258035e-05, 'lr/param_group1': 3.5606084510258035e-05, 'lr/param_group2': 3.5606084510258035e-05, 'lr/param_group3': 3.5606084510258035e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:20:45,530 - INFO - epoch 557: train loss 0.005996805944488625\n",
      "2025-09-10 12:20:45,551 - INFO - 557 epochs completed!\n",
      "\n",
      "2025-09-10 12:20:45,570 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:20:45,588 - INFO - --------------------\n",
      "\n",
      "558/600: 100%|██████████| 216/216 [00:11<00:00, 18.09it/s]\n",
      "2025-09-10 12:20:57,805 - INFO - All types `lr` of epoch 558: {'lr/param_group0': 3.416198066220997e-05, 'lr/param_group1': 3.416198066220997e-05, 'lr/param_group2': 3.416198066220997e-05, 'lr/param_group3': 3.416198066220997e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:20:57,813 - INFO - epoch 558: train loss 0.00599625439671972\n",
      "2025-09-10 12:20:57,832 - INFO - 558 epochs completed!\n",
      "\n",
      "2025-09-10 12:20:57,851 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:20:57,858 - INFO - --------------------\n",
      "\n",
      "559/600: 100%|██████████| 216/216 [00:11<00:00, 19.39it/s]\n",
      "2025-09-10 12:21:09,258 - INFO - All types `lr` of epoch 559: {'lr/param_group0': 3.274682821466704e-05, 'lr/param_group1': 3.274682821466704e-05, 'lr/param_group2': 3.274682821466704e-05, 'lr/param_group3': 3.274682821466704e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:21:09,279 - INFO - epoch 559: train loss 0.005991667709572034\n",
      "2025-09-10 12:21:09,286 - INFO - 559 epochs completed!\n",
      "\n",
      "2025-09-10 12:21:09,304 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:21:09,324 - INFO - --------------------\n",
      "\n",
      "560/600: 100%|██████████| 216/216 [00:11<00:00, 18.26it/s]\n",
      "2025-09-10 12:21:21,399 - INFO - All types `lr` of epoch 560: {'lr/param_group0': 3.13609763353203e-05, 'lr/param_group1': 3.13609763353203e-05, 'lr/param_group2': 3.13609763353203e-05, 'lr/param_group3': 3.13609763353203e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:21:21,418 - INFO - epoch 560: train loss 0.005990297421468077\n",
      "2025-09-10 12:21:21,424 - INFO - 560 epochs completed!\n",
      "\n",
      "2025-09-10 12:21:21,442 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:21:21,461 - INFO - --------------------\n",
      "\n",
      "561/600: 100%|██████████| 216/216 [00:12<00:00, 17.72it/s]\n",
      "2025-09-10 12:21:33,898 - INFO - All types `lr` of epoch 561: {'lr/param_group0': 3.0004766962383986e-05, 'lr/param_group1': 3.0004766962383986e-05, 'lr/param_group2': 3.0004766962383986e-05, 'lr/param_group3': 3.0004766962383986e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:21:33,918 - INFO - epoch 561: train loss 0.005988804438082433\n",
      "2025-09-10 12:21:33,938 - INFO - 561 epochs completed!\n",
      "\n",
      "2025-09-10 12:21:33,946 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:21:33,965 - INFO - --------------------\n",
      "\n",
      "562/600: 100%|██████████| 216/216 [00:11<00:00, 18.02it/s]\n",
      "2025-09-10 12:21:46,230 - INFO - All types `lr` of epoch 562: {'lr/param_group0': 2.8678534720227554e-05, 'lr/param_group1': 2.8678534720227554e-05, 'lr/param_group2': 2.8678534720227554e-05, 'lr/param_group3': 2.8678534720227554e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:21:46,250 - INFO - epoch 562: train loss 0.005994964517109717\n",
      "2025-09-10 12:21:46,258 - INFO - 562 epochs completed!\n",
      "\n",
      "2025-09-10 12:21:46,277 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:21:46,295 - INFO - --------------------\n",
      "\n",
      "563/600: 100%|██████████| 216/216 [00:12<00:00, 17.65it/s]\n",
      "2025-09-10 12:21:58,791 - INFO - All types `lr` of epoch 563: {'lr/param_group0': 2.7382606836811927e-05, 'lr/param_group1': 2.7382606836811927e-05, 'lr/param_group2': 2.7382606836811927e-05, 'lr/param_group3': 2.7382606836811927e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:21:58,798 - INFO - epoch 563: train loss 0.005996896367934015\n",
      "2025-09-10 12:21:58,819 - INFO - 563 epochs completed!\n",
      "\n",
      "2025-09-10 12:21:58,839 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:21:58,846 - INFO - --------------------\n",
      "\n",
      "564/600: 100%|██████████| 216/216 [00:11<00:00, 19.04it/s]\n",
      "2025-09-10 12:22:10,458 - INFO - All types `lr` of epoch 564: {'lr/param_group0': 2.61173030629508e-05, 'lr/param_group1': 2.61173030629508e-05, 'lr/param_group2': 2.61173030629508e-05, 'lr/param_group3': 2.61173030629508e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:10,463 - INFO - epoch 564: train loss 0.00599691766978207\n",
      "2025-09-10 12:22:10,474 - INFO - 564 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:10,477 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:10,487 - INFO - --------------------\n",
      "\n",
      "565/600: 100%|██████████| 216/216 [00:06<00:00, 32.24it/s]\n",
      "2025-09-10 12:22:17,356 - INFO - All types `lr` of epoch 565: {'lr/param_group0': 2.4882935593417308e-05, 'lr/param_group1': 2.4882935593417308e-05, 'lr/param_group2': 2.4882935593417308e-05, 'lr/param_group3': 2.4882935593417308e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:17,377 - INFO - epoch 565: train loss 0.005992165076787825\n",
      "2025-09-10 12:22:17,385 - INFO - 565 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:17,404 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:17,423 - INFO - --------------------\n",
      "\n",
      "566/600: 100%|██████████| 216/216 [00:07<00:00, 29.95it/s]\n",
      "2025-09-10 12:22:24,844 - INFO - All types `lr` of epoch 566: {'lr/param_group0': 2.3679808989914373e-05, 'lr/param_group1': 2.3679808989914373e-05, 'lr/param_group2': 2.3679808989914373e-05, 'lr/param_group3': 2.3679808989914373e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:24,863 - INFO - epoch 566: train loss 0.005987749583760483\n",
      "2025-09-10 12:22:24,883 - INFO - 566 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:24,890 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:24,908 - INFO - --------------------\n",
      "\n",
      "567/600: 100%|██████████| 216/216 [00:07<00:00, 30.09it/s]\n",
      "2025-09-10 12:22:32,336 - INFO - All types `lr` of epoch 567: {'lr/param_group0': 2.250822010592862e-05, 'lr/param_group1': 2.250822010592862e-05, 'lr/param_group2': 2.250822010592862e-05, 'lr/param_group3': 2.250822010592862e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:32,344 - INFO - epoch 567: train loss 0.0059840156970528404\n",
      "2025-09-10 12:22:32,363 - INFO - 567 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:32,383 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:32,390 - INFO - --------------------\n",
      "\n",
      "568/600: 100%|██████████| 216/216 [00:06<00:00, 32.65it/s]\n",
      "2025-09-10 12:22:39,229 - INFO - All types `lr` of epoch 568: {'lr/param_group0': 2.1368458013486268e-05, 'lr/param_group1': 2.1368458013486268e-05, 'lr/param_group2': 2.1368458013486268e-05, 'lr/param_group3': 2.1368458013486268e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:39,242 - INFO - epoch 568: train loss 0.005982925167902269\n",
      "2025-09-10 12:22:39,253 - INFO - 568 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:39,257 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:39,266 - INFO - --------------------\n",
      "\n",
      "569/600: 100%|██████████| 216/216 [00:06<00:00, 35.22it/s]\n",
      "2025-09-10 12:22:45,565 - INFO - All types `lr` of epoch 569: {'lr/param_group0': 2.0260803931829005e-05, 'lr/param_group1': 2.0260803931829005e-05, 'lr/param_group2': 2.0260803931829005e-05, 'lr/param_group3': 2.0260803931829005e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:45,579 - INFO - epoch 569: train loss 0.0059866447807979525\n",
      "100%|██████████| 54/54 [00:01<00:00, 35.10it/s]\n",
      "2025-09-10 12:22:47,294 - INFO - epoch 569: val loss 0.006200422920907537\n",
      "2025-09-10 12:22:47,300 - INFO - 569 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:22:47,337 - INFO - 569 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:47,348 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:47,353 - INFO - --------------------\n",
      "\n",
      "570/600: 100%|██████████| 216/216 [00:07<00:00, 27.41it/s]\n",
      "2025-09-10 12:22:55,397 - INFO - All types `lr` of epoch 570: {'lr/param_group0': 1.918553115802738e-05, 'lr/param_group1': 1.918553115802738e-05, 'lr/param_group2': 1.918553115802738e-05, 'lr/param_group3': 1.918553115802738e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:22:55,416 - INFO - epoch 570: train loss 0.00598890975190982\n",
      "2025-09-10 12:22:55,435 - INFO - 570 epochs completed!\n",
      "\n",
      "2025-09-10 12:22:55,442 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:22:55,458 - INFO - --------------------\n",
      "\n",
      "571/600: 100%|██████████| 216/216 [00:09<00:00, 23.77it/s]\n",
      "2025-09-10 12:23:04,773 - INFO - All types `lr` of epoch 571: {'lr/param_group0': 1.814290499954858e-05, 'lr/param_group1': 1.814290499954858e-05, 'lr/param_group2': 1.814290499954858e-05, 'lr/param_group3': 1.814290499954858e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:23:04,798 - INFO - epoch 571: train loss 0.005988929138294663\n",
      "2025-09-10 12:23:04,819 - INFO - 571 epochs completed!\n",
      "\n",
      "2025-09-10 12:23:04,839 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:23:04,857 - INFO - --------------------\n",
      "\n",
      "572/600: 100%|██████████| 216/216 [00:11<00:00, 19.46it/s]\n",
      "2025-09-10 12:23:16,235 - INFO - All types `lr` of epoch 572: {'lr/param_group0': 1.713318270879612e-05, 'lr/param_group1': 1.713318270879612e-05, 'lr/param_group2': 1.713318270879612e-05, 'lr/param_group3': 1.713318270879612e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:23:16,243 - INFO - epoch 572: train loss 0.005986074818927726\n",
      "2025-09-10 12:23:16,262 - INFO - 572 epochs completed!\n",
      "\n",
      "2025-09-10 12:23:16,267 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:23:16,285 - INFO - --------------------\n",
      "\n",
      "573/600: 100%|██████████| 216/216 [00:11<00:00, 18.32it/s]\n",
      "2025-09-10 12:23:28,344 - INFO - All types `lr` of epoch 573: {'lr/param_group0': 1.6156613419636378e-05, 'lr/param_group1': 1.6156613419636378e-05, 'lr/param_group2': 1.6156613419636378e-05, 'lr/param_group3': 1.6156613419636378e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:23:28,351 - INFO - epoch 573: train loss 0.005985519048947565\n",
      "2025-09-10 12:23:28,370 - INFO - 573 epochs completed!\n",
      "\n",
      "2025-09-10 12:23:28,389 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:23:28,396 - INFO - --------------------\n",
      "\n",
      "574/600: 100%|██████████| 216/216 [00:11<00:00, 18.95it/s]\n",
      "2025-09-10 12:23:40,037 - INFO - All types `lr` of epoch 574: {'lr/param_group0': 1.5213438085928809e-05, 'lr/param_group1': 1.5213438085928809e-05, 'lr/param_group2': 1.5213438085928809e-05, 'lr/param_group3': 1.5213438085928809e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:23:40,058 - INFO - epoch 574: train loss 0.0059850285825733505\n",
      "2025-09-10 12:23:40,067 - INFO - 574 epochs completed!\n",
      "\n",
      "2025-09-10 12:23:40,085 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:23:40,107 - INFO - --------------------\n",
      "\n",
      "575/600: 100%|██████████| 216/216 [00:12<00:00, 17.48it/s]\n",
      "2025-09-10 12:23:52,708 - INFO - All types `lr` of epoch 575: {'lr/param_group0': 1.4303889422073933e-05, 'lr/param_group1': 1.4303889422073933e-05, 'lr/param_group2': 1.4303889422073933e-05, 'lr/param_group3': 1.4303889422073933e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:23:52,728 - INFO - epoch 575: train loss 0.005985679748442231\n",
      "2025-09-10 12:23:52,749 - INFO - 575 epochs completed!\n",
      "\n",
      "2025-09-10 12:23:52,757 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:23:52,776 - INFO - --------------------\n",
      "\n",
      "576/600: 100%|██████████| 216/216 [00:12<00:00, 17.81it/s]\n",
      "2025-09-10 12:24:05,162 - INFO - All types `lr` of epoch 576: {'lr/param_group0': 1.3428191845594682e-05, 'lr/param_group1': 1.3428191845594682e-05, 'lr/param_group2': 1.3428191845594682e-05, 'lr/param_group3': 1.3428191845594682e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:24:05,181 - INFO - epoch 576: train loss 0.00598386281894313\n",
      "2025-09-10 12:24:05,187 - INFO - 576 epochs completed!\n",
      "\n",
      "2025-09-10 12:24:05,205 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:24:05,224 - INFO - --------------------\n",
      "\n",
      "577/600: 100%|██████████| 216/216 [00:12<00:00, 17.92it/s]\n",
      "2025-09-10 12:24:17,534 - INFO - All types `lr` of epoch 577: {'lr/param_group0': 1.2586561421764697e-05, 'lr/param_group1': 1.2586561421764697e-05, 'lr/param_group2': 1.2586561421764697e-05, 'lr/param_group3': 1.2586561421764697e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:24:17,542 - INFO - epoch 577: train loss 0.005985717511201209\n",
      "2025-09-10 12:24:17,561 - INFO - 577 epochs completed!\n",
      "\n",
      "2025-09-10 12:24:17,581 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:24:17,589 - INFO - --------------------\n",
      "\n",
      "578/600: 100%|██████████| 216/216 [00:12<00:00, 17.95it/s]\n",
      "2025-09-10 12:24:29,877 - INFO - All types `lr` of epoch 578: {'lr/param_group0': 1.1779205810297499e-05, 'lr/param_group1': 1.1779205810297499e-05, 'lr/param_group2': 1.1779205810297499e-05, 'lr/param_group3': 1.1779205810297499e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:24:29,899 - INFO - epoch 578: train loss 0.00598673628000715\n",
      "2025-09-10 12:24:29,922 - INFO - 578 epochs completed!\n",
      "\n",
      "2025-09-10 12:24:29,929 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:24:29,948 - INFO - --------------------\n",
      "\n",
      "579/600: 100%|██████████| 216/216 [00:10<00:00, 20.08it/s]\n",
      "2025-09-10 12:24:40,975 - INFO - All types `lr` of epoch 579: {'lr/param_group0': 1.1006324214109518e-05, 'lr/param_group1': 1.1006324214109518e-05, 'lr/param_group2': 1.1006324214109518e-05, 'lr/param_group3': 1.1006324214109518e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:24:40,997 - INFO - epoch 579: train loss 0.005986569640097312\n",
      "2025-09-10 12:24:41,004 - INFO - 579 epochs completed!\n",
      "\n",
      "2025-09-10 12:24:41,024 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:24:41,030 - INFO - --------------------\n",
      "\n",
      "580/600: 100%|██████████| 216/216 [00:11<00:00, 18.71it/s]\n",
      "2025-09-10 12:24:52,830 - INFO - All types `lr` of epoch 580: {'lr/param_group0': 1.0268107330169672e-05, 'lr/param_group1': 1.0268107330169672e-05, 'lr/param_group2': 1.0268107330169672e-05, 'lr/param_group3': 1.0268107330169672e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:24:52,851 - INFO - epoch 580: train loss 0.00598680532399427\n",
      "2025-09-10 12:24:52,859 - INFO - 580 epochs completed!\n",
      "\n",
      "2025-09-10 12:24:52,878 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:24:52,897 - INFO - --------------------\n",
      "\n",
      "581/600: 100%|██████████| 216/216 [00:12<00:00, 17.65it/s]\n",
      "2025-09-10 12:25:05,400 - INFO - All types `lr` of epoch 581: {'lr/param_group0': 9.564737302448001e-06, 'lr/param_group1': 9.564737302448001e-06, 'lr/param_group2': 9.564737302448001e-06, 'lr/param_group3': 9.564737302448001e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:25:05,409 - INFO - epoch 581: train loss 0.005988973807284815\n",
      "2025-09-10 12:25:05,430 - INFO - 581 epochs completed!\n",
      "\n",
      "2025-09-10 12:25:05,451 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:25:05,459 - INFO - --------------------\n",
      "\n",
      "582/600: 100%|██████████| 216/216 [00:11<00:00, 19.36it/s]\n",
      "2025-09-10 12:25:16,883 - INFO - All types `lr` of epoch 582: {'lr/param_group0': 8.896387676973949e-06, 'lr/param_group1': 8.896387676973949e-06, 'lr/param_group2': 8.896387676973949e-06, 'lr/param_group3': 8.896387676973949e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:25:16,905 - INFO - epoch 582: train loss 0.005989539771151074\n",
      "2025-09-10 12:25:16,930 - INFO - 582 epochs completed!\n",
      "\n",
      "2025-09-10 12:25:16,937 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:25:16,958 - INFO - --------------------\n",
      "\n",
      "583/600: 100%|██████████| 216/216 [00:11<00:00, 18.13it/s]\n",
      "2025-09-10 12:25:29,124 - INFO - All types `lr` of epoch 583: {'lr/param_group0': 8.26322335901699e-06, 'lr/param_group1': 8.26322335901699e-06, 'lr/param_group2': 8.26322335901699e-06, 'lr/param_group3': 8.26322335901699e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:25:29,132 - INFO - epoch 583: train loss 0.005990236268930689\n",
      "2025-09-10 12:25:29,152 - INFO - 583 epochs completed!\n",
      "\n",
      "2025-09-10 12:25:29,171 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:25:29,178 - INFO - --------------------\n",
      "\n",
      "584/600: 100%|██████████| 216/216 [00:12<00:00, 17.88it/s]\n",
      "2025-09-10 12:25:41,518 - INFO - All types `lr` of epoch 584: {'lr/param_group0': 7.665400572398272e-06, 'lr/param_group1': 7.665400572398272e-06, 'lr/param_group2': 7.665400572398272e-06, 'lr/param_group3': 7.665400572398272e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:25:41,539 - INFO - epoch 584: train loss 0.005989122662598405\n",
      "2025-09-10 12:25:41,545 - INFO - 584 epochs completed!\n",
      "\n",
      "2025-09-10 12:25:41,565 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:25:41,586 - INFO - --------------------\n",
      "\n",
      "585/600: 100%|██████████| 216/216 [00:12<00:00, 17.91it/s]\n",
      "2025-09-10 12:25:53,889 - INFO - All types `lr` of epoch 585: {'lr/param_group0': 7.103066820945047e-06, 'lr/param_group1': 7.103066820945047e-06, 'lr/param_group2': 7.103066820945047e-06, 'lr/param_group3': 7.103066820945047e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:25:53,911 - INFO - epoch 585: train loss 0.005987067670233686\n",
      "2025-09-10 12:25:53,919 - INFO - 585 epochs completed!\n",
      "\n",
      "2025-09-10 12:25:53,937 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:25:53,957 - INFO - --------------------\n",
      "\n",
      "586/600: 100%|██████████| 216/216 [00:11<00:00, 18.09it/s]\n",
      "2025-09-10 12:26:06,154 - INFO - All types `lr` of epoch 586: {'lr/param_group0': 6.576360852096019e-06, 'lr/param_group1': 6.576360852096019e-06, 'lr/param_group2': 6.576360852096019e-06, 'lr/param_group3': 6.576360852096019e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:26:06,162 - INFO - epoch 586: train loss 0.005991239198785344\n",
      "2025-09-10 12:26:06,182 - INFO - 586 epochs completed!\n",
      "\n",
      "2025-09-10 12:26:06,203 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:26:06,211 - INFO - --------------------\n",
      "\n",
      "587/600: 100%|██████████| 216/216 [00:12<00:00, 17.94it/s]\n",
      "2025-09-10 12:26:18,519 - INFO - All types `lr` of epoch 587: {'lr/param_group0': 6.085412622667795e-06, 'lr/param_group1': 6.085412622667795e-06, 'lr/param_group2': 6.085412622667795e-06, 'lr/param_group3': 6.085412622667795e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:26:18,528 - INFO - epoch 587: train loss 0.005989869132732834\n",
      "2025-09-10 12:26:18,549 - INFO - 587 epochs completed!\n",
      "\n",
      "2025-09-10 12:26:18,572 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:26:18,593 - INFO - --------------------\n",
      "\n",
      "588/600: 100%|██████████| 216/216 [00:12<00:00, 17.59it/s]\n",
      "2025-09-10 12:26:31,133 - INFO - All types `lr` of epoch 588: {'lr/param_group0': 5.630343266789739e-06, 'lr/param_group1': 5.630343266789739e-06, 'lr/param_group2': 5.630343266789739e-06, 'lr/param_group3': 5.630343266789739e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:26:31,153 - INFO - epoch 588: train loss 0.005991472672947027\n",
      "2025-09-10 12:26:31,161 - INFO - 588 epochs completed!\n",
      "\n",
      "2025-09-10 12:26:31,181 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:26:31,202 - INFO - --------------------\n",
      "\n",
      "589/600: 100%|██████████| 216/216 [00:12<00:00, 17.54it/s]\n",
      "2025-09-10 12:26:43,776 - INFO - All types `lr` of epoch 589: {'lr/param_group0': 5.211265066016068e-06, 'lr/param_group1': 5.211265066016068e-06, 'lr/param_group2': 5.211265066016068e-06, 'lr/param_group3': 5.211265066016068e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:26:43,787 - INFO - epoch 589: train loss 0.0059866794876547325\n",
      "2025-09-10 12:26:43,808 - INFO - 589 epochs completed!\n",
      "\n",
      "2025-09-10 12:26:43,814 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:26:43,834 - INFO - --------------------\n",
      "\n",
      "590/600: 100%|██████████| 216/216 [00:12<00:00, 17.71it/s]\n",
      "2025-09-10 12:26:56,300 - INFO - All types `lr` of epoch 590: {'lr/param_group0': 4.8282814216220265e-06, 'lr/param_group1': 4.8282814216220265e-06, 'lr/param_group2': 4.8282814216220265e-06, 'lr/param_group3': 4.8282814216220265e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:26:56,322 - INFO - epoch 590: train loss 0.005987252630465837\n",
      "2025-09-10 12:26:56,344 - INFO - 590 epochs completed!\n",
      "\n",
      "2025-09-10 12:26:56,354 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:26:56,375 - INFO - --------------------\n",
      "\n",
      "591/600: 100%|██████████| 216/216 [00:11<00:00, 18.01it/s]\n",
      "2025-09-10 12:27:08,640 - INFO - All types `lr` of epoch 591: {'lr/param_group0': 4.4814868290912184e-06, 'lr/param_group1': 4.4814868290912184e-06, 'lr/param_group2': 4.4814868290912184e-06, 'lr/param_group3': 4.4814868290912184e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:27:08,660 - INFO - epoch 591: train loss 0.0059911662732095765\n",
      "2025-09-10 12:27:08,668 - INFO - 591 epochs completed!\n",
      "\n",
      "2025-09-10 12:27:08,687 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:27:08,706 - INFO - --------------------\n",
      "\n",
      "592/600: 100%|██████████| 216/216 [00:12<00:00, 17.62it/s]\n",
      "2025-09-10 12:27:21,218 - INFO - All types `lr` of epoch 592: {'lr/param_group0': 4.170966854800062e-06, 'lr/param_group1': 4.170966854800062e-06, 'lr/param_group2': 4.170966854800062e-06, 'lr/param_group3': 4.170966854800062e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:27:21,226 - INFO - epoch 592: train loss 0.005990221833430782\n",
      "2025-09-10 12:27:21,246 - INFO - 592 epochs completed!\n",
      "\n",
      "2025-09-10 12:27:21,252 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:27:21,272 - INFO - --------------------\n",
      "\n",
      "593/600: 100%|██████████| 216/216 [00:12<00:00, 17.13it/s]\n",
      "2025-09-10 12:27:34,161 - INFO - All types `lr` of epoch 593: {'lr/param_group0': 3.896798114905841e-06, 'lr/param_group1': 3.896798114905841e-06, 'lr/param_group2': 3.896798114905841e-06, 'lr/param_group3': 3.896798114905841e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:27:34,170 - INFO - epoch 593: train loss 0.005989468707142536\n",
      "2025-09-10 12:27:34,192 - INFO - 593 epochs completed!\n",
      "\n",
      "2025-09-10 12:27:34,213 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:27:34,222 - INFO - --------------------\n",
      "\n",
      "594/600: 100%|██████████| 216/216 [00:12<00:00, 17.06it/s]\n",
      "2025-09-10 12:27:47,156 - INFO - All types `lr` of epoch 594: {'lr/param_group0': 3.6590482564426316e-06, 'lr/param_group1': 3.6590482564426316e-06, 'lr/param_group2': 3.6590482564426316e-06, 'lr/param_group3': 3.6590482564426316e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:27:47,165 - INFO - epoch 594: train loss 0.005990749043929908\n",
      "2025-09-10 12:27:47,187 - INFO - 594 epochs completed!\n",
      "\n",
      "2025-09-10 12:27:47,208 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:27:47,216 - INFO - --------------------\n",
      "\n",
      "595/600: 100%|██████████| 216/216 [00:12<00:00, 17.12it/s]\n",
      "2025-09-10 12:28:00,097 - INFO - All types `lr` of epoch 595: {'lr/param_group0': 3.4577759406304806e-06, 'lr/param_group1': 3.4577759406304806e-06, 'lr/param_group2': 3.4577759406304806e-06, 'lr/param_group3': 3.4577759406304806e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:28:00,120 - INFO - epoch 595: train loss 0.005993072026521312\n",
      "2025-09-10 12:28:00,143 - INFO - 595 epochs completed!\n",
      "\n",
      "2025-09-10 12:28:00,166 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:28:00,186 - INFO - --------------------\n",
      "\n",
      "596/600: 100%|██████████| 216/216 [00:12<00:00, 17.09it/s]\n",
      "2025-09-10 12:28:13,087 - INFO - All types `lr` of epoch 596: {'lr/param_group0': 3.293030828401688e-06, 'lr/param_group1': 3.293030828401688e-06, 'lr/param_group2': 3.293030828401688e-06, 'lr/param_group3': 3.293030828401688e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:28:13,109 - INFO - epoch 596: train loss 0.005992201309978824\n",
      "2025-09-10 12:28:13,118 - INFO - 596 epochs completed!\n",
      "\n",
      "2025-09-10 12:28:13,138 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:28:13,159 - INFO - --------------------\n",
      "\n",
      "597/600: 100%|██████████| 216/216 [00:12<00:00, 17.21it/s]\n",
      "2025-09-10 12:28:25,977 - INFO - All types `lr` of epoch 597: {'lr/param_group0': 3.164853568147474e-06, 'lr/param_group1': 3.164853568147474e-06, 'lr/param_group2': 3.164853568147474e-06, 'lr/param_group3': 3.164853568147474e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:28:25,997 - INFO - epoch 597: train loss 0.0059909133835592205\n",
      "2025-09-10 12:28:26,019 - INFO - 597 epochs completed!\n",
      "\n",
      "2025-09-10 12:28:26,027 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:28:26,048 - INFO - --------------------\n",
      "\n",
      "598/600: 100%|██████████| 216/216 [00:12<00:00, 17.02it/s]\n",
      "2025-09-10 12:28:39,016 - INFO - All types `lr` of epoch 598: {'lr/param_group0': 3.073275785688867e-06, 'lr/param_group1': 3.073275785688867e-06, 'lr/param_group2': 3.073275785688867e-06, 'lr/param_group3': 3.073275785688867e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:28:39,039 - INFO - epoch 598: train loss 0.005991571535425329\n",
      "2025-09-10 12:28:39,048 - INFO - 598 epochs completed!\n",
      "\n",
      "2025-09-10 12:28:39,068 - INFO - --------------------\n",
      "\n",
      "2025-09-10 12:28:39,091 - INFO - --------------------\n",
      "\n",
      "599/600: 100%|██████████| 216/216 [00:12<00:00, 16.97it/s]\n",
      "2025-09-10 12:28:52,086 - INFO - All types `lr` of epoch 599: {'lr/param_group0': 3.0183200764734126e-06, 'lr/param_group1': 3.0183200764734126e-06, 'lr/param_group2': 3.0183200764734126e-06, 'lr/param_group3': 3.0183200764734126e-06}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-10 12:28:52,108 - INFO - epoch 599: train loss 0.005992255069065356\n",
      "100%|██████████| 54/54 [00:01<00:00, 30.67it/s]\n",
      "2025-09-10 12:28:54,141 - INFO - epoch 599: val loss 0.006208300719865494\n",
      "2025-09-10 12:28:54,163 - INFO - 599 epoch vae reconstruct images complete!\n",
      "2025-09-10 12:28:54,248 - INFO - epoch 599 has been saved\n",
      "2025-09-10 12:28:54,337 - INFO - 599 epochs completed!\n",
      "\n",
      "2025-09-10 12:28:54,351 - INFO - --------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vqvaen_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
