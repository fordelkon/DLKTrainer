{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f02e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6033f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Encoder\n",
    "# --------------------\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, latent_dim=128, hidden_dims=None):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]  # 适合64x64\n",
    "\n",
    "        modules = []\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, h_dim,\n",
    "                              kernel_size=3, stride=2, padding=1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # 输入 (3,64,64) -> 输出 (512, 2, 2)，展平就是 512*2*2=2048\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1] * 2 * 2, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1] * 2 * 2, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.encoder(x)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_logvar(result)\n",
    "        return mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6195acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Decoder\n",
    "# --------------------\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, out_channels=3, latent_dim=128, hidden_dims=None):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 2 * 2)\n",
    "\n",
    "        modules = []\n",
    "        hidden_dims = hidden_dims[::-1]  # 反转\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        # 最后一层恢复到64x64\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dims[-1], hidden_dims[-1],\n",
    "                               kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dims[-1], out_channels=out_channels,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.Tanh()  # 输出范围 [-1,1]，可改成 Sigmoid 取 [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[-1], 2, 2)  # (B, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eddd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, image_num=-1):\n",
    "        # Collects image file paths from the root directory, limited to `image_num` images.\n",
    "        self.image_paths = sorted(\n",
    "            [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)\n",
    "             if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        )[:image_num]  # Limit to the first `image_num` images\n",
    "        self.transform = transform # Transformation to apply to images\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the number of images in the dataset.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Loads an image by index, converts it to RGB, and applies transformations if provided.\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Since no actual labels, return 0 as dummy labels\n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af303e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pipeline for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Randomly applies a horizontal flip with 40% probability.\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ], p=0.4),  \n",
    "    transforms.ToTensor(), # Converts image to a PyTorch tensor.\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5)), # Normalizes using mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774c6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(root_dir=\"/datasets/delkon/dm_data\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a6570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ConvEncoder()\n",
    "decoder = ConvDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c41d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2lightrainer.UnsupervisedLearning.VAE.trainer_config import VAETrainerConfig\n",
    "from d2lightrainer.UnsupervisedLearning.VAE.trainer import VAETrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca76026",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_cfg = VAETrainerConfig()\n",
    "new_param_dict = {\"device\": 3, \"save_dir\": \"runs_vae\", \"batch_size\": 16, \"nominal_batch_size\": 64}\n",
    "vae_cfg.update(**new_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d82255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:36:58,884 - INFO - Using GPU: 3\n",
      "2025-09-07 19:36:58,892 - INFO - 'optimizer:' Adam(lr=0.0003, momentum=0.937) with parameter groups 10 weight(decay=0.0), 0 weight(decay=1.0000000000000002e-06), 14 weight(decay=0.0001), 24 bias(decay=0.0)\n",
      "2025-09-07 19:36:59,001 - INFO - --------------------\n",
      "\n",
      "0/800: 100%|██████████| 216/216 [00:06<00:00, 35.27it/s]\n",
      "2025-09-07 19:37:05,256 - INFO - All types `lr` of epoch 0: {'lr/param_group0': np.float64(0.0005850694444444444), 'lr/param_group1': np.float64(1.4930555555555555e-05), 'lr/param_group2': np.float64(1.4930555555555555e-05), 'lr/param_group3': np.float64(1.4930555555555555e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:05,257 - INFO - epoch 0: train loss 0.34191476457096914\n",
      "2025-09-07 19:37:05,259 - INFO - 0 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:05,260 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:05,261 - INFO - --------------------\n",
      "\n",
      "1/800: 100%|██████████| 216/216 [00:05<00:00, 40.29it/s]\n",
      "2025-09-07 19:37:10,773 - INFO - All types `lr` of epoch 1: {'lr/param_group0': np.float64(0.0005700693405920511), 'lr/param_group1': np.float64(2.993045170316224e-05), 'lr/param_group2': np.float64(2.993045170316224e-05), 'lr/param_group3': np.float64(2.993045170316224e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:10,774 - INFO - epoch 1: train loss 0.20303691792543288\n",
      "2025-09-07 19:37:10,776 - INFO - 1 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:10,777 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:10,777 - INFO - --------------------\n",
      "\n",
      "2/800: 100%|██████████| 216/216 [00:05<00:00, 40.46it/s]\n",
      "2025-09-07 19:37:16,251 - INFO - All types `lr` of epoch 2: {'lr/param_group0': np.float64(0.0005550688208505749), 'lr/param_group1': np.float64(4.4929931961686144e-05), 'lr/param_group2': np.float64(4.4929931961686144e-05), 'lr/param_group3': np.float64(4.4929931961686144e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:16,252 - INFO - epoch 2: train loss 0.14111845602315884\n",
      "2025-09-07 19:37:16,254 - INFO - 2 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:16,254 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:16,255 - INFO - --------------------\n",
      "\n",
      "3/800: 100%|██████████| 216/216 [00:05<00:00, 42.18it/s]\n",
      "2025-09-07 19:37:21,530 - INFO - All types `lr` of epoch 3: {'lr/param_group0': np.float64(0.0005400675729519939), 'lr/param_group1': np.float64(5.992868406310501e-05), 'lr/param_group2': np.float64(5.992868406310501e-05), 'lr/param_group3': np.float64(5.992868406310501e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:21,531 - INFO - epoch 3: train loss 0.12270470011841368\n",
      "2025-09-07 19:37:21,532 - INFO - 3 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:21,533 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:21,534 - INFO - --------------------\n",
      "\n",
      "4/800: 100%|██████████| 216/216 [00:05<00:00, 42.87it/s]\n",
      "2025-09-07 19:37:26,719 - INFO - All types `lr` of epoch 4: {'lr/param_group0': np.float64(0.0005250652846459354), 'lr/param_group1': np.float64(7.492639575704655e-05), 'lr/param_group2': np.float64(7.492639575704655e-05), 'lr/param_group3': np.float64(7.492639575704655e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:26,721 - INFO - epoch 4: train loss 0.110005475235758\n",
      "2025-09-07 19:37:26,722 - INFO - 4 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:26,723 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:26,724 - INFO - --------------------\n",
      "\n",
      "5/800: 100%|██████████| 216/216 [00:05<00:00, 42.90it/s]\n",
      "2025-09-07 19:37:31,908 - INFO - All types `lr` of epoch 5: {'lr/param_group0': np.float64(0.0005100616437077029), 'lr/param_group1': np.float64(8.992275481881413e-05), 'lr/param_group2': np.float64(8.992275481881413e-05), 'lr/param_group3': np.float64(8.992275481881413e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:31,909 - INFO - epoch 5: train loss 0.09710893152212655\n",
      "2025-09-07 19:37:31,911 - INFO - 5 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:31,912 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:31,913 - INFO - --------------------\n",
      "\n",
      "6/800: 100%|██████████| 216/216 [00:04<00:00, 43.38it/s]\n",
      "2025-09-07 19:37:37,040 - INFO - All types `lr` of epoch 6: {'lr/param_group0': np.float64(0.0004950563379463006), 'lr/param_group1': np.float64(0.00010491744905741176), 'lr/param_group2': np.float64(0.00010491744905741176), 'lr/param_group3': np.float64(0.00010491744905741176)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:37,041 - INFO - epoch 6: train loss 0.08956518838251079\n",
      "2025-09-07 19:37:37,043 - INFO - 6 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:37,043 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:37,044 - INFO - --------------------\n",
      "\n",
      "7/800: 100%|██████████| 216/216 [00:04<00:00, 50.67it/s]\n",
      "2025-09-07 19:37:41,444 - INFO - All types `lr` of epoch 7: {'lr/param_group0': np.float64(0.00048004905521245746), 'lr/param_group1': np.float64(0.00011991016632356861), 'lr/param_group2': np.float64(0.00011991016632356861), 'lr/param_group3': np.float64(0.00011991016632356861)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:41,445 - INFO - epoch 7: train loss 0.08522583073419002\n",
      "2025-09-07 19:37:41,447 - INFO - 7 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:41,448 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:41,449 - INFO - --------------------\n",
      "\n",
      "8/800: 100%|██████████| 216/216 [00:04<00:00, 43.30it/s]\n",
      "2025-09-07 19:37:46,584 - INFO - All types `lr` of epoch 8: {'lr/param_group0': np.float64(0.0004650394834066512), 'lr/param_group1': np.float64(0.0001349005945177623), 'lr/param_group2': np.float64(0.0001349005945177623), 'lr/param_group3': np.float64(0.0001349005945177623)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:46,585 - INFO - epoch 8: train loss 0.08219755471994479\n",
      "2025-09-07 19:37:46,587 - INFO - 8 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:46,587 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:46,588 - INFO - --------------------\n",
      "\n",
      "9/800: 100%|██████████| 216/216 [00:05<00:00, 42.59it/s]\n",
      "2025-09-07 19:37:51,793 - INFO - All types `lr` of epoch 9: {'lr/param_group0': np.float64(0.00045002731048713034), 'lr/param_group1': np.float64(0.00014988842159824144), 'lr/param_group2': np.float64(0.00014988842159824144), 'lr/param_group3': np.float64(0.00014988842159824144)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:51,794 - INFO - epoch 9: train loss 0.07943897946151318\n",
      "2025-09-07 19:37:51,795 - INFO - 9 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:51,796 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:51,797 - INFO - --------------------\n",
      "\n",
      "10/800: 100%|██████████| 216/216 [00:04<00:00, 45.09it/s]\n",
      "2025-09-07 19:37:56,731 - INFO - All types `lr` of epoch 10: {'lr/param_group0': np.float64(0.00043501222447793556), 'lr/param_group1': np.float64(0.00016487333558904668), 'lr/param_group2': np.float64(0.00016487333558904668), 'lr/param_group3': np.float64(0.00016487333558904668)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:37:56,733 - INFO - epoch 10: train loss 0.0769600141276088\n",
      "2025-09-07 19:37:56,734 - INFO - 10 epochs completed!\n",
      "\n",
      "2025-09-07 19:37:56,735 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:37:56,736 - INFO - --------------------\n",
      "\n",
      "11/800: 100%|██████████| 216/216 [00:04<00:00, 44.98it/s]\n",
      "2025-09-07 19:38:01,688 - INFO - All types `lr` of epoch 11: {'lr/param_group0': np.float64(0.0004199939134769195), 'lr/param_group1': np.float64(0.00017985502458803062), 'lr/param_group2': np.float64(0.00017985502458803062), 'lr/param_group3': np.float64(0.00017985502458803062)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:01,689 - INFO - epoch 11: train loss 0.07527941555060723\n",
      "2025-09-07 19:38:01,691 - INFO - 11 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:01,692 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:01,692 - INFO - --------------------\n",
      "\n",
      "12/800: 100%|██████████| 216/216 [00:05<00:00, 42.50it/s]\n",
      "2025-09-07 19:38:06,928 - INFO - All types `lr` of epoch 12: {'lr/param_group0': np.float64(0.00040497206566376476), 'lr/param_group1': np.float64(0.00019483317677487585), 'lr/param_group2': np.float64(0.00019483317677487585), 'lr/param_group3': np.float64(0.00019483317677487585)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:06,929 - INFO - epoch 12: train loss 0.07354069406304646\n",
      "2025-09-07 19:38:06,930 - INFO - 12 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:06,931 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:06,933 - INFO - --------------------\n",
      "\n",
      "13/800: 100%|██████████| 216/216 [00:04<00:00, 44.89it/s]\n",
      "2025-09-07 19:38:11,894 - INFO - All types `lr` of epoch 13: {'lr/param_group0': np.float64(0.00038994636930800015), 'lr/param_group1': np.float64(0.00020980748041911132), 'lr/param_group2': np.float64(0.00020980748041911132), 'lr/param_group3': np.float64(0.00020980748041911132)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:11,896 - INFO - epoch 13: train loss 0.07193442130530323\n",
      "2025-09-07 19:38:11,897 - INFO - 13 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:11,898 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:11,899 - INFO - --------------------\n",
      "\n",
      "14/800: 100%|██████████| 216/216 [00:04<00:00, 43.64it/s]\n",
      "2025-09-07 19:38:17,001 - INFO - All types `lr` of epoch 14: {'lr/param_group0': np.float64(0.0003749165127770161), 'lr/param_group1': np.float64(0.00022477762388812723), 'lr/param_group2': np.float64(0.00022477762388812723), 'lr/param_group3': np.float64(0.00022477762388812723)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:17,002 - INFO - epoch 14: train loss 0.07101093975965071\n",
      "2025-09-07 19:38:17,003 - INFO - 14 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:17,003 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:17,004 - INFO - --------------------\n",
      "\n",
      "15/800: 100%|██████████| 216/216 [00:04<00:00, 43.76it/s]\n",
      "2025-09-07 19:38:22,082 - INFO - All types `lr` of epoch 15: {'lr/param_group0': np.float64(0.00035988218454407545), 'lr/param_group1': np.float64(0.00023974329565518658), 'lr/param_group2': np.float64(0.00023974329565518658), 'lr/param_group3': np.float64(0.00023974329565518658)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:22,083 - INFO - epoch 15: train loss 0.0706744806289121\n",
      "2025-09-07 19:38:22,085 - INFO - 15 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:22,086 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:22,087 - INFO - --------------------\n",
      "\n",
      "16/800: 100%|██████████| 216/216 [00:05<00:00, 42.95it/s]\n",
      "2025-09-07 19:38:27,259 - INFO - All types `lr` of epoch 16: {'lr/param_group0': np.float64(0.0003448430731963252), 'lr/param_group1': np.float64(0.0002547041843074363), 'lr/param_group2': np.float64(0.0002547041843074363), 'lr/param_group3': np.float64(0.0002547041843074363)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:27,260 - INFO - epoch 16: train loss 0.06947468969694993\n",
      "2025-09-07 19:38:27,262 - INFO - 16 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:27,263 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:27,263 - INFO - --------------------\n",
      "\n",
      "17/800: 100%|██████████| 216/216 [00:04<00:00, 44.70it/s]\n",
      "2025-09-07 19:38:32,226 - INFO - All types `lr` of epoch 17: {'lr/param_group0': np.float64(0.00032979886744280304), 'lr/param_group1': np.float64(0.00026965997855391417), 'lr/param_group2': np.float64(0.00026965997855391417), 'lr/param_group3': np.float64(0.00026965997855391417)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:32,227 - INFO - epoch 17: train loss 0.06838950511344054\n",
      "2025-09-07 19:38:32,229 - INFO - 17 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:32,230 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:32,231 - INFO - --------------------\n",
      "\n",
      "18/800: 100%|██████████| 216/216 [00:04<00:00, 45.96it/s]\n",
      "2025-09-07 19:38:37,062 - INFO - All types `lr` of epoch 18: {'lr/param_group0': np.float64(0.00031474925612244304), 'lr/param_group1': np.float64(0.0002846103672335542), 'lr/param_group2': np.float64(0.0002846103672335542), 'lr/param_group3': np.float64(0.0002846103672335542)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:37,063 - INFO - epoch 18: train loss 0.06906845113607468\n",
      "2025-09-07 19:38:37,064 - INFO - 18 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:37,065 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:37,066 - INFO - --------------------\n",
      "\n",
      "19/800: 100%|██████████| 216/216 [00:04<00:00, 45.67it/s]\n",
      "2025-09-07 19:38:41,929 - INFO - All types `lr` of epoch 19: {'lr/param_group0': np.float64(0.0002996939282120775), 'lr/param_group1': np.float64(0.00029955503932318855), 'lr/param_group2': np.float64(0.00029955503932318855), 'lr/param_group3': np.float64(0.00029955503932318855)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:41,931 - INFO - epoch 19: train loss 0.06749307205555616\n",
      "2025-09-07 19:38:41,932 - INFO - 19 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:41,933 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:41,934 - INFO - --------------------\n",
      "\n",
      "20/800: 100%|██████████| 216/216 [00:04<00:00, 44.49it/s]\n",
      "2025-09-07 19:38:46,937 - INFO - All types `lr` of epoch 20: {'lr/param_group0': np.float64(0.00029958384005397226), 'lr/param_group1': np.float64(0.00029958384005397226), 'lr/param_group2': np.float64(0.00029958384005397226), 'lr/param_group3': np.float64(0.00029958384005397226)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:46,939 - INFO - epoch 20: train loss 0.06700122280529251\n",
      "2025-09-07 19:38:46,940 - INFO - 20 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:46,941 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:46,942 - INFO - --------------------\n",
      "\n",
      "21/800: 100%|██████████| 216/216 [00:04<00:00, 43.39it/s]\n",
      "2025-09-07 19:38:52,071 - INFO - All types `lr` of epoch 21: {'lr/param_group0': 0.00029954120783618973, 'lr/param_group1': 0.00029954120783618973, 'lr/param_group2': 0.00029954120783618973, 'lr/param_group3': 0.00029954120783618973}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:52,072 - INFO - epoch 21: train loss 0.0659168505937689\n",
      "2025-09-07 19:38:52,074 - INFO - 21 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:52,074 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:52,075 - INFO - --------------------\n",
      "\n",
      "22/800: 100%|██████████| 216/216 [00:04<00:00, 44.12it/s]\n",
      "2025-09-07 19:38:57,123 - INFO - All types `lr` of epoch 22: {'lr/param_group0': 0.000299496500826547, 'lr/param_group1': 0.000299496500826547, 'lr/param_group2': 0.000299496500826547, 'lr/param_group3': 0.000299496500826547}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:38:57,124 - INFO - epoch 22: train loss 0.06528307099102272\n",
      "2025-09-07 19:38:57,125 - INFO - 22 epochs completed!\n",
      "\n",
      "2025-09-07 19:38:57,126 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:38:57,126 - INFO - --------------------\n",
      "\n",
      "23/800: 100%|██████████| 216/216 [00:04<00:00, 44.21it/s]\n",
      "2025-09-07 19:39:02,155 - INFO - All types `lr` of epoch 23: {'lr/param_group0': 0.0002994497197144815, 'lr/param_group1': 0.0002994497197144815, 'lr/param_group2': 0.0002994497197144815, 'lr/param_group3': 0.0002994497197144815}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:02,157 - INFO - epoch 23: train loss 0.06476069719496148\n",
      "2025-09-07 19:39:02,158 - INFO - 23 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:02,159 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:02,160 - INFO - --------------------\n",
      "\n",
      "24/800: 100%|██████████| 216/216 [00:04<00:00, 45.47it/s]\n",
      "2025-09-07 19:39:07,062 - INFO - All types `lr` of epoch 24: {'lr/param_group0': 0.0002994008652214158, 'lr/param_group1': 0.0002994008652214158, 'lr/param_group2': 0.0002994008652214158, 'lr/param_group3': 0.0002994008652214158}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:07,063 - INFO - epoch 24: train loss 0.06516998825180861\n",
      "2025-09-07 19:39:07,064 - INFO - 24 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:07,065 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:07,066 - INFO - --------------------\n",
      "\n",
      "25/800: 100%|██████████| 216/216 [00:04<00:00, 45.07it/s]\n",
      "2025-09-07 19:39:12,006 - INFO - All types `lr` of epoch 25: {'lr/param_group0': 0.0002993499381007466, 'lr/param_group1': 0.0002993499381007466, 'lr/param_group2': 0.0002993499381007466, 'lr/param_group3': 0.0002993499381007466}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:12,007 - INFO - epoch 25: train loss 0.0643182312897234\n",
      "2025-09-07 19:39:12,008 - INFO - 25 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:12,009 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:12,010 - INFO - --------------------\n",
      "\n",
      "26/800: 100%|██████████| 216/216 [00:04<00:00, 44.47it/s]\n",
      "2025-09-07 19:39:17,016 - INFO - All types `lr` of epoch 26: {'lr/param_group0': 0.00029929693913783304, 'lr/param_group1': 0.00029929693913783304, 'lr/param_group2': 0.00029929693913783304, 'lr/param_group3': 0.00029929693913783304}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:17,018 - INFO - epoch 26: train loss 0.06382222732322083\n",
      "2025-09-07 19:39:17,019 - INFO - 26 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:17,020 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:17,021 - INFO - --------------------\n",
      "\n",
      "27/800: 100%|██████████| 216/216 [00:04<00:00, 43.94it/s]\n",
      "2025-09-07 19:39:22,090 - INFO - All types `lr` of epoch 27: {'lr/param_group0': 0.0002992418691499848, 'lr/param_group1': 0.0002992418691499848, 'lr/param_group2': 0.0002992418691499848, 'lr/param_group3': 0.0002992418691499848}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:22,091 - INFO - epoch 27: train loss 0.0625108678618239\n",
      "2025-09-07 19:39:22,093 - INFO - 27 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:22,094 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:22,095 - INFO - --------------------\n",
      "\n",
      "28/800: 100%|██████████| 216/216 [00:05<00:00, 43.18it/s]\n",
      "2025-09-07 19:39:27,250 - INFO - All types `lr` of epoch 28: {'lr/param_group0': 0.00029918472898644925, 'lr/param_group1': 0.00029918472898644925, 'lr/param_group2': 0.00029918472898644925, 'lr/param_group3': 0.00029918472898644925}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:27,252 - INFO - epoch 28: train loss 0.06317540701409732\n",
      "2025-09-07 19:39:27,253 - INFO - 28 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:27,254 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:27,255 - INFO - --------------------\n",
      "\n",
      "29/800: 100%|██████████| 216/216 [00:04<00:00, 44.36it/s]\n",
      "2025-09-07 19:39:32,277 - INFO - All types `lr` of epoch 29: {'lr/param_group0': 0.0002991255195283983, 'lr/param_group1': 0.0002991255195283983, 'lr/param_group2': 0.0002991255195283983, 'lr/param_group3': 0.0002991255195283983}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:32,278 - INFO - epoch 29: train loss 0.06354472008361309\n",
      "2025-09-07 19:39:32,280 - INFO - 29 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:32,281 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:32,282 - INFO - --------------------\n",
      "\n",
      "30/800: 100%|██████████| 216/216 [00:05<00:00, 42.61it/s]\n",
      "2025-09-07 19:39:37,501 - INFO - All types `lr` of epoch 30: {'lr/param_group0': 0.000299064241688915, 'lr/param_group1': 0.000299064241688915, 'lr/param_group2': 0.000299064241688915, 'lr/param_group3': 0.000299064241688915}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:37,502 - INFO - epoch 30: train loss 0.06313864591841896\n",
      "2025-09-07 19:39:37,504 - INFO - 30 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:37,505 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:37,506 - INFO - --------------------\n",
      "\n",
      "31/800: 100%|██████████| 216/216 [00:04<00:00, 43.99it/s]\n",
      "2025-09-07 19:39:42,565 - INFO - All types `lr` of epoch 31: {'lr/param_group0': 0.0002990008964129796, 'lr/param_group1': 0.0002990008964129796, 'lr/param_group2': 0.0002990008964129796, 'lr/param_group3': 0.0002990008964129796}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:42,566 - INFO - epoch 31: train loss 0.061817957588505966\n",
      "2025-09-07 19:39:42,568 - INFO - 31 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:42,569 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:42,570 - INFO - --------------------\n",
      "\n",
      "32/800: 100%|██████████| 216/216 [00:04<00:00, 44.00it/s]\n",
      "2025-09-07 19:39:47,633 - INFO - All types `lr` of epoch 32: {'lr/param_group0': 0.0002989354846774545, 'lr/param_group1': 0.0002989354846774545, 'lr/param_group2': 0.0002989354846774545, 'lr/param_group3': 0.0002989354846774545}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:47,635 - INFO - epoch 32: train loss 0.06159771395916188\n",
      "2025-09-07 19:39:47,636 - INFO - 32 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:47,637 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:47,638 - INFO - --------------------\n",
      "\n",
      "33/800: 100%|██████████| 216/216 [00:04<00:00, 46.04it/s]\n",
      "2025-09-07 19:39:52,479 - INFO - All types `lr` of epoch 33: {'lr/param_group0': 0.0002988680074910696, 'lr/param_group1': 0.0002988680074910696, 'lr/param_group2': 0.0002988680074910696, 'lr/param_group3': 0.0002988680074910696}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:52,480 - INFO - epoch 33: train loss 0.06186527776083461\n",
      "2025-09-07 19:39:52,482 - INFO - 33 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:52,483 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:52,484 - INFO - --------------------\n",
      "\n",
      "34/800: 100%|██████████| 216/216 [00:04<00:00, 46.76it/s]\n",
      "2025-09-07 19:39:57,253 - INFO - All types `lr` of epoch 34: {'lr/param_group0': 0.00029879846589440657, 'lr/param_group1': 0.00029879846589440657, 'lr/param_group2': 0.00029879846589440657, 'lr/param_group3': 0.00029879846589440657}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:39:57,255 - INFO - epoch 34: train loss 0.061248302839144515\n",
      "2025-09-07 19:39:57,256 - INFO - 34 epochs completed!\n",
      "\n",
      "2025-09-07 19:39:57,257 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:39:57,258 - INFO - --------------------\n",
      "\n",
      "35/800: 100%|██████████| 216/216 [00:04<00:00, 45.38it/s]\n",
      "2025-09-07 19:40:02,169 - INFO - All types `lr` of epoch 35: {'lr/param_group0': 0.0002987268609598829, 'lr/param_group1': 0.0002987268609598829, 'lr/param_group2': 0.0002987268609598829, 'lr/param_group3': 0.0002987268609598829}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:02,170 - INFO - epoch 35: train loss 0.06053890506909401\n",
      "2025-09-07 19:40:02,172 - INFO - 35 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:02,173 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:02,174 - INFO - --------------------\n",
      "\n",
      "36/800: 100%|██████████| 216/216 [00:04<00:00, 44.89it/s]\n",
      "2025-09-07 19:40:07,137 - INFO - All types `lr` of epoch 36: {'lr/param_group0': 0.0002986531937917352, 'lr/param_group1': 0.0002986531937917352, 'lr/param_group2': 0.0002986531937917352, 'lr/param_group3': 0.0002986531937917352}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:07,139 - INFO - epoch 36: train loss 0.061479566929241024\n",
      "2025-09-07 19:40:07,140 - INFO - 36 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:07,141 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:07,142 - INFO - --------------------\n",
      "\n",
      "37/800: 100%|██████████| 216/216 [00:04<00:00, 44.15it/s]\n",
      "2025-09-07 19:40:12,185 - INFO - All types `lr` of epoch 37: {'lr/param_group0': 0.00029857746552600247, 'lr/param_group1': 0.00029857746552600247, 'lr/param_group2': 0.00029857746552600247, 'lr/param_group3': 0.00029857746552600247}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:12,186 - INFO - epoch 37: train loss 0.06086600190718417\n",
      "2025-09-07 19:40:12,188 - INFO - 37 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:12,189 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:12,190 - INFO - --------------------\n",
      "\n",
      "38/800: 100%|██████████| 216/216 [00:04<00:00, 44.40it/s]\n",
      "2025-09-07 19:40:17,198 - INFO - All types `lr` of epoch 38: {'lr/param_group0': 0.0002984996773305081, 'lr/param_group1': 0.0002984996773305081, 'lr/param_group2': 0.0002984996773305081, 'lr/param_group3': 0.0002984996773305081}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:17,199 - INFO - epoch 38: train loss 0.06156995678665461\n",
      "2025-09-07 19:40:17,201 - INFO - 38 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:17,202 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:17,203 - INFO - --------------------\n",
      "\n",
      "39/800: 100%|██████████| 216/216 [00:04<00:00, 44.89it/s]\n",
      "2025-09-07 19:40:22,164 - INFO - All types `lr` of epoch 39: {'lr/param_group0': 0.00029841983040484235, 'lr/param_group1': 0.00029841983040484235, 'lr/param_group2': 0.00029841983040484235, 'lr/param_group3': 0.00029841983040484235}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:22,165 - INFO - epoch 39: train loss 0.060331129279263596\n",
      "100%|██████████| 54/54 [00:01<00:00, 37.89it/s]\n",
      "2025-09-07 19:40:23,741 - INFO - epoch 39: val loss 0.06173465573401363\n",
      "2025-09-07 19:40:23,763 - INFO - 39 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:40:23,779 - INFO - 39 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:23,781 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:23,782 - INFO - --------------------\n",
      "\n",
      "40/800: 100%|██████████| 216/216 [00:04<00:00, 44.41it/s]\n",
      "2025-09-07 19:40:28,793 - INFO - All types `lr` of epoch 40: {'lr/param_group0': 0.0002983379259803436, 'lr/param_group1': 0.0002983379259803436, 'lr/param_group2': 0.0002983379259803436, 'lr/param_group3': 0.0002983379259803436}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:28,795 - INFO - epoch 40: train loss 0.05970185686385742\n",
      "2025-09-07 19:40:28,796 - INFO - 40 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:28,797 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:28,798 - INFO - --------------------\n",
      "\n",
      "41/800: 100%|██████████| 216/216 [00:04<00:00, 44.15it/s]\n",
      "2025-09-07 19:40:33,846 - INFO - All types `lr` of epoch 41: {'lr/param_group0': 0.0002982539653200793, 'lr/param_group1': 0.0002982539653200793, 'lr/param_group2': 0.0002982539653200793, 'lr/param_group3': 0.0002982539653200793}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:33,848 - INFO - epoch 41: train loss 0.05946652491197542\n",
      "2025-09-07 19:40:33,849 - INFO - 41 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:33,850 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:33,851 - INFO - --------------------\n",
      "\n",
      "42/800: 100%|██████████| 216/216 [00:04<00:00, 43.90it/s]\n",
      "2025-09-07 19:40:38,920 - INFO - All types `lr` of epoch 42: {'lr/param_group0': 0.00029816794971882686, 'lr/param_group1': 0.00029816794971882686, 'lr/param_group2': 0.00029816794971882686, 'lr/param_group3': 0.00029816794971882686}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:38,921 - INFO - epoch 42: train loss 0.05989064255522357\n",
      "2025-09-07 19:40:38,923 - INFO - 42 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:38,924 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:38,925 - INFO - --------------------\n",
      "\n",
      "43/800: 100%|██████████| 216/216 [00:04<00:00, 44.93it/s]\n",
      "2025-09-07 19:40:43,889 - INFO - All types `lr` of epoch 43: {'lr/param_group0': 0.00029807988050305315, 'lr/param_group1': 0.00029807988050305315, 'lr/param_group2': 0.00029807988050305315, 'lr/param_group3': 0.00029807988050305315}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:43,891 - INFO - epoch 43: train loss 0.05888565089898529\n",
      "2025-09-07 19:40:43,893 - INFO - 43 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:43,894 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:43,896 - INFO - --------------------\n",
      "\n",
      "44/800: 100%|██████████| 216/216 [00:04<00:00, 46.95it/s]\n",
      "2025-09-07 19:40:48,668 - INFO - All types `lr` of epoch 44: {'lr/param_group0': 0.0002979897590308945, 'lr/param_group1': 0.0002979897590308945, 'lr/param_group2': 0.0002979897590308945, 'lr/param_group3': 0.0002979897590308945}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:48,669 - INFO - epoch 44: train loss 0.05916433736543964\n",
      "2025-09-07 19:40:48,671 - INFO - 44 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:48,672 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:48,673 - INFO - --------------------\n",
      "\n",
      "45/800: 100%|██████████| 216/216 [00:04<00:00, 45.32it/s]\n",
      "2025-09-07 19:40:53,582 - INFO - All types `lr` of epoch 45: {'lr/param_group0': 0.00029789758669213534, 'lr/param_group1': 0.00029789758669213534, 'lr/param_group2': 0.00029789758669213534, 'lr/param_group3': 0.00029789758669213534}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:53,584 - INFO - epoch 45: train loss 0.05896009339226617\n",
      "2025-09-07 19:40:53,585 - INFO - 45 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:53,587 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:53,588 - INFO - --------------------\n",
      "\n",
      "46/800: 100%|██████████| 216/216 [00:04<00:00, 45.35it/s]\n",
      "2025-09-07 19:40:58,502 - INFO - All types `lr` of epoch 46: {'lr/param_group0': 0.00029780336490818735, 'lr/param_group1': 0.00029780336490818735, 'lr/param_group2': 0.00029780336490818735, 'lr/param_group3': 0.00029780336490818735}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:40:58,503 - INFO - epoch 46: train loss 0.058872752357274294\n",
      "2025-09-07 19:40:58,505 - INFO - 46 epochs completed!\n",
      "\n",
      "2025-09-07 19:40:58,506 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:40:58,507 - INFO - --------------------\n",
      "\n",
      "47/800: 100%|██████████| 216/216 [00:04<00:00, 45.49it/s]\n",
      "2025-09-07 19:41:03,407 - INFO - All types `lr` of epoch 47: {'lr/param_group0': 0.00029770709513206686, 'lr/param_group1': 0.00029770709513206686, 'lr/param_group2': 0.00029770709513206686, 'lr/param_group3': 0.00029770709513206686}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:03,408 - INFO - epoch 47: train loss 0.05836913258665138\n",
      "2025-09-07 19:41:03,410 - INFO - 47 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:03,411 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:03,412 - INFO - --------------------\n",
      "\n",
      "48/800: 100%|██████████| 216/216 [00:04<00:00, 44.95it/s]\n",
      "2025-09-07 19:41:08,372 - INFO - All types `lr` of epoch 48: {'lr/param_group0': 0.00029760877884837294, 'lr/param_group1': 0.00029760877884837294, 'lr/param_group2': 0.00029760877884837294, 'lr/param_group3': 0.00029760877884837294}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:08,374 - INFO - epoch 48: train loss 0.058868673681798905\n",
      "2025-09-07 19:41:08,375 - INFO - 48 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:08,377 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:08,378 - INFO - --------------------\n",
      "\n",
      "49/800: 100%|██████████| 216/216 [00:04<00:00, 45.14it/s]\n",
      "2025-09-07 19:41:13,316 - INFO - All types `lr` of epoch 49: {'lr/param_group0': 0.00029750841757326436, 'lr/param_group1': 0.00029750841757326436, 'lr/param_group2': 0.00029750841757326436, 'lr/param_group3': 0.00029750841757326436}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:13,318 - INFO - epoch 49: train loss 0.05852760959209667\n",
      "2025-09-07 19:41:13,320 - INFO - 49 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:13,321 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:13,322 - INFO - --------------------\n",
      "\n",
      "50/800: 100%|██████████| 216/216 [00:04<00:00, 45.06it/s]\n",
      "2025-09-07 19:41:18,269 - INFO - All types `lr` of epoch 50: {'lr/param_group0': 0.0002974060128544361, 'lr/param_group1': 0.0002974060128544361, 'lr/param_group2': 0.0002974060128544361, 'lr/param_group3': 0.0002974060128544361}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:18,271 - INFO - epoch 50: train loss 0.05831880634650588\n",
      "2025-09-07 19:41:18,273 - INFO - 50 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:18,274 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:18,275 - INFO - --------------------\n",
      "\n",
      "51/800: 100%|██████████| 216/216 [00:04<00:00, 44.23it/s]\n",
      "2025-09-07 19:41:23,312 - INFO - All types `lr` of epoch 51: {'lr/param_group0': 0.0002973015662710956, 'lr/param_group1': 0.0002973015662710956, 'lr/param_group2': 0.0002973015662710956, 'lr/param_group3': 0.0002973015662710956}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:23,313 - INFO - epoch 51: train loss 0.058386478642070735\n",
      "2025-09-07 19:41:23,314 - INFO - 51 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:23,315 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:23,316 - INFO - --------------------\n",
      "\n",
      "52/800: 100%|██████████| 216/216 [00:04<00:00, 43.96it/s]\n",
      "2025-09-07 19:41:28,377 - INFO - All types `lr` of epoch 52: {'lr/param_group0': 0.00029719507943393837, 'lr/param_group1': 0.00029719507943393837, 'lr/param_group2': 0.00029719507943393837, 'lr/param_group3': 0.00029719507943393837}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:28,379 - INFO - epoch 52: train loss 0.0583021680617498\n",
      "2025-09-07 19:41:28,381 - INFO - 52 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:28,382 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:28,383 - INFO - --------------------\n",
      "\n",
      "53/800: 100%|██████████| 216/216 [00:04<00:00, 43.55it/s]\n",
      "2025-09-07 19:41:33,494 - INFO - All types `lr` of epoch 53: {'lr/param_group0': 0.0002970865539851232, 'lr/param_group1': 0.0002970865539851232, 'lr/param_group2': 0.0002970865539851232, 'lr/param_group3': 0.0002970865539851232}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:33,496 - INFO - epoch 53: train loss 0.05778326147615358\n",
      "2025-09-07 19:41:33,498 - INFO - 53 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:33,499 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:33,500 - INFO - --------------------\n",
      "\n",
      "54/800: 100%|██████████| 216/216 [00:04<00:00, 44.12it/s]\n",
      "2025-09-07 19:41:38,554 - INFO - All types `lr` of epoch 54: {'lr/param_group0': 0.0002969759915982467, 'lr/param_group1': 0.0002969759915982467, 'lr/param_group2': 0.0002969759915982467, 'lr/param_group3': 0.0002969759915982467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:38,555 - INFO - epoch 54: train loss 0.057517639033634355\n",
      "2025-09-07 19:41:38,557 - INFO - 54 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:38,558 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:38,559 - INFO - --------------------\n",
      "\n",
      "55/800: 100%|██████████| 216/216 [00:04<00:00, 43.98it/s]\n",
      "2025-09-07 19:41:43,622 - INFO - All types `lr` of epoch 55: {'lr/param_group0': 0.00029686339397831776, 'lr/param_group1': 0.00029686339397831776, 'lr/param_group2': 0.00029686339397831776, 'lr/param_group3': 0.00029686339397831776}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:43,623 - INFO - epoch 55: train loss 0.057992562289453216\n",
      "2025-09-07 19:41:43,625 - INFO - 55 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:43,627 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:43,628 - INFO - --------------------\n",
      "\n",
      "56/800: 100%|██████████| 216/216 [00:04<00:00, 44.67it/s]\n",
      "2025-09-07 19:41:48,612 - INFO - All types `lr` of epoch 56: {'lr/param_group0': 0.00029674876286173087, 'lr/param_group1': 0.00029674876286173087, 'lr/param_group2': 0.00029674876286173087, 'lr/param_group3': 0.00029674876286173087}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:48,614 - INFO - epoch 56: train loss 0.058008847775420654\n",
      "2025-09-07 19:41:48,616 - INFO - 56 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:48,617 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:48,619 - INFO - --------------------\n",
      "\n",
      "57/800: 100%|██████████| 216/216 [00:05<00:00, 40.04it/s]\n",
      "2025-09-07 19:41:54,184 - INFO - All types `lr` of epoch 57: {'lr/param_group0': 0.0002966321000162397, 'lr/param_group1': 0.0002966321000162397, 'lr/param_group2': 0.0002966321000162397, 'lr/param_group3': 0.0002966321000162397}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:54,185 - INFO - epoch 57: train loss 0.05742584839808168\n",
      "2025-09-07 19:41:54,187 - INFO - 57 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:54,188 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:54,189 - INFO - --------------------\n",
      "\n",
      "58/800: 100%|██████████| 216/216 [00:04<00:00, 44.31it/s]\n",
      "2025-09-07 19:41:59,217 - INFO - All types `lr` of epoch 58: {'lr/param_group0': 0.0002965134072409296, 'lr/param_group1': 0.0002965134072409296, 'lr/param_group2': 0.0002965134072409296, 'lr/param_group3': 0.0002965134072409296}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:41:59,219 - INFO - epoch 58: train loss 0.05781199845174948\n",
      "2025-09-07 19:41:59,220 - INFO - 58 epochs completed!\n",
      "\n",
      "2025-09-07 19:41:59,222 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:41:59,223 - INFO - --------------------\n",
      "\n",
      "59/800: 100%|██████████| 216/216 [00:04<00:00, 44.80it/s]\n",
      "2025-09-07 19:42:04,203 - INFO - All types `lr` of epoch 59: {'lr/param_group0': 0.0002963926863661901, 'lr/param_group1': 0.0002963926863661901, 'lr/param_group2': 0.0002963926863661901, 'lr/param_group3': 0.0002963926863661901}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:04,205 - INFO - epoch 59: train loss 0.057190586605833635\n",
      "2025-09-07 19:42:04,207 - INFO - 59 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:04,208 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:04,209 - INFO - --------------------\n",
      "\n",
      "60/800: 100%|██████████| 216/216 [00:04<00:00, 44.56it/s]\n",
      "2025-09-07 19:42:09,201 - INFO - All types `lr` of epoch 60: {'lr/param_group0': 0.0002962699392536863, 'lr/param_group1': 0.0002962699392536863, 'lr/param_group2': 0.0002962699392536863, 'lr/param_group3': 0.0002962699392536863}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:09,202 - INFO - epoch 60: train loss 0.05717388894064007\n",
      "2025-09-07 19:42:09,204 - INFO - 60 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:09,205 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:09,206 - INFO - --------------------\n",
      "\n",
      "61/800: 100%|██████████| 216/216 [00:04<00:00, 45.37it/s]\n",
      "2025-09-07 19:42:14,121 - INFO - All types `lr` of epoch 61: {'lr/param_group0': 0.00029614516779633064, 'lr/param_group1': 0.00029614516779633064, 'lr/param_group2': 0.00029614516779633064, 'lr/param_group3': 0.00029614516779633064}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:14,122 - INFO - epoch 61: train loss 0.057249954936129076\n",
      "2025-09-07 19:42:14,125 - INFO - 61 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:14,126 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:14,127 - INFO - --------------------\n",
      "\n",
      "62/800: 100%|██████████| 216/216 [00:04<00:00, 43.59it/s]\n",
      "2025-09-07 19:42:19,223 - INFO - All types `lr` of epoch 62: {'lr/param_group0': 0.0002960183739182532, 'lr/param_group1': 0.0002960183739182532, 'lr/param_group2': 0.0002960183739182532, 'lr/param_group3': 0.0002960183739182532}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:19,224 - INFO - epoch 62: train loss 0.05710644487084614\n",
      "2025-09-07 19:42:19,226 - INFO - 62 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:19,227 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:19,229 - INFO - --------------------\n",
      "\n",
      "63/800: 100%|██████████| 216/216 [00:04<00:00, 43.52it/s]\n",
      "2025-09-07 19:42:24,344 - INFO - All types `lr` of epoch 63: {'lr/param_group0': 0.00029588955957477256, 'lr/param_group1': 0.00029588955957477256, 'lr/param_group2': 0.00029588955957477256, 'lr/param_group3': 0.00029588955957477256}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:24,346 - INFO - epoch 63: train loss 0.05658003339474952\n",
      "2025-09-07 19:42:24,348 - INFO - 63 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:24,349 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:24,350 - INFO - --------------------\n",
      "\n",
      "64/800: 100%|██████████| 216/216 [00:04<00:00, 44.29it/s]\n",
      "2025-09-07 19:42:29,389 - INFO - All types `lr` of epoch 64: {'lr/param_group0': 0.0002957587267523652, 'lr/param_group1': 0.0002957587267523652, 'lr/param_group2': 0.0002957587267523652, 'lr/param_group3': 0.0002957587267523652}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:29,390 - INFO - epoch 64: train loss 0.05659023287740571\n",
      "2025-09-07 19:42:29,392 - INFO - 64 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:29,393 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:29,394 - INFO - --------------------\n",
      "\n",
      "65/800: 100%|██████████| 216/216 [00:04<00:00, 45.45it/s]\n",
      "2025-09-07 19:42:34,289 - INFO - All types `lr` of epoch 65: {'lr/param_group0': 0.00029562587746863507, 'lr/param_group1': 0.00029562587746863507, 'lr/param_group2': 0.00029562587746863507, 'lr/param_group3': 0.00029562587746863507}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:34,290 - INFO - epoch 65: train loss 0.0568704406592857\n",
      "2025-09-07 19:42:34,292 - INFO - 65 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:34,293 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:34,295 - INFO - --------------------\n",
      "\n",
      "66/800: 100%|██████████| 216/216 [00:04<00:00, 45.59it/s]\n",
      "2025-09-07 19:42:39,176 - INFO - All types `lr` of epoch 66: {'lr/param_group0': 0.00029549101377228246, 'lr/param_group1': 0.00029549101377228246, 'lr/param_group2': 0.00029549101377228246, 'lr/param_group3': 0.00029549101377228246}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:39,178 - INFO - epoch 66: train loss 0.05661548085993639\n",
      "2025-09-07 19:42:39,179 - INFO - 66 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:39,181 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:39,182 - INFO - --------------------\n",
      "\n",
      "67/800: 100%|██████████| 216/216 [00:04<00:00, 46.15it/s]\n",
      "2025-09-07 19:42:44,019 - INFO - All types `lr` of epoch 67: {'lr/param_group0': 0.0002953541377430725, 'lr/param_group1': 0.0002953541377430725, 'lr/param_group2': 0.0002953541377430725, 'lr/param_group3': 0.0002953541377430725}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:44,020 - INFO - epoch 67: train loss 0.05595049889827216\n",
      "2025-09-07 19:42:44,022 - INFO - 67 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:44,023 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:44,024 - INFO - --------------------\n",
      "\n",
      "68/800: 100%|██████████| 216/216 [00:04<00:00, 44.45it/s]\n",
      "2025-09-07 19:42:49,041 - INFO - All types `lr` of epoch 68: {'lr/param_group0': 0.00029521525149180274, 'lr/param_group1': 0.00029521525149180274, 'lr/param_group2': 0.00029521525149180274, 'lr/param_group3': 0.00029521525149180274}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:49,042 - INFO - epoch 68: train loss 0.056133189600788884\n",
      "2025-09-07 19:42:49,044 - INFO - 68 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:49,045 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:49,045 - INFO - --------------------\n",
      "\n",
      "69/800: 100%|██████████| 216/216 [00:04<00:00, 44.49it/s]\n",
      "2025-09-07 19:42:54,050 - INFO - All types `lr` of epoch 69: {'lr/param_group0': 0.00029507435716027107, 'lr/param_group1': 0.00029507435716027107, 'lr/param_group2': 0.00029507435716027107, 'lr/param_group3': 0.00029507435716027107}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:54,051 - INFO - epoch 69: train loss 0.05630762906124195\n",
      "2025-09-07 19:42:54,053 - INFO - 69 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:54,054 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:54,055 - INFO - --------------------\n",
      "\n",
      "70/800: 100%|██████████| 216/216 [00:04<00:00, 45.15it/s]\n",
      "2025-09-07 19:42:58,985 - INFO - All types `lr` of epoch 70: {'lr/param_group0': 0.00029493145692124234, 'lr/param_group1': 0.00029493145692124234, 'lr/param_group2': 0.00029493145692124234, 'lr/param_group3': 0.00029493145692124234}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:42:58,986 - INFO - epoch 70: train loss 0.056163014447385515\n",
      "2025-09-07 19:42:58,988 - INFO - 70 epochs completed!\n",
      "\n",
      "2025-09-07 19:42:58,989 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:42:58,990 - INFO - --------------------\n",
      "\n",
      "71/800: 100%|██████████| 216/216 [00:04<00:00, 48.37it/s]\n",
      "2025-09-07 19:43:03,613 - INFO - All types `lr` of epoch 71: {'lr/param_group0': 0.00029478655297841507, 'lr/param_group1': 0.00029478655297841507, 'lr/param_group2': 0.00029478655297841507, 'lr/param_group3': 0.00029478655297841507}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:03,614 - INFO - epoch 71: train loss 0.055898944588585034\n",
      "2025-09-07 19:43:03,616 - INFO - 71 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:03,617 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:03,618 - INFO - --------------------\n",
      "\n",
      "72/800: 100%|██████████| 216/216 [00:04<00:00, 43.86it/s]\n",
      "2025-09-07 19:43:08,683 - INFO - All types `lr` of epoch 72: {'lr/param_group0': 0.00029463964756638725, 'lr/param_group1': 0.00029463964756638725, 'lr/param_group2': 0.00029463964756638725, 'lr/param_group3': 0.00029463964756638725}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:08,684 - INFO - epoch 72: train loss 0.05576717041225897\n",
      "2025-09-07 19:43:08,686 - INFO - 72 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:08,687 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:08,688 - INFO - --------------------\n",
      "\n",
      "73/800: 100%|██████████| 216/216 [00:04<00:00, 43.76it/s]\n",
      "2025-09-07 19:43:13,776 - INFO - All types `lr` of epoch 73: {'lr/param_group0': 0.00029449074295062215, 'lr/param_group1': 0.00029449074295062215, 'lr/param_group2': 0.00029449074295062215, 'lr/param_group3': 0.00029449074295062215}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:13,777 - INFO - epoch 73: train loss 0.05556940511558895\n",
      "2025-09-07 19:43:13,778 - INFO - 73 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:13,779 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:13,780 - INFO - --------------------\n",
      "\n",
      "74/800: 100%|██████████| 216/216 [00:04<00:00, 43.51it/s]\n",
      "2025-09-07 19:43:18,891 - INFO - All types `lr` of epoch 74: {'lr/param_group0': 0.00029433984142741306, 'lr/param_group1': 0.00029433984142741306, 'lr/param_group2': 0.00029433984142741306, 'lr/param_group3': 0.00029433984142741306}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:18,892 - INFO - epoch 74: train loss 0.05599331988573626\n",
      "2025-09-07 19:43:18,894 - INFO - 74 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:18,896 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:18,897 - INFO - --------------------\n",
      "\n",
      "75/800: 100%|██████████| 216/216 [00:04<00:00, 43.80it/s]\n",
      "2025-09-07 19:43:23,984 - INFO - All types `lr` of epoch 75: {'lr/param_group0': 0.00029418694532384816, 'lr/param_group1': 0.00029418694532384816, 'lr/param_group2': 0.00029418694532384816, 'lr/param_group3': 0.00029418694532384816}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:23,985 - INFO - epoch 75: train loss 0.05556956578597978\n",
      "2025-09-07 19:43:23,987 - INFO - 75 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:23,988 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:23,990 - INFO - --------------------\n",
      "\n",
      "76/800: 100%|██████████| 216/216 [00:04<00:00, 43.82it/s]\n",
      "2025-09-07 19:43:29,074 - INFO - All types `lr` of epoch 76: {'lr/param_group0': 0.00029403205699777456, 'lr/param_group1': 0.00029403205699777456, 'lr/param_group2': 0.00029403205699777456, 'lr/param_group3': 0.00029403205699777456}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:29,075 - INFO - epoch 76: train loss 0.05498155372010337\n",
      "2025-09-07 19:43:29,077 - INFO - 76 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:29,079 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:29,080 - INFO - --------------------\n",
      "\n",
      "77/800: 100%|██████████| 216/216 [00:04<00:00, 43.32it/s]\n",
      "2025-09-07 19:43:34,220 - INFO - All types `lr` of epoch 77: {'lr/param_group0': 0.0002938751788377618, 'lr/param_group1': 0.0002938751788377618, 'lr/param_group2': 0.0002938751788377618, 'lr/param_group3': 0.0002938751788377618}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:34,221 - INFO - epoch 77: train loss 0.055262483621912974\n",
      "2025-09-07 19:43:34,223 - INFO - 77 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:34,224 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:34,225 - INFO - --------------------\n",
      "\n",
      "78/800: 100%|██████████| 216/216 [00:04<00:00, 44.33it/s]\n",
      "2025-09-07 19:43:39,248 - INFO - All types `lr` of epoch 78: {'lr/param_group0': 0.00029371631326306514, 'lr/param_group1': 0.00029371631326306514, 'lr/param_group2': 0.00029371631326306514, 'lr/param_group3': 0.00029371631326306514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:39,250 - INFO - epoch 78: train loss 0.05542022705561033\n",
      "2025-09-07 19:43:39,251 - INFO - 78 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:39,252 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:39,253 - INFO - --------------------\n",
      "\n",
      "79/800: 100%|██████████| 216/216 [00:04<00:00, 43.55it/s]\n",
      "2025-09-07 19:43:44,359 - INFO - All types `lr` of epoch 79: {'lr/param_group0': 0.00029355546272358837, 'lr/param_group1': 0.00029355546272358837, 'lr/param_group2': 0.00029355546272358837, 'lr/param_group3': 0.00029355546272358837}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:44,360 - INFO - epoch 79: train loss 0.0554614684165076\n",
      "100%|██████████| 54/54 [00:01<00:00, 38.40it/s]\n",
      "2025-09-07 19:43:45,922 - INFO - epoch 79: val loss 0.05889171506795618\n",
      "2025-09-07 19:43:45,925 - INFO - 79 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:43:45,937 - INFO - 79 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:45,938 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:45,939 - INFO - --------------------\n",
      "\n",
      "80/800: 100%|██████████| 216/216 [00:04<00:00, 43.68it/s]\n",
      "2025-09-07 19:43:51,041 - INFO - All types `lr` of epoch 80: {'lr/param_group0': 0.0002933926296998457, 'lr/param_group1': 0.0002933926296998457, 'lr/param_group2': 0.0002933926296998457, 'lr/param_group3': 0.0002933926296998457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:51,043 - INFO - epoch 80: train loss 0.05522068803785024\n",
      "2025-09-07 19:43:51,045 - INFO - 80 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:51,046 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:51,047 - INFO - --------------------\n",
      "\n",
      "81/800: 100%|██████████| 216/216 [00:04<00:00, 43.77it/s]\n",
      "2025-09-07 19:43:56,136 - INFO - All types `lr` of epoch 81: {'lr/param_group0': 0.00029322781670292384, 'lr/param_group1': 0.00029322781670292384, 'lr/param_group2': 0.00029322781670292384, 'lr/param_group3': 0.00029322781670292384}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:43:56,138 - INFO - epoch 81: train loss 0.05499659706321028\n",
      "2025-09-07 19:43:56,140 - INFO - 81 epochs completed!\n",
      "\n",
      "2025-09-07 19:43:56,142 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:43:56,143 - INFO - --------------------\n",
      "\n",
      "82/800: 100%|██████████| 216/216 [00:04<00:00, 44.16it/s]\n",
      "2025-09-07 19:44:01,182 - INFO - All types `lr` of epoch 82: {'lr/param_group0': 0.0002930610262744431, 'lr/param_group1': 0.0002930610262744431, 'lr/param_group2': 0.0002930610262744431, 'lr/param_group3': 0.0002930610262744431}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:01,183 - INFO - epoch 82: train loss 0.05476460254026784\n",
      "2025-09-07 19:44:01,185 - INFO - 82 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:01,186 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:01,188 - INFO - --------------------\n",
      "\n",
      "83/800: 100%|██████████| 216/216 [00:05<00:00, 42.83it/s]\n",
      "2025-09-07 19:44:06,388 - INFO - All types `lr` of epoch 83: {'lr/param_group0': 0.00029289226098651815, 'lr/param_group1': 0.00029289226098651815, 'lr/param_group2': 0.00029289226098651815, 'lr/param_group3': 0.00029289226098651815}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:06,389 - INFO - epoch 83: train loss 0.05489034429882412\n",
      "2025-09-07 19:44:06,391 - INFO - 83 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:06,392 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:06,394 - INFO - --------------------\n",
      "\n",
      "84/800: 100%|██████████| 216/216 [00:04<00:00, 43.83it/s]\n",
      "2025-09-07 19:44:11,475 - INFO - All types `lr` of epoch 84: {'lr/param_group0': 0.0002927215234417186, 'lr/param_group1': 0.0002927215234417186, 'lr/param_group2': 0.0002927215234417186, 'lr/param_group3': 0.0002927215234417186}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:11,477 - INFO - epoch 84: train loss 0.054410971632158314\n",
      "2025-09-07 19:44:11,479 - INFO - 84 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:11,481 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:11,482 - INFO - --------------------\n",
      "\n",
      "85/800: 100%|██████████| 216/216 [00:04<00:00, 45.06it/s]\n",
      "2025-09-07 19:44:16,422 - INFO - All types `lr` of epoch 85: {'lr/param_group0': 0.0002925488162730285, 'lr/param_group1': 0.0002925488162730285, 'lr/param_group2': 0.0002925488162730285, 'lr/param_group3': 0.0002925488162730285}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:16,424 - INFO - epoch 85: train loss 0.054902412428486126\n",
      "2025-09-07 19:44:16,426 - INFO - 85 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:16,428 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:16,429 - INFO - --------------------\n",
      "\n",
      "86/800: 100%|██████████| 216/216 [00:04<00:00, 44.49it/s]\n",
      "2025-09-07 19:44:21,431 - INFO - All types `lr` of epoch 86: {'lr/param_group0': 0.0002923741421438061, 'lr/param_group1': 0.0002923741421438061, 'lr/param_group2': 0.0002923741421438061, 'lr/param_group3': 0.0002923741421438061}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:21,432 - INFO - epoch 86: train loss 0.05530946058462615\n",
      "2025-09-07 19:44:21,433 - INFO - 86 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:21,434 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:21,435 - INFO - --------------------\n",
      "\n",
      "87/800: 100%|██████████| 216/216 [00:04<00:00, 44.26it/s]\n",
      "2025-09-07 19:44:26,464 - INFO - All types `lr` of epoch 87: {'lr/param_group0': 0.0002921975037477426, 'lr/param_group1': 0.0002921975037477426, 'lr/param_group2': 0.0002921975037477426, 'lr/param_group3': 0.0002921975037477426}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:26,466 - INFO - epoch 87: train loss 0.054857267135823215\n",
      "2025-09-07 19:44:26,468 - INFO - 87 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:26,469 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:26,471 - INFO - --------------------\n",
      "\n",
      "88/800: 100%|██████████| 216/216 [00:05<00:00, 43.18it/s]\n",
      "2025-09-07 19:44:31,623 - INFO - All types `lr` of epoch 88: {'lr/param_group0': 0.00029201890380882044, 'lr/param_group1': 0.00029201890380882044, 'lr/param_group2': 0.00029201890380882044, 'lr/param_group3': 0.00029201890380882044}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:31,624 - INFO - epoch 88: train loss 0.05512803617037005\n",
      "2025-09-07 19:44:31,626 - INFO - 88 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:31,628 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:31,629 - INFO - --------------------\n",
      "\n",
      "89/800: 100%|██████████| 216/216 [00:04<00:00, 44.57it/s]\n",
      "2025-09-07 19:44:36,631 - INFO - All types `lr` of epoch 89: {'lr/param_group0': 0.0002918383450812717, 'lr/param_group1': 0.0002918383450812717, 'lr/param_group2': 0.0002918383450812717, 'lr/param_group3': 0.0002918383450812717}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:36,633 - INFO - epoch 89: train loss 0.05436519786922468\n",
      "2025-09-07 19:44:36,636 - INFO - 89 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:36,637 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:36,638 - INFO - --------------------\n",
      "\n",
      "90/800: 100%|██████████| 216/216 [00:04<00:00, 44.84it/s]\n",
      "2025-09-07 19:44:41,612 - INFO - All types `lr` of epoch 90: {'lr/param_group0': 0.0002916558303495353, 'lr/param_group1': 0.0002916558303495353, 'lr/param_group2': 0.0002916558303495353, 'lr/param_group3': 0.0002916558303495353}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:41,614 - INFO - epoch 90: train loss 0.054212877751086595\n",
      "2025-09-07 19:44:41,616 - INFO - 90 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:41,617 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:41,618 - INFO - --------------------\n",
      "\n",
      "91/800: 100%|██████████| 216/216 [00:04<00:00, 45.67it/s]\n",
      "2025-09-07 19:44:46,501 - INFO - All types `lr` of epoch 91: {'lr/param_group0': 0.00029147136242821425, 'lr/param_group1': 0.00029147136242821425, 'lr/param_group2': 0.00029147136242821425, 'lr/param_group3': 0.00029147136242821425}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:46,503 - INFO - epoch 91: train loss 0.054520332219975966\n",
      "2025-09-07 19:44:46,504 - INFO - 91 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:46,506 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:46,507 - INFO - --------------------\n",
      "\n",
      "92/800: 100%|██████████| 216/216 [00:04<00:00, 45.04it/s]\n",
      "2025-09-07 19:44:51,456 - INFO - All types `lr` of epoch 92: {'lr/param_group0': 0.0002912849441620321, 'lr/param_group1': 0.0002912849441620321, 'lr/param_group2': 0.0002912849441620321, 'lr/param_group3': 0.0002912849441620321}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:51,457 - INFO - epoch 92: train loss 0.05443025721857945\n",
      "2025-09-07 19:44:51,459 - INFO - 92 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:51,461 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:51,462 - INFO - --------------------\n",
      "\n",
      "93/800: 100%|██████████| 216/216 [00:04<00:00, 43.90it/s]\n",
      "2025-09-07 19:44:56,534 - INFO - All types `lr` of epoch 93: {'lr/param_group0': 0.00029109657842578895, 'lr/param_group1': 0.00029109657842578895, 'lr/param_group2': 0.00029109657842578895, 'lr/param_group3': 0.00029109657842578895}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:44:56,536 - INFO - epoch 93: train loss 0.05424643044049541\n",
      "2025-09-07 19:44:56,538 - INFO - 93 epochs completed!\n",
      "\n",
      "2025-09-07 19:44:56,539 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:44:56,540 - INFO - --------------------\n",
      "\n",
      "94/800: 100%|██████████| 216/216 [00:04<00:00, 45.94it/s]\n",
      "2025-09-07 19:45:01,401 - INFO - All types `lr` of epoch 94: {'lr/param_group0': 0.0002909062681243177, 'lr/param_group1': 0.0002909062681243177, 'lr/param_group2': 0.0002909062681243177, 'lr/param_group3': 0.0002909062681243177}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:01,403 - INFO - epoch 94: train loss 0.05407086287245706\n",
      "2025-09-07 19:45:01,405 - INFO - 94 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:01,407 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:01,408 - INFO - --------------------\n",
      "\n",
      "95/800: 100%|██████████| 216/216 [00:04<00:00, 44.32it/s]\n",
      "2025-09-07 19:45:06,421 - INFO - All types `lr` of epoch 95: {'lr/param_group0': 0.00029071401619243847, 'lr/param_group1': 0.00029071401619243847, 'lr/param_group2': 0.00029071401619243847, 'lr/param_group3': 0.00029071401619243847}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:06,422 - INFO - epoch 95: train loss 0.054351762006128276\n",
      "2025-09-07 19:45:06,424 - INFO - 95 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:06,426 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:06,427 - INFO - --------------------\n",
      "\n",
      "96/800: 100%|██████████| 216/216 [00:04<00:00, 43.80it/s]\n",
      "2025-09-07 19:45:11,509 - INFO - All types `lr` of epoch 96: {'lr/param_group0': 0.00029051982559491393, 'lr/param_group1': 0.00029051982559491393, 'lr/param_group2': 0.00029051982559491393, 'lr/param_group3': 0.00029051982559491393}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:11,510 - INFO - epoch 96: train loss 0.053964342542544556\n",
      "2025-09-07 19:45:11,512 - INFO - 96 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:11,514 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:11,515 - INFO - --------------------\n",
      "\n",
      "97/800: 100%|██████████| 216/216 [00:04<00:00, 45.01it/s]\n",
      "2025-09-07 19:45:16,470 - INFO - All types `lr` of epoch 97: {'lr/param_group0': 0.0002903236993264033, 'lr/param_group1': 0.0002903236993264033, 'lr/param_group2': 0.0002903236993264033, 'lr/param_group3': 0.0002903236993264033}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:16,472 - INFO - epoch 97: train loss 0.05385585776012805\n",
      "2025-09-07 19:45:16,474 - INFO - 97 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:16,476 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:16,477 - INFO - --------------------\n",
      "\n",
      "98/800: 100%|██████████| 216/216 [00:04<00:00, 45.10it/s]\n",
      "2025-09-07 19:45:21,421 - INFO - All types `lr` of epoch 98: {'lr/param_group0': 0.0002901256404114163, 'lr/param_group1': 0.0002901256404114163, 'lr/param_group2': 0.0002901256404114163, 'lr/param_group3': 0.0002901256404114163}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:21,422 - INFO - epoch 98: train loss 0.05419327936100739\n",
      "2025-09-07 19:45:21,424 - INFO - 98 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:21,426 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:21,428 - INFO - --------------------\n",
      "\n",
      "99/800: 100%|██████████| 216/216 [00:04<00:00, 44.95it/s]\n",
      "2025-09-07 19:45:26,386 - INFO - All types `lr` of epoch 99: {'lr/param_group0': 0.00028992565190426637, 'lr/param_group1': 0.00028992565190426637, 'lr/param_group2': 0.00028992565190426637, 'lr/param_group3': 0.00028992565190426637}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:26,388 - INFO - epoch 99: train loss 0.05392707598016218\n",
      "2025-09-07 19:45:26,390 - INFO - 99 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:26,391 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:26,393 - INFO - --------------------\n",
      "\n",
      "100/800: 100%|██████████| 216/216 [00:04<00:00, 44.30it/s]\n",
      "2025-09-07 19:45:31,424 - INFO - All types `lr` of epoch 100: {'lr/param_group0': 0.0002897237368890237, 'lr/param_group1': 0.0002897237368890237, 'lr/param_group2': 0.0002897237368890237, 'lr/param_group3': 0.0002897237368890237}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:31,426 - INFO - epoch 100: train loss 0.05400402693905764\n",
      "2025-09-07 19:45:31,428 - INFO - 100 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:31,429 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:31,431 - INFO - --------------------\n",
      "\n",
      "101/800: 100%|██████████| 216/216 [00:04<00:00, 43.92it/s]\n",
      "2025-09-07 19:45:36,487 - INFO - All types `lr` of epoch 101: {'lr/param_group0': 0.0002895198984794676, 'lr/param_group1': 0.0002895198984794676, 'lr/param_group2': 0.0002895198984794676, 'lr/param_group3': 0.0002895198984794676}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:36,488 - INFO - epoch 101: train loss 0.05369376311837523\n",
      "2025-09-07 19:45:36,490 - INFO - 101 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:36,492 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:36,493 - INFO - --------------------\n",
      "\n",
      "102/800: 100%|██████████| 216/216 [00:04<00:00, 43.32it/s]\n",
      "2025-09-07 19:45:41,639 - INFO - All types `lr` of epoch 102: {'lr/param_group0': 0.00028931413981903855, 'lr/param_group1': 0.00028931413981903855, 'lr/param_group2': 0.00028931413981903855, 'lr/param_group3': 0.00028931413981903855}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:41,641 - INFO - epoch 102: train loss 0.053637300997420596\n",
      "2025-09-07 19:45:41,643 - INFO - 102 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:41,644 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:41,645 - INFO - --------------------\n",
      "\n",
      "103/800: 100%|██████████| 216/216 [00:04<00:00, 44.69it/s]\n",
      "2025-09-07 19:45:46,637 - INFO - All types `lr` of epoch 103: {'lr/param_group0': 0.00028910646408078955, 'lr/param_group1': 0.00028910646408078955, 'lr/param_group2': 0.00028910646408078955, 'lr/param_group3': 0.00028910646408078955}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:46,639 - INFO - epoch 103: train loss 0.053806173925598465\n",
      "2025-09-07 19:45:46,641 - INFO - 103 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:46,642 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:46,643 - INFO - --------------------\n",
      "\n",
      "104/800: 100%|██████████| 216/216 [00:04<00:00, 44.96it/s]\n",
      "2025-09-07 19:45:51,605 - INFO - All types `lr` of epoch 104: {'lr/param_group0': 0.00028889687446733743, 'lr/param_group1': 0.00028889687446733743, 'lr/param_group2': 0.00028889687446733743, 'lr/param_group3': 0.00028889687446733743}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:51,607 - INFO - epoch 104: train loss 0.053645372580460926\n",
      "2025-09-07 19:45:51,609 - INFO - 104 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:51,610 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:51,612 - INFO - --------------------\n",
      "\n",
      "105/800: 100%|██████████| 216/216 [00:04<00:00, 43.88it/s]\n",
      "2025-09-07 19:45:56,691 - INFO - All types `lr` of epoch 105: {'lr/param_group0': 0.00028868537421081333, 'lr/param_group1': 0.00028868537421081333, 'lr/param_group2': 0.00028868537421081333, 'lr/param_group3': 0.00028868537421081333}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:45:56,693 - INFO - epoch 105: train loss 0.05486854646975795\n",
      "2025-09-07 19:45:56,694 - INFO - 105 epochs completed!\n",
      "\n",
      "2025-09-07 19:45:56,696 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:45:56,697 - INFO - --------------------\n",
      "\n",
      "106/800: 100%|██████████| 216/216 [00:04<00:00, 44.34it/s]\n",
      "2025-09-07 19:46:01,719 - INFO - All types `lr` of epoch 106: {'lr/param_group0': 0.00028847196657281283, 'lr/param_group1': 0.00028847196657281283, 'lr/param_group2': 0.00028847196657281283, 'lr/param_group3': 0.00028847196657281283}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:01,720 - INFO - epoch 106: train loss 0.053494440426153166\n",
      "2025-09-07 19:46:01,722 - INFO - 106 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:01,724 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:01,725 - INFO - --------------------\n",
      "\n",
      "107/800: 100%|██████████| 216/216 [00:04<00:00, 44.92it/s]\n",
      "2025-09-07 19:46:06,687 - INFO - All types `lr` of epoch 107: {'lr/param_group0': 0.00028825665484434566, 'lr/param_group1': 0.00028825665484434566, 'lr/param_group2': 0.00028825665484434566, 'lr/param_group3': 0.00028825665484434566}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:06,689 - INFO - epoch 107: train loss 0.053072898769406254\n",
      "2025-09-07 19:46:06,691 - INFO - 107 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:06,692 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:06,693 - INFO - --------------------\n",
      "\n",
      "108/800: 100%|██████████| 216/216 [00:04<00:00, 44.85it/s]\n",
      "2025-09-07 19:46:11,665 - INFO - All types `lr` of epoch 108: {'lr/param_group0': 0.0002880394423457851, 'lr/param_group1': 0.0002880394423457851, 'lr/param_group2': 0.0002880394423457851, 'lr/param_group3': 0.0002880394423457851}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:11,667 - INFO - epoch 108: train loss 0.053698222428836206\n",
      "2025-09-07 19:46:11,670 - INFO - 108 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:11,671 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:11,672 - INFO - --------------------\n",
      "\n",
      "109/800: 100%|██████████| 216/216 [00:04<00:00, 44.85it/s]\n",
      "2025-09-07 19:46:16,642 - INFO - All types `lr` of epoch 109: {'lr/param_group0': 0.00028782033242681653, 'lr/param_group1': 0.00028782033242681653, 'lr/param_group2': 0.00028782033242681653, 'lr/param_group3': 0.00028782033242681653}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:16,644 - INFO - epoch 109: train loss 0.054165381058636636\n",
      "2025-09-07 19:46:16,646 - INFO - 109 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:16,647 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:16,649 - INFO - --------------------\n",
      "\n",
      "110/800: 100%|██████████| 216/216 [00:04<00:00, 45.61it/s]\n",
      "2025-09-07 19:46:21,541 - INFO - All types `lr` of epoch 110: {'lr/param_group0': 0.00028759932846638596, 'lr/param_group1': 0.00028759932846638596, 'lr/param_group2': 0.00028759932846638596, 'lr/param_group3': 0.00028759932846638596}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:21,542 - INFO - epoch 110: train loss 0.053411173444517235\n",
      "2025-09-07 19:46:21,544 - INFO - 110 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:21,545 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:21,546 - INFO - --------------------\n",
      "\n",
      "111/800: 100%|██████████| 216/216 [00:05<00:00, 43.07it/s]\n",
      "2025-09-07 19:46:26,706 - INFO - All types `lr` of epoch 111: {'lr/param_group0': 0.0002873764338726479, 'lr/param_group1': 0.0002873764338726479, 'lr/param_group2': 0.0002873764338726479, 'lr/param_group3': 0.0002873764338726479}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:26,707 - INFO - epoch 111: train loss 0.05262770860766371\n",
      "2025-09-07 19:46:26,709 - INFO - 111 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:26,711 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:26,712 - INFO - --------------------\n",
      "\n",
      "112/800: 100%|██████████| 216/216 [00:04<00:00, 44.71it/s]\n",
      "2025-09-07 19:46:31,699 - INFO - All types `lr` of epoch 112: {'lr/param_group0': 0.00028715165208291265, 'lr/param_group1': 0.00028715165208291265, 'lr/param_group2': 0.00028715165208291265, 'lr/param_group3': 0.00028715165208291265}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:31,700 - INFO - epoch 112: train loss 0.052873544895124656\n",
      "2025-09-07 19:46:31,702 - INFO - 112 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:31,703 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:31,704 - INFO - --------------------\n",
      "\n",
      "113/800: 100%|██████████| 216/216 [00:04<00:00, 44.59it/s]\n",
      "2025-09-07 19:46:36,704 - INFO - All types `lr` of epoch 113: {'lr/param_group0': 0.00028692498656359344, 'lr/param_group1': 0.00028692498656359344, 'lr/param_group2': 0.00028692498656359344, 'lr/param_group3': 0.00028692498656359344}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:36,706 - INFO - epoch 113: train loss 0.053016575794942955\n",
      "2025-09-07 19:46:36,708 - INFO - 113 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:36,709 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:36,710 - INFO - --------------------\n",
      "\n",
      "114/800: 100%|██████████| 216/216 [00:04<00:00, 43.67it/s]\n",
      "2025-09-07 19:46:41,810 - INFO - All types `lr` of epoch 114: {'lr/param_group0': 0.0002866964408101531, 'lr/param_group1': 0.0002866964408101531, 'lr/param_group2': 0.0002866964408101531, 'lr/param_group3': 0.0002866964408101531}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:41,812 - INFO - epoch 114: train loss 0.05248878887613063\n",
      "2025-09-07 19:46:41,814 - INFO - 114 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:41,816 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:41,817 - INFO - --------------------\n",
      "\n",
      "115/800: 100%|██████████| 216/216 [00:04<00:00, 43.87it/s]\n",
      "2025-09-07 19:46:46,902 - INFO - All types `lr` of epoch 115: {'lr/param_group0': 0.0002864660183470499, 'lr/param_group1': 0.0002864660183470499, 'lr/param_group2': 0.0002864660183470499, 'lr/param_group3': 0.0002864660183470499}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:46,904 - INFO - epoch 115: train loss 0.0532252820795057\n",
      "2025-09-07 19:46:46,906 - INFO - 115 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:46,907 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:46,909 - INFO - --------------------\n",
      "\n",
      "116/800: 100%|██████████| 216/216 [00:04<00:00, 45.12it/s]\n",
      "2025-09-07 19:46:51,850 - INFO - All types `lr` of epoch 116: {'lr/param_group0': 0.0002862337227276831, 'lr/param_group1': 0.0002862337227276831, 'lr/param_group2': 0.0002862337227276831, 'lr/param_group3': 0.0002862337227276831}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:51,852 - INFO - epoch 116: train loss 0.0531384637751789\n",
      "2025-09-07 19:46:51,854 - INFO - 116 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:51,855 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:51,857 - INFO - --------------------\n",
      "\n",
      "117/800: 100%|██████████| 216/216 [00:04<00:00, 44.95it/s]\n",
      "2025-09-07 19:46:56,818 - INFO - All types `lr` of epoch 117: {'lr/param_group0': 0.0002859995575343386, 'lr/param_group1': 0.0002859995575343386, 'lr/param_group2': 0.0002859995575343386, 'lr/param_group3': 0.0002859995575343386}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:46:56,819 - INFO - epoch 117: train loss 0.05313973440961153\n",
      "2025-09-07 19:46:56,821 - INFO - 117 epochs completed!\n",
      "\n",
      "2025-09-07 19:46:56,822 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:46:56,823 - INFO - --------------------\n",
      "\n",
      "118/800: 100%|██████████| 216/216 [00:04<00:00, 44.42it/s]\n",
      "2025-09-07 19:47:01,837 - INFO - All types `lr` of epoch 118: {'lr/param_group0': 0.0002857635263781334, 'lr/param_group1': 0.0002857635263781334, 'lr/param_group2': 0.0002857635263781334, 'lr/param_group3': 0.0002857635263781334}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:01,839 - INFO - epoch 118: train loss 0.05317506038894256\n",
      "2025-09-07 19:47:01,841 - INFO - 118 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:01,843 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:01,844 - INFO - --------------------\n",
      "\n",
      "119/800: 100%|██████████| 216/216 [00:04<00:00, 44.97it/s]\n",
      "2025-09-07 19:47:06,805 - INFO - All types `lr` of epoch 119: {'lr/param_group0': 0.0002855256328989598, 'lr/param_group1': 0.0002855256328989598, 'lr/param_group2': 0.0002855256328989598, 'lr/param_group3': 0.0002855256328989598}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:06,807 - INFO - epoch 119: train loss 0.052733902267559814\n",
      "100%|██████████| 54/54 [00:01<00:00, 40.36it/s]\n",
      "2025-09-07 19:47:08,299 - INFO - epoch 119: val loss 0.05813052256902059\n",
      "2025-09-07 19:47:08,302 - INFO - 119 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:47:08,313 - INFO - 119 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:08,315 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:08,316 - INFO - --------------------\n",
      "\n",
      "120/800: 100%|██████████| 216/216 [00:04<00:00, 45.11it/s]\n",
      "2025-09-07 19:47:13,253 - INFO - All types `lr` of epoch 120: {'lr/param_group0': 0.00028528588076542964, 'lr/param_group1': 0.00028528588076542964, 'lr/param_group2': 0.00028528588076542964, 'lr/param_group3': 0.00028528588076542964}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:13,255 - INFO - epoch 120: train loss 0.05250053124985209\n",
      "2025-09-07 19:47:13,257 - INFO - 120 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:13,259 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:13,261 - INFO - --------------------\n",
      "\n",
      "121/800: 100%|██████████| 216/216 [00:04<00:00, 44.91it/s]\n",
      "2025-09-07 19:47:18,231 - INFO - All types `lr` of epoch 121: {'lr/param_group0': 0.0002850442736748174, 'lr/param_group1': 0.0002850442736748174, 'lr/param_group2': 0.0002850442736748174, 'lr/param_group3': 0.0002850442736748174}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:18,233 - INFO - epoch 121: train loss 0.05298360095669826\n",
      "2025-09-07 19:47:18,235 - INFO - 121 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:18,236 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:18,238 - INFO - --------------------\n",
      "\n",
      "122/800: 100%|██████████| 216/216 [00:05<00:00, 42.27it/s]\n",
      "2025-09-07 19:47:23,509 - INFO - All types `lr` of epoch 122: {'lr/param_group0': 0.00028480081535300325, 'lr/param_group1': 0.00028480081535300325, 'lr/param_group2': 0.00028480081535300325, 'lr/param_group3': 0.00028480081535300325}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:23,511 - INFO - epoch 122: train loss 0.05267791487966423\n",
      "2025-09-07 19:47:23,513 - INFO - 122 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:23,514 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:23,516 - INFO - --------------------\n",
      "\n",
      "123/800: 100%|██████████| 216/216 [00:05<00:00, 42.53it/s]\n",
      "2025-09-07 19:47:28,755 - INFO - All types `lr` of epoch 123: {'lr/param_group0': 0.00028455550955441567, 'lr/param_group1': 0.00028455550955441567, 'lr/param_group2': 0.00028455550955441567, 'lr/param_group3': 0.00028455550955441567}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:28,757 - INFO - epoch 123: train loss 0.052961351074002405\n",
      "2025-09-07 19:47:28,759 - INFO - 123 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:28,761 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:28,763 - INFO - --------------------\n",
      "\n",
      "124/800: 100%|██████████| 216/216 [00:05<00:00, 43.19it/s]\n",
      "2025-09-07 19:47:33,922 - INFO - All types `lr` of epoch 124: {'lr/param_group0': 0.0002843083600619736, 'lr/param_group1': 0.0002843083600619736, 'lr/param_group2': 0.0002843083600619736, 'lr/param_group3': 0.0002843083600619736}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:33,924 - INFO - epoch 124: train loss 0.05251922946492279\n",
      "2025-09-07 19:47:33,926 - INFO - 124 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:33,928 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:33,929 - INFO - --------------------\n",
      "\n",
      "125/800: 100%|██████████| 216/216 [00:04<00:00, 43.55it/s]\n",
      "2025-09-07 19:47:39,055 - INFO - All types `lr` of epoch 125: {'lr/param_group0': 0.0002840593706870279, 'lr/param_group1': 0.0002840593706870279, 'lr/param_group2': 0.0002840593706870279, 'lr/param_group3': 0.0002840593706870279}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:39,057 - INFO - epoch 125: train loss 0.05325779225677252\n",
      "2025-09-07 19:47:39,059 - INFO - 125 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:39,061 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:39,062 - INFO - --------------------\n",
      "\n",
      "126/800: 100%|██████████| 216/216 [00:05<00:00, 42.19it/s]\n",
      "2025-09-07 19:47:44,326 - INFO - All types `lr` of epoch 126: {'lr/param_group0': 0.0002838085452693028, 'lr/param_group1': 0.0002838085452693028, 'lr/param_group2': 0.0002838085452693028, 'lr/param_group3': 0.0002838085452693028}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:44,328 - INFO - epoch 126: train loss 0.052627302102606605\n",
      "2025-09-07 19:47:44,330 - INFO - 126 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:44,332 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:44,333 - INFO - --------------------\n",
      "\n",
      "127/800: 100%|██████████| 216/216 [00:04<00:00, 43.63it/s]\n",
      "2025-09-07 19:47:49,443 - INFO - All types `lr` of epoch 127: {'lr/param_group0': 0.00028355588767683645, 'lr/param_group1': 0.00028355588767683645, 'lr/param_group2': 0.00028355588767683645, 'lr/param_group3': 0.00028355588767683645}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:49,445 - INFO - epoch 127: train loss 0.052973703360529964\n",
      "2025-09-07 19:47:49,447 - INFO - 127 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:49,448 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:49,450 - INFO - --------------------\n",
      "\n",
      "128/800: 100%|██████████| 216/216 [00:05<00:00, 42.69it/s]\n",
      "2025-09-07 19:47:54,650 - INFO - All types `lr` of epoch 128: {'lr/param_group0': 0.00028330140180592156, 'lr/param_group1': 0.00028330140180592156, 'lr/param_group2': 0.00028330140180592156, 'lr/param_group3': 0.00028330140180592156}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:54,652 - INFO - epoch 128: train loss 0.052598817739635706\n",
      "2025-09-07 19:47:54,655 - INFO - 128 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:54,656 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:54,658 - INFO - --------------------\n",
      "\n",
      "129/800: 100%|██████████| 216/216 [00:04<00:00, 44.57it/s]\n",
      "2025-09-07 19:47:59,661 - INFO - All types `lr` of epoch 129: {'lr/param_group0': 0.00028304509158104505, 'lr/param_group1': 0.00028304509158104505, 'lr/param_group2': 0.00028304509158104505, 'lr/param_group3': 0.00028304509158104505}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:47:59,663 - INFO - epoch 129: train loss 0.05290586813525469\n",
      "2025-09-07 19:47:59,665 - INFO - 129 epochs completed!\n",
      "\n",
      "2025-09-07 19:47:59,667 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:47:59,668 - INFO - --------------------\n",
      "\n",
      "130/800: 100%|██████████| 216/216 [00:04<00:00, 44.64it/s]\n",
      "2025-09-07 19:48:04,668 - INFO - All types `lr` of epoch 130: {'lr/param_group0': 0.0002827869609548276, 'lr/param_group1': 0.0002827869609548276, 'lr/param_group2': 0.0002827869609548276, 'lr/param_group3': 0.0002827869609548276}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:04,670 - INFO - epoch 130: train loss 0.052545239545266936\n",
      "2025-09-07 19:48:04,672 - INFO - 130 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:04,674 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:04,675 - INFO - --------------------\n",
      "\n",
      "131/800: 100%|██████████| 216/216 [00:05<00:00, 42.99it/s]\n",
      "2025-09-07 19:48:09,859 - INFO - All types `lr` of epoch 131: {'lr/param_group0': 0.0002825270139079628, 'lr/param_group1': 0.0002825270139079628, 'lr/param_group2': 0.0002825270139079628, 'lr/param_group3': 0.0002825270139079628}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:09,861 - INFO - epoch 131: train loss 0.052037855644744856\n",
      "2025-09-07 19:48:09,863 - INFO - 131 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:09,864 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:09,866 - INFO - --------------------\n",
      "\n",
      "132/800: 100%|██████████| 216/216 [00:05<00:00, 41.94it/s]\n",
      "2025-09-07 19:48:15,173 - INFO - All types `lr` of epoch 132: {'lr/param_group0': 0.0002822652544491558, 'lr/param_group1': 0.0002822652544491558, 'lr/param_group2': 0.0002822652544491558, 'lr/param_group3': 0.0002822652544491558}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:15,175 - INFO - epoch 132: train loss 0.05232135566917283\n",
      "2025-09-07 19:48:15,177 - INFO - 132 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:15,178 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:15,179 - INFO - --------------------\n",
      "\n",
      "133/800: 100%|██████████| 216/216 [00:04<00:00, 44.06it/s]\n",
      "2025-09-07 19:48:20,219 - INFO - All types `lr` of epoch 133: {'lr/param_group0': 0.0002820016866150611, 'lr/param_group1': 0.0002820016866150611, 'lr/param_group2': 0.0002820016866150611, 'lr/param_group3': 0.0002820016866150611}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:20,221 - INFO - epoch 133: train loss 0.05261001052955786\n",
      "2025-09-07 19:48:20,223 - INFO - 133 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:20,225 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:20,226 - INFO - --------------------\n",
      "\n",
      "134/800: 100%|██████████| 216/216 [00:04<00:00, 44.38it/s]\n",
      "2025-09-07 19:48:25,251 - INFO - All types `lr` of epoch 134: {'lr/param_group0': 0.0002817363144702209, 'lr/param_group1': 0.0002817363144702209, 'lr/param_group2': 0.0002817363144702209, 'lr/param_group3': 0.0002817363144702209}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:25,253 - INFO - epoch 134: train loss 0.05246566425732992\n",
      "2025-09-07 19:48:25,256 - INFO - 134 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:25,257 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:25,259 - INFO - --------------------\n",
      "\n",
      "135/800: 100%|██████████| 216/216 [00:04<00:00, 45.40it/s]\n",
      "2025-09-07 19:48:30,173 - INFO - All types `lr` of epoch 135: {'lr/param_group0': 0.00028146914210700185, 'lr/param_group1': 0.00028146914210700185, 'lr/param_group2': 0.00028146914210700185, 'lr/param_group3': 0.00028146914210700185}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:30,175 - INFO - epoch 135: train loss 0.05223489959758741\n",
      "2025-09-07 19:48:30,178 - INFO - 135 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:30,179 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:30,181 - INFO - --------------------\n",
      "\n",
      "136/800: 100%|██████████| 216/216 [00:04<00:00, 44.68it/s]\n",
      "2025-09-07 19:48:35,170 - INFO - All types `lr` of epoch 136: {'lr/param_group0': 0.00028120017364553237, 'lr/param_group1': 0.00028120017364553237, 'lr/param_group2': 0.00028120017364553237, 'lr/param_group3': 0.00028120017364553237}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:35,172 - INFO - epoch 136: train loss 0.05174053315487173\n",
      "2025-09-07 19:48:35,174 - INFO - 136 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:35,175 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:35,177 - INFO - --------------------\n",
      "\n",
      "137/800: 100%|██████████| 216/216 [00:04<00:00, 43.83it/s]\n",
      "2025-09-07 19:48:40,264 - INFO - All types `lr` of epoch 137: {'lr/param_group0': 0.0002809294132336388, 'lr/param_group1': 0.0002809294132336388, 'lr/param_group2': 0.0002809294132336388, 'lr/param_group3': 0.0002809294132336388}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:40,266 - INFO - epoch 137: train loss 0.05206248155553584\n",
      "2025-09-07 19:48:40,268 - INFO - 137 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:40,270 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:40,271 - INFO - --------------------\n",
      "\n",
      "138/800: 100%|██████████| 216/216 [00:04<00:00, 44.47it/s]\n",
      "2025-09-07 19:48:45,287 - INFO - All types `lr` of epoch 138: {'lr/param_group0': 0.00028065686504678166, 'lr/param_group1': 0.00028065686504678166, 'lr/param_group2': 0.00028065686504678166, 'lr/param_group3': 0.00028065686504678166}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:45,289 - INFO - epoch 138: train loss 0.05170661381756266\n",
      "2025-09-07 19:48:45,291 - INFO - 138 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:45,293 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:45,295 - INFO - --------------------\n",
      "\n",
      "139/800: 100%|██████████| 216/216 [00:05<00:00, 43.17it/s]\n",
      "2025-09-07 19:48:50,454 - INFO - All types `lr` of epoch 139: {'lr/param_group0': 0.00028038253328799116, 'lr/param_group1': 0.00028038253328799116, 'lr/param_group2': 0.00028038253328799116, 'lr/param_group3': 0.00028038253328799116}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:50,456 - INFO - epoch 139: train loss 0.05192533261315138\n",
      "2025-09-07 19:48:50,458 - INFO - 139 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:50,460 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:50,461 - INFO - --------------------\n",
      "\n",
      "140/800: 100%|██████████| 216/216 [00:04<00:00, 44.50it/s]\n",
      "2025-09-07 19:48:55,458 - INFO - All types `lr` of epoch 140: {'lr/param_group0': 0.0002801064221878024, 'lr/param_group1': 0.0002801064221878024, 'lr/param_group2': 0.0002801064221878024, 'lr/param_group3': 0.0002801064221878024}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:48:55,460 - INFO - epoch 140: train loss 0.0521295398508233\n",
      "2025-09-07 19:48:55,462 - INFO - 140 epochs completed!\n",
      "\n",
      "2025-09-07 19:48:55,464 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:48:55,465 - INFO - --------------------\n",
      "\n",
      "141/800: 100%|██████████| 216/216 [00:04<00:00, 44.49it/s]\n",
      "2025-09-07 19:49:00,479 - INFO - All types `lr` of epoch 141: {'lr/param_group0': 0.0002798285360041901, 'lr/param_group1': 0.0002798285360041901, 'lr/param_group2': 0.0002798285360041901, 'lr/param_group3': 0.0002798285360041901}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:00,481 - INFO - epoch 141: train loss 0.052349984594103366\n",
      "2025-09-07 19:49:00,483 - INFO - 141 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:00,485 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:00,486 - INFO - --------------------\n",
      "\n",
      "142/800: 100%|██████████| 216/216 [00:04<00:00, 44.40it/s]\n",
      "2025-09-07 19:49:05,511 - INFO - All types `lr` of epoch 142: {'lr/param_group0': 0.00027954887902250297, 'lr/param_group1': 0.00027954887902250297, 'lr/param_group2': 0.00027954887902250297, 'lr/param_group3': 0.00027954887902250297}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:05,513 - INFO - epoch 142: train loss 0.052039916075214195\n",
      "2025-09-07 19:49:05,515 - INFO - 142 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:05,516 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:05,518 - INFO - --------------------\n",
      "\n",
      "143/800: 100%|██████████| 216/216 [00:04<00:00, 43.80it/s]\n",
      "2025-09-07 19:49:10,610 - INFO - All types `lr` of epoch 143: {'lr/param_group0': 0.00027926745555539764, 'lr/param_group1': 0.00027926745555539764, 'lr/param_group2': 0.00027926745555539764, 'lr/param_group3': 0.00027926745555539764}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:10,612 - INFO - epoch 143: train loss 0.05209132021775952\n",
      "2025-09-07 19:49:10,614 - INFO - 143 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:10,615 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:10,617 - INFO - --------------------\n",
      "\n",
      "144/800: 100%|██████████| 216/216 [00:04<00:00, 43.28it/s]\n",
      "2025-09-07 19:49:15,770 - INFO - All types `lr` of epoch 144: {'lr/param_group0': 0.00027898426994277204, 'lr/param_group1': 0.00027898426994277204, 'lr/param_group2': 0.00027898426994277204, 'lr/param_group3': 0.00027898426994277204}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:15,772 - INFO - epoch 144: train loss 0.05228467775439775\n",
      "2025-09-07 19:49:15,774 - INFO - 144 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:15,776 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:15,778 - INFO - --------------------\n",
      "\n",
      "145/800: 100%|██████████| 216/216 [00:04<00:00, 44.26it/s]\n",
      "2025-09-07 19:49:20,817 - INFO - All types `lr` of epoch 145: {'lr/param_group0': 0.00027869932655169864, 'lr/param_group1': 0.00027869932655169864, 'lr/param_group2': 0.00027869932655169864, 'lr/param_group3': 0.00027869932655169864}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:20,819 - INFO - epoch 145: train loss 0.05157741904258728\n",
      "2025-09-07 19:49:20,821 - INFO - 145 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:20,823 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:20,824 - INFO - --------------------\n",
      "\n",
      "146/800: 100%|██████████| 216/216 [00:04<00:00, 44.42it/s]\n",
      "2025-09-07 19:49:25,849 - INFO - All types `lr` of epoch 146: {'lr/param_group0': 0.0002784126297763571, 'lr/param_group1': 0.0002784126297763571, 'lr/param_group2': 0.0002784126297763571, 'lr/param_group3': 0.0002784126297763571}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:25,851 - INFO - epoch 146: train loss 0.051727279779259804\n",
      "2025-09-07 19:49:25,853 - INFO - 146 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:25,855 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:25,857 - INFO - --------------------\n",
      "\n",
      "147/800: 100%|██████████| 216/216 [00:04<00:00, 44.12it/s]\n",
      "2025-09-07 19:49:30,907 - INFO - All types `lr` of epoch 147: {'lr/param_group0': 0.0002781241840379663, 'lr/param_group1': 0.0002781241840379663, 'lr/param_group2': 0.0002781241840379663, 'lr/param_group3': 0.0002781241840379663}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:30,909 - INFO - epoch 147: train loss 0.05158944122700228\n",
      "2025-09-07 19:49:30,912 - INFO - 147 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:30,914 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:30,915 - INFO - --------------------\n",
      "\n",
      "148/800: 100%|██████████| 216/216 [00:05<00:00, 41.17it/s]\n",
      "2025-09-07 19:49:36,327 - INFO - All types `lr` of epoch 148: {'lr/param_group0': 0.0002778339937847165, 'lr/param_group1': 0.0002778339937847165, 'lr/param_group2': 0.0002778339937847165, 'lr/param_group3': 0.0002778339937847165}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:36,333 - INFO - epoch 148: train loss 0.051566334130863346\n",
      "2025-09-07 19:49:36,336 - INFO - 148 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:36,342 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:36,347 - INFO - --------------------\n",
      "\n",
      "149/800: 100%|██████████| 216/216 [00:05<00:00, 38.07it/s]\n",
      "2025-09-07 19:49:42,183 - INFO - All types `lr` of epoch 149: {'lr/param_group0': 0.0002775420634917001, 'lr/param_group1': 0.0002775420634917001, 'lr/param_group2': 0.0002775420634917001, 'lr/param_group3': 0.0002775420634917001}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:42,187 - INFO - epoch 149: train loss 0.05144510193969364\n",
      "2025-09-07 19:49:42,193 - INFO - 149 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:42,199 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:42,201 - INFO - --------------------\n",
      "\n",
      "150/800: 100%|██████████| 216/216 [00:05<00:00, 38.29it/s]\n",
      "2025-09-07 19:49:48,013 - INFO - All types `lr` of epoch 150: {'lr/param_group0': 0.0002772483976608436, 'lr/param_group1': 0.0002772483976608436, 'lr/param_group2': 0.0002772483976608436, 'lr/param_group3': 0.0002772483976608436}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:48,020 - INFO - epoch 150: train loss 0.05184343676255257\n",
      "2025-09-07 19:49:48,026 - INFO - 150 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:48,028 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:48,033 - INFO - --------------------\n",
      "\n",
      "151/800: 100%|██████████| 216/216 [00:05<00:00, 38.02it/s]\n",
      "2025-09-07 19:49:53,877 - INFO - All types `lr` of epoch 151: {'lr/param_group0': 0.00027695300082083724, 'lr/param_group1': 0.00027695300082083724, 'lr/param_group2': 0.00027695300082083724, 'lr/param_group3': 0.00027695300082083724}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:53,884 - INFO - epoch 151: train loss 0.05140848745833392\n",
      "2025-09-07 19:49:53,890 - INFO - 151 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:53,892 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:53,897 - INFO - --------------------\n",
      "\n",
      "152/800: 100%|██████████| 216/216 [00:05<00:00, 39.18it/s]\n",
      "2025-09-07 19:49:59,578 - INFO - All types `lr` of epoch 152: {'lr/param_group0': 0.0002766558775270658, 'lr/param_group1': 0.0002766558775270658, 'lr/param_group2': 0.0002766558775270658, 'lr/param_group3': 0.0002766558775270658}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:49:59,580 - INFO - epoch 152: train loss 0.051065362938162356\n",
      "2025-09-07 19:49:59,587 - INFO - 152 epochs completed!\n",
      "\n",
      "2025-09-07 19:49:59,592 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:49:59,594 - INFO - --------------------\n",
      "\n",
      "153/800: 100%|██████████| 216/216 [00:05<00:00, 39.37it/s]\n",
      "2025-09-07 19:50:05,240 - INFO - All types `lr` of epoch 153: {'lr/param_group0': 0.00027635703236153806, 'lr/param_group1': 0.00027635703236153806, 'lr/param_group2': 0.00027635703236153806, 'lr/param_group3': 0.00027635703236153806}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:05,247 - INFO - epoch 153: train loss 0.05102688337986668\n",
      "2025-09-07 19:50:05,254 - INFO - 153 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:05,256 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:05,261 - INFO - --------------------\n",
      "\n",
      "154/800: 100%|██████████| 216/216 [00:05<00:00, 37.97it/s]\n",
      "2025-09-07 19:50:11,112 - INFO - All types `lr` of epoch 154: {'lr/param_group0': 0.000276056469932816, 'lr/param_group1': 0.000276056469932816, 'lr/param_group2': 0.000276056469932816, 'lr/param_group3': 0.000276056469932816}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:11,115 - INFO - epoch 154: train loss 0.05150912469252944\n",
      "2025-09-07 19:50:11,122 - INFO - 154 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:11,128 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:11,130 - INFO - --------------------\n",
      "\n",
      "155/800: 100%|██████████| 216/216 [00:05<00:00, 37.82it/s]\n",
      "2025-09-07 19:50:17,001 - INFO - All types `lr` of epoch 155: {'lr/param_group0': 0.00027575419487594434, 'lr/param_group1': 0.00027575419487594434, 'lr/param_group2': 0.00027575419487594434, 'lr/param_group3': 0.00027575419487594434}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:17,009 - INFO - epoch 155: train loss 0.05108434625866788\n",
      "2025-09-07 19:50:17,016 - INFO - 155 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:17,021 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:17,025 - INFO - --------------------\n",
      "\n",
      "156/800: 100%|██████████| 216/216 [00:05<00:00, 38.15it/s]\n",
      "2025-09-07 19:50:22,857 - INFO - All types `lr` of epoch 156: {'lr/param_group0': 0.00027545021185237814, 'lr/param_group1': 0.00027545021185237814, 'lr/param_group2': 0.00027545021185237814, 'lr/param_group3': 0.00027545021185237814}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:22,860 - INFO - epoch 156: train loss 0.0515847477061605\n",
      "2025-09-07 19:50:22,867 - INFO - 156 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:22,869 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:22,873 - INFO - --------------------\n",
      "\n",
      "157/800: 100%|██████████| 216/216 [00:05<00:00, 38.40it/s]\n",
      "2025-09-07 19:50:28,660 - INFO - All types `lr` of epoch 157: {'lr/param_group0': 0.0002751445255499118, 'lr/param_group1': 0.0002751445255499118, 'lr/param_group2': 0.0002751445255499118, 'lr/param_group3': 0.0002751445255499118}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:28,670 - INFO - epoch 157: train loss 0.05156231942345147\n",
      "2025-09-07 19:50:28,677 - INFO - 157 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:28,682 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:28,686 - INFO - --------------------\n",
      "\n",
      "158/800: 100%|██████████| 216/216 [00:05<00:00, 37.66it/s]\n",
      "2025-09-07 19:50:34,583 - INFO - All types `lr` of epoch 158: {'lr/param_group0': 0.00027483714068260624, 'lr/param_group1': 0.00027483714068260624, 'lr/param_group2': 0.00027483714068260624, 'lr/param_group3': 0.00027483714068260624}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:34,592 - INFO - epoch 158: train loss 0.05168571618075172\n",
      "2025-09-07 19:50:34,599 - INFO - 158 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:34,604 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:34,608 - INFO - --------------------\n",
      "\n",
      "159/800: 100%|██████████| 216/216 [00:05<00:00, 37.48it/s]\n",
      "2025-09-07 19:50:40,534 - INFO - All types `lr` of epoch 159: {'lr/param_group0': 0.00027452806199071634, 'lr/param_group1': 0.00027452806199071634, 'lr/param_group2': 0.00027452806199071634, 'lr/param_group3': 0.00027452806199071634}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:40,541 - INFO - epoch 159: train loss 0.051363965548161\n",
      "100%|██████████| 54/54 [00:01<00:00, 38.58it/s]\n",
      "2025-09-07 19:50:42,102 - INFO - epoch 159: val loss 0.05838277142632891\n",
      "2025-09-07 19:50:42,111 - INFO - 159 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:50:42,124 - INFO - 159 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:42,126 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:42,131 - INFO - --------------------\n",
      "\n",
      "160/800: 100%|██████████| 216/216 [00:05<00:00, 41.27it/s]\n",
      "2025-09-07 19:50:47,530 - INFO - All types `lr` of epoch 160: {'lr/param_group0': 0.00027421729424061787, 'lr/param_group1': 0.00027421729424061787, 'lr/param_group2': 0.00027421729424061787, 'lr/param_group3': 0.00027421729424061787}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:47,532 - INFO - epoch 160: train loss 0.05132765705800719\n",
      "2025-09-07 19:50:47,539 - INFO - 160 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:47,541 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:47,547 - INFO - --------------------\n",
      "\n",
      "161/800: 100%|██████████| 216/216 [00:04<00:00, 43.99it/s]\n",
      "2025-09-07 19:50:52,622 - INFO - All types `lr` of epoch 161: {'lr/param_group0': 0.000273904842224734, 'lr/param_group1': 0.000273904842224734, 'lr/param_group2': 0.000273904842224734, 'lr/param_group3': 0.000273904842224734}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:52,629 - INFO - epoch 161: train loss 0.05128435557708144\n",
      "2025-09-07 19:50:52,636 - INFO - 161 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:52,639 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:52,644 - INFO - --------------------\n",
      "\n",
      "162/800: 100%|██████████| 216/216 [00:05<00:00, 37.65it/s]\n",
      "2025-09-07 19:50:58,538 - INFO - All types `lr` of epoch 162: {'lr/param_group0': 0.0002735907107614614, 'lr/param_group1': 0.0002735907107614614, 'lr/param_group2': 0.0002735907107614614, 'lr/param_group3': 0.0002735907107614614}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:50:58,545 - INFO - epoch 162: train loss 0.05127935192582232\n",
      "2025-09-07 19:50:58,552 - INFO - 162 epochs completed!\n",
      "\n",
      "2025-09-07 19:50:58,555 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:50:58,560 - INFO - --------------------\n",
      "\n",
      "163/800: 100%|██████████| 216/216 [00:05<00:00, 40.20it/s]\n",
      "2025-09-07 19:51:04,095 - INFO - All types `lr` of epoch 163: {'lr/param_group0': 0.0002732749046950957, 'lr/param_group1': 0.0002732749046950957, 'lr/param_group2': 0.0002732749046950957, 'lr/param_group3': 0.0002732749046950957}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:04,103 - INFO - epoch 163: train loss 0.051374519088615976\n",
      "2025-09-07 19:51:04,110 - INFO - 163 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:04,113 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:04,117 - INFO - --------------------\n",
      "\n",
      "164/800: 100%|██████████| 216/216 [00:05<00:00, 37.37it/s]\n",
      "2025-09-07 19:51:10,060 - INFO - All types `lr` of epoch 164: {'lr/param_group0': 0.00027295742889575723, 'lr/param_group1': 0.00027295742889575723, 'lr/param_group2': 0.00027295742889575723, 'lr/param_group3': 0.00027295742889575723}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:10,068 - INFO - epoch 164: train loss 0.0510262539955201\n",
      "2025-09-07 19:51:10,071 - INFO - 164 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:10,077 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:10,081 - INFO - --------------------\n",
      "\n",
      "165/800: 100%|██████████| 216/216 [00:05<00:00, 37.59it/s]\n",
      "2025-09-07 19:51:15,990 - INFO - All types `lr` of epoch 165: {'lr/param_group0': 0.00027263828825931547, 'lr/param_group1': 0.00027263828825931547, 'lr/param_group2': 0.00027263828825931547, 'lr/param_group3': 0.00027263828825931547}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:15,997 - INFO - epoch 165: train loss 0.05102279045860524\n",
      "2025-09-07 19:51:16,003 - INFO - 165 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:16,005 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:16,010 - INFO - --------------------\n",
      "\n",
      "166/800: 100%|██████████| 216/216 [00:05<00:00, 37.42it/s]\n",
      "2025-09-07 19:51:21,945 - INFO - All types `lr` of epoch 166: {'lr/param_group0': 0.0002723174877073138, 'lr/param_group1': 0.0002723174877073138, 'lr/param_group2': 0.0002723174877073138, 'lr/param_group3': 0.0002723174877073138}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:21,953 - INFO - epoch 166: train loss 0.051320816217749206\n",
      "2025-09-07 19:51:21,959 - INFO - 166 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:21,962 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:21,967 - INFO - --------------------\n",
      "\n",
      "167/800: 100%|██████████| 216/216 [00:05<00:00, 37.57it/s]\n",
      "2025-09-07 19:51:27,881 - INFO - All types `lr` of epoch 167: {'lr/param_group0': 0.00027199503218689375, 'lr/param_group1': 0.00027199503218689375, 'lr/param_group2': 0.00027199503218689375, 'lr/param_group3': 0.00027199503218689375}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:27,888 - INFO - epoch 167: train loss 0.051163825344432284\n",
      "2025-09-07 19:51:27,895 - INFO - 167 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:27,898 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:27,903 - INFO - --------------------\n",
      "\n",
      "168/800: 100%|██████████| 216/216 [00:05<00:00, 38.19it/s]\n",
      "2025-09-07 19:51:33,729 - INFO - All types `lr` of epoch 168: {'lr/param_group0': 0.00027167092667071814, 'lr/param_group1': 0.00027167092667071814, 'lr/param_group2': 0.00027167092667071814, 'lr/param_group3': 0.00027167092667071814}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:33,732 - INFO - epoch 168: train loss 0.05096662499838405\n",
      "2025-09-07 19:51:33,739 - INFO - 168 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:33,744 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:33,746 - INFO - --------------------\n",
      "\n",
      "169/800: 100%|██████████| 216/216 [00:05<00:00, 36.68it/s]\n",
      "2025-09-07 19:51:39,797 - INFO - All types `lr` of epoch 169: {'lr/param_group0': 0.00027134517615689515, 'lr/param_group1': 0.00027134517615689515, 'lr/param_group2': 0.00027134517615689515, 'lr/param_group3': 0.00027134517615689515}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:39,804 - INFO - epoch 169: train loss 0.051354407626031724\n",
      "2025-09-07 19:51:39,807 - INFO - 169 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:39,813 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:39,818 - INFO - --------------------\n",
      "\n",
      "170/800: 100%|██████████| 216/216 [00:05<00:00, 37.29it/s]\n",
      "2025-09-07 19:51:45,774 - INFO - All types `lr` of epoch 170: {'lr/param_group0': 0.00027101778566890057, 'lr/param_group1': 0.00027101778566890057, 'lr/param_group2': 0.00027101778566890057, 'lr/param_group3': 0.00027101778566890057}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:45,777 - INFO - epoch 170: train loss 0.05067651651592718\n",
      "2025-09-07 19:51:45,784 - INFO - 170 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:45,790 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:45,792 - INFO - --------------------\n",
      "\n",
      "171/800: 100%|██████████| 216/216 [00:05<00:00, 41.99it/s]\n",
      "2025-09-07 19:51:51,103 - INFO - All types `lr` of epoch 171: {'lr/param_group0': 0.0002706887602555007, 'lr/param_group1': 0.0002706887602555007, 'lr/param_group2': 0.0002706887602555007, 'lr/param_group3': 0.0002706887602555007}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:51,106 - INFO - epoch 171: train loss 0.050666226677734544\n",
      "2025-09-07 19:51:51,113 - INFO - 171 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:51,118 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:51,120 - INFO - --------------------\n",
      "\n",
      "172/800: 100%|██████████| 216/216 [00:05<00:00, 37.36it/s]\n",
      "2025-09-07 19:51:57,066 - INFO - All types `lr` of epoch 172: {'lr/param_group0': 0.00027035810499067447, 'lr/param_group1': 0.00027035810499067447, 'lr/param_group2': 0.00027035810499067447, 'lr/param_group3': 0.00027035810499067447}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:51:57,074 - INFO - epoch 172: train loss 0.050586448378722976\n",
      "2025-09-07 19:51:57,076 - INFO - 172 epochs completed!\n",
      "\n",
      "2025-09-07 19:51:57,082 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:51:57,087 - INFO - --------------------\n",
      "\n",
      "173/800: 100%|██████████| 216/216 [00:05<00:00, 37.47it/s]\n",
      "2025-09-07 19:52:03,019 - INFO - All types `lr` of epoch 173: {'lr/param_group0': 0.00027002582497353514, 'lr/param_group1': 0.00027002582497353514, 'lr/param_group2': 0.00027002582497353514, 'lr/param_group3': 0.00027002582497353514}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:03,021 - INFO - epoch 173: train loss 0.05093924087230806\n",
      "2025-09-07 19:52:03,028 - INFO - 173 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:03,033 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:03,035 - INFO - --------------------\n",
      "\n",
      "174/800: 100%|██████████| 216/216 [00:05<00:00, 37.73it/s]\n",
      "2025-09-07 19:52:08,932 - INFO - All types `lr` of epoch 174: {'lr/param_group0': 0.00026969192532825165, 'lr/param_group1': 0.00026969192532825165, 'lr/param_group2': 0.00026969192532825165, 'lr/param_group3': 0.00026969192532825165}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:08,935 - INFO - epoch 174: train loss 0.050437841167742456\n",
      "2025-09-07 19:52:08,942 - INFO - 174 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:08,948 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:08,950 - INFO - --------------------\n",
      "\n",
      "175/800: 100%|██████████| 216/216 [00:05<00:00, 37.33it/s]\n",
      "2025-09-07 19:52:14,899 - INFO - All types `lr` of epoch 175: {'lr/param_group0': 0.0002693564112039695, 'lr/param_group1': 0.0002693564112039695, 'lr/param_group2': 0.0002693564112039695, 'lr/param_group3': 0.0002693564112039695}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:14,907 - INFO - epoch 175: train loss 0.050623617962830596\n",
      "2025-09-07 19:52:14,913 - INFO - 175 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:14,915 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:14,920 - INFO - --------------------\n",
      "\n",
      "176/800: 100%|██████████| 216/216 [00:05<00:00, 37.36it/s]\n",
      "2025-09-07 19:52:20,865 - INFO - All types `lr` of epoch 176: {'lr/param_group0': 0.0002690192877747315, 'lr/param_group1': 0.0002690192877747315, 'lr/param_group2': 0.0002690192877747315, 'lr/param_group3': 0.0002690192877747315}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:20,873 - INFO - epoch 176: train loss 0.05065281618455494\n",
      "2025-09-07 19:52:20,880 - INFO - 176 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:20,882 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:20,887 - INFO - --------------------\n",
      "\n",
      "177/800: 100%|██████████| 216/216 [00:05<00:00, 37.45it/s]\n",
      "2025-09-07 19:52:26,825 - INFO - All types `lr` of epoch 177: {'lr/param_group0': 0.0002686805602393981, 'lr/param_group1': 0.0002686805602393981, 'lr/param_group2': 0.0002686805602393981, 'lr/param_group3': 0.0002686805602393981}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:26,828 - INFO - epoch 177: train loss 0.05038857563502259\n",
      "2025-09-07 19:52:26,835 - INFO - 177 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:26,840 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:26,843 - INFO - --------------------\n",
      "\n",
      "178/800: 100%|██████████| 216/216 [00:05<00:00, 37.27it/s]\n",
      "2025-09-07 19:52:32,801 - INFO - All types `lr` of epoch 178: {'lr/param_group0': 0.00026834023382156687, 'lr/param_group1': 0.00026834023382156687, 'lr/param_group2': 0.00026834023382156687, 'lr/param_group3': 0.00026834023382156687}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:32,809 - INFO - epoch 178: train loss 0.05118924201707597\n",
      "2025-09-07 19:52:32,812 - INFO - 178 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:32,818 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:32,823 - INFO - --------------------\n",
      "\n",
      "179/800: 100%|██████████| 216/216 [00:05<00:00, 37.23it/s]\n",
      "2025-09-07 19:52:38,783 - INFO - All types `lr` of epoch 179: {'lr/param_group0': 0.00026799831376949214, 'lr/param_group1': 0.00026799831376949214, 'lr/param_group2': 0.00026799831376949214, 'lr/param_group3': 0.00026799831376949214}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:38,791 - INFO - epoch 179: train loss 0.0506812585345297\n",
      "2025-09-07 19:52:38,794 - INFO - 179 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:38,800 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:38,806 - INFO - --------------------\n",
      "\n",
      "180/800: 100%|██████████| 216/216 [00:05<00:00, 37.34it/s]\n",
      "2025-09-07 19:52:44,745 - INFO - All types `lr` of epoch 180: {'lr/param_group0': 0.00026765480535600414, 'lr/param_group1': 0.00026765480535600414, 'lr/param_group2': 0.00026765480535600414, 'lr/param_group3': 0.00026765480535600414}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:44,748 - INFO - epoch 180: train loss 0.05049051718648385\n",
      "2025-09-07 19:52:44,755 - INFO - 180 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:44,761 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:44,763 - INFO - --------------------\n",
      "\n",
      "181/800: 100%|██████████| 216/216 [00:05<00:00, 37.75it/s]\n",
      "2025-09-07 19:52:50,647 - INFO - All types `lr` of epoch 181: {'lr/param_group0': 0.00026730971387842753, 'lr/param_group1': 0.00026730971387842753, 'lr/param_group2': 0.00026730971387842753, 'lr/param_group3': 0.00026730971387842753}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:50,655 - INFO - epoch 181: train loss 0.05057272694453045\n",
      "2025-09-07 19:52:50,662 - INFO - 181 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:50,665 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:50,670 - INFO - --------------------\n",
      "\n",
      "182/800: 100%|██████████| 216/216 [00:05<00:00, 37.27it/s]\n",
      "2025-09-07 19:52:56,630 - INFO - All types `lr` of epoch 182: {'lr/param_group0': 0.00026696304465849977, 'lr/param_group1': 0.00026696304465849977, 'lr/param_group2': 0.00026696304465849977, 'lr/param_group3': 0.00026696304465849977}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:52:56,638 - INFO - epoch 182: train loss 0.05015643865421966\n",
      "2025-09-07 19:52:56,645 - INFO - 182 epochs completed!\n",
      "\n",
      "2025-09-07 19:52:56,648 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:52:56,653 - INFO - --------------------\n",
      "\n",
      "183/800: 100%|██████████| 216/216 [00:05<00:00, 36.95it/s]\n",
      "2025-09-07 19:53:02,668 - INFO - All types `lr` of epoch 183: {'lr/param_group0': 0.00026661480304228906, 'lr/param_group1': 0.00026661480304228906, 'lr/param_group2': 0.00026661480304228906, 'lr/param_group3': 0.00026661480304228906}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:02,671 - INFO - epoch 183: train loss 0.05104509390959585\n",
      "2025-09-07 19:53:02,678 - INFO - 183 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:02,684 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:02,686 - INFO - --------------------\n",
      "\n",
      "184/800: 100%|██████████| 216/216 [00:05<00:00, 36.92it/s]\n",
      "2025-09-07 19:53:08,702 - INFO - All types `lr` of epoch 184: {'lr/param_group0': 0.000266264994400112, 'lr/param_group1': 0.000266264994400112, 'lr/param_group2': 0.000266264994400112, 'lr/param_group3': 0.000266264994400112}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:08,711 - INFO - epoch 184: train loss 0.050911254784161294\n",
      "2025-09-07 19:53:08,718 - INFO - 184 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:08,720 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:08,725 - INFO - --------------------\n",
      "\n",
      "185/800: 100%|██████████| 216/216 [00:05<00:00, 37.16it/s]\n",
      "2025-09-07 19:53:14,704 - INFO - All types `lr` of epoch 185: {'lr/param_group0': 0.00026591362412645055, 'lr/param_group1': 0.00026591362412645055, 'lr/param_group2': 0.00026591362412645055, 'lr/param_group3': 0.00026591362412645055}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:14,712 - INFO - epoch 185: train loss 0.05016416801070726\n",
      "2025-09-07 19:53:14,715 - INFO - 185 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:14,722 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:14,727 - INFO - --------------------\n",
      "\n",
      "186/800: 100%|██████████| 216/216 [00:05<00:00, 36.97it/s]\n",
      "2025-09-07 19:53:20,732 - INFO - All types `lr` of epoch 186: {'lr/param_group0': 0.00026556069763986897, 'lr/param_group1': 0.00026556069763986897, 'lr/param_group2': 0.00026556069763986897, 'lr/param_group3': 0.00026556069763986897}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:20,740 - INFO - epoch 186: train loss 0.05027954433872192\n",
      "2025-09-07 19:53:20,748 - INFO - 186 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:20,750 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:20,755 - INFO - --------------------\n",
      "\n",
      "187/800: 100%|██████████| 216/216 [00:05<00:00, 36.83it/s]\n",
      "2025-09-07 19:53:26,787 - INFO - All types `lr` of epoch 187: {'lr/param_group0': 0.00026520622038293026, 'lr/param_group1': 0.00026520622038293026, 'lr/param_group2': 0.00026520622038293026, 'lr/param_group3': 0.00026520622038293026}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:26,794 - INFO - epoch 187: train loss 0.05052420231341212\n",
      "2025-09-07 19:53:26,802 - INFO - 187 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:26,804 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:26,809 - INFO - --------------------\n",
      "\n",
      "188/800: 100%|██████████| 216/216 [00:05<00:00, 36.67it/s]\n",
      "2025-09-07 19:53:32,870 - INFO - All types `lr` of epoch 188: {'lr/param_group0': 0.0002648501978221123, 'lr/param_group1': 0.0002648501978221123, 'lr/param_group2': 0.0002648501978221123, 'lr/param_group3': 0.0002648501978221123}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:32,873 - INFO - epoch 188: train loss 0.05028997779030491\n",
      "2025-09-07 19:53:32,880 - INFO - 188 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:32,886 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:32,888 - INFO - --------------------\n",
      "\n",
      "189/800: 100%|██████████| 216/216 [00:05<00:00, 36.46it/s]\n",
      "2025-09-07 19:53:38,983 - INFO - All types `lr` of epoch 189: {'lr/param_group0': 0.0002644926354477233, 'lr/param_group1': 0.0002644926354477233, 'lr/param_group2': 0.0002644926354477233, 'lr/param_group3': 0.0002644926354477233}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:38,986 - INFO - epoch 189: train loss 0.05044171793593301\n",
      "2025-09-07 19:53:38,993 - INFO - 189 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:39,000 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:39,002 - INFO - --------------------\n",
      "\n",
      "190/800: 100%|██████████| 216/216 [00:05<00:00, 36.96it/s]\n",
      "2025-09-07 19:53:45,013 - INFO - All types `lr` of epoch 190: {'lr/param_group0': 0.0002641335387738175, 'lr/param_group1': 0.0002641335387738175, 'lr/param_group2': 0.0002641335387738175, 'lr/param_group3': 0.0002641335387738175}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:45,016 - INFO - epoch 190: train loss 0.05056034540757537\n",
      "2025-09-07 19:53:45,023 - INFO - 190 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:45,029 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:45,031 - INFO - --------------------\n",
      "\n",
      "191/800: 100%|██████████| 216/216 [00:05<00:00, 36.91it/s]\n",
      "2025-09-07 19:53:51,048 - INFO - All types `lr` of epoch 191: {'lr/param_group0': 0.00026377291333810985, 'lr/param_group1': 0.00026377291333810985, 'lr/param_group2': 0.00026377291333810985, 'lr/param_group3': 0.00026377291333810985}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:51,057 - INFO - epoch 191: train loss 0.050066850458582245\n",
      "2025-09-07 19:53:51,064 - INFO - 191 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:51,066 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:51,072 - INFO - --------------------\n",
      "\n",
      "192/800: 100%|██████████| 216/216 [00:05<00:00, 36.78it/s]\n",
      "2025-09-07 19:53:57,116 - INFO - All types `lr` of epoch 192: {'lr/param_group0': 0.00026341076470189057, 'lr/param_group1': 0.00026341076470189057, 'lr/param_group2': 0.00026341076470189057, 'lr/param_group3': 0.00026341076470189057}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:53:57,118 - INFO - epoch 192: train loss 0.04990528058260679\n",
      "2025-09-07 19:53:57,125 - INFO - 192 epochs completed!\n",
      "\n",
      "2025-09-07 19:53:57,130 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:53:57,132 - INFO - --------------------\n",
      "\n",
      "193/800: 100%|██████████| 216/216 [00:05<00:00, 36.95it/s]\n",
      "2025-09-07 19:54:03,131 - INFO - All types `lr` of epoch 193: {'lr/param_group0': 0.00026304709844993964, 'lr/param_group1': 0.00026304709844993964, 'lr/param_group2': 0.00026304709844993964, 'lr/param_group3': 0.00026304709844993964}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:03,139 - INFO - epoch 193: train loss 0.05010838116760607\n",
      "2025-09-07 19:54:03,145 - INFO - 193 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:03,148 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:03,153 - INFO - --------------------\n",
      "\n",
      "194/800: 100%|██████████| 216/216 [00:05<00:00, 36.87it/s]\n",
      "2025-09-07 19:54:09,173 - INFO - All types `lr` of epoch 194: {'lr/param_group0': 0.0002626819201904406, 'lr/param_group1': 0.0002626819201904406, 'lr/param_group2': 0.0002626819201904406, 'lr/param_group3': 0.0002626819201904406}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:09,175 - INFO - epoch 194: train loss 0.05002503219509014\n",
      "2025-09-07 19:54:09,180 - INFO - 194 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:09,185 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:09,187 - INFO - --------------------\n",
      "\n",
      "195/800: 100%|██████████| 216/216 [00:05<00:00, 36.94it/s]\n",
      "2025-09-07 19:54:15,208 - INFO - All types `lr` of epoch 195: {'lr/param_group0': 0.000262315235554894, 'lr/param_group1': 0.000262315235554894, 'lr/param_group2': 0.000262315235554894, 'lr/param_group3': 0.000262315235554894}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:15,210 - INFO - epoch 195: train loss 0.04985000933003095\n",
      "2025-09-07 19:54:15,217 - INFO - 195 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:15,223 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:15,225 - INFO - --------------------\n",
      "\n",
      "196/800: 100%|██████████| 216/216 [00:05<00:00, 36.45it/s]\n",
      "2025-09-07 19:54:21,320 - INFO - All types `lr` of epoch 196: {'lr/param_group0': 0.00026194705019803047, 'lr/param_group1': 0.00026194705019803047, 'lr/param_group2': 0.00026194705019803047, 'lr/param_group3': 0.00026194705019803047}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:21,323 - INFO - epoch 196: train loss 0.05015905523948647\n",
      "2025-09-07 19:54:21,330 - INFO - 196 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:21,337 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:21,342 - INFO - --------------------\n",
      "\n",
      "197/800: 100%|██████████| 216/216 [00:05<00:00, 36.84it/s]\n",
      "2025-09-07 19:54:27,369 - INFO - All types `lr` of epoch 197: {'lr/param_group0': 0.00026157736979772367, 'lr/param_group1': 0.00026157736979772367, 'lr/param_group2': 0.00026157736979772367, 'lr/param_group3': 0.00026157736979772367}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:27,379 - INFO - epoch 197: train loss 0.050189700391557485\n",
      "2025-09-07 19:54:27,387 - INFO - 197 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:27,392 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:27,397 - INFO - --------------------\n",
      "\n",
      "198/800: 100%|██████████| 216/216 [00:05<00:00, 36.80it/s]\n",
      "2025-09-07 19:54:33,433 - INFO - All types `lr` of epoch 198: {'lr/param_group0': 0.0002612062000549027, 'lr/param_group1': 0.0002612062000549027, 'lr/param_group2': 0.0002612062000549027, 'lr/param_group3': 0.0002612062000549027}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:33,442 - INFO - epoch 198: train loss 0.050100821208346774\n",
      "2025-09-07 19:54:33,445 - INFO - 198 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:33,452 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:33,458 - INFO - --------------------\n",
      "\n",
      "199/800: 100%|██████████| 216/216 [00:05<00:00, 36.86it/s]\n",
      "2025-09-07 19:54:39,478 - INFO - All types `lr` of epoch 199: {'lr/param_group0': 0.0002608335466934642, 'lr/param_group1': 0.0002608335466934642, 'lr/param_group2': 0.0002608335466934642, 'lr/param_group3': 0.0002608335466934642}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:39,488 - INFO - epoch 199: train loss 0.04986616627623638\n",
      "100%|██████████| 54/54 [00:01<00:00, 38.53it/s]\n",
      "2025-09-07 19:54:41,058 - INFO - epoch 199: val loss 0.05794977251854208\n",
      "2025-09-07 19:54:41,067 - INFO - 199 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:54:41,172 - INFO - epoch 199 has been saved\n",
      "2025-09-07 19:54:41,431 - INFO - 199 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:41,440 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:41,443 - INFO - --------------------\n",
      "\n",
      "200/800: 100%|██████████| 216/216 [00:05<00:00, 37.46it/s]\n",
      "2025-09-07 19:54:47,386 - INFO - All types `lr` of epoch 200: {'lr/param_group0': 0.00026045941546018394, 'lr/param_group1': 0.00026045941546018394, 'lr/param_group2': 0.00026045941546018394, 'lr/param_group3': 0.00026045941546018394}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:47,389 - INFO - epoch 200: train loss 0.04970105030332451\n",
      "2025-09-07 19:54:47,397 - INFO - 200 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:47,403 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:47,405 - INFO - --------------------\n",
      "\n",
      "201/800: 100%|██████████| 216/216 [00:05<00:00, 36.53it/s]\n",
      "2025-09-07 19:54:53,489 - INFO - All types `lr` of epoch 201: {'lr/param_group0': 0.0002600838121246283, 'lr/param_group1': 0.0002600838121246283, 'lr/param_group2': 0.0002600838121246283, 'lr/param_group3': 0.0002600838121246283}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:53,492 - INFO - epoch 201: train loss 0.050049863255548256\n",
      "2025-09-07 19:54:53,499 - INFO - 201 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:53,506 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:53,508 - INFO - --------------------\n",
      "\n",
      "202/800: 100%|██████████| 216/216 [00:05<00:00, 36.42it/s]\n",
      "2025-09-07 19:54:59,610 - INFO - All types `lr` of epoch 202: {'lr/param_group0': 0.00025970674247906554, 'lr/param_group1': 0.00025970674247906554, 'lr/param_group2': 0.00025970674247906554, 'lr/param_group3': 0.00025970674247906554}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:54:59,614 - INFO - epoch 202: train loss 0.049770748139255576\n",
      "2025-09-07 19:54:59,620 - INFO - 202 epochs completed!\n",
      "\n",
      "2025-09-07 19:54:59,626 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:54:59,628 - INFO - --------------------\n",
      "\n",
      "203/800: 100%|██████████| 216/216 [00:05<00:00, 36.81it/s]\n",
      "2025-09-07 19:55:05,662 - INFO - All types `lr` of epoch 203: {'lr/param_group0': 0.00025932821233837585, 'lr/param_group1': 0.00025932821233837585, 'lr/param_group2': 0.00025932821233837585, 'lr/param_group3': 0.00025932821233837585}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:05,671 - INFO - epoch 203: train loss 0.04987892173920517\n",
      "2025-09-07 19:55:05,674 - INFO - 203 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:05,681 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:05,686 - INFO - --------------------\n",
      "\n",
      "204/800: 100%|██████████| 216/216 [00:05<00:00, 36.86it/s]\n",
      "2025-09-07 19:55:11,711 - INFO - All types `lr` of epoch 204: {'lr/param_group0': 0.0002589482275399624, 'lr/param_group1': 0.0002589482275399624, 'lr/param_group2': 0.0002589482275399624, 'lr/param_group3': 0.0002589482275399624}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:11,719 - INFO - epoch 204: train loss 0.04970332498972615\n",
      "2025-09-07 19:55:11,723 - INFO - 204 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:11,729 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:11,735 - INFO - --------------------\n",
      "\n",
      "205/800: 100%|██████████| 216/216 [00:05<00:00, 37.00it/s]\n",
      "2025-09-07 19:55:17,742 - INFO - All types `lr` of epoch 205: {'lr/param_group0': 0.0002585667939436608, 'lr/param_group1': 0.0002585667939436608, 'lr/param_group2': 0.0002585667939436608, 'lr/param_group3': 0.0002585667939436608}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:17,745 - INFO - epoch 205: train loss 0.050076773010746194\n",
      "2025-09-07 19:55:17,752 - INFO - 205 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:17,759 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:17,761 - INFO - --------------------\n",
      "\n",
      "206/800: 100%|██████████| 216/216 [00:05<00:00, 36.58it/s]\n",
      "2025-09-07 19:55:23,831 - INFO - All types `lr` of epoch 206: {'lr/param_group0': 0.000258183917431649, 'lr/param_group1': 0.000258183917431649, 'lr/param_group2': 0.000258183917431649, 'lr/param_group3': 0.000258183917431649}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:23,840 - INFO - epoch 206: train loss 0.050230499167271236\n",
      "2025-09-07 19:55:23,843 - INFO - 206 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:23,850 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:23,856 - INFO - --------------------\n",
      "\n",
      "207/800: 100%|██████████| 216/216 [00:05<00:00, 41.63it/s]\n",
      "2025-09-07 19:55:29,209 - INFO - All types `lr` of epoch 207: {'lr/param_group0': 0.0002577996039083564, 'lr/param_group1': 0.0002577996039083564, 'lr/param_group2': 0.0002577996039083564, 'lr/param_group3': 0.0002577996039083564}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:29,217 - INFO - epoch 207: train loss 0.04971075435686442\n",
      "2025-09-07 19:55:29,224 - INFO - 207 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:29,227 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:29,232 - INFO - --------------------\n",
      "\n",
      "208/800: 100%|██████████| 216/216 [00:05<00:00, 36.94it/s]\n",
      "2025-09-07 19:55:35,254 - INFO - All types `lr` of epoch 208: {'lr/param_group0': 0.00025741385930037295, 'lr/param_group1': 0.00025741385930037295, 'lr/param_group2': 0.00025741385930037295, 'lr/param_group3': 0.00025741385930037295}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:35,257 - INFO - epoch 208: train loss 0.04987552789626298\n",
      "2025-09-07 19:55:35,264 - INFO - 208 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:35,271 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:35,273 - INFO - --------------------\n",
      "\n",
      "209/800: 100%|██████████| 216/216 [00:05<00:00, 36.55it/s]\n",
      "2025-09-07 19:55:41,351 - INFO - All types `lr` of epoch 209: {'lr/param_group0': 0.00025702668955635775, 'lr/param_group1': 0.00025702668955635775, 'lr/param_group2': 0.00025702668955635775, 'lr/param_group3': 0.00025702668955635775}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:41,360 - INFO - epoch 209: train loss 0.049477063895513616\n",
      "2025-09-07 19:55:41,363 - INFO - 209 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:41,370 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:41,377 - INFO - --------------------\n",
      "\n",
      "210/800: 100%|██████████| 216/216 [00:05<00:00, 36.88it/s]\n",
      "2025-09-07 19:55:47,404 - INFO - All types `lr` of epoch 210: {'lr/param_group0': 0.0002566381006469471, 'lr/param_group1': 0.0002566381006469471, 'lr/param_group2': 0.0002566381006469471, 'lr/param_group3': 0.0002566381006469471}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:47,408 - INFO - epoch 210: train loss 0.049876877917321746\n",
      "2025-09-07 19:55:47,415 - INFO - 210 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:47,422 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:47,424 - INFO - --------------------\n",
      "\n",
      "211/800: 100%|██████████| 216/216 [00:05<00:00, 36.58it/s]\n",
      "2025-09-07 19:55:53,502 - INFO - All types `lr` of epoch 211: {'lr/param_group0': 0.0002562480985646628, 'lr/param_group1': 0.0002562480985646628, 'lr/param_group2': 0.0002562480985646628, 'lr/param_group3': 0.0002562480985646628}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:53,505 - INFO - epoch 211: train loss 0.04962394886684639\n",
      "2025-09-07 19:55:53,513 - INFO - 211 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:53,519 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:53,521 - INFO - --------------------\n",
      "\n",
      "212/800: 100%|██████████| 216/216 [00:05<00:00, 36.67it/s]\n",
      "2025-09-07 19:55:59,578 - INFO - All types `lr` of epoch 212: {'lr/param_group0': 0.0002558566893238194, 'lr/param_group1': 0.0002558566893238194, 'lr/param_group2': 0.0002558566893238194, 'lr/param_group3': 0.0002558566893238194}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:55:59,587 - INFO - epoch 212: train loss 0.049908922985196114\n",
      "2025-09-07 19:55:59,594 - INFO - 212 epochs completed!\n",
      "\n",
      "2025-09-07 19:55:59,597 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:55:59,603 - INFO - --------------------\n",
      "\n",
      "213/800: 100%|██████████| 216/216 [00:04<00:00, 45.08it/s]\n",
      "2025-09-07 19:56:04,561 - INFO - All types `lr` of epoch 213: {'lr/param_group0': 0.0002554638789604315, 'lr/param_group1': 0.0002554638789604315, 'lr/param_group2': 0.0002554638789604315, 'lr/param_group3': 0.0002554638789604315}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:04,571 - INFO - epoch 213: train loss 0.04941128216752851\n",
      "2025-09-07 19:56:04,574 - INFO - 213 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:04,580 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:04,586 - INFO - --------------------\n",
      "\n",
      "214/800: 100%|██████████| 216/216 [00:05<00:00, 37.18it/s]\n",
      "2025-09-07 19:56:10,559 - INFO - All types `lr` of epoch 214: {'lr/param_group0': 0.00025506967353212094, 'lr/param_group1': 0.00025506967353212094, 'lr/param_group2': 0.00025506967353212094, 'lr/param_group3': 0.00025506967353212094}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:10,568 - INFO - epoch 214: train loss 0.049258550784240164\n",
      "2025-09-07 19:56:10,576 - INFO - 214 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:10,579 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:10,584 - INFO - --------------------\n",
      "\n",
      "215/800: 100%|██████████| 216/216 [00:05<00:00, 36.89it/s]\n",
      "2025-09-07 19:56:16,609 - INFO - All types `lr` of epoch 215: {'lr/param_group0': 0.000254674079118023, 'lr/param_group1': 0.000254674079118023, 'lr/param_group2': 0.000254674079118023, 'lr/param_group3': 0.000254674079118023}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:16,618 - INFO - epoch 215: train loss 0.04962200799060089\n",
      "2025-09-07 19:56:16,627 - INFO - 215 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:16,629 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:16,635 - INFO - --------------------\n",
      "\n",
      "216/800: 100%|██████████| 216/216 [00:05<00:00, 37.70it/s]\n",
      "2025-09-07 19:56:22,534 - INFO - All types `lr` of epoch 216: {'lr/param_group0': 0.000254277101818693, 'lr/param_group1': 0.000254277101818693, 'lr/param_group2': 0.000254277101818693, 'lr/param_group3': 0.000254277101818693}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:22,543 - INFO - epoch 216: train loss 0.04914777586236596\n",
      "2025-09-07 19:56:22,551 - INFO - 216 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:22,553 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:22,559 - INFO - --------------------\n",
      "\n",
      "217/800: 100%|██████████| 216/216 [00:05<00:00, 36.75it/s]\n",
      "2025-09-07 19:56:28,608 - INFO - All types `lr` of epoch 217: {'lr/param_group0': 0.00025387874775601187, 'lr/param_group1': 0.00025387874775601187, 'lr/param_group2': 0.00025387874775601187, 'lr/param_group3': 0.00025387874775601187}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:28,617 - INFO - epoch 217: train loss 0.04904010134783608\n",
      "2025-09-07 19:56:28,625 - INFO - 217 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:28,628 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:28,634 - INFO - --------------------\n",
      "\n",
      "218/800: 100%|██████████| 216/216 [00:05<00:00, 36.82it/s]\n",
      "2025-09-07 19:56:34,673 - INFO - All types `lr` of epoch 218: {'lr/param_group0': 0.0002534790230730922, 'lr/param_group1': 0.0002534790230730922, 'lr/param_group2': 0.0002534790230730922, 'lr/param_group3': 0.0002534790230730922}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:34,682 - INFO - epoch 218: train loss 0.049141694170733295\n",
      "2025-09-07 19:56:34,685 - INFO - 218 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:34,692 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:34,698 - INFO - --------------------\n",
      "\n",
      "219/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 19:56:40,759 - INFO - All types `lr` of epoch 219: {'lr/param_group0': 0.0002530779339341829, 'lr/param_group1': 0.0002530779339341829, 'lr/param_group2': 0.0002530779339341829, 'lr/param_group3': 0.0002530779339341829}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:40,768 - INFO - epoch 219: train loss 0.04933044485126933\n",
      "2025-09-07 19:56:40,776 - INFO - 219 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:40,778 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:40,784 - INFO - --------------------\n",
      "\n",
      "220/800: 100%|██████████| 216/216 [00:05<00:00, 37.39it/s]\n",
      "2025-09-07 19:56:46,728 - INFO - All types `lr` of epoch 220: {'lr/param_group0': 0.0002526754865245748, 'lr/param_group1': 0.0002526754865245748, 'lr/param_group2': 0.0002526754865245748, 'lr/param_group3': 0.0002526754865245748}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:46,737 - INFO - epoch 220: train loss 0.049906573361820646\n",
      "2025-09-07 19:56:46,740 - INFO - 220 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:46,747 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:46,753 - INFO - --------------------\n",
      "\n",
      "221/800: 100%|██████████| 216/216 [00:05<00:00, 36.83it/s]\n",
      "2025-09-07 19:56:52,786 - INFO - All types `lr` of epoch 221: {'lr/param_group0': 0.0002522716870505047, 'lr/param_group1': 0.0002522716870505047, 'lr/param_group2': 0.0002522716870505047, 'lr/param_group3': 0.0002522716870505047}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:52,789 - INFO - epoch 221: train loss 0.04945004222638629\n",
      "2025-09-07 19:56:52,798 - INFO - 221 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:52,804 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:52,807 - INFO - --------------------\n",
      "\n",
      "222/800: 100%|██████████| 216/216 [00:05<00:00, 36.55it/s]\n",
      "2025-09-07 19:56:58,880 - INFO - All types `lr` of epoch 222: {'lr/param_group0': 0.00025186654173906014, 'lr/param_group1': 0.00025186654173906014, 'lr/param_group2': 0.00025186654173906014, 'lr/param_group3': 0.00025186654173906014}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:56:58,889 - INFO - epoch 222: train loss 0.04928184298936416\n",
      "2025-09-07 19:56:58,893 - INFO - 222 epochs completed!\n",
      "\n",
      "2025-09-07 19:56:58,900 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:56:58,905 - INFO - --------------------\n",
      "\n",
      "223/800: 100%|██████████| 216/216 [00:05<00:00, 36.69it/s]\n",
      "2025-09-07 19:57:04,960 - INFO - All types `lr` of epoch 223: {'lr/param_group0': 0.0002514600568380829, 'lr/param_group1': 0.0002514600568380829, 'lr/param_group2': 0.0002514600568380829, 'lr/param_group3': 0.0002514600568380829}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:04,964 - INFO - epoch 223: train loss 0.04909838094479508\n",
      "2025-09-07 19:57:04,971 - INFO - 223 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:04,977 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:04,980 - INFO - --------------------\n",
      "\n",
      "224/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 19:57:11,045 - INFO - All types `lr` of epoch 224: {'lr/param_group0': 0.00025105223861607306, 'lr/param_group1': 0.00025105223861607306, 'lr/param_group2': 0.00025105223861607306, 'lr/param_group3': 0.00025105223861607306}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:11,054 - INFO - epoch 224: train loss 0.04927981600027393\n",
      "2025-09-07 19:57:11,058 - INFO - 224 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:11,064 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:11,070 - INFO - --------------------\n",
      "\n",
      "225/800: 100%|██████████| 216/216 [00:05<00:00, 36.83it/s]\n",
      "2025-09-07 19:57:17,099 - INFO - All types `lr` of epoch 225: {'lr/param_group0': 0.00025064309336209214, 'lr/param_group1': 0.00025064309336209214, 'lr/param_group2': 0.00025064309336209214, 'lr/param_group3': 0.00025064309336209214}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:17,108 - INFO - epoch 225: train loss 0.049080750059888316\n",
      "2025-09-07 19:57:17,111 - INFO - 225 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:17,118 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:17,123 - INFO - --------------------\n",
      "\n",
      "226/800: 100%|██████████| 216/216 [00:05<00:00, 36.76it/s]\n",
      "2025-09-07 19:57:23,153 - INFO - All types `lr` of epoch 226: {'lr/param_group0': 0.00025023262738566596, 'lr/param_group1': 0.00025023262738566596, 'lr/param_group2': 0.00025023262738566596, 'lr/param_group3': 0.00025023262738566596}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:23,162 - INFO - epoch 226: train loss 0.04937332213200905\n",
      "2025-09-07 19:57:23,164 - INFO - 226 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:23,171 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:23,177 - INFO - --------------------\n",
      "\n",
      "227/800: 100%|██████████| 216/216 [00:05<00:00, 36.79it/s]\n",
      "2025-09-07 19:57:29,204 - INFO - All types `lr` of epoch 227: {'lr/param_group0': 0.0002498208470166878, 'lr/param_group1': 0.0002498208470166878, 'lr/param_group2': 0.0002498208470166878, 'lr/param_group3': 0.0002498208470166878}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:29,213 - INFO - epoch 227: train loss 0.04935515897900418\n",
      "2025-09-07 19:57:29,221 - INFO - 227 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:29,227 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:29,232 - INFO - --------------------\n",
      "\n",
      "228/800: 100%|██████████| 216/216 [00:05<00:00, 37.05it/s]\n",
      "2025-09-07 19:57:35,225 - INFO - All types `lr` of epoch 228: {'lr/param_group0': 0.0002494077586053202, 'lr/param_group1': 0.0002494077586053202, 'lr/param_group2': 0.0002494077586053202, 'lr/param_group3': 0.0002494077586053202}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:35,227 - INFO - epoch 228: train loss 0.049132694179813065\n",
      "2025-09-07 19:57:35,235 - INFO - 228 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:35,237 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:35,241 - INFO - --------------------\n",
      "\n",
      "229/800: 100%|██████████| 216/216 [00:05<00:00, 36.88it/s]\n",
      "2025-09-07 19:57:41,258 - INFO - All types `lr` of epoch 229: {'lr/param_group0': 0.00024899336852189755, 'lr/param_group1': 0.00024899336852189755, 'lr/param_group2': 0.00024899336852189755, 'lr/param_group3': 0.00024899336852189755}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:41,269 - INFO - epoch 229: train loss 0.04904952712564005\n",
      "2025-09-07 19:57:41,277 - INFO - 229 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:41,283 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:41,288 - INFO - --------------------\n",
      "\n",
      "230/800: 100%|██████████| 216/216 [00:05<00:00, 36.44it/s]\n",
      "2025-09-07 19:57:47,385 - INFO - All types `lr` of epoch 230: {'lr/param_group0': 0.0002485776831568276, 'lr/param_group1': 0.0002485776831568276, 'lr/param_group2': 0.0002485776831568276, 'lr/param_group3': 0.0002485776831568276}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:47,396 - INFO - epoch 230: train loss 0.04906520889037185\n",
      "2025-09-07 19:57:47,404 - INFO - 230 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:47,410 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:47,415 - INFO - --------------------\n",
      "\n",
      "231/800: 100%|██████████| 216/216 [00:05<00:00, 36.71it/s]\n",
      "2025-09-07 19:57:53,475 - INFO - All types `lr` of epoch 231: {'lr/param_group0': 0.0002481607089204928, 'lr/param_group1': 0.0002481607089204928, 'lr/param_group2': 0.0002481607089204928, 'lr/param_group3': 0.0002481607089204928}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:53,478 - INFO - epoch 231: train loss 0.04907477812634574\n",
      "2025-09-07 19:57:53,485 - INFO - 231 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:53,487 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:53,492 - INFO - --------------------\n",
      "\n",
      "232/800: 100%|██████████| 216/216 [00:05<00:00, 37.02it/s]\n",
      "2025-09-07 19:57:59,505 - INFO - All types `lr` of epoch 232: {'lr/param_group0': 0.0002477424522431518, 'lr/param_group1': 0.0002477424522431518, 'lr/param_group2': 0.0002477424522431518, 'lr/param_group3': 0.0002477424522431518}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:57:59,508 - INFO - epoch 232: train loss 0.04938589051986734\n",
      "2025-09-07 19:57:59,516 - INFO - 232 epochs completed!\n",
      "\n",
      "2025-09-07 19:57:59,518 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:57:59,524 - INFO - --------------------\n",
      "\n",
      "233/800: 100%|██████████| 216/216 [00:06<00:00, 35.11it/s]\n",
      "2025-09-07 19:58:05,878 - INFO - All types `lr` of epoch 233: {'lr/param_group0': 0.00024732291957483996, 'lr/param_group1': 0.00024732291957483996, 'lr/param_group2': 0.00024732291957483996, 'lr/param_group3': 0.00024732291957483996}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:05,887 - INFO - epoch 233: train loss 0.04917097914343079\n",
      "2025-09-07 19:58:05,894 - INFO - 233 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:05,897 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:05,902 - INFO - --------------------\n",
      "\n",
      "234/800: 100%|██████████| 216/216 [00:05<00:00, 37.17it/s]\n",
      "2025-09-07 19:58:11,873 - INFO - All types `lr` of epoch 234: {'lr/param_group0': 0.0002469021173852699, 'lr/param_group1': 0.0002469021173852699, 'lr/param_group2': 0.0002469021173852699, 'lr/param_group3': 0.0002469021173852699}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:11,882 - INFO - epoch 234: train loss 0.048956561005777784\n",
      "2025-09-07 19:58:11,886 - INFO - 234 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:11,893 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:11,899 - INFO - --------------------\n",
      "\n",
      "235/800: 100%|██████████| 216/216 [00:05<00:00, 38.17it/s]\n",
      "2025-09-07 19:58:17,728 - INFO - All types `lr` of epoch 235: {'lr/param_group0': 0.0002464800521637321, 'lr/param_group1': 0.0002464800521637321, 'lr/param_group2': 0.0002464800521637321, 'lr/param_group3': 0.0002464800521637321}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:17,737 - INFO - epoch 235: train loss 0.048859888342795546\n",
      "2025-09-07 19:58:17,744 - INFO - 235 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:17,747 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:17,752 - INFO - --------------------\n",
      "\n",
      "236/800: 100%|██████████| 216/216 [00:05<00:00, 36.51it/s]\n",
      "2025-09-07 19:58:23,838 - INFO - All types `lr` of epoch 236: {'lr/param_group0': 0.0002460567304189943, 'lr/param_group1': 0.0002460567304189943, 'lr/param_group2': 0.0002460567304189943, 'lr/param_group3': 0.0002460567304189943}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:23,848 - INFO - epoch 236: train loss 0.04933073975283791\n",
      "2025-09-07 19:58:23,856 - INFO - 236 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:23,859 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:23,864 - INFO - --------------------\n",
      "\n",
      "237/800: 100%|██████████| 216/216 [00:05<00:00, 36.69it/s]\n",
      "2025-09-07 19:58:29,927 - INFO - All types `lr` of epoch 237: {'lr/param_group0': 0.00024563215867920153, 'lr/param_group1': 0.00024563215867920153, 'lr/param_group2': 0.00024563215867920153, 'lr/param_group3': 0.00024563215867920153}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:29,930 - INFO - epoch 237: train loss 0.04883809696400055\n",
      "2025-09-07 19:58:29,936 - INFO - 237 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:29,942 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:29,944 - INFO - --------------------\n",
      "\n",
      "238/800: 100%|██████████| 216/216 [00:05<00:00, 36.53it/s]\n",
      "2025-09-07 19:58:36,037 - INFO - All types `lr` of epoch 238: {'lr/param_group0': 0.0002452063434917752, 'lr/param_group1': 0.0002452063434917752, 'lr/param_group2': 0.0002452063434917752, 'lr/param_group3': 0.0002452063434917752}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:36,040 - INFO - epoch 238: train loss 0.048962763872825436\n",
      "2025-09-07 19:58:36,047 - INFO - 238 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:36,053 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:36,055 - INFO - --------------------\n",
      "\n",
      "239/800: 100%|██████████| 216/216 [00:05<00:00, 38.38it/s]\n",
      "2025-09-07 19:58:41,850 - INFO - All types `lr` of epoch 239: {'lr/param_group0': 0.0002447792914233122, 'lr/param_group1': 0.0002447792914233122, 'lr/param_group2': 0.0002447792914233122, 'lr/param_group3': 0.0002447792914233122}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:41,859 - INFO - epoch 239: train loss 0.04885093070980576\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.66it/s]\n",
      "2025-09-07 19:58:43,328 - INFO - epoch 239: val loss 0.05829288120622988\n",
      "2025-09-07 19:58:43,339 - INFO - 239 epoch vae reconstruct images complete!\n",
      "2025-09-07 19:58:43,352 - INFO - 239 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:43,354 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:43,360 - INFO - --------------------\n",
      "\n",
      "240/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 19:58:49,478 - INFO - All types `lr` of epoch 240: {'lr/param_group0': 0.00024435100905948387, 'lr/param_group1': 0.00024435100905948387, 'lr/param_group2': 0.00024435100905948387, 'lr/param_group3': 0.00024435100905948387}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:49,488 - INFO - epoch 240: train loss 0.04870186749569796\n",
      "2025-09-07 19:58:49,495 - INFO - 240 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:49,498 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:49,503 - INFO - --------------------\n",
      "\n",
      "241/800: 100%|██████████| 216/216 [00:05<00:00, 36.48it/s]\n",
      "2025-09-07 19:58:55,605 - INFO - All types `lr` of epoch 241: {'lr/param_group0': 0.0002439215030049339, 'lr/param_group1': 0.0002439215030049339, 'lr/param_group2': 0.0002439215030049339, 'lr/param_group3': 0.0002439215030049339}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:58:55,608 - INFO - epoch 241: train loss 0.04870876587099499\n",
      "2025-09-07 19:58:55,616 - INFO - 241 epochs completed!\n",
      "\n",
      "2025-09-07 19:58:55,623 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:58:55,625 - INFO - --------------------\n",
      "\n",
      "242/800: 100%|██████████| 216/216 [00:05<00:00, 37.36it/s]\n",
      "2025-09-07 19:59:01,575 - INFO - All types `lr` of epoch 242: {'lr/param_group0': 0.00024349077988317712, 'lr/param_group1': 0.00024349077988317712, 'lr/param_group2': 0.00024349077988317712, 'lr/param_group3': 0.00024349077988317712}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:01,585 - INFO - epoch 242: train loss 0.048592062322077925\n",
      "2025-09-07 19:59:01,588 - INFO - 242 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:01,594 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:01,600 - INFO - --------------------\n",
      "\n",
      "243/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 19:59:07,753 - INFO - All types `lr` of epoch 243: {'lr/param_group0': 0.0002430588463364968, 'lr/param_group1': 0.0002430588463364968, 'lr/param_group2': 0.0002430588463364968, 'lr/param_group3': 0.0002430588463364968}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:07,763 - INFO - epoch 243: train loss 0.04875051161205327\n",
      "2025-09-07 19:59:07,766 - INFO - 243 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:07,773 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:07,779 - INFO - --------------------\n",
      "\n",
      "244/800: 100%|██████████| 216/216 [00:05<00:00, 36.76it/s]\n",
      "2025-09-07 19:59:13,826 - INFO - All types `lr` of epoch 244: {'lr/param_group0': 0.00024262570902584257, 'lr/param_group1': 0.00024262570902584257, 'lr/param_group2': 0.00024262570902584257, 'lr/param_group3': 0.00024262570902584257}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:13,829 - INFO - epoch 244: train loss 0.04881211268474107\n",
      "2025-09-07 19:59:13,837 - INFO - 244 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:13,843 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:13,845 - INFO - --------------------\n",
      "\n",
      "245/800: 100%|██████████| 216/216 [00:05<00:00, 36.52it/s]\n",
      "2025-09-07 19:59:19,932 - INFO - All types `lr` of epoch 245: {'lr/param_group0': 0.00024219137463072764, 'lr/param_group1': 0.00024219137463072764, 'lr/param_group2': 0.00024219137463072764, 'lr/param_group3': 0.00024219137463072764}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:19,942 - INFO - epoch 245: train loss 0.04910416219866386\n",
      "2025-09-07 19:59:19,945 - INFO - 245 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:19,952 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:19,954 - INFO - --------------------\n",
      "\n",
      "246/800: 100%|██████████| 216/216 [00:05<00:00, 39.53it/s]\n",
      "2025-09-07 19:59:25,591 - INFO - All types `lr` of epoch 246: {'lr/param_group0': 0.00024175584984912563, 'lr/param_group1': 0.00024175584984912563, 'lr/param_group2': 0.00024175584984912563, 'lr/param_group3': 0.00024175584984912563}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:25,601 - INFO - epoch 246: train loss 0.049224341150235246\n",
      "2025-09-07 19:59:25,605 - INFO - 246 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:25,611 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:25,618 - INFO - --------------------\n",
      "\n",
      "247/800: 100%|██████████| 216/216 [00:05<00:00, 36.44it/s]\n",
      "2025-09-07 19:59:31,713 - INFO - All types `lr` of epoch 247: {'lr/param_group0': 0.00024131914139736743, 'lr/param_group1': 0.00024131914139736743, 'lr/param_group2': 0.00024131914139736743, 'lr/param_group3': 0.00024131914139736743}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:31,722 - INFO - epoch 247: train loss 0.048636061812026635\n",
      "2025-09-07 19:59:31,725 - INFO - 247 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:31,732 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:31,738 - INFO - --------------------\n",
      "\n",
      "248/800: 100%|██████████| 216/216 [00:05<00:00, 36.62it/s]\n",
      "2025-09-07 19:59:37,807 - INFO - All types `lr` of epoch 248: {'lr/param_group0': 0.0002408812560100376, 'lr/param_group1': 0.0002408812560100376, 'lr/param_group2': 0.0002408812560100376, 'lr/param_group3': 0.0002408812560100376}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:37,816 - INFO - epoch 248: train loss 0.048573405067953795\n",
      "2025-09-07 19:59:37,825 - INFO - 248 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:37,831 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:37,837 - INFO - --------------------\n",
      "\n",
      "249/800: 100%|██████████| 216/216 [00:05<00:00, 36.86it/s]\n",
      "2025-09-07 19:59:43,866 - INFO - All types `lr` of epoch 249: {'lr/param_group0': 0.00024044220043987057, 'lr/param_group1': 0.00024044220043987057, 'lr/param_group2': 0.00024044220043987057, 'lr/param_group3': 0.00024044220043987057}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:43,876 - INFO - epoch 249: train loss 0.048639951911927375\n",
      "2025-09-07 19:59:43,879 - INFO - 249 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:43,886 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:43,888 - INFO - --------------------\n",
      "\n",
      "250/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 19:59:50,013 - INFO - All types `lr` of epoch 250: {'lr/param_group0': 0.0002400019814576463, 'lr/param_group1': 0.0002400019814576463, 'lr/param_group2': 0.0002400019814576463, 'lr/param_group3': 0.0002400019814576463}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:50,017 - INFO - epoch 250: train loss 0.048718861821624965\n",
      "2025-09-07 19:59:50,025 - INFO - 250 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:50,027 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:50,033 - INFO - --------------------\n",
      "\n",
      "251/800: 100%|██████████| 216/216 [00:05<00:00, 36.57it/s]\n",
      "2025-09-07 19:59:56,120 - INFO - All types `lr` of epoch 251: {'lr/param_group0': 0.00023956060585208607, 'lr/param_group1': 0.00023956060585208607, 'lr/param_group2': 0.00023956060585208607, 'lr/param_group3': 0.00023956060585208607}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 19:59:56,123 - INFO - epoch 251: train loss 0.048667959937894786\n",
      "2025-09-07 19:59:56,130 - INFO - 251 epochs completed!\n",
      "\n",
      "2025-09-07 19:59:56,132 - INFO - --------------------\n",
      "\n",
      "2025-09-07 19:59:56,137 - INFO - --------------------\n",
      "\n",
      "252/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 20:00:02,265 - INFO - All types `lr` of epoch 252: {'lr/param_group0': 0.00023911808042974774, 'lr/param_group1': 0.00023911808042974774, 'lr/param_group2': 0.00023911808042974774, 'lr/param_group3': 0.00023911808042974774}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:02,272 - INFO - epoch 252: train loss 0.048264955153205884\n",
      "2025-09-07 20:00:02,279 - INFO - 252 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:02,282 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:02,287 - INFO - --------------------\n",
      "\n",
      "253/800: 100%|██████████| 216/216 [00:05<00:00, 36.44it/s]\n",
      "2025-09-07 20:00:08,380 - INFO - All types `lr` of epoch 253: {'lr/param_group0': 0.00023867441201492082, 'lr/param_group1': 0.00023867441201492082, 'lr/param_group2': 0.00023867441201492082, 'lr/param_group3': 0.00023867441201492082}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:08,387 - INFO - epoch 253: train loss 0.04815230820396984\n",
      "2025-09-07 20:00:08,390 - INFO - 253 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:08,398 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:08,406 - INFO - --------------------\n",
      "\n",
      "254/800: 100%|██████████| 216/216 [00:05<00:00, 36.84it/s]\n",
      "2025-09-07 20:00:14,446 - INFO - All types `lr` of epoch 254: {'lr/param_group0': 0.000238229607449521, 'lr/param_group1': 0.000238229607449521, 'lr/param_group2': 0.000238229607449521, 'lr/param_group3': 0.000238229607449521}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:14,449 - INFO - epoch 254: train loss 0.048411482738124\n",
      "2025-09-07 20:00:14,457 - INFO - 254 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:14,463 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:14,466 - INFO - --------------------\n",
      "\n",
      "255/800: 100%|██████████| 216/216 [00:05<00:00, 36.41it/s]\n",
      "2025-09-07 20:00:20,577 - INFO - All types `lr` of epoch 255: {'lr/param_group0': 0.00023778367359298498, 'lr/param_group1': 0.00023778367359298498, 'lr/param_group2': 0.00023778367359298498, 'lr/param_group3': 0.00023778367359298498}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:20,580 - INFO - epoch 255: train loss 0.04879683645925036\n",
      "2025-09-07 20:00:20,588 - INFO - 255 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:20,595 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:20,597 - INFO - --------------------\n",
      "\n",
      "256/800: 100%|██████████| 216/216 [00:05<00:00, 36.46it/s]\n",
      "2025-09-07 20:00:26,700 - INFO - All types `lr` of epoch 256: {'lr/param_group0': 0.00023733661732216452, 'lr/param_group1': 0.00023733661732216452, 'lr/param_group2': 0.00023733661732216452, 'lr/param_group3': 0.00023733661732216452}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:26,704 - INFO - epoch 256: train loss 0.04853627734162189\n",
      "2025-09-07 20:00:26,711 - INFO - 256 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:26,718 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:26,721 - INFO - --------------------\n",
      "\n",
      "257/800: 100%|██████████| 216/216 [00:05<00:00, 36.54it/s]\n",
      "2025-09-07 20:00:32,807 - INFO - All types `lr` of epoch 257: {'lr/param_group0': 0.00023688844553122027, 'lr/param_group1': 0.00023688844553122027, 'lr/param_group2': 0.00023688844553122027, 'lr/param_group3': 0.00023688844553122027}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:32,818 - INFO - epoch 257: train loss 0.048158558240781225\n",
      "2025-09-07 20:00:32,821 - INFO - 257 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:32,828 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:32,834 - INFO - --------------------\n",
      "\n",
      "258/800: 100%|██████████| 216/216 [00:06<00:00, 32.99it/s]\n",
      "2025-09-07 20:00:39,543 - INFO - All types `lr` of epoch 258: {'lr/param_group0': 0.0002364391651315157, 'lr/param_group1': 0.0002364391651315157, 'lr/param_group2': 0.0002364391651315157, 'lr/param_group3': 0.0002364391651315157}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:39,548 - INFO - epoch 258: train loss 0.04825991171377676\n",
      "2025-09-07 20:00:39,551 - INFO - 258 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:39,558 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:39,566 - INFO - --------------------\n",
      "\n",
      "259/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:00:45,684 - INFO - All types `lr` of epoch 259: {'lr/param_group0': 0.0002359887830515104, 'lr/param_group1': 0.0002359887830515104, 'lr/param_group2': 0.0002359887830515104, 'lr/param_group3': 0.0002359887830515104}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:45,695 - INFO - epoch 259: train loss 0.048174783811663034\n",
      "2025-09-07 20:00:45,698 - INFO - 259 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:45,705 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:45,711 - INFO - --------------------\n",
      "\n",
      "260/800: 100%|██████████| 216/216 [00:05<00:00, 36.51it/s]\n",
      "2025-09-07 20:00:51,801 - INFO - All types `lr` of epoch 260: {'lr/param_group0': 0.0002355373062366531, 'lr/param_group1': 0.0002355373062366531, 'lr/param_group2': 0.0002355373062366531, 'lr/param_group3': 0.0002355373062366531}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:51,804 - INFO - epoch 260: train loss 0.04827467583257843\n",
      "2025-09-07 20:00:51,812 - INFO - 260 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:51,818 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:51,820 - INFO - --------------------\n",
      "\n",
      "261/800: 100%|██████████| 216/216 [00:05<00:00, 36.23it/s]\n",
      "2025-09-07 20:00:57,960 - INFO - All types `lr` of epoch 261: {'lr/param_group0': 0.00023508474164927483, 'lr/param_group1': 0.00023508474164927483, 'lr/param_group2': 0.00023508474164927483, 'lr/param_group3': 0.00023508474164927483}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:00:57,963 - INFO - epoch 261: train loss 0.04792694471500538\n",
      "2025-09-07 20:00:57,971 - INFO - 261 epochs completed!\n",
      "\n",
      "2025-09-07 20:00:57,977 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:00:57,980 - INFO - --------------------\n",
      "\n",
      "262/800: 100%|██████████| 216/216 [00:05<00:00, 36.42it/s]\n",
      "2025-09-07 20:01:04,082 - INFO - All types `lr` of epoch 262: {'lr/param_group0': 0.00023463109626848137, 'lr/param_group1': 0.00023463109626848137, 'lr/param_group2': 0.00023463109626848137, 'lr/param_group3': 0.00023463109626848137}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:04,092 - INFO - epoch 262: train loss 0.04811827712519853\n",
      "2025-09-07 20:01:04,096 - INFO - 262 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:04,103 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:04,110 - INFO - --------------------\n",
      "\n",
      "263/800: 100%|██████████| 216/216 [00:05<00:00, 38.81it/s]\n",
      "2025-09-07 20:01:09,855 - INFO - All types `lr` of epoch 263: {'lr/param_group0': 0.00023417637709004574, 'lr/param_group1': 0.00023417637709004574, 'lr/param_group2': 0.00023417637709004574, 'lr/param_group3': 0.00023417637709004574}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:09,858 - INFO - epoch 263: train loss 0.0480426036476813\n",
      "2025-09-07 20:01:09,866 - INFO - 263 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:09,872 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:09,875 - INFO - --------------------\n",
      "\n",
      "264/800: 100%|██████████| 216/216 [00:05<00:00, 41.53it/s]\n",
      "2025-09-07 20:01:15,251 - INFO - All types `lr` of epoch 264: {'lr/param_group0': 0.0002337205911263001, 'lr/param_group1': 0.0002337205911263001, 'lr/param_group2': 0.0002337205911263001, 'lr/param_group3': 0.0002337205911263001}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:15,261 - INFO - epoch 264: train loss 0.04799768944374389\n",
      "2025-09-07 20:01:15,269 - INFO - 264 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:15,272 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:15,278 - INFO - --------------------\n",
      "\n",
      "265/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 20:01:21,357 - INFO - All types `lr` of epoch 265: {'lr/param_group0': 0.00023326374540602788, 'lr/param_group1': 0.00023326374540602788, 'lr/param_group2': 0.00023326374540602788, 'lr/param_group3': 0.00023326374540602788}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:21,368 - INFO - epoch 265: train loss 0.0483882960828918\n",
      "2025-09-07 20:01:21,376 - INFO - 265 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:21,379 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:21,385 - INFO - --------------------\n",
      "\n",
      "266/800: 100%|██████████| 216/216 [00:05<00:00, 36.96it/s]\n",
      "2025-09-07 20:01:27,413 - INFO - All types `lr` of epoch 266: {'lr/param_group0': 0.00023280584697435528, 'lr/param_group1': 0.00023280584697435528, 'lr/param_group2': 0.00023280584697435528, 'lr/param_group3': 0.00023280584697435528}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:27,416 - INFO - epoch 266: train loss 0.04818540076828665\n",
      "2025-09-07 20:01:27,424 - INFO - 266 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:27,431 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:27,433 - INFO - --------------------\n",
      "\n",
      "267/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:01:33,543 - INFO - All types `lr` of epoch 267: {'lr/param_group0': 0.00023234690289264246, 'lr/param_group1': 0.00023234690289264246, 'lr/param_group2': 0.00023234690289264246, 'lr/param_group3': 0.00023234690289264246}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:33,553 - INFO - epoch 267: train loss 0.04785198707961374\n",
      "2025-09-07 20:01:33,556 - INFO - 267 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:33,563 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:33,570 - INFO - --------------------\n",
      "\n",
      "268/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:01:39,688 - INFO - All types `lr` of epoch 268: {'lr/param_group0': 0.000231886920238375, 'lr/param_group1': 0.000231886920238375, 'lr/param_group2': 0.000231886920238375, 'lr/param_group3': 0.000231886920238375}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:39,698 - INFO - epoch 268: train loss 0.04785299556398833\n",
      "2025-09-07 20:01:39,706 - INFO - 268 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:39,708 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:39,714 - INFO - --------------------\n",
      "\n",
      "269/800: 100%|██████████| 216/216 [00:05<00:00, 36.50it/s]\n",
      "2025-09-07 20:01:45,810 - INFO - All types `lr` of epoch 269: {'lr/param_group0': 0.0002314259061050544, 'lr/param_group1': 0.0002314259061050544, 'lr/param_group2': 0.0002314259061050544, 'lr/param_group3': 0.0002314259061050544}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:45,820 - INFO - epoch 269: train loss 0.0479017224645725\n",
      "2025-09-07 20:01:45,823 - INFO - 269 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:45,831 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:45,838 - INFO - --------------------\n",
      "\n",
      "270/800: 100%|██████████| 216/216 [00:05<00:00, 36.64it/s]\n",
      "2025-09-07 20:01:51,898 - INFO - All types `lr` of epoch 270: {'lr/param_group0': 0.0002309638676020889, 'lr/param_group1': 0.0002309638676020889, 'lr/param_group2': 0.0002309638676020889, 'lr/param_group3': 0.0002309638676020889}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:51,905 - INFO - epoch 270: train loss 0.04794225719308964\n",
      "2025-09-07 20:01:51,916 - INFO - 270 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:51,925 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:51,931 - INFO - --------------------\n",
      "\n",
      "271/800: 100%|██████████| 216/216 [00:05<00:00, 36.47it/s]\n",
      "2025-09-07 20:01:58,032 - INFO - All types `lr` of epoch 271: {'lr/param_group0': 0.0002305008118546838, 'lr/param_group1': 0.0002305008118546838, 'lr/param_group2': 0.0002305008118546838, 'lr/param_group3': 0.0002305008118546838}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:01:58,042 - INFO - epoch 271: train loss 0.04815606131321854\n",
      "2025-09-07 20:01:58,050 - INFO - 271 epochs completed!\n",
      "\n",
      "2025-09-07 20:01:58,052 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:01:58,058 - INFO - --------------------\n",
      "\n",
      "272/800: 100%|██████████| 216/216 [00:05<00:00, 36.07it/s]\n",
      "2025-09-07 20:02:04,214 - INFO - All types `lr` of epoch 272: {'lr/param_group0': 0.00023003674600373153, 'lr/param_group1': 0.00023003674600373153, 'lr/param_group2': 0.00023003674600373153, 'lr/param_group3': 0.00023003674600373153}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:04,225 - INFO - epoch 272: train loss 0.04794866910756186\n",
      "2025-09-07 20:02:04,227 - INFO - 272 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:04,235 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:04,241 - INFO - --------------------\n",
      "\n",
      "273/800: 100%|██████████| 216/216 [00:05<00:00, 36.29it/s]\n",
      "2025-09-07 20:02:10,361 - INFO - All types `lr` of epoch 273: {'lr/param_group0': 0.0002295716772057016, 'lr/param_group1': 0.0002295716772057016, 'lr/param_group2': 0.0002295716772057016, 'lr/param_group3': 0.0002295716772057016}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:10,373 - INFO - epoch 273: train loss 0.04801235548048108\n",
      "2025-09-07 20:02:10,382 - INFO - 273 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:10,388 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:10,394 - INFO - --------------------\n",
      "\n",
      "274/800: 100%|██████████| 216/216 [00:05<00:00, 36.25it/s]\n",
      "2025-09-07 20:02:16,526 - INFO - All types `lr` of epoch 274: {'lr/param_group0': 0.00022910561263253025, 'lr/param_group1': 0.00022910561263253025, 'lr/param_group2': 0.00022910561263253025, 'lr/param_group3': 0.00022910561263253025}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:16,535 - INFO - epoch 274: train loss 0.04819587704346136\n",
      "2025-09-07 20:02:16,538 - INFO - 274 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:16,545 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:16,551 - INFO - --------------------\n",
      "\n",
      "275/800: 100%|██████████| 216/216 [00:05<00:00, 37.36it/s]\n",
      "2025-09-07 20:02:22,498 - INFO - All types `lr` of epoch 275: {'lr/param_group0': 0.00022863855947150965, 'lr/param_group1': 0.00022863855947150965, 'lr/param_group2': 0.00022863855947150965, 'lr/param_group3': 0.00022863855947150965}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:22,508 - INFO - epoch 275: train loss 0.047935124710892084\n",
      "2025-09-07 20:02:22,511 - INFO - 275 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:22,519 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:22,525 - INFO - --------------------\n",
      "\n",
      "276/800: 100%|██████████| 216/216 [00:05<00:00, 36.24it/s]\n",
      "2025-09-07 20:02:28,663 - INFO - All types `lr` of epoch 276: {'lr/param_group0': 0.0002281705249251774, 'lr/param_group1': 0.0002281705249251774, 'lr/param_group2': 0.0002281705249251774, 'lr/param_group3': 0.0002281705249251774}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:28,666 - INFO - epoch 276: train loss 0.047809161297563046\n",
      "2025-09-07 20:02:28,674 - INFO - 276 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:28,676 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:28,683 - INFO - --------------------\n",
      "\n",
      "277/800: 100%|██████████| 216/216 [00:05<00:00, 36.21it/s]\n",
      "2025-09-07 20:02:34,823 - INFO - All types `lr` of epoch 277: {'lr/param_group0': 0.0002277015162112051, 'lr/param_group1': 0.0002277015162112051, 'lr/param_group2': 0.0002277015162112051, 'lr/param_group3': 0.0002277015162112051}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:34,826 - INFO - epoch 277: train loss 0.04763357177445734\n",
      "2025-09-07 20:02:34,835 - INFO - 277 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:34,843 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:34,845 - INFO - --------------------\n",
      "\n",
      "278/800: 100%|██████████| 216/216 [00:05<00:00, 36.34it/s]\n",
      "2025-09-07 20:02:40,968 - INFO - All types `lr` of epoch 278: {'lr/param_group0': 0.00022723154056228742, 'lr/param_group1': 0.00022723154056228742, 'lr/param_group2': 0.00022723154056228742, 'lr/param_group3': 0.00022723154056228742}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:40,971 - INFO - epoch 278: train loss 0.04784868500643858\n",
      "2025-09-07 20:02:40,979 - INFO - 278 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:40,986 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:40,988 - INFO - --------------------\n",
      "\n",
      "279/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:02:47,142 - INFO - All types `lr` of epoch 279: {'lr/param_group0': 0.00022676060522603016, 'lr/param_group1': 0.00022676060522603016, 'lr/param_group2': 0.00022676060522603016, 'lr/param_group3': 0.00022676060522603016}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:47,145 - INFO - epoch 279: train loss 0.04753124505212462\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.54it/s]\n",
      "2025-09-07 20:02:48,625 - INFO - epoch 279: val loss 0.05823827265865273\n",
      "2025-09-07 20:02:48,630 - INFO - 279 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:02:48,643 - INFO - 279 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:48,649 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:48,651 - INFO - --------------------\n",
      "\n",
      "280/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:02:54,930 - INFO - All types `lr` of epoch 280: {'lr/param_group0': 0.0002262887174648388, 'lr/param_group1': 0.0002262887174648388, 'lr/param_group2': 0.0002262887174648388, 'lr/param_group3': 0.0002262887174648388}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:02:54,935 - INFO - epoch 280: train loss 0.047656792750651086\n",
      "2025-09-07 20:02:54,946 - INFO - 280 epochs completed!\n",
      "\n",
      "2025-09-07 20:02:54,957 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:02:54,961 - INFO - --------------------\n",
      "\n",
      "281/800: 100%|██████████| 216/216 [00:06<00:00, 32.13it/s]\n",
      "2025-09-07 20:03:01,934 - INFO - All types `lr` of epoch 281: {'lr/param_group0': 0.0002258158845558064, 'lr/param_group1': 0.0002258158845558064, 'lr/param_group2': 0.0002258158845558064, 'lr/param_group3': 0.0002258158845558064}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:01,947 - INFO - epoch 281: train loss 0.047770536659906306\n",
      "2025-09-07 20:03:01,959 - INFO - 281 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:01,963 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:01,974 - INFO - --------------------\n",
      "\n",
      "282/800: 100%|██████████| 216/216 [00:06<00:00, 35.98it/s]\n",
      "2025-09-07 20:03:08,223 - INFO - All types `lr` of epoch 282: {'lr/param_group0': 0.00022534211379060136, 'lr/param_group1': 0.00022534211379060136, 'lr/param_group2': 0.00022534211379060136, 'lr/param_group3': 0.00022534211379060136}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:08,232 - INFO - epoch 282: train loss 0.04784522833371604\n",
      "2025-09-07 20:03:08,242 - INFO - 282 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:08,249 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:08,255 - INFO - --------------------\n",
      "\n",
      "283/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:03:14,363 - INFO - All types `lr` of epoch 283: {'lr/param_group0': 0.00022486741247535486, 'lr/param_group1': 0.00022486741247535486, 'lr/param_group2': 0.00022486741247535486, 'lr/param_group3': 0.00022486741247535486}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:14,374 - INFO - epoch 283: train loss 0.0481819575480013\n",
      "2025-09-07 20:03:14,376 - INFO - 283 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:14,384 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:14,391 - INFO - --------------------\n",
      "\n",
      "284/800: 100%|██████████| 216/216 [00:05<00:00, 36.53it/s]\n",
      "2025-09-07 20:03:20,482 - INFO - All types `lr` of epoch 284: {'lr/param_group0': 0.00022439178793054853, 'lr/param_group1': 0.00022439178793054853, 'lr/param_group2': 0.00022439178793054853, 'lr/param_group3': 0.00022439178793054853}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:20,486 - INFO - epoch 284: train loss 0.04780828838960992\n",
      "2025-09-07 20:03:20,495 - INFO - 284 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:20,498 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:20,505 - INFO - --------------------\n",
      "\n",
      "285/800: 100%|██████████| 216/216 [00:05<00:00, 37.96it/s]\n",
      "2025-09-07 20:03:26,379 - INFO - All types `lr` of epoch 285: {'lr/param_group0': 0.00022391524749090113, 'lr/param_group1': 0.00022391524749090113, 'lr/param_group2': 0.00022391524749090113, 'lr/param_group3': 0.00022391524749090113}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:26,390 - INFO - epoch 285: train loss 0.0475594213715306\n",
      "2025-09-07 20:03:26,398 - INFO - 285 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:26,405 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:26,411 - INFO - --------------------\n",
      "\n",
      "286/800: 100%|██████████| 216/216 [00:05<00:00, 37.12it/s]\n",
      "2025-09-07 20:03:32,419 - INFO - All types `lr` of epoch 286: {'lr/param_group0': 0.00022343779850525586, 'lr/param_group1': 0.00022343779850525586, 'lr/param_group2': 0.00022343779850525586, 'lr/param_group3': 0.00022343779850525586}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:32,430 - INFO - epoch 286: train loss 0.047416990571137935\n",
      "2025-09-07 20:03:32,438 - INFO - 286 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:32,445 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:32,451 - INFO - --------------------\n",
      "\n",
      "287/800: 100%|██████████| 216/216 [00:05<00:00, 37.00it/s]\n",
      "2025-09-07 20:03:38,457 - INFO - All types `lr` of epoch 287: {'lr/param_group0': 0.00022295944833646662, 'lr/param_group1': 0.00022295944833646662, 'lr/param_group2': 0.00022295944833646662, 'lr/param_group3': 0.00022295944833646662}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:38,467 - INFO - epoch 287: train loss 0.04750914852721272\n",
      "2025-09-07 20:03:38,478 - INFO - 287 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:38,486 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:38,493 - INFO - --------------------\n",
      "\n",
      "288/800: 100%|██████████| 216/216 [00:05<00:00, 36.33it/s]\n",
      "2025-09-07 20:03:44,615 - INFO - All types `lr` of epoch 288: {'lr/param_group0': 0.00022248020436128478, 'lr/param_group1': 0.00022248020436128478, 'lr/param_group2': 0.00022248020436128478, 'lr/param_group3': 0.00022248020436128478}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:44,625 - INFO - epoch 288: train loss 0.047715535318409955\n",
      "2025-09-07 20:03:44,628 - INFO - 288 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:44,636 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:44,642 - INFO - --------------------\n",
      "\n",
      "289/800: 100%|██████████| 216/216 [00:05<00:00, 37.32it/s]\n",
      "2025-09-07 20:03:50,591 - INFO - All types `lr` of epoch 289: {'lr/param_group0': 0.0002220000739702453, 'lr/param_group1': 0.0002220000739702453, 'lr/param_group2': 0.0002220000739702453, 'lr/param_group3': 0.0002220000739702453}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:50,599 - INFO - epoch 289: train loss 0.04752635479801231\n",
      "2025-09-07 20:03:50,608 - INFO - 289 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:50,616 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:50,624 - INFO - --------------------\n",
      "\n",
      "290/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:03:56,746 - INFO - All types `lr` of epoch 290: {'lr/param_group0': 0.0002215190645675528, 'lr/param_group1': 0.0002215190645675528, 'lr/param_group2': 0.0002215190645675528, 'lr/param_group3': 0.0002215190645675528}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:03:56,749 - INFO - epoch 290: train loss 0.047650379594415426\n",
      "2025-09-07 20:03:56,757 - INFO - 290 epochs completed!\n",
      "\n",
      "2025-09-07 20:03:56,759 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:03:56,765 - INFO - --------------------\n",
      "\n",
      "291/800: 100%|██████████| 216/216 [00:05<00:00, 36.39it/s]\n",
      "2025-09-07 20:04:02,878 - INFO - All types `lr` of epoch 291: {'lr/param_group0': 0.0002210371835709672, 'lr/param_group1': 0.0002210371835709672, 'lr/param_group2': 0.0002210371835709672, 'lr/param_group3': 0.0002210371835709672}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:02,895 - INFO - epoch 291: train loss 0.047380274092709576\n",
      "2025-09-07 20:04:02,906 - INFO - 291 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:02,914 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:02,920 - INFO - --------------------\n",
      "\n",
      "292/800: 100%|██████████| 216/216 [00:05<00:00, 36.62it/s]\n",
      "2025-09-07 20:04:08,994 - INFO - All types `lr` of epoch 292: {'lr/param_group0': 0.00022055443841168969, 'lr/param_group1': 0.00022055443841168969, 'lr/param_group2': 0.00022055443841168969, 'lr/param_group3': 0.00022055443841168969}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:09,005 - INFO - epoch 292: train loss 0.047381029947212445\n",
      "2025-09-07 20:04:09,008 - INFO - 292 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:09,015 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:09,022 - INFO - --------------------\n",
      "\n",
      "293/800: 100%|██████████| 216/216 [00:05<00:00, 36.95it/s]\n",
      "2025-09-07 20:04:15,045 - INFO - All types `lr` of epoch 293: {'lr/param_group0': 0.00022007083653424774, 'lr/param_group1': 0.00022007083653424774, 'lr/param_group2': 0.00022007083653424774, 'lr/param_group3': 0.00022007083653424774}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:15,049 - INFO - epoch 293: train loss 0.047036622564687776\n",
      "2025-09-07 20:04:15,057 - INFO - 293 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:15,059 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:15,065 - INFO - --------------------\n",
      "\n",
      "294/800: 100%|██████████| 216/216 [00:05<00:00, 36.53it/s]\n",
      "2025-09-07 20:04:21,161 - INFO - All types `lr` of epoch 294: {'lr/param_group0': 0.00021958638539638055, 'lr/param_group1': 0.00021958638539638055, 'lr/param_group2': 0.00021958638539638055, 'lr/param_group3': 0.00021958638539638055}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:21,165 - INFO - epoch 294: train loss 0.04737350236003598\n",
      "2025-09-07 20:04:21,173 - INFO - 294 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:21,175 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:21,181 - INFO - --------------------\n",
      "\n",
      "295/800: 100%|██████████| 216/216 [00:05<00:00, 36.28it/s]\n",
      "2025-09-07 20:04:27,312 - INFO - All types `lr` of epoch 295: {'lr/param_group0': 0.000219101092468924, 'lr/param_group1': 0.000219101092468924, 'lr/param_group2': 0.000219101092468924, 'lr/param_group3': 0.000219101092468924}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:27,322 - INFO - epoch 295: train loss 0.047368634940573466\n",
      "2025-09-07 20:04:27,330 - INFO - 295 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:27,333 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:27,339 - INFO - --------------------\n",
      "\n",
      "296/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:04:33,459 - INFO - All types `lr` of epoch 296: {'lr/param_group0': 0.00021861496523569536, 'lr/param_group1': 0.00021861496523569536, 'lr/param_group2': 0.00021861496523569536, 'lr/param_group3': 0.00021861496523569536}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:33,463 - INFO - epoch 296: train loss 0.04717584113004031\n",
      "2025-09-07 20:04:33,471 - INFO - 296 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:33,477 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:33,480 - INFO - --------------------\n",
      "\n",
      "297/800: 100%|██████████| 216/216 [00:05<00:00, 36.62it/s]\n",
      "2025-09-07 20:04:39,553 - INFO - All types `lr` of epoch 297: {'lr/param_group0': 0.00021812801119337793, 'lr/param_group1': 0.00021812801119337793, 'lr/param_group2': 0.00021812801119337793, 'lr/param_group3': 0.00021812801119337793}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:39,564 - INFO - epoch 297: train loss 0.04717390434126611\n",
      "2025-09-07 20:04:39,572 - INFO - 297 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:39,575 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:39,581 - INFO - --------------------\n",
      "\n",
      "298/800: 100%|██████████| 216/216 [00:05<00:00, 37.54it/s]\n",
      "2025-09-07 20:04:45,518 - INFO - All types `lr` of epoch 298: {'lr/param_group0': 0.00021764023785140538, 'lr/param_group1': 0.00021764023785140538, 'lr/param_group2': 0.00021764023785140538, 'lr/param_group3': 0.00021764023785140538}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:45,522 - INFO - epoch 298: train loss 0.04768162131033562\n",
      "2025-09-07 20:04:45,530 - INFO - 298 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:45,537 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:45,539 - INFO - --------------------\n",
      "\n",
      "299/800: 100%|██████████| 216/216 [00:05<00:00, 36.69it/s]\n",
      "2025-09-07 20:04:51,596 - INFO - All types `lr` of epoch 299: {'lr/param_group0': 0.00021715165273184615, 'lr/param_group1': 0.00021715165273184615, 'lr/param_group2': 0.00021715165273184615, 'lr/param_group3': 0.00021715165273184615}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:51,604 - INFO - epoch 299: train loss 0.04759314516559243\n",
      "2025-09-07 20:04:51,615 - INFO - 299 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:51,618 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:51,626 - INFO - --------------------\n",
      "\n",
      "300/800: 100%|██████████| 216/216 [00:05<00:00, 36.35it/s]\n",
      "2025-09-07 20:04:57,748 - INFO - All types `lr` of epoch 300: {'lr/param_group0': 0.00021666226336928708, 'lr/param_group1': 0.00021666226336928708, 'lr/param_group2': 0.00021666226336928708, 'lr/param_group3': 0.00021666226336928708}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:04:57,758 - INFO - epoch 300: train loss 0.04742712463700661\n",
      "2025-09-07 20:04:57,762 - INFO - 300 epochs completed!\n",
      "\n",
      "2025-09-07 20:04:57,769 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:04:57,776 - INFO - --------------------\n",
      "\n",
      "301/800: 100%|██████████| 216/216 [00:05<00:00, 37.37it/s]\n",
      "2025-09-07 20:05:03,728 - INFO - All types `lr` of epoch 301: {'lr/param_group0': 0.00021617207731071766, 'lr/param_group1': 0.00021617207731071766, 'lr/param_group2': 0.00021617207731071766, 'lr/param_group3': 0.00021617207731071766}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:03,737 - INFO - epoch 301: train loss 0.04721069725713244\n",
      "2025-09-07 20:05:03,746 - INFO - 301 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:03,749 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:03,755 - INFO - --------------------\n",
      "\n",
      "302/800: 100%|██████████| 216/216 [00:05<00:00, 36.84it/s]\n",
      "2025-09-07 20:05:09,809 - INFO - All types `lr` of epoch 302: {'lr/param_group0': 0.0002156811021154132, 'lr/param_group1': 0.0002156811021154132, 'lr/param_group2': 0.0002156811021154132, 'lr/param_group3': 0.0002156811021154132}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:09,813 - INFO - epoch 302: train loss 0.04710293371506311\n",
      "2025-09-07 20:05:09,821 - INFO - 302 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:09,828 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:09,831 - INFO - --------------------\n",
      "\n",
      "303/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 20:05:15,917 - INFO - All types `lr` of epoch 303: {'lr/param_group0': 0.0002151893453548186, 'lr/param_group1': 0.0002151893453548186, 'lr/param_group2': 0.0002151893453548186, 'lr/param_group3': 0.0002151893453548186}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:15,921 - INFO - epoch 303: train loss 0.04722727153933159\n",
      "2025-09-07 20:05:15,929 - INFO - 303 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:15,936 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:15,938 - INFO - --------------------\n",
      "\n",
      "304/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:05:22,073 - INFO - All types `lr` of epoch 304: {'lr/param_group0': 0.00021469681461243153, 'lr/param_group1': 0.00021469681461243153, 'lr/param_group2': 0.00021469681461243153, 'lr/param_group3': 0.00021469681461243153}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:22,076 - INFO - epoch 304: train loss 0.04709639391620402\n",
      "2025-09-07 20:05:22,085 - INFO - 304 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:22,091 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:22,094 - INFO - --------------------\n",
      "\n",
      "305/800: 100%|██████████| 216/216 [00:05<00:00, 36.26it/s]\n",
      "2025-09-07 20:05:28,237 - INFO - All types `lr` of epoch 305: {'lr/param_group0': 0.00021420351748368516, 'lr/param_group1': 0.00021420351748368516, 'lr/param_group2': 0.00021420351748368516, 'lr/param_group3': 0.00021420351748368516}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:28,241 - INFO - epoch 305: train loss 0.04696667823871529\n",
      "2025-09-07 20:05:28,250 - INFO - 305 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:28,256 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:28,259 - INFO - --------------------\n",
      "\n",
      "306/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 20:05:34,384 - INFO - All types `lr` of epoch 306: {'lr/param_group0': 0.00021370946157583162, 'lr/param_group1': 0.00021370946157583162, 'lr/param_group2': 0.00021370946157583162, 'lr/param_group3': 0.00021370946157583162}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:34,395 - INFO - epoch 306: train loss 0.047070251501820703\n",
      "2025-09-07 20:05:34,398 - INFO - 306 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:34,405 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:34,412 - INFO - --------------------\n",
      "\n",
      "307/800: 100%|██████████| 216/216 [00:05<00:00, 36.42it/s]\n",
      "2025-09-07 20:05:40,519 - INFO - All types `lr` of epoch 307: {'lr/param_group0': 0.0002132146545078241, 'lr/param_group1': 0.0002132146545078241, 'lr/param_group2': 0.0002132146545078241, 'lr/param_group3': 0.0002132146545078241}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:40,529 - INFO - epoch 307: train loss 0.04706716787552944\n",
      "2025-09-07 20:05:40,538 - INFO - 307 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:40,541 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:40,547 - INFO - --------------------\n",
      "\n",
      "308/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:05:46,719 - INFO - All types `lr` of epoch 308: {'lr/param_group0': 0.0002127191039101997, 'lr/param_group1': 0.0002127191039101997, 'lr/param_group2': 0.0002127191039101997, 'lr/param_group3': 0.0002127191039101997}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:46,729 - INFO - epoch 308: train loss 0.047026391675764764\n",
      "2025-09-07 20:05:46,737 - INFO - 308 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:46,740 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:46,746 - INFO - --------------------\n",
      "\n",
      "309/800: 100%|██████████| 216/216 [00:05<00:00, 36.54it/s]\n",
      "2025-09-07 20:05:52,841 - INFO - All types `lr` of epoch 309: {'lr/param_group0': 0.00021222281742496165, 'lr/param_group1': 0.00021222281742496165, 'lr/param_group2': 0.00021222281742496165, 'lr/param_group3': 0.00021222281742496165}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:52,852 - INFO - epoch 309: train loss 0.047318677262713514\n",
      "2025-09-07 20:05:52,855 - INFO - 309 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:52,862 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:52,869 - INFO - --------------------\n",
      "\n",
      "310/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 20:05:58,951 - INFO - All types `lr` of epoch 310: {'lr/param_group0': 0.00021172580270546152, 'lr/param_group1': 0.00021172580270546152, 'lr/param_group2': 0.00021172580270546152, 'lr/param_group3': 0.00021172580270546152}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:05:58,954 - INFO - epoch 310: train loss 0.04707880188814468\n",
      "2025-09-07 20:05:58,962 - INFO - 310 epochs completed!\n",
      "\n",
      "2025-09-07 20:05:58,969 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:05:58,971 - INFO - --------------------\n",
      "\n",
      "311/800: 100%|██████████| 216/216 [00:05<00:00, 36.33it/s]\n",
      "2025-09-07 20:06:05,098 - INFO - All types `lr` of epoch 311: {'lr/param_group0': 0.0002112280674162811, 'lr/param_group1': 0.0002112280674162811, 'lr/param_group2': 0.0002112280674162811, 'lr/param_group3': 0.0002112280674162811}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:05,109 - INFO - epoch 311: train loss 0.04711187118664384\n",
      "2025-09-07 20:06:05,113 - INFO - 311 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:05,120 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:05,127 - INFO - --------------------\n",
      "\n",
      "312/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:06:11,278 - INFO - All types `lr` of epoch 312: {'lr/param_group0': 0.00021072961923311432, 'lr/param_group1': 0.00021072961923311432, 'lr/param_group2': 0.00021072961923311432, 'lr/param_group3': 0.00021072961923311432}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:11,281 - INFO - epoch 312: train loss 0.04709861041219146\n",
      "2025-09-07 20:06:11,290 - INFO - 312 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:11,298 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:11,305 - INFO - --------------------\n",
      "\n",
      "313/800: 100%|██████████| 216/216 [00:05<00:00, 36.07it/s]\n",
      "2025-09-07 20:06:17,472 - INFO - All types `lr` of epoch 313: {'lr/param_group0': 0.00021023046584264874, 'lr/param_group1': 0.00021023046584264874, 'lr/param_group2': 0.00021023046584264874, 'lr/param_group3': 0.00021023046584264874}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:17,483 - INFO - epoch 313: train loss 0.046838298353745984\n",
      "2025-09-07 20:06:17,487 - INFO - 313 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:17,494 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:17,496 - INFO - --------------------\n",
      "\n",
      "314/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:06:23,658 - INFO - All types `lr` of epoch 314: {'lr/param_group0': 0.0002097306149424471, 'lr/param_group1': 0.0002097306149424471, 'lr/param_group2': 0.0002097306149424471, 'lr/param_group3': 0.0002097306149424471}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:23,662 - INFO - epoch 314: train loss 0.04706862882745487\n",
      "2025-09-07 20:06:23,671 - INFO - 314 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:23,673 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:23,680 - INFO - --------------------\n",
      "\n",
      "315/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 20:06:29,849 - INFO - All types `lr` of epoch 315: {'lr/param_group0': 0.0002092300742408286, 'lr/param_group1': 0.0002092300742408286, 'lr/param_group2': 0.0002092300742408286, 'lr/param_group3': 0.0002092300742408286}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:29,862 - INFO - epoch 315: train loss 0.04696056591691794\n",
      "2025-09-07 20:06:29,870 - INFO - 315 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:29,878 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:29,884 - INFO - --------------------\n",
      "\n",
      "316/800: 100%|██████████| 216/216 [00:05<00:00, 36.10it/s]\n",
      "2025-09-07 20:06:36,052 - INFO - All types `lr` of epoch 316: {'lr/param_group0': 0.00020872885145675014, 'lr/param_group1': 0.00020872885145675014, 'lr/param_group2': 0.00020872885145675014, 'lr/param_group3': 0.00020872885145675014}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:36,063 - INFO - epoch 316: train loss 0.04661800222540343\n",
      "2025-09-07 20:06:36,066 - INFO - 316 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:36,074 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:36,081 - INFO - --------------------\n",
      "\n",
      "317/800: 100%|██████████| 216/216 [00:05<00:00, 36.34it/s]\n",
      "2025-09-07 20:06:42,201 - INFO - All types `lr` of epoch 317: {'lr/param_group0': 0.00020822695431968707, 'lr/param_group1': 0.00020822695431968707, 'lr/param_group2': 0.00020822695431968707, 'lr/param_group3': 0.00020822695431968707}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:42,212 - INFO - epoch 317: train loss 0.04690046667086857\n",
      "2025-09-07 20:06:42,221 - INFO - 317 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:42,224 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:42,231 - INFO - --------------------\n",
      "\n",
      "318/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:06:48,359 - INFO - All types `lr` of epoch 318: {'lr/param_group0': 0.0002077243905695141, 'lr/param_group1': 0.0002077243905695141, 'lr/param_group2': 0.0002077243905695141, 'lr/param_group3': 0.0002077243905695141}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:48,362 - INFO - epoch 318: train loss 0.04686893546884811\n",
      "2025-09-07 20:06:48,370 - INFO - 318 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:48,377 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:48,380 - INFO - --------------------\n",
      "\n",
      "319/800: 100%|██████████| 216/216 [00:05<00:00, 36.28it/s]\n",
      "2025-09-07 20:06:54,512 - INFO - All types `lr` of epoch 319: {'lr/param_group0': 0.00020722116795638597, 'lr/param_group1': 0.00020722116795638597, 'lr/param_group2': 0.00020722116795638597, 'lr/param_group3': 0.00020722116795638597}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:06:54,523 - INFO - epoch 319: train loss 0.0467699909651721\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.30it/s]\n",
      "2025-09-07 20:06:55,974 - INFO - epoch 319: val loss 0.05861674856256555\n",
      "2025-09-07 20:06:55,990 - INFO - 319 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:06:55,999 - INFO - 319 epochs completed!\n",
      "\n",
      "2025-09-07 20:06:56,008 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:06:56,016 - INFO - --------------------\n",
      "\n",
      "320/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 20:07:02,140 - INFO - All types `lr` of epoch 320: {'lr/param_group0': 0.00020671729424061788, 'lr/param_group1': 0.00020671729424061788, 'lr/param_group2': 0.00020671729424061788, 'lr/param_group3': 0.00020671729424061788}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:02,144 - INFO - epoch 320: train loss 0.04687315275616668\n",
      "2025-09-07 20:07:02,152 - INFO - 320 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:02,159 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:02,162 - INFO - --------------------\n",
      "\n",
      "321/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:07:08,332 - INFO - All types `lr` of epoch 321: {'lr/param_group0': 0.00020621277719256586, 'lr/param_group1': 0.00020621277719256586, 'lr/param_group2': 0.00020621277719256586, 'lr/param_group3': 0.00020621277719256586}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:08,343 - INFO - epoch 321: train loss 0.04682006141929715\n",
      "2025-09-07 20:07:08,347 - INFO - 321 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:08,354 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:08,361 - INFO - --------------------\n",
      "\n",
      "322/800: 100%|██████████| 216/216 [00:06<00:00, 36.00it/s]\n",
      "2025-09-07 20:07:14,536 - INFO - All types `lr` of epoch 322: {'lr/param_group0': 0.00020570762459250693, 'lr/param_group1': 0.00020570762459250693, 'lr/param_group2': 0.00020570762459250693, 'lr/param_group3': 0.00020570762459250693}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:14,546 - INFO - epoch 322: train loss 0.04650912061333656\n",
      "2025-09-07 20:07:14,555 - INFO - 322 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:14,558 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:14,565 - INFO - --------------------\n",
      "\n",
      "323/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:07:20,691 - INFO - All types `lr` of epoch 323: {'lr/param_group0': 0.000205201844230519, 'lr/param_group1': 0.000205201844230519, 'lr/param_group2': 0.000205201844230519, 'lr/param_group3': 0.000205201844230519}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:20,695 - INFO - epoch 323: train loss 0.04714523586961958\n",
      "2025-09-07 20:07:20,703 - INFO - 323 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:20,712 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:20,719 - INFO - --------------------\n",
      "\n",
      "324/800: 100%|██████████| 216/216 [00:05<00:00, 36.11it/s]\n",
      "2025-09-07 20:07:26,881 - INFO - All types `lr` of epoch 324: {'lr/param_group0': 0.00020469544390636101, 'lr/param_group1': 0.00020469544390636101, 'lr/param_group2': 0.00020469544390636101, 'lr/param_group3': 0.00020469544390636101}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:26,892 - INFO - epoch 324: train loss 0.046794877370336545\n",
      "2025-09-07 20:07:26,896 - INFO - 324 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:26,903 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:26,906 - INFO - --------------------\n",
      "\n",
      "325/800: 100%|██████████| 216/216 [00:05<00:00, 36.35it/s]\n",
      "2025-09-07 20:07:33,038 - INFO - All types `lr` of epoch 325: {'lr/param_group0': 0.00020418843142935245, 'lr/param_group1': 0.00020418843142935245, 'lr/param_group2': 0.00020418843142935245, 'lr/param_group3': 0.00020418843142935245}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:33,042 - INFO - epoch 325: train loss 0.046560900630774324\n",
      "2025-09-07 20:07:33,051 - INFO - 325 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:33,053 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:33,059 - INFO - --------------------\n",
      "\n",
      "326/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:07:39,217 - INFO - All types `lr` of epoch 326: {'lr/param_group0': 0.0002036808146182528, 'lr/param_group1': 0.0002036808146182528, 'lr/param_group2': 0.0002036808146182528, 'lr/param_group3': 0.0002036808146182528}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:39,220 - INFO - epoch 326: train loss 0.04647173247886477\n",
      "2025-09-07 20:07:39,229 - INFO - 326 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:39,231 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:39,238 - INFO - --------------------\n",
      "\n",
      "327/800: 100%|██████████| 216/216 [00:05<00:00, 36.20it/s]\n",
      "2025-09-07 20:07:45,390 - INFO - All types `lr` of epoch 327: {'lr/param_group0': 0.00020317260130114126, 'lr/param_group1': 0.00020317260130114126, 'lr/param_group2': 0.00020317260130114126, 'lr/param_group3': 0.00020317260130114126}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:45,403 - INFO - epoch 327: train loss 0.046323606537448034\n",
      "2025-09-07 20:07:45,412 - INFO - 327 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:45,419 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:45,426 - INFO - --------------------\n",
      "\n",
      "328/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:07:51,561 - INFO - All types `lr` of epoch 328: {'lr/param_group0': 0.00020266379931529595, 'lr/param_group1': 0.00020266379931529595, 'lr/param_group2': 0.00020266379931529595, 'lr/param_group3': 0.00020266379931529595}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:51,574 - INFO - epoch 328: train loss 0.04655124588559071\n",
      "2025-09-07 20:07:51,582 - INFO - 328 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:51,590 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:51,596 - INFO - --------------------\n",
      "\n",
      "329/800: 100%|██████████| 216/216 [00:06<00:00, 35.68it/s]\n",
      "2025-09-07 20:07:57,834 - INFO - All types `lr` of epoch 329: {'lr/param_group0': 0.00020215441650707283, 'lr/param_group1': 0.00020215441650707283, 'lr/param_group2': 0.00020215441650707283, 'lr/param_group3': 0.00020215441650707283}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:07:57,838 - INFO - epoch 329: train loss 0.046644492643988796\n",
      "2025-09-07 20:07:57,849 - INFO - 329 epochs completed!\n",
      "\n",
      "2025-09-07 20:07:57,857 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:07:57,860 - INFO - --------------------\n",
      "\n",
      "330/800: 100%|██████████| 216/216 [00:05<00:00, 36.08it/s]\n",
      "2025-09-07 20:08:04,034 - INFO - All types `lr` of epoch 330: {'lr/param_group0': 0.00020164446073178504, 'lr/param_group1': 0.00020164446073178504, 'lr/param_group2': 0.00020164446073178504, 'lr/param_group3': 0.00020164446073178504}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:04,038 - INFO - epoch 330: train loss 0.04662954112238906\n",
      "2025-09-07 20:08:04,046 - INFO - 330 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:04,053 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:04,056 - INFO - --------------------\n",
      "\n",
      "331/800: 100%|██████████| 216/216 [00:06<00:00, 35.79it/s]\n",
      "2025-09-07 20:08:10,280 - INFO - All types `lr` of epoch 331: {'lr/param_group0': 0.00020113393985358134, 'lr/param_group1': 0.00020113393985358134, 'lr/param_group2': 0.00020113393985358134, 'lr/param_group3': 0.00020113393985358134}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:10,284 - INFO - epoch 331: train loss 0.04636424498770524\n",
      "2025-09-07 20:08:10,292 - INFO - 331 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:10,300 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:10,302 - INFO - --------------------\n",
      "\n",
      "332/800: 100%|██████████| 216/216 [00:05<00:00, 36.02it/s]\n",
      "2025-09-07 20:08:16,493 - INFO - All types `lr` of epoch 332: {'lr/param_group0': 0.00020062286174532532, 'lr/param_group1': 0.00020062286174532532, 'lr/param_group2': 0.00020062286174532532, 'lr/param_group3': 0.00020062286174532532}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:16,498 - INFO - epoch 332: train loss 0.046700376448118024\n",
      "2025-09-07 20:08:16,510 - INFO - 332 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:16,519 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:16,522 - INFO - --------------------\n",
      "\n",
      "333/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:08:22,666 - INFO - All types `lr` of epoch 333: {'lr/param_group0': 0.00020011123428847363, 'lr/param_group1': 0.00020011123428847363, 'lr/param_group2': 0.00020011123428847363, 'lr/param_group3': 0.00020011123428847363}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:22,677 - INFO - epoch 333: train loss 0.046583549947374396\n",
      "2025-09-07 20:08:22,681 - INFO - 333 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:22,689 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:22,696 - INFO - --------------------\n",
      "\n",
      "334/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:08:28,833 - INFO - All types `lr` of epoch 334: {'lr/param_group0': 0.00019959906537295448, 'lr/param_group1': 0.00019959906537295448, 'lr/param_group2': 0.00019959906537295448, 'lr/param_group3': 0.00019959906537295448}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:28,844 - INFO - epoch 334: train loss 0.04654293498714213\n",
      "2025-09-07 20:08:28,848 - INFO - 334 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:28,855 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:28,862 - INFO - --------------------\n",
      "\n",
      "335/800: 100%|██████████| 216/216 [00:05<00:00, 36.08it/s]\n",
      "2025-09-07 20:08:35,015 - INFO - All types `lr` of epoch 335: {'lr/param_group0': 0.00019908636289704633, 'lr/param_group1': 0.00019908636289704633, 'lr/param_group2': 0.00019908636289704633, 'lr/param_group3': 0.00019908636289704633}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:35,027 - INFO - epoch 335: train loss 0.04631076999767511\n",
      "2025-09-07 20:08:35,031 - INFO - 335 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:35,039 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:35,046 - INFO - --------------------\n",
      "\n",
      "336/800: 100%|██████████| 216/216 [00:05<00:00, 36.34it/s]\n",
      "2025-09-07 20:08:41,182 - INFO - All types `lr` of epoch 336: {'lr/param_group0': 0.00019857313476725536, 'lr/param_group1': 0.00019857313476725536, 'lr/param_group2': 0.00019857313476725536, 'lr/param_group3': 0.00019857313476725536}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:41,194 - INFO - epoch 336: train loss 0.04662069110889678\n",
      "2025-09-07 20:08:41,203 - INFO - 336 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:41,206 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:41,214 - INFO - --------------------\n",
      "\n",
      "337/800: 100%|██████████| 216/216 [00:05<00:00, 37.77it/s]\n",
      "2025-09-07 20:08:47,117 - INFO - All types `lr` of epoch 337: {'lr/param_group0': 0.0001980593888981944, 'lr/param_group1': 0.0001980593888981944, 'lr/param_group2': 0.0001980593888981944, 'lr/param_group3': 0.0001980593888981944}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:47,127 - INFO - epoch 337: train loss 0.04676129020474575\n",
      "2025-09-07 20:08:47,136 - INFO - 337 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:47,139 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:47,145 - INFO - --------------------\n",
      "\n",
      "338/800: 100%|██████████| 216/216 [00:05<00:00, 36.69it/s]\n",
      "2025-09-07 20:08:53,219 - INFO - All types `lr` of epoch 338: {'lr/param_group0': 0.0001975451332124602, 'lr/param_group1': 0.0001975451332124602, 'lr/param_group2': 0.0001975451332124602, 'lr/param_group3': 0.0001975451332124602}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:53,230 - INFO - epoch 338: train loss 0.04672117572691706\n",
      "2025-09-07 20:08:53,234 - INFO - 338 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:53,241 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:53,248 - INFO - --------------------\n",
      "\n",
      "339/800: 100%|██████████| 216/216 [00:05<00:00, 36.01it/s]\n",
      "2025-09-07 20:08:59,425 - INFO - All types `lr` of epoch 339: {'lr/param_group0': 0.00019703037564051167, 'lr/param_group1': 0.00019703037564051167, 'lr/param_group2': 0.00019703037564051167, 'lr/param_group3': 0.00019703037564051167}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:08:59,437 - INFO - epoch 339: train loss 0.04645068351938217\n",
      "2025-09-07 20:08:59,440 - INFO - 339 epochs completed!\n",
      "\n",
      "2025-09-07 20:08:59,448 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:08:59,456 - INFO - --------------------\n",
      "\n",
      "340/800: 100%|██████████| 216/216 [00:05<00:00, 36.20it/s]\n",
      "2025-09-07 20:09:05,595 - INFO - All types `lr` of epoch 340: {'lr/param_group0': 0.00019651512412054723, 'lr/param_group1': 0.00019651512412054723, 'lr/param_group2': 0.00019651512412054723, 'lr/param_group3': 0.00019651512412054723}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:05,598 - INFO - epoch 340: train loss 0.04628365776605076\n",
      "2025-09-07 20:09:05,608 - INFO - 340 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:05,620 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:05,622 - INFO - --------------------\n",
      "\n",
      "341/800: 100%|██████████| 216/216 [00:05<00:00, 37.10it/s]\n",
      "2025-09-07 20:09:11,628 - INFO - All types `lr` of epoch 341: {'lr/param_group0': 0.00019599938659838281, 'lr/param_group1': 0.00019599938659838281, 'lr/param_group2': 0.00019599938659838281, 'lr/param_group3': 0.00019599938659838281}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:11,639 - INFO - epoch 341: train loss 0.046562274676506164\n",
      "2025-09-07 20:09:11,643 - INFO - 341 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:11,650 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:11,657 - INFO - --------------------\n",
      "\n",
      "342/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:09:17,833 - INFO - All types `lr` of epoch 342: {'lr/param_group0': 0.00019548317102732903, 'lr/param_group1': 0.00019548317102732903, 'lr/param_group2': 0.00019548317102732903, 'lr/param_group3': 0.00019548317102732903}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:17,844 - INFO - epoch 342: train loss 0.04679191093546925\n",
      "2025-09-07 20:09:17,848 - INFO - 342 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:17,856 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:17,863 - INFO - --------------------\n",
      "\n",
      "343/800: 100%|██████████| 216/216 [00:05<00:00, 36.21it/s]\n",
      "2025-09-07 20:09:24,005 - INFO - All types `lr` of epoch 343: {'lr/param_group0': 0.0001949664853680684, 'lr/param_group1': 0.0001949664853680684, 'lr/param_group2': 0.0001949664853680684, 'lr/param_group3': 0.0001949664853680684}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:24,016 - INFO - epoch 343: train loss 0.046348972953166125\n",
      "2025-09-07 20:09:24,020 - INFO - 343 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:24,027 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:24,029 - INFO - --------------------\n",
      "\n",
      "344/800: 100%|██████████| 216/216 [00:05<00:00, 36.40it/s]\n",
      "2025-09-07 20:09:30,148 - INFO - All types `lr` of epoch 344: {'lr/param_group0': 0.00019444933758853327, 'lr/param_group1': 0.00019444933758853327, 'lr/param_group2': 0.00019444933758853327, 'lr/param_group3': 0.00019444933758853327}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:30,152 - INFO - epoch 344: train loss 0.04619996351431365\n",
      "2025-09-07 20:09:30,160 - INFO - 344 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:30,162 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:30,169 - INFO - --------------------\n",
      "\n",
      "345/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:09:36,303 - INFO - All types `lr` of epoch 345: {'lr/param_group0': 0.00019393173566378184, 'lr/param_group1': 0.00019393173566378184, 'lr/param_group2': 0.00019393173566378184, 'lr/param_group3': 0.00019393173566378184}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:36,316 - INFO - epoch 345: train loss 0.0464576232523002\n",
      "2025-09-07 20:09:36,325 - INFO - 345 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:36,332 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:36,338 - INFO - --------------------\n",
      "\n",
      "346/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:09:42,537 - INFO - All types `lr` of epoch 346: {'lr/param_group0': 0.00019341368757587625, 'lr/param_group1': 0.00019341368757587625, 'lr/param_group2': 0.00019341368757587625, 'lr/param_group3': 0.00019341368757587625}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:42,550 - INFO - epoch 346: train loss 0.04642494400549266\n",
      "2025-09-07 20:09:42,558 - INFO - 346 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:42,566 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:42,572 - INFO - --------------------\n",
      "\n",
      "347/800: 100%|██████████| 216/216 [00:05<00:00, 36.43it/s]\n",
      "2025-09-07 20:09:48,689 - INFO - All types `lr` of epoch 347: {'lr/param_group0': 0.00019289520131375882, 'lr/param_group1': 0.00019289520131375882, 'lr/param_group2': 0.00019289520131375882, 'lr/param_group3': 0.00019289520131375882}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:48,700 - INFO - epoch 347: train loss 0.046109637073068706\n",
      "2025-09-07 20:09:48,703 - INFO - 347 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:48,711 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:48,718 - INFO - --------------------\n",
      "\n",
      "348/800: 100%|██████████| 216/216 [00:05<00:00, 36.20it/s]\n",
      "2025-09-07 20:09:54,861 - INFO - All types `lr` of epoch 348: {'lr/param_group0': 0.0001923762848731292, 'lr/param_group1': 0.0001923762848731292, 'lr/param_group2': 0.0001923762848731292, 'lr/param_group3': 0.0001923762848731292}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:09:54,871 - INFO - epoch 348: train loss 0.04642074713828387\n",
      "2025-09-07 20:09:54,880 - INFO - 348 epochs completed!\n",
      "\n",
      "2025-09-07 20:09:54,883 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:09:54,890 - INFO - --------------------\n",
      "\n",
      "349/800: 100%|██████████| 216/216 [00:05<00:00, 36.35it/s]\n",
      "2025-09-07 20:10:01,025 - INFO - All types `lr` of epoch 349: {'lr/param_group0': 0.0001918569462563207, 'lr/param_group1': 0.0001918569462563207, 'lr/param_group2': 0.0001918569462563207, 'lr/param_group3': 0.0001918569462563207}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:01,029 - INFO - epoch 349: train loss 0.04630584800960841\n",
      "2025-09-07 20:10:01,038 - INFO - 349 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:01,045 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:01,048 - INFO - --------------------\n",
      "\n",
      "350/800: 100%|██████████| 216/216 [00:05<00:00, 36.52it/s]\n",
      "2025-09-07 20:10:07,151 - INFO - All types `lr` of epoch 350: {'lr/param_group0': 0.00019133719347217735, 'lr/param_group1': 0.00019133719347217735, 'lr/param_group2': 0.00019133719347217735, 'lr/param_group3': 0.00019133719347217735}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:07,155 - INFO - epoch 350: train loss 0.04599488226489888\n",
      "2025-09-07 20:10:07,163 - INFO - 350 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:07,171 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:07,174 - INFO - --------------------\n",
      "\n",
      "351/800: 100%|██████████| 216/216 [00:06<00:00, 35.91it/s]\n",
      "2025-09-07 20:10:13,378 - INFO - All types `lr` of epoch 351: {'lr/param_group0': 0.00019081703453592991, 'lr/param_group1': 0.00019081703453592991, 'lr/param_group2': 0.00019081703453592991, 'lr/param_group3': 0.00019081703453592991}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:13,381 - INFO - epoch 351: train loss 0.045959833543747663\n",
      "2025-09-07 20:10:13,390 - INFO - 351 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:13,398 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:13,401 - INFO - --------------------\n",
      "\n",
      "352/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:10:19,565 - INFO - All types `lr` of epoch 352: {'lr/param_group0': 0.0001902964774690728, 'lr/param_group1': 0.0001902964774690728, 'lr/param_group2': 0.0001902964774690728, 'lr/param_group3': 0.0001902964774690728}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:19,569 - INFO - epoch 352: train loss 0.046169436174548335\n",
      "2025-09-07 20:10:19,578 - INFO - 352 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:19,585 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:19,588 - INFO - --------------------\n",
      "\n",
      "353/800: 100%|██████████| 216/216 [00:05<00:00, 36.41it/s]\n",
      "2025-09-07 20:10:25,702 - INFO - All types `lr` of epoch 353: {'lr/param_group0': 0.0001897755302992399, 'lr/param_group1': 0.0001897755302992399, 'lr/param_group2': 0.0001897755302992399, 'lr/param_group3': 0.0001897755302992399}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:25,713 - INFO - epoch 353: train loss 0.04577062182404377\n",
      "2025-09-07 20:10:25,722 - INFO - 353 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:25,725 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:25,732 - INFO - --------------------\n",
      "\n",
      "354/800: 100%|██████████| 216/216 [00:06<00:00, 35.94it/s]\n",
      "2025-09-07 20:10:31,935 - INFO - All types `lr` of epoch 354: {'lr/param_group0': 0.00018925420106008097, 'lr/param_group1': 0.00018925420106008097, 'lr/param_group2': 0.00018925420106008097, 'lr/param_group3': 0.00018925420106008097}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:31,939 - INFO - epoch 354: train loss 0.04567192117166188\n",
      "2025-09-07 20:10:31,948 - INFO - 354 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:31,955 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:31,957 - INFO - --------------------\n",
      "\n",
      "355/800: 100%|██████████| 216/216 [00:05<00:00, 36.15it/s]\n",
      "2025-09-07 20:10:38,124 - INFO - All types `lr` of epoch 355: {'lr/param_group0': 0.00018873249779113784, 'lr/param_group1': 0.00018873249779113784, 'lr/param_group2': 0.00018873249779113784, 'lr/param_group3': 0.00018873249779113784}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:38,128 - INFO - epoch 355: train loss 0.04579173864934732\n",
      "2025-09-07 20:10:38,137 - INFO - 355 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:38,144 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:38,148 - INFO - --------------------\n",
      "\n",
      "356/800: 100%|██████████| 216/216 [00:05<00:00, 36.05it/s]\n",
      "2025-09-07 20:10:44,324 - INFO - All types `lr` of epoch 356: {'lr/param_group0': 0.00018821042853772027, 'lr/param_group1': 0.00018821042853772027, 'lr/param_group2': 0.00018821042853772027, 'lr/param_group3': 0.00018821042853772027}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:44,328 - INFO - epoch 356: train loss 0.04590609331649763\n",
      "2025-09-07 20:10:44,337 - INFO - 356 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:44,344 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:44,347 - INFO - --------------------\n",
      "\n",
      "357/800: 100%|██████████| 216/216 [00:05<00:00, 36.29it/s]\n",
      "2025-09-07 20:10:50,485 - INFO - All types `lr` of epoch 357: {'lr/param_group0': 0.00018768800135078204, 'lr/param_group1': 0.00018768800135078204, 'lr/param_group2': 0.00018768800135078204, 'lr/param_group3': 0.00018768800135078204}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:50,497 - INFO - epoch 357: train loss 0.04620684090035933\n",
      "2025-09-07 20:10:50,501 - INFO - 357 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:50,508 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:50,516 - INFO - --------------------\n",
      "\n",
      "358/800: 100%|██████████| 216/216 [00:05<00:00, 36.62it/s]\n",
      "2025-09-07 20:10:56,591 - INFO - All types `lr` of epoch 358: {'lr/param_group0': 0.00018716522428679645, 'lr/param_group1': 0.00018716522428679645, 'lr/param_group2': 0.00018716522428679645, 'lr/param_group3': 0.00018716522428679645}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:10:56,603 - INFO - epoch 358: train loss 0.04612552757478423\n",
      "2025-09-07 20:10:56,607 - INFO - 358 epochs completed!\n",
      "\n",
      "2025-09-07 20:10:56,614 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:10:56,622 - INFO - --------------------\n",
      "\n",
      "359/800: 100%|██████████| 216/216 [00:05<00:00, 37.37it/s]\n",
      "2025-09-07 20:11:02,577 - INFO - All types `lr` of epoch 359: {'lr/param_group0': 0.0001866421054076328, 'lr/param_group1': 0.0001866421054076328, 'lr/param_group2': 0.0001866421054076328, 'lr/param_group3': 0.0001866421054076328}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:02,588 - INFO - epoch 359: train loss 0.045791213090221085\n",
      "100%|██████████| 54/54 [00:01<00:00, 40.91it/s]\n",
      "2025-09-07 20:11:04,089 - INFO - epoch 359: val loss 0.05851033067813626\n",
      "2025-09-07 20:11:04,093 - INFO - 359 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:11:04,106 - INFO - 359 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:04,113 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:04,116 - INFO - --------------------\n",
      "\n",
      "360/800: 100%|██████████| 216/216 [00:05<00:00, 42.58it/s]\n",
      "2025-09-07 20:11:09,369 - INFO - All types `lr` of epoch 360: {'lr/param_group0': 0.00018611865278043117, 'lr/param_group1': 0.00018611865278043117, 'lr/param_group2': 0.00018611865278043117, 'lr/param_group3': 0.00018611865278043117}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:09,381 - INFO - epoch 360: train loss 0.04578868327317415\n",
      "2025-09-07 20:11:09,384 - INFO - 360 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:09,392 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:09,399 - INFO - --------------------\n",
      "\n",
      "361/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 20:11:15,478 - INFO - All types `lr` of epoch 361: {'lr/param_group0': 0.00018559487447747866, 'lr/param_group1': 0.00018559487447747866, 'lr/param_group2': 0.00018559487447747866, 'lr/param_group3': 0.00018559487447747866}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:15,489 - INFO - epoch 361: train loss 0.04566741239762417\n",
      "2025-09-07 20:11:15,498 - INFO - 361 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:15,501 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:15,508 - INFO - --------------------\n",
      "\n",
      "362/800: 100%|██████████| 216/216 [00:05<00:00, 36.39it/s]\n",
      "2025-09-07 20:11:21,640 - INFO - All types `lr` of epoch 362: {'lr/param_group0': 0.0001850707785760846, 'lr/param_group1': 0.0001850707785760846, 'lr/param_group2': 0.0001850707785760846, 'lr/param_group3': 0.0001850707785760846}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:21,644 - INFO - epoch 362: train loss 0.046087042773487394\n",
      "2025-09-07 20:11:21,653 - INFO - 362 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:21,661 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:21,664 - INFO - --------------------\n",
      "\n",
      "363/800: 100%|██████████| 216/216 [00:05<00:00, 36.05it/s]\n",
      "2025-09-07 20:11:27,842 - INFO - All types `lr` of epoch 363: {'lr/param_group0': 0.00018454637315845615, 'lr/param_group1': 0.00018454637315845615, 'lr/param_group2': 0.00018454637315845615, 'lr/param_group3': 0.00018454637315845615}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:27,852 - INFO - epoch 363: train loss 0.045770402618304444\n",
      "2025-09-07 20:11:27,855 - INFO - 363 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:27,864 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:27,871 - INFO - --------------------\n",
      "\n",
      "364/800: 100%|██████████| 216/216 [00:05<00:00, 36.26it/s]\n",
      "2025-09-07 20:11:34,008 - INFO - All types `lr` of epoch 364: {'lr/param_group0': 0.00018402166631157368, 'lr/param_group1': 0.00018402166631157368, 'lr/param_group2': 0.00018402166631157368, 'lr/param_group3': 0.00018402166631157368}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:34,021 - INFO - epoch 364: train loss 0.045790655314232466\n",
      "2025-09-07 20:11:34,030 - INFO - 364 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:34,038 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:34,045 - INFO - --------------------\n",
      "\n",
      "365/800: 100%|██████████| 216/216 [00:05<00:00, 36.34it/s]\n",
      "2025-09-07 20:11:40,177 - INFO - All types `lr` of epoch 365: {'lr/param_group0': 0.00018349666612706565, 'lr/param_group1': 0.00018349666612706565, 'lr/param_group2': 0.00018349666612706565, 'lr/param_group3': 0.00018349666612706565}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:40,187 - INFO - epoch 365: train loss 0.04581994923797471\n",
      "2025-09-07 20:11:40,191 - INFO - 365 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:40,199 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:40,207 - INFO - --------------------\n",
      "\n",
      "366/800: 100%|██████████| 216/216 [00:05<00:00, 36.80it/s]\n",
      "2025-09-07 20:11:46,253 - INFO - All types `lr` of epoch 366: {'lr/param_group0': 0.00018297138070108457, 'lr/param_group1': 0.00018297138070108457, 'lr/param_group2': 0.00018297138070108457, 'lr/param_group3': 0.00018297138070108457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:46,266 - INFO - epoch 366: train loss 0.045731319252539565\n",
      "2025-09-07 20:11:46,275 - INFO - 366 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:46,282 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:46,290 - INFO - --------------------\n",
      "\n",
      "367/800: 100%|██████████| 216/216 [00:05<00:00, 36.17it/s]\n",
      "2025-09-07 20:11:52,451 - INFO - All types `lr` of epoch 367: {'lr/param_group0': 0.00018244581813418138, 'lr/param_group1': 0.00018244581813418138, 'lr/param_group2': 0.00018244581813418138, 'lr/param_group3': 0.00018244581813418138}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:52,463 - INFO - epoch 367: train loss 0.045584807344884785\n",
      "2025-09-07 20:11:52,466 - INFO - 367 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:52,474 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:52,482 - INFO - --------------------\n",
      "\n",
      "368/800: 100%|██████████| 216/216 [00:05<00:00, 40.12it/s]\n",
      "2025-09-07 20:11:58,045 - INFO - All types `lr` of epoch 368: {'lr/param_group0': 0.00018191998653118108, 'lr/param_group1': 0.00018191998653118108, 'lr/param_group2': 0.00018191998653118108, 'lr/param_group3': 0.00018191998653118108}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:11:58,058 - INFO - epoch 368: train loss 0.04600979520559863\n",
      "2025-09-07 20:11:58,067 - INFO - 368 epochs completed!\n",
      "\n",
      "2025-09-07 20:11:58,075 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:11:58,082 - INFO - --------------------\n",
      "\n",
      "369/800: 100%|██████████| 216/216 [00:05<00:00, 36.42it/s]\n",
      "2025-09-07 20:12:04,210 - INFO - All types `lr` of epoch 369: {'lr/param_group0': 0.00018139389400105742, 'lr/param_group1': 0.00018139389400105742, 'lr/param_group2': 0.00018139389400105742, 'lr/param_group3': 0.00018139389400105742}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:04,213 - INFO - epoch 369: train loss 0.046278299625825\n",
      "2025-09-07 20:12:04,223 - INFO - 369 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:04,225 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:04,233 - INFO - --------------------\n",
      "\n",
      "370/800: 100%|██████████| 216/216 [00:05<00:00, 36.25it/s]\n",
      "2025-09-07 20:12:10,380 - INFO - All types `lr` of epoch 370: {'lr/param_group0': 0.00018086754865680808, 'lr/param_group1': 0.00018086754865680808, 'lr/param_group2': 0.00018086754865680808, 'lr/param_group3': 0.00018086754865680808}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:10,393 - INFO - epoch 370: train loss 0.046065383228576846\n",
      "2025-09-07 20:12:10,402 - INFO - 370 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:10,410 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:10,417 - INFO - --------------------\n",
      "\n",
      "371/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:12:16,592 - INFO - All types `lr` of epoch 371: {'lr/param_group0': 0.00018034095861532937, 'lr/param_group1': 0.00018034095861532937, 'lr/param_group2': 0.00018034095861532937, 'lr/param_group3': 0.00018034095861532937}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:16,596 - INFO - epoch 371: train loss 0.04565277973327924\n",
      "2025-09-07 20:12:16,604 - INFO - 371 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:16,607 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:16,614 - INFO - --------------------\n",
      "\n",
      "372/800: 100%|██████████| 216/216 [00:06<00:00, 35.77it/s]\n",
      "2025-09-07 20:12:22,848 - INFO - All types `lr` of epoch 372: {'lr/param_group0': 0.0001798141319972911, 'lr/param_group1': 0.0001798141319972911, 'lr/param_group2': 0.0001798141319972911, 'lr/param_group3': 0.0001798141319972911}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:22,852 - INFO - epoch 372: train loss 0.04568237273229493\n",
      "2025-09-07 20:12:22,860 - INFO - 372 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:22,869 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:22,872 - INFO - --------------------\n",
      "\n",
      "373/800: 100%|██████████| 216/216 [00:05<00:00, 39.17it/s]\n",
      "2025-09-07 20:12:28,578 - INFO - All types `lr` of epoch 373: {'lr/param_group0': 0.0001792870769270115, 'lr/param_group1': 0.0001792870769270115, 'lr/param_group2': 0.0001792870769270115, 'lr/param_group3': 0.0001792870769270115}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:28,582 - INFO - epoch 373: train loss 0.04548051337608033\n",
      "2025-09-07 20:12:28,590 - INFO - 373 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:28,593 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:28,600 - INFO - --------------------\n",
      "\n",
      "374/800: 100%|██████████| 216/216 [00:05<00:00, 36.29it/s]\n",
      "2025-09-07 20:12:34,740 - INFO - All types `lr` of epoch 374: {'lr/param_group0': 0.0001787598015323317, 'lr/param_group1': 0.0001787598015323317, 'lr/param_group2': 0.0001787598015323317, 'lr/param_group3': 0.0001787598015323317}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:34,752 - INFO - epoch 374: train loss 0.04560837929171545\n",
      "2025-09-07 20:12:34,761 - INFO - 374 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:34,764 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:34,771 - INFO - --------------------\n",
      "\n",
      "375/800: 100%|██████████| 216/216 [00:05<00:00, 36.23it/s]\n",
      "2025-09-07 20:12:40,922 - INFO - All types `lr` of epoch 375: {'lr/param_group0': 0.0001782323139444907, 'lr/param_group1': 0.0001782323139444907, 'lr/param_group2': 0.0001782323139444907, 'lr/param_group3': 0.0001782323139444907}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:40,934 - INFO - epoch 375: train loss 0.04589302001383017\n",
      "2025-09-07 20:12:40,938 - INFO - 375 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:40,946 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:40,955 - INFO - --------------------\n",
      "\n",
      "376/800: 100%|██████████| 216/216 [00:06<00:00, 35.98it/s]\n",
      "2025-09-07 20:12:47,142 - INFO - All types `lr` of epoch 376: {'lr/param_group0': 0.00017770462229799942, 'lr/param_group1': 0.00017770462229799942, 'lr/param_group2': 0.00017770462229799942, 'lr/param_group3': 0.00017770462229799942}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:47,154 - INFO - epoch 376: train loss 0.045857389733471254\n",
      "2025-09-07 20:12:47,158 - INFO - 376 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:47,167 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:47,175 - INFO - --------------------\n",
      "\n",
      "377/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:12:53,489 - INFO - All types `lr` of epoch 377: {'lr/param_group0': 0.00017717673473051598, 'lr/param_group1': 0.00017717673473051598, 'lr/param_group2': 0.00017717673473051598, 'lr/param_group3': 0.00017717673473051598}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:53,500 - INFO - epoch 377: train loss 0.04550797723371674\n",
      "2025-09-07 20:12:53,509 - INFO - 377 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:53,512 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:53,519 - INFO - --------------------\n",
      "\n",
      "378/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:12:59,691 - INFO - All types `lr` of epoch 378: {'lr/param_group0': 0.00017664865938271966, 'lr/param_group1': 0.00017664865938271966, 'lr/param_group2': 0.00017664865938271966, 'lr/param_group3': 0.00017664865938271966}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:12:59,695 - INFO - epoch 378: train loss 0.045495317283051985\n",
      "2025-09-07 20:12:59,703 - INFO - 378 epochs completed!\n",
      "\n",
      "2025-09-07 20:12:59,711 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:12:59,714 - INFO - --------------------\n",
      "\n",
      "379/800: 100%|██████████| 216/216 [00:05<00:00, 41.25it/s]\n",
      "2025-09-07 20:13:05,131 - INFO - All types `lr` of epoch 379: {'lr/param_group0': 0.00017612040439818555, 'lr/param_group1': 0.00017612040439818555, 'lr/param_group2': 0.00017612040439818555, 'lr/param_group3': 0.00017612040439818555}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:05,143 - INFO - epoch 379: train loss 0.04542130514703415\n",
      "2025-09-07 20:13:05,147 - INFO - 379 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:05,156 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:05,163 - INFO - --------------------\n",
      "\n",
      "380/800: 100%|██████████| 216/216 [00:05<00:00, 38.95it/s]\n",
      "2025-09-07 20:13:10,887 - INFO - All types `lr` of epoch 380: {'lr/param_group0': 0.0001755919779232591, 'lr/param_group1': 0.0001755919779232591, 'lr/param_group2': 0.0001755919779232591, 'lr/param_group3': 0.0001755919779232591}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:10,891 - INFO - epoch 380: train loss 0.04606017627304903\n",
      "2025-09-07 20:13:10,902 - INFO - 380 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:10,911 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:10,914 - INFO - --------------------\n",
      "\n",
      "381/800: 100%|██████████| 216/216 [00:05<00:00, 36.27it/s]\n",
      "2025-09-07 20:13:17,056 - INFO - All types `lr` of epoch 381: {'lr/param_group0': 0.0001750633881069301, 'lr/param_group1': 0.0001750633881069301, 'lr/param_group2': 0.0001750633881069301, 'lr/param_group3': 0.0001750633881069301}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:17,068 - INFO - epoch 381: train loss 0.04560363273722706\n",
      "2025-09-07 20:13:17,077 - INFO - 381 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:17,080 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:17,088 - INFO - --------------------\n",
      "\n",
      "382/800: 100%|██████████| 216/216 [00:05<00:00, 36.89it/s]\n",
      "2025-09-07 20:13:23,140 - INFO - All types `lr` of epoch 382: {'lr/param_group0': 0.00017453464310070749, 'lr/param_group1': 0.00017453464310070749, 'lr/param_group2': 0.00017453464310070749, 'lr/param_group3': 0.00017453464310070749}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:23,152 - INFO - epoch 382: train loss 0.045360068773367894\n",
      "2025-09-07 20:13:23,161 - INFO - 382 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:23,164 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:23,172 - INFO - --------------------\n",
      "\n",
      "383/800: 100%|██████████| 216/216 [00:04<00:00, 46.90it/s]\n",
      "2025-09-07 20:13:27,952 - INFO - All types `lr` of epoch 383: {'lr/param_group0': 0.00017400575105849336, 'lr/param_group1': 0.00017400575105849336, 'lr/param_group2': 0.00017400575105849336, 'lr/param_group3': 0.00017400575105849336}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:27,962 - INFO - epoch 383: train loss 0.0454911261934925\n",
      "2025-09-07 20:13:27,971 - INFO - 383 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:27,975 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:27,982 - INFO - --------------------\n",
      "\n",
      "384/800: 100%|██████████| 216/216 [00:05<00:00, 38.66it/s]\n",
      "2025-09-07 20:13:33,759 - INFO - All types `lr` of epoch 384: {'lr/param_group0': 0.0001734767201364573, 'lr/param_group1': 0.0001734767201364573, 'lr/param_group2': 0.0001734767201364573, 'lr/param_group3': 0.0001734767201364573}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:33,771 - INFO - epoch 384: train loss 0.04525046409280212\n",
      "2025-09-07 20:13:33,775 - INFO - 384 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:33,782 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:33,791 - INFO - --------------------\n",
      "\n",
      "385/800: 100%|██████████| 216/216 [00:05<00:00, 43.11it/s]\n",
      "2025-09-07 20:13:38,983 - INFO - All types `lr` of epoch 385: {'lr/param_group0': 0.00017294755849291048, 'lr/param_group1': 0.00017294755849291048, 'lr/param_group2': 0.00017294755849291048, 'lr/param_group3': 0.00017294755849291048}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:38,990 - INFO - epoch 385: train loss 0.045469008955276675\n",
      "2025-09-07 20:13:39,006 - INFO - 385 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:39,016 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:39,019 - INFO - --------------------\n",
      "\n",
      "386/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 20:13:45,135 - INFO - All types `lr` of epoch 386: {'lr/param_group0': 0.00017241827428818017, 'lr/param_group1': 0.00017241827428818017, 'lr/param_group2': 0.00017241827428818017, 'lr/param_group3': 0.00017241827428818017}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:45,139 - INFO - epoch 386: train loss 0.04540561296528688\n",
      "2025-09-07 20:13:45,147 - INFO - 386 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:45,155 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:45,158 - INFO - --------------------\n",
      "\n",
      "387/800: 100%|██████████| 216/216 [00:05<00:00, 36.45it/s]\n",
      "2025-09-07 20:13:51,281 - INFO - All types `lr` of epoch 387: {'lr/param_group0': 0.00017188887568448345, 'lr/param_group1': 0.00017188887568448345, 'lr/param_group2': 0.00017188887568448345, 'lr/param_group3': 0.00017188887568448345}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:51,285 - INFO - epoch 387: train loss 0.0448778880139192\n",
      "2025-09-07 20:13:51,294 - INFO - 387 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:51,301 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:51,304 - INFO - --------------------\n",
      "\n",
      "388/800: 100%|██████████| 216/216 [00:05<00:00, 36.35it/s]\n",
      "2025-09-07 20:13:57,430 - INFO - All types `lr` of epoch 388: {'lr/param_group0': 0.00017135937084580176, 'lr/param_group1': 0.00017135937084580176, 'lr/param_group2': 0.00017135937084580176, 'lr/param_group3': 0.00017135937084580176}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:13:57,442 - INFO - epoch 388: train loss 0.04539086454099527\n",
      "2025-09-07 20:13:57,446 - INFO - 388 epochs completed!\n",
      "\n",
      "2025-09-07 20:13:57,454 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:13:57,462 - INFO - --------------------\n",
      "\n",
      "389/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:14:03,632 - INFO - All types `lr` of epoch 389: {'lr/param_group0': 0.00017082976793775467, 'lr/param_group1': 0.00017082976793775467, 'lr/param_group2': 0.00017082976793775467, 'lr/param_group3': 0.00017082976793775467}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:03,643 - INFO - epoch 389: train loss 0.04537354839137859\n",
      "2025-09-07 20:14:03,653 - INFO - 389 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:03,656 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:03,663 - INFO - --------------------\n",
      "\n",
      "390/800: 100%|██████████| 216/216 [00:06<00:00, 35.86it/s]\n",
      "2025-09-07 20:14:09,882 - INFO - All types `lr` of epoch 390: {'lr/param_group0': 0.00017030007512747425, 'lr/param_group1': 0.00017030007512747425, 'lr/param_group2': 0.00017030007512747425, 'lr/param_group3': 0.00017030007512747425}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:09,886 - INFO - epoch 390: train loss 0.04540754504570806\n",
      "2025-09-07 20:14:09,895 - INFO - 390 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:09,902 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:09,906 - INFO - --------------------\n",
      "\n",
      "391/800: 100%|██████████| 216/216 [00:06<00:00, 35.88it/s]\n",
      "2025-09-07 20:14:16,122 - INFO - All types `lr` of epoch 391: {'lr/param_group0': 0.00016977030058347884, 'lr/param_group1': 0.00016977030058347884, 'lr/param_group2': 0.00016977030058347884, 'lr/param_group3': 0.00016977030058347884}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:16,126 - INFO - epoch 391: train loss 0.04525983343935675\n",
      "2025-09-07 20:14:16,135 - INFO - 391 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:16,144 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:16,152 - INFO - --------------------\n",
      "\n",
      "392/800: 100%|██████████| 216/216 [00:06<00:00, 35.91it/s]\n",
      "2025-09-07 20:14:22,361 - INFO - All types `lr` of epoch 392: {'lr/param_group0': 0.0001692404524755473, 'lr/param_group1': 0.0001692404524755473, 'lr/param_group2': 0.0001692404524755473, 'lr/param_group3': 0.0001692404524755473}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:22,365 - INFO - epoch 392: train loss 0.04536345249248876\n",
      "2025-09-07 20:14:22,375 - INFO - 392 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:22,377 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:22,385 - INFO - --------------------\n",
      "\n",
      "393/800: 100%|██████████| 216/216 [00:05<00:00, 36.04it/s]\n",
      "2025-09-07 20:14:28,566 - INFO - All types `lr` of epoch 393: {'lr/param_group0': 0.00016871053897459296, 'lr/param_group1': 0.00016871053897459296, 'lr/param_group2': 0.00016871053897459296, 'lr/param_group3': 0.00016871053897459296}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:28,579 - INFO - epoch 393: train loss 0.045274658887474624\n",
      "2025-09-07 20:14:28,589 - INFO - 393 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:28,597 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:28,604 - INFO - --------------------\n",
      "\n",
      "394/800: 100%|██████████| 216/216 [00:06<00:00, 33.74it/s]\n",
      "2025-09-07 20:14:35,205 - INFO - All types `lr` of epoch 394: {'lr/param_group0': 0.00016818056825253737, 'lr/param_group1': 0.00016818056825253737, 'lr/param_group2': 0.00016818056825253737, 'lr/param_group3': 0.00016818056825253737}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:35,209 - INFO - epoch 394: train loss 0.04522524382574139\n",
      "2025-09-07 20:14:35,219 - INFO - 394 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:35,221 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:35,229 - INFO - --------------------\n",
      "\n",
      "395/800: 100%|██████████| 216/216 [00:05<00:00, 36.45it/s]\n",
      "2025-09-07 20:14:41,345 - INFO - All types `lr` of epoch 395: {'lr/param_group0': 0.00016765054848218484, 'lr/param_group1': 0.00016765054848218484, 'lr/param_group2': 0.00016765054848218484, 'lr/param_group3': 0.00016765054848218484}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:41,356 - INFO - epoch 395: train loss 0.045116270909568774\n",
      "2025-09-07 20:14:41,360 - INFO - 395 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:41,368 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:41,376 - INFO - --------------------\n",
      "\n",
      "396/800: 100%|██████████| 216/216 [00:05<00:00, 36.18it/s]\n",
      "2025-09-07 20:14:47,532 - INFO - All types `lr` of epoch 396: {'lr/param_group0': 0.00016712048783709574, 'lr/param_group1': 0.00016712048783709574, 'lr/param_group2': 0.00016712048783709574, 'lr/param_group3': 0.00016712048783709574}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:47,536 - INFO - epoch 396: train loss 0.04525557482891061\n",
      "2025-09-07 20:14:47,545 - INFO - 396 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:47,553 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:47,556 - INFO - --------------------\n",
      "\n",
      "397/800: 100%|██████████| 216/216 [00:06<00:00, 35.80it/s]\n",
      "2025-09-07 20:14:53,782 - INFO - All types `lr` of epoch 397: {'lr/param_group0': 0.00016659039449146113, 'lr/param_group1': 0.00016659039449146113, 'lr/param_group2': 0.00016659039449146113, 'lr/param_group3': 0.00016659039449146113}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:14:53,786 - INFO - epoch 397: train loss 0.0453525273370798\n",
      "2025-09-07 20:14:53,794 - INFO - 397 epochs completed!\n",
      "\n",
      "2025-09-07 20:14:53,802 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:14:53,805 - INFO - --------------------\n",
      "\n",
      "398/800: 100%|██████████| 216/216 [00:06<00:00, 35.67it/s]\n",
      "2025-09-07 20:15:00,056 - INFO - All types `lr` of epoch 398: {'lr/param_group0': 0.000166060276619976, 'lr/param_group1': 0.000166060276619976, 'lr/param_group2': 0.000166060276619976, 'lr/param_group3': 0.000166060276619976}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:00,060 - INFO - epoch 398: train loss 0.04536098441867917\n",
      "2025-09-07 20:15:00,069 - INFO - 398 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:00,077 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:00,080 - INFO - --------------------\n",
      "\n",
      "399/800: 100%|██████████| 216/216 [00:05<00:00, 37.05it/s]\n",
      "2025-09-07 20:15:06,097 - INFO - All types `lr` of epoch 399: {'lr/param_group0': 0.0001655301423977138, 'lr/param_group1': 0.0001655301423977138, 'lr/param_group2': 0.0001655301423977138, 'lr/param_group3': 0.0001655301423977138}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:06,110 - INFO - epoch 399: train loss 0.04540463571471197\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.49it/s]\n",
      "2025-09-07 20:15:07,591 - INFO - epoch 399: val loss 0.058798284649297046\n",
      "2025-09-07 20:15:07,604 - INFO - 399 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:15:07,709 - INFO - epoch 399 has been saved\n",
      "2025-09-07 20:15:07,938 - INFO - 399 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:07,941 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:07,944 - INFO - --------------------\n",
      "\n",
      "400/800: 100%|██████████| 216/216 [00:05<00:00, 37.91it/s]\n",
      "2025-09-07 20:15:13,830 - INFO - All types `lr` of epoch 400: {'lr/param_group0': 0.000165, 'lr/param_group1': 0.000165, 'lr/param_group2': 0.000165, 'lr/param_group3': 0.000165}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:13,841 - INFO - epoch 400: train loss 0.04512129372192754\n",
      "2025-09-07 20:15:13,849 - INFO - 400 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:13,852 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:13,860 - INFO - --------------------\n",
      "\n",
      "401/800: 100%|██████████| 216/216 [00:05<00:00, 39.45it/s]\n",
      "2025-09-07 20:15:19,515 - INFO - All types `lr` of epoch 401: {'lr/param_group0': 0.0001644698576022862, 'lr/param_group1': 0.0001644698576022862, 'lr/param_group2': 0.0001644698576022862, 'lr/param_group3': 0.0001644698576022862}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:19,526 - INFO - epoch 401: train loss 0.04529338645645314\n",
      "2025-09-07 20:15:19,535 - INFO - 401 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:19,538 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:19,546 - INFO - --------------------\n",
      "\n",
      "402/800: 100%|██████████| 216/216 [00:06<00:00, 35.68it/s]\n",
      "2025-09-07 20:15:25,789 - INFO - All types `lr` of epoch 402: {'lr/param_group0': 0.00016393972338002395, 'lr/param_group1': 0.00016393972338002395, 'lr/param_group2': 0.00016393972338002395, 'lr/param_group3': 0.00016393972338002395}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:25,801 - INFO - epoch 402: train loss 0.04526562983584073\n",
      "2025-09-07 20:15:25,811 - INFO - 402 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:25,814 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:25,822 - INFO - --------------------\n",
      "\n",
      "403/800: 100%|██████████| 216/216 [00:05<00:00, 37.70it/s]\n",
      "2025-09-07 20:15:31,742 - INFO - All types `lr` of epoch 403: {'lr/param_group0': 0.00016340960550853884, 'lr/param_group1': 0.00016340960550853884, 'lr/param_group2': 0.00016340960550853884, 'lr/param_group3': 0.00016340960550853884}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:31,753 - INFO - epoch 403: train loss 0.04510983084845874\n",
      "2025-09-07 20:15:31,762 - INFO - 403 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:31,765 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:31,773 - INFO - --------------------\n",
      "\n",
      "404/800: 100%|██████████| 216/216 [00:05<00:00, 37.77it/s]\n",
      "2025-09-07 20:15:37,671 - INFO - All types `lr` of epoch 404: {'lr/param_group0': 0.0001628795121629042, 'lr/param_group1': 0.0001628795121629042, 'lr/param_group2': 0.0001628795121629042, 'lr/param_group3': 0.0001628795121629042}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:37,683 - INFO - epoch 404: train loss 0.04529863256202252\n",
      "2025-09-07 20:15:37,686 - INFO - 404 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:37,694 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:37,702 - INFO - --------------------\n",
      "\n",
      "405/800: 100%|██████████| 216/216 [00:05<00:00, 36.56it/s]\n",
      "2025-09-07 20:15:43,779 - INFO - All types `lr` of epoch 405: {'lr/param_group0': 0.00016234945151781516, 'lr/param_group1': 0.00016234945151781516, 'lr/param_group2': 0.00016234945151781516, 'lr/param_group3': 0.00016234945151781516}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:43,790 - INFO - epoch 405: train loss 0.04511807326020466\n",
      "2025-09-07 20:15:43,794 - INFO - 405 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:43,802 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:43,810 - INFO - --------------------\n",
      "\n",
      "406/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:15:49,992 - INFO - All types `lr` of epoch 406: {'lr/param_group0': 0.00016181943174746263, 'lr/param_group1': 0.00016181943174746263, 'lr/param_group2': 0.00016181943174746263, 'lr/param_group3': 0.00016181943174746263}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:49,996 - INFO - epoch 406: train loss 0.04514068073627574\n",
      "2025-09-07 20:15:50,004 - INFO - 406 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:50,013 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:50,016 - INFO - --------------------\n",
      "\n",
      "407/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:15:56,225 - INFO - All types `lr` of epoch 407: {'lr/param_group0': 0.00016128946102540704, 'lr/param_group1': 0.00016128946102540704, 'lr/param_group2': 0.00016128946102540704, 'lr/param_group3': 0.00016128946102540704}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:15:56,230 - INFO - epoch 407: train loss 0.04497984703630209\n",
      "2025-09-07 20:15:56,239 - INFO - 407 epochs completed!\n",
      "\n",
      "2025-09-07 20:15:56,248 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:15:56,251 - INFO - --------------------\n",
      "\n",
      "408/800: 100%|██████████| 216/216 [00:06<00:00, 35.89it/s]\n",
      "2025-09-07 20:16:02,473 - INFO - All types `lr` of epoch 408: {'lr/param_group0': 0.00016075954752445268, 'lr/param_group1': 0.00016075954752445268, 'lr/param_group2': 0.00016075954752445268, 'lr/param_group3': 0.00016075954752445268}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:02,478 - INFO - epoch 408: train loss 0.044921656156441676\n",
      "2025-09-07 20:16:02,490 - INFO - 408 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:02,499 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:02,502 - INFO - --------------------\n",
      "\n",
      "409/800: 100%|██████████| 216/216 [00:05<00:00, 36.25it/s]\n",
      "2025-09-07 20:16:08,649 - INFO - All types `lr` of epoch 409: {'lr/param_group0': 0.00016022969941652116, 'lr/param_group1': 0.00016022969941652116, 'lr/param_group2': 0.00016022969941652116, 'lr/param_group3': 0.00016022969941652116}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:08,661 - INFO - epoch 409: train loss 0.044731924362066716\n",
      "2025-09-07 20:16:08,665 - INFO - 409 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:08,673 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:08,681 - INFO - --------------------\n",
      "\n",
      "410/800: 100%|██████████| 216/216 [00:04<00:00, 45.13it/s]\n",
      "2025-09-07 20:16:13,658 - INFO - All types `lr` of epoch 410: {'lr/param_group0': 0.00015969992487252575, 'lr/param_group1': 0.00015969992487252575, 'lr/param_group2': 0.00015969992487252575, 'lr/param_group3': 0.00015969992487252575}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:13,663 - INFO - epoch 410: train loss 0.04452974718340017\n",
      "2025-09-07 20:16:13,672 - INFO - 410 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:13,680 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:13,683 - INFO - --------------------\n",
      "\n",
      "411/800: 100%|██████████| 216/216 [00:04<00:00, 46.12it/s]\n",
      "2025-09-07 20:16:18,565 - INFO - All types `lr` of epoch 411: {'lr/param_group0': 0.0001591702320622453, 'lr/param_group1': 0.0001591702320622453, 'lr/param_group2': 0.0001591702320622453, 'lr/param_group3': 0.0001591702320622453}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:18,569 - INFO - epoch 411: train loss 0.044966731358457496\n",
      "2025-09-07 20:16:18,578 - INFO - 411 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:18,586 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:18,590 - INFO - --------------------\n",
      "\n",
      "412/800: 100%|██████████| 216/216 [00:05<00:00, 37.57it/s]\n",
      "2025-09-07 20:16:24,529 - INFO - All types `lr` of epoch 412: {'lr/param_group0': 0.00015864062915419823, 'lr/param_group1': 0.00015864062915419823, 'lr/param_group2': 0.00015864062915419823, 'lr/param_group3': 0.00015864062915419823}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:24,541 - INFO - epoch 412: train loss 0.04512278204438863\n",
      "2025-09-07 20:16:24,545 - INFO - 412 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:24,554 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:24,562 - INFO - --------------------\n",
      "\n",
      "413/800: 100%|██████████| 216/216 [00:05<00:00, 37.32it/s]\n",
      "2025-09-07 20:16:30,533 - INFO - All types `lr` of epoch 413: {'lr/param_group0': 0.00015811112431551654, 'lr/param_group1': 0.00015811112431551654, 'lr/param_group2': 0.00015811112431551654, 'lr/param_group3': 0.00015811112431551654}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:30,546 - INFO - epoch 413: train loss 0.044665938381243636\n",
      "2025-09-07 20:16:30,549 - INFO - 413 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:30,558 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:30,566 - INFO - --------------------\n",
      "\n",
      "414/800: 100%|██████████| 216/216 [00:05<00:00, 36.82it/s]\n",
      "2025-09-07 20:16:36,615 - INFO - All types `lr` of epoch 414: {'lr/param_group0': 0.0001575817257118198, 'lr/param_group1': 0.0001575817257118198, 'lr/param_group2': 0.0001575817257118198, 'lr/param_group3': 0.0001575817257118198}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:36,627 - INFO - epoch 414: train loss 0.044982624930088165\n",
      "2025-09-07 20:16:36,631 - INFO - 414 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:36,640 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:36,649 - INFO - --------------------\n",
      "\n",
      "415/800: 100%|██████████| 216/216 [00:05<00:00, 36.89it/s]\n",
      "2025-09-07 20:16:42,688 - INFO - All types `lr` of epoch 415: {'lr/param_group0': 0.00015705244150708943, 'lr/param_group1': 0.00015705244150708943, 'lr/param_group2': 0.00015705244150708943, 'lr/param_group3': 0.00015705244150708943}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:42,691 - INFO - epoch 415: train loss 0.0448380015031607\n",
      "2025-09-07 20:16:42,699 - INFO - 415 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:42,708 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:42,711 - INFO - --------------------\n",
      "\n",
      "416/800: 100%|██████████| 216/216 [00:05<00:00, 42.43it/s]\n",
      "2025-09-07 20:16:47,989 - INFO - All types `lr` of epoch 416: {'lr/param_group0': 0.00015652327986354265, 'lr/param_group1': 0.00015652327986354265, 'lr/param_group2': 0.00015652327986354265, 'lr/param_group3': 0.00015652327986354265}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:48,001 - INFO - epoch 416: train loss 0.044772048877483164\n",
      "2025-09-07 20:16:48,010 - INFO - 416 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:48,013 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:48,021 - INFO - --------------------\n",
      "\n",
      "417/800: 100%|██████████| 216/216 [00:05<00:00, 37.13it/s]\n",
      "2025-09-07 20:16:54,036 - INFO - All types `lr` of epoch 417: {'lr/param_group0': 0.00015599424894150663, 'lr/param_group1': 0.00015599424894150663, 'lr/param_group2': 0.00015599424894150663, 'lr/param_group3': 0.00015599424894150663}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:16:54,040 - INFO - epoch 417: train loss 0.04496683837432\n",
      "2025-09-07 20:16:54,049 - INFO - 417 epochs completed!\n",
      "\n",
      "2025-09-07 20:16:54,058 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:16:54,061 - INFO - --------------------\n",
      "\n",
      "418/800: 100%|██████████| 216/216 [00:05<00:00, 36.81it/s]\n",
      "2025-09-07 20:17:00,115 - INFO - All types `lr` of epoch 418: {'lr/param_group0': 0.0001554653568992925, 'lr/param_group1': 0.0001554653568992925, 'lr/param_group2': 0.0001554653568992925, 'lr/param_group3': 0.0001554653568992925}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:00,127 - INFO - epoch 418: train loss 0.04469426476431114\n",
      "2025-09-07 20:17:00,131 - INFO - 418 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:00,140 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:00,148 - INFO - --------------------\n",
      "\n",
      "419/800: 100%|██████████| 216/216 [00:05<00:00, 37.05it/s]\n",
      "2025-09-07 20:17:06,155 - INFO - All types `lr` of epoch 419: {'lr/param_group0': 0.0001549366118930699, 'lr/param_group1': 0.0001549366118930699, 'lr/param_group2': 0.0001549366118930699, 'lr/param_group3': 0.0001549366118930699}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:06,167 - INFO - epoch 419: train loss 0.04493796551186177\n",
      "2025-09-07 20:17:06,171 - INFO - 419 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:06,179 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:06,187 - INFO - --------------------\n",
      "\n",
      "420/800: 100%|██████████| 216/216 [00:05<00:00, 36.96it/s]\n",
      "2025-09-07 20:17:12,213 - INFO - All types `lr` of epoch 420: {'lr/param_group0': 0.0001544080220767409, 'lr/param_group1': 0.0001544080220767409, 'lr/param_group2': 0.0001544080220767409, 'lr/param_group3': 0.0001544080220767409}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:12,225 - INFO - epoch 420: train loss 0.04477010337911822\n",
      "2025-09-07 20:17:12,229 - INFO - 420 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:12,237 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:12,245 - INFO - --------------------\n",
      "\n",
      "421/800: 100%|██████████| 216/216 [00:05<00:00, 39.65it/s]\n",
      "2025-09-07 20:17:17,873 - INFO - All types `lr` of epoch 421: {'lr/param_group0': 0.00015387959560181442, 'lr/param_group1': 0.00015387959560181442, 'lr/param_group2': 0.00015387959560181442, 'lr/param_group3': 0.00015387959560181442}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:17,886 - INFO - epoch 421: train loss 0.044593456891123893\n",
      "2025-09-07 20:17:17,890 - INFO - 421 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:17,898 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:17,907 - INFO - --------------------\n",
      "\n",
      "422/800: 100%|██████████| 216/216 [00:05<00:00, 39.10it/s]\n",
      "2025-09-07 20:17:23,614 - INFO - All types `lr` of epoch 422: {'lr/param_group0': 0.00015335134061728034, 'lr/param_group1': 0.00015335134061728034, 'lr/param_group2': 0.00015335134061728034, 'lr/param_group3': 0.00015335134061728034}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:23,626 - INFO - epoch 422: train loss 0.04498074062306572\n",
      "2025-09-07 20:17:23,630 - INFO - 422 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:23,639 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:23,647 - INFO - --------------------\n",
      "\n",
      "423/800: 100%|██████████| 216/216 [00:04<00:00, 45.70it/s]\n",
      "2025-09-07 20:17:28,558 - INFO - All types `lr` of epoch 423: {'lr/param_group0': 0.00015282326526948402, 'lr/param_group1': 0.00015282326526948402, 'lr/param_group2': 0.00015282326526948402, 'lr/param_group3': 0.00015282326526948402}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:28,573 - INFO - epoch 423: train loss 0.044499594166322994\n",
      "2025-09-07 20:17:28,583 - INFO - 423 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:28,591 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:28,600 - INFO - --------------------\n",
      "\n",
      "424/800: 100%|██████████| 216/216 [00:05<00:00, 39.67it/s]\n",
      "2025-09-07 20:17:34,241 - INFO - All types `lr` of epoch 424: {'lr/param_group0': 0.00015229537770200055, 'lr/param_group1': 0.00015229537770200055, 'lr/param_group2': 0.00015229537770200055, 'lr/param_group3': 0.00015229537770200055}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:34,253 - INFO - epoch 424: train loss 0.044553954585420864\n",
      "2025-09-07 20:17:34,264 - INFO - 424 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:34,272 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:34,279 - INFO - --------------------\n",
      "\n",
      "425/800: 100%|██████████| 216/216 [00:05<00:00, 39.03it/s]\n",
      "2025-09-07 20:17:39,979 - INFO - All types `lr` of epoch 425: {'lr/param_group0': 0.0001517676860555093, 'lr/param_group1': 0.0001517676860555093, 'lr/param_group2': 0.0001517676860555093, 'lr/param_group3': 0.0001517676860555093}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:39,991 - INFO - epoch 425: train loss 0.044499558983025725\n",
      "2025-09-07 20:17:40,001 - INFO - 425 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:40,004 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:40,013 - INFO - --------------------\n",
      "\n",
      "426/800: 100%|██████████| 216/216 [00:05<00:00, 36.70it/s]\n",
      "2025-09-07 20:17:46,089 - INFO - All types `lr` of epoch 426: {'lr/param_group0': 0.0001512401984676682, 'lr/param_group1': 0.0001512401984676682, 'lr/param_group2': 0.0001512401984676682, 'lr/param_group3': 0.0001512401984676682}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:46,102 - INFO - epoch 426: train loss 0.04448256971038602\n",
      "2025-09-07 20:17:46,106 - INFO - 426 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:46,115 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:46,125 - INFO - --------------------\n",
      "\n",
      "427/800: 100%|██████████| 216/216 [00:05<00:00, 36.32it/s]\n",
      "2025-09-07 20:17:52,274 - INFO - All types `lr` of epoch 427: {'lr/param_group0': 0.00015071292307298844, 'lr/param_group1': 0.00015071292307298844, 'lr/param_group2': 0.00015071292307298844, 'lr/param_group3': 0.00015071292307298844}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:52,278 - INFO - epoch 427: train loss 0.044676508081869945\n",
      "2025-09-07 20:17:52,287 - INFO - 427 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:52,298 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:52,307 - INFO - --------------------\n",
      "\n",
      "428/800: 100%|██████████| 216/216 [00:05<00:00, 36.98it/s]\n",
      "2025-09-07 20:17:58,339 - INFO - All types `lr` of epoch 428: {'lr/param_group0': 0.0001501858680027089, 'lr/param_group1': 0.0001501858680027089, 'lr/param_group2': 0.0001501858680027089, 'lr/param_group3': 0.0001501858680027089}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:17:58,352 - INFO - epoch 428: train loss 0.04483528121340054\n",
      "2025-09-07 20:17:58,363 - INFO - 428 epochs completed!\n",
      "\n",
      "2025-09-07 20:17:58,372 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:17:58,381 - INFO - --------------------\n",
      "\n",
      "429/800: 100%|██████████| 216/216 [00:05<00:00, 36.57it/s]\n",
      "2025-09-07 20:18:04,478 - INFO - All types `lr` of epoch 429: {'lr/param_group0': 0.0001496590413846706, 'lr/param_group1': 0.0001496590413846706, 'lr/param_group2': 0.0001496590413846706, 'lr/param_group3': 0.0001496590413846706}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:04,492 - INFO - epoch 429: train loss 0.04451327707135567\n",
      "2025-09-07 20:18:04,495 - INFO - 429 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:04,504 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:04,507 - INFO - --------------------\n",
      "\n",
      "430/800: 100%|██████████| 216/216 [00:05<00:00, 40.44it/s]\n",
      "2025-09-07 20:18:10,038 - INFO - All types `lr` of epoch 430: {'lr/param_group0': 0.00014913245134319191, 'lr/param_group1': 0.00014913245134319191, 'lr/param_group2': 0.00014913245134319191, 'lr/param_group3': 0.00014913245134319191}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:10,050 - INFO - epoch 430: train loss 0.0448478737294122\n",
      "2025-09-07 20:18:10,060 - INFO - 430 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:10,063 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:10,071 - INFO - --------------------\n",
      "\n",
      "431/800: 100%|██████████| 216/216 [00:05<00:00, 36.50it/s]\n",
      "2025-09-07 20:18:16,190 - INFO - All types `lr` of epoch 431: {'lr/param_group0': 0.00014860610599894258, 'lr/param_group1': 0.00014860610599894258, 'lr/param_group2': 0.00014860610599894258, 'lr/param_group3': 0.00014860610599894258}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:16,194 - INFO - epoch 431: train loss 0.04453209670329535\n",
      "2025-09-07 20:18:16,203 - INFO - 431 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:16,213 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:16,217 - INFO - --------------------\n",
      "\n",
      "432/800: 100%|██████████| 216/216 [00:05<00:00, 38.88it/s]\n",
      "2025-09-07 20:18:21,961 - INFO - All types `lr` of epoch 432: {'lr/param_group0': 0.0001480800134688189, 'lr/param_group1': 0.0001480800134688189, 'lr/param_group2': 0.0001480800134688189, 'lr/param_group3': 0.0001480800134688189}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:21,972 - INFO - epoch 432: train loss 0.044450040768693994\n",
      "2025-09-07 20:18:21,982 - INFO - 432 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:21,986 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:21,994 - INFO - --------------------\n",
      "\n",
      "433/800: 100%|██████████| 216/216 [00:05<00:00, 36.39it/s]\n",
      "2025-09-07 20:18:28,125 - INFO - All types `lr` of epoch 433: {'lr/param_group0': 0.0001475541818658186, 'lr/param_group1': 0.0001475541818658186, 'lr/param_group2': 0.0001475541818658186, 'lr/param_group3': 0.0001475541818658186}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:28,138 - INFO - epoch 433: train loss 0.04458246947507615\n",
      "2025-09-07 20:18:28,141 - INFO - 433 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:28,150 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:28,159 - INFO - --------------------\n",
      "\n",
      "434/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:18:34,352 - INFO - All types `lr` of epoch 434: {'lr/param_group0': 0.00014702861929891546, 'lr/param_group1': 0.00014702861929891546, 'lr/param_group2': 0.00014702861929891546, 'lr/param_group3': 0.00014702861929891546}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:34,363 - INFO - epoch 434: train loss 0.04430659751718243\n",
      "2025-09-07 20:18:34,373 - INFO - 434 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:34,376 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:34,384 - INFO - --------------------\n",
      "\n",
      "435/800: 100%|██████████| 216/216 [00:05<00:00, 36.42it/s]\n",
      "2025-09-07 20:18:40,516 - INFO - All types `lr` of epoch 435: {'lr/param_group0': 0.0001465033338729343, 'lr/param_group1': 0.0001465033338729343, 'lr/param_group2': 0.0001465033338729343, 'lr/param_group3': 0.0001465033338729343}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:40,520 - INFO - epoch 435: train loss 0.0445200648262269\n",
      "2025-09-07 20:18:40,530 - INFO - 435 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:40,540 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:40,549 - INFO - --------------------\n",
      "\n",
      "436/800: 100%|██████████| 216/216 [00:06<00:00, 35.98it/s]\n",
      "2025-09-07 20:18:46,749 - INFO - All types `lr` of epoch 436: {'lr/param_group0': 0.00014597833368842634, 'lr/param_group1': 0.00014597833368842634, 'lr/param_group2': 0.00014597833368842634, 'lr/param_group3': 0.00014597833368842634}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:46,753 - INFO - epoch 436: train loss 0.04441233043110481\n",
      "2025-09-07 20:18:46,762 - INFO - 436 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:46,765 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:46,773 - INFO - --------------------\n",
      "\n",
      "437/800: 100%|██████████| 216/216 [00:06<00:00, 35.86it/s]\n",
      "2025-09-07 20:18:52,984 - INFO - All types `lr` of epoch 437: {'lr/param_group0': 0.0001454536268415438, 'lr/param_group1': 0.0001454536268415438, 'lr/param_group2': 0.0001454536268415438, 'lr/param_group3': 0.0001454536268415438}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:52,998 - INFO - epoch 437: train loss 0.04408640371359609\n",
      "2025-09-07 20:18:53,008 - INFO - 437 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:53,017 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:53,026 - INFO - --------------------\n",
      "\n",
      "438/800: 100%|██████████| 216/216 [00:06<00:00, 35.60it/s]\n",
      "2025-09-07 20:18:59,290 - INFO - All types `lr` of epoch 438: {'lr/param_group0': 0.00014492922142391538, 'lr/param_group1': 0.00014492922142391538, 'lr/param_group2': 0.00014492922142391538, 'lr/param_group3': 0.00014492922142391538}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:18:59,304 - INFO - epoch 438: train loss 0.04450083110067579\n",
      "2025-09-07 20:18:59,315 - INFO - 438 epochs completed!\n",
      "\n",
      "2025-09-07 20:18:59,324 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:18:59,332 - INFO - --------------------\n",
      "\n",
      "439/800: 100%|██████████| 216/216 [00:06<00:00, 35.88it/s]\n",
      "2025-09-07 20:19:05,549 - INFO - All types `lr` of epoch 439: {'lr/param_group0': 0.00014440512552252134, 'lr/param_group1': 0.00014440512552252134, 'lr/param_group2': 0.00014440512552252134, 'lr/param_group3': 0.00014440512552252134}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:05,553 - INFO - epoch 439: train loss 0.04416867856074263\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.84it/s]\n",
      "2025-09-07 20:19:07,043 - INFO - epoch 439: val loss 0.05857258917832816\n",
      "2025-09-07 20:19:07,048 - INFO - 439 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:19:07,061 - INFO - 439 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:07,070 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:07,073 - INFO - --------------------\n",
      "\n",
      "440/800: 100%|██████████| 216/216 [00:05<00:00, 36.28it/s]\n",
      "2025-09-07 20:19:13,230 - INFO - All types `lr` of epoch 440: {'lr/param_group0': 0.00014388134721956883, 'lr/param_group1': 0.00014388134721956883, 'lr/param_group2': 0.00014388134721956883, 'lr/param_group3': 0.00014388134721956883}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:13,242 - INFO - epoch 440: train loss 0.04421482978526641\n",
      "2025-09-07 20:19:13,252 - INFO - 440 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:13,255 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:13,264 - INFO - --------------------\n",
      "\n",
      "441/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:19:19,432 - INFO - All types `lr` of epoch 441: {'lr/param_group0': 0.0001433578945923672, 'lr/param_group1': 0.0001433578945923672, 'lr/param_group2': 0.0001433578945923672, 'lr/param_group3': 0.0001433578945923672}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:19,444 - INFO - epoch 441: train loss 0.04423722728259034\n",
      "2025-09-07 20:19:19,454 - INFO - 441 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:19,458 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:19,466 - INFO - --------------------\n",
      "\n",
      "442/800: 100%|██████████| 216/216 [00:06<00:00, 35.54it/s]\n",
      "2025-09-07 20:19:25,744 - INFO - All types `lr` of epoch 442: {'lr/param_group0': 0.00014283477571320346, 'lr/param_group1': 0.00014283477571320346, 'lr/param_group2': 0.00014283477571320346, 'lr/param_group3': 0.00014283477571320346}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:25,756 - INFO - epoch 442: train loss 0.04423845887046169\n",
      "2025-09-07 20:19:25,766 - INFO - 442 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:25,769 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:25,778 - INFO - --------------------\n",
      "\n",
      "443/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:19:31,988 - INFO - All types `lr` of epoch 443: {'lr/param_group0': 0.000142311998649218, 'lr/param_group1': 0.000142311998649218, 'lr/param_group2': 0.000142311998649218, 'lr/param_group3': 0.000142311998649218}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:32,000 - INFO - epoch 443: train loss 0.04434525233658927\n",
      "2025-09-07 20:19:32,004 - INFO - 443 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:32,013 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:32,022 - INFO - --------------------\n",
      "\n",
      "444/800: 100%|██████████| 216/216 [00:05<00:00, 36.26it/s]\n",
      "2025-09-07 20:19:38,174 - INFO - All types `lr` of epoch 444: {'lr/param_group0': 0.00014178957146227967, 'lr/param_group1': 0.00014178957146227967, 'lr/param_group2': 0.00014178957146227967, 'lr/param_group3': 0.00014178957146227967}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:38,179 - INFO - epoch 444: train loss 0.0442292470726426\n",
      "2025-09-07 20:19:38,188 - INFO - 444 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:38,198 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:38,208 - INFO - --------------------\n",
      "\n",
      "445/800: 100%|██████████| 216/216 [00:05<00:00, 36.01it/s]\n",
      "2025-09-07 20:19:44,408 - INFO - All types `lr` of epoch 445: {'lr/param_group0': 0.00014126750220886213, 'lr/param_group1': 0.00014126750220886213, 'lr/param_group2': 0.00014126750220886213, 'lr/param_group3': 0.00014126750220886213}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:44,412 - INFO - epoch 445: train loss 0.04434175211591301\n",
      "2025-09-07 20:19:44,422 - INFO - 445 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:44,424 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:44,433 - INFO - --------------------\n",
      "\n",
      "446/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:19:50,608 - INFO - All types `lr` of epoch 446: {'lr/param_group0': 0.000140745798939919, 'lr/param_group1': 0.000140745798939919, 'lr/param_group2': 0.000140745798939919, 'lr/param_group3': 0.000140745798939919}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:50,612 - INFO - epoch 446: train loss 0.044364470816044894\n",
      "2025-09-07 20:19:50,621 - INFO - 446 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:50,624 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:50,633 - INFO - --------------------\n",
      "\n",
      "447/800: 100%|██████████| 216/216 [00:05<00:00, 36.18it/s]\n",
      "2025-09-07 20:19:56,811 - INFO - All types `lr` of epoch 447: {'lr/param_group0': 0.0001402244697007601, 'lr/param_group1': 0.0001402244697007601, 'lr/param_group2': 0.0001402244697007601, 'lr/param_group3': 0.0001402244697007601}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:19:56,815 - INFO - epoch 447: train loss 0.044484013932998535\n",
      "2025-09-07 20:19:56,824 - INFO - 447 epochs completed!\n",
      "\n",
      "2025-09-07 20:19:56,827 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:19:56,836 - INFO - --------------------\n",
      "\n",
      "448/800: 100%|██████████| 216/216 [00:06<00:00, 35.70it/s]\n",
      "2025-09-07 20:20:03,083 - INFO - All types `lr` of epoch 448: {'lr/param_group0': 0.00013970352253092716, 'lr/param_group1': 0.00013970352253092716, 'lr/param_group2': 0.00013970352253092716, 'lr/param_group3': 0.00013970352253092716}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:03,096 - INFO - epoch 448: train loss 0.04440485258345251\n",
      "2025-09-07 20:20:03,106 - INFO - 448 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:03,110 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:03,119 - INFO - --------------------\n",
      "\n",
      "449/800: 100%|██████████| 216/216 [00:05<00:00, 37.81it/s]\n",
      "2025-09-07 20:20:09,029 - INFO - All types `lr` of epoch 449: {'lr/param_group0': 0.00013918296546407006, 'lr/param_group1': 0.00013918296546407006, 'lr/param_group2': 0.00013918296546407006, 'lr/param_group3': 0.00013918296546407006}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:09,041 - INFO - epoch 449: train loss 0.04449098976328969\n",
      "2025-09-07 20:20:09,044 - INFO - 449 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:09,054 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:09,062 - INFO - --------------------\n",
      "\n",
      "450/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 20:20:15,238 - INFO - All types `lr` of epoch 450: {'lr/param_group0': 0.00013866280652782267, 'lr/param_group1': 0.00013866280652782267, 'lr/param_group2': 0.00013866280652782267, 'lr/param_group3': 0.00013866280652782267}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:15,248 - INFO - epoch 450: train loss 0.04444746417855775\n",
      "2025-09-07 20:20:15,257 - INFO - 450 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:15,260 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:15,269 - INFO - --------------------\n",
      "\n",
      "451/800: 100%|██████████| 216/216 [00:06<00:00, 35.92it/s]\n",
      "2025-09-07 20:20:21,476 - INFO - All types `lr` of epoch 451: {'lr/param_group0': 0.00013814305374367926, 'lr/param_group1': 0.00013814305374367926, 'lr/param_group2': 0.00013814305374367926, 'lr/param_group3': 0.00013814305374367926}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:21,489 - INFO - epoch 451: train loss 0.0443031394129826\n",
      "2025-09-07 20:20:21,493 - INFO - 451 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:21,502 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:21,511 - INFO - --------------------\n",
      "\n",
      "452/800: 100%|██████████| 216/216 [00:05<00:00, 36.02it/s]\n",
      "2025-09-07 20:20:27,691 - INFO - All types `lr` of epoch 452: {'lr/param_group0': 0.0001376237151268708, 'lr/param_group1': 0.0001376237151268708, 'lr/param_group2': 0.0001376237151268708, 'lr/param_group3': 0.0001376237151268708}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:27,703 - INFO - epoch 452: train loss 0.04402790968823764\n",
      "2025-09-07 20:20:27,707 - INFO - 452 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:27,716 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:27,725 - INFO - --------------------\n",
      "\n",
      "453/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:20:33,897 - INFO - All types `lr` of epoch 453: {'lr/param_group0': 0.00013710479868624112, 'lr/param_group1': 0.00013710479868624112, 'lr/param_group2': 0.00013710479868624112, 'lr/param_group3': 0.00013710479868624112}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:33,901 - INFO - epoch 453: train loss 0.04415300331526884\n",
      "2025-09-07 20:20:33,910 - INFO - 453 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:33,919 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:33,922 - INFO - --------------------\n",
      "\n",
      "454/800: 100%|██████████| 216/216 [00:05<00:00, 36.02it/s]\n",
      "2025-09-07 20:20:40,118 - INFO - All types `lr` of epoch 454: {'lr/param_group0': 0.00013658631242412375, 'lr/param_group1': 0.00013658631242412375, 'lr/param_group2': 0.00013658631242412375, 'lr/param_group3': 0.00013658631242412375}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:40,122 - INFO - epoch 454: train loss 0.044126613082847106\n",
      "2025-09-07 20:20:40,132 - INFO - 454 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:40,141 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:40,144 - INFO - --------------------\n",
      "\n",
      "455/800: 100%|██████████| 216/216 [00:05<00:00, 36.02it/s]\n",
      "2025-09-07 20:20:46,331 - INFO - All types `lr` of epoch 455: {'lr/param_group0': 0.00013606826433621813, 'lr/param_group1': 0.00013606826433621813, 'lr/param_group2': 0.00013606826433621813, 'lr/param_group3': 0.00013606826433621813}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:46,344 - INFO - epoch 455: train loss 0.04423243047117635\n",
      "2025-09-07 20:20:46,348 - INFO - 455 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:46,357 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:46,366 - INFO - --------------------\n",
      "\n",
      "456/800: 100%|██████████| 216/216 [00:06<00:00, 36.00it/s]\n",
      "2025-09-07 20:20:52,550 - INFO - All types `lr` of epoch 456: {'lr/param_group0': 0.00013555066241146676, 'lr/param_group1': 0.00013555066241146676, 'lr/param_group2': 0.00013555066241146676, 'lr/param_group3': 0.00013555066241146676}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:52,562 - INFO - epoch 456: train loss 0.04426878551021218\n",
      "2025-09-07 20:20:52,567 - INFO - 456 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:52,576 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:52,585 - INFO - --------------------\n",
      "\n",
      "457/800: 100%|██████████| 216/216 [00:06<00:00, 35.67it/s]\n",
      "2025-09-07 20:20:58,825 - INFO - All types `lr` of epoch 457: {'lr/param_group0': 0.00013503351463193153, 'lr/param_group1': 0.00013503351463193153, 'lr/param_group2': 0.00013503351463193153, 'lr/param_group3': 0.00013503351463193153}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:20:58,838 - INFO - epoch 457: train loss 0.044216157816764384\n",
      "2025-09-07 20:20:58,847 - INFO - 457 epochs completed!\n",
      "\n",
      "2025-09-07 20:20:58,851 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:20:58,860 - INFO - --------------------\n",
      "\n",
      "458/800: 100%|██████████| 216/216 [00:06<00:00, 35.74it/s]\n",
      "2025-09-07 20:21:05,108 - INFO - All types `lr` of epoch 458: {'lr/param_group0': 0.000134516828972671, 'lr/param_group1': 0.000134516828972671, 'lr/param_group2': 0.000134516828972671, 'lr/param_group3': 0.000134516828972671}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:05,112 - INFO - epoch 458: train loss 0.043873965136568854\n",
      "2025-09-07 20:21:05,122 - INFO - 458 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:05,131 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:05,134 - INFO - --------------------\n",
      "\n",
      "459/800: 100%|██████████| 216/216 [00:05<00:00, 36.85it/s]\n",
      "2025-09-07 20:21:11,189 - INFO - All types `lr` of epoch 459: {'lr/param_group0': 0.00013400061340161716, 'lr/param_group1': 0.00013400061340161716, 'lr/param_group2': 0.00013400061340161716, 'lr/param_group3': 0.00013400061340161716}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:11,202 - INFO - epoch 459: train loss 0.04388325183686835\n",
      "2025-09-07 20:21:11,206 - INFO - 459 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:11,214 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:11,224 - INFO - --------------------\n",
      "\n",
      "460/800: 100%|██████████| 216/216 [00:06<00:00, 32.33it/s]\n",
      "2025-09-07 20:21:18,098 - INFO - All types `lr` of epoch 460: {'lr/param_group0': 0.00013348487587945275, 'lr/param_group1': 0.00013348487587945275, 'lr/param_group2': 0.00013348487587945275, 'lr/param_group3': 0.00013348487587945275}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:18,102 - INFO - epoch 460: train loss 0.04423400188830716\n",
      "2025-09-07 20:21:18,112 - INFO - 460 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:18,123 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:18,133 - INFO - --------------------\n",
      "\n",
      "461/800: 100%|██████████| 216/216 [00:06<00:00, 35.95it/s]\n",
      "2025-09-07 20:21:24,331 - INFO - All types `lr` of epoch 461: {'lr/param_group0': 0.00013296962435948838, 'lr/param_group1': 0.00013296962435948838, 'lr/param_group2': 0.00013296962435948838, 'lr/param_group3': 0.00013296962435948838}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:24,344 - INFO - epoch 461: train loss 0.04364684772574239\n",
      "2025-09-07 20:21:24,348 - INFO - 461 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:24,357 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:24,360 - INFO - --------------------\n",
      "\n",
      "462/800: 100%|██████████| 216/216 [00:06<00:00, 35.77it/s]\n",
      "2025-09-07 20:21:30,591 - INFO - All types `lr` of epoch 462: {'lr/param_group0': 0.00013245486678753975, 'lr/param_group1': 0.00013245486678753975, 'lr/param_group2': 0.00013245486678753975, 'lr/param_group3': 0.00013245486678753975}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:30,604 - INFO - epoch 462: train loss 0.04374640233193835\n",
      "2025-09-07 20:21:30,607 - INFO - 462 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:30,616 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:30,626 - INFO - --------------------\n",
      "\n",
      "463/800: 100%|██████████| 216/216 [00:06<00:00, 35.91it/s]\n",
      "2025-09-07 20:21:36,830 - INFO - All types `lr` of epoch 463: {'lr/param_group0': 0.00013194061110180557, 'lr/param_group1': 0.00013194061110180557, 'lr/param_group2': 0.00013194061110180557, 'lr/param_group3': 0.00013194061110180557}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:36,841 - INFO - epoch 463: train loss 0.04389112184031142\n",
      "2025-09-07 20:21:36,844 - INFO - 463 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:36,853 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:36,863 - INFO - --------------------\n",
      "\n",
      "464/800: 100%|██████████| 216/216 [00:05<00:00, 36.30it/s]\n",
      "2025-09-07 20:21:43,005 - INFO - All types `lr` of epoch 464: {'lr/param_group0': 0.00013142686523274458, 'lr/param_group1': 0.00013142686523274458, 'lr/param_group2': 0.00013142686523274458, 'lr/param_group3': 0.00013142686523274458}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:43,009 - INFO - epoch 464: train loss 0.043874896942051475\n",
      "2025-09-07 20:21:43,019 - INFO - 464 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:43,022 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:43,031 - INFO - --------------------\n",
      "\n",
      "465/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:21:49,200 - INFO - All types `lr` of epoch 465: {'lr/param_group0': 0.00013091363710295367, 'lr/param_group1': 0.00013091363710295367, 'lr/param_group2': 0.00013091363710295367, 'lr/param_group3': 0.00013091363710295367}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:49,204 - INFO - epoch 465: train loss 0.044205414700425334\n",
      "2025-09-07 20:21:49,214 - INFO - 465 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:49,216 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:49,225 - INFO - --------------------\n",
      "\n",
      "466/800: 100%|██████████| 216/216 [00:06<00:00, 34.46it/s]\n",
      "2025-09-07 20:21:55,689 - INFO - All types `lr` of epoch 466: {'lr/param_group0': 0.00013040093462704543, 'lr/param_group1': 0.00013040093462704543, 'lr/param_group2': 0.00013040093462704543, 'lr/param_group3': 0.00013040093462704543}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:21:55,702 - INFO - epoch 466: train loss 0.04385595489293337\n",
      "2025-09-07 20:21:55,713 - INFO - 466 epochs completed!\n",
      "\n",
      "2025-09-07 20:21:55,716 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:21:55,725 - INFO - --------------------\n",
      "\n",
      "467/800: 100%|██████████| 216/216 [00:05<00:00, 36.11it/s]\n",
      "2025-09-07 20:22:01,904 - INFO - All types `lr` of epoch 467: {'lr/param_group0': 0.00012988876571152634, 'lr/param_group1': 0.00012988876571152634, 'lr/param_group2': 0.00012988876571152634, 'lr/param_group3': 0.00012988876571152634}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:01,916 - INFO - epoch 467: train loss 0.04409746584241037\n",
      "2025-09-07 20:22:01,927 - INFO - 467 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:01,930 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:01,939 - INFO - --------------------\n",
      "\n",
      "468/800: 100%|██████████| 216/216 [00:05<00:00, 36.15it/s]\n",
      "2025-09-07 20:22:08,120 - INFO - All types `lr` of epoch 468: {'lr/param_group0': 0.00012937713825467463, 'lr/param_group1': 0.00012937713825467463, 'lr/param_group2': 0.00012937713825467463, 'lr/param_group3': 0.00012937713825467463}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:08,125 - INFO - epoch 468: train loss 0.04390003095829376\n",
      "2025-09-07 20:22:08,134 - INFO - 468 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:08,144 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:08,148 - INFO - --------------------\n",
      "\n",
      "469/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:22:14,321 - INFO - All types `lr` of epoch 469: {'lr/param_group0': 0.00012886606014641866, 'lr/param_group1': 0.00012886606014641866, 'lr/param_group2': 0.00012886606014641866, 'lr/param_group3': 0.00012886606014641866}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:14,325 - INFO - epoch 469: train loss 0.04365153169190442\n",
      "2025-09-07 20:22:14,335 - INFO - 469 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:14,344 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:14,348 - INFO - --------------------\n",
      "\n",
      "470/800: 100%|██████████| 216/216 [00:06<00:00, 35.85it/s]\n",
      "2025-09-07 20:22:20,565 - INFO - All types `lr` of epoch 470: {'lr/param_group0': 0.00012835553926821496, 'lr/param_group1': 0.00012835553926821496, 'lr/param_group2': 0.00012835553926821496, 'lr/param_group3': 0.00012835553926821496}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:20,577 - INFO - epoch 470: train loss 0.04392046253714296\n",
      "2025-09-07 20:22:20,582 - INFO - 470 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:20,591 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:20,600 - INFO - --------------------\n",
      "\n",
      "471/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:22:26,751 - INFO - All types `lr` of epoch 471: {'lr/param_group0': 0.00012784558349292712, 'lr/param_group1': 0.00012784558349292712, 'lr/param_group2': 0.00012784558349292712, 'lr/param_group3': 0.00012784558349292712}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:26,763 - INFO - epoch 471: train loss 0.043741642859660916\n",
      "2025-09-07 20:22:26,773 - INFO - 471 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:26,777 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:26,786 - INFO - --------------------\n",
      "\n",
      "472/800: 100%|██████████| 216/216 [00:05<00:00, 36.15it/s]\n",
      "2025-09-07 20:22:32,957 - INFO - All types `lr` of epoch 472: {'lr/param_group0': 0.00012733620068470405, 'lr/param_group1': 0.00012733620068470405, 'lr/param_group2': 0.00012733620068470405, 'lr/param_group3': 0.00012733620068470405}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:32,970 - INFO - epoch 472: train loss 0.04371849183614055\n",
      "2025-09-07 20:22:32,980 - INFO - 472 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:32,984 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:32,993 - INFO - --------------------\n",
      "\n",
      "473/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:22:39,189 - INFO - All types `lr` of epoch 473: {'lr/param_group0': 0.00012682739869885872, 'lr/param_group1': 0.00012682739869885872, 'lr/param_group2': 0.00012682739869885872, 'lr/param_group3': 0.00012682739869885872}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:39,200 - INFO - epoch 473: train loss 0.043567616302795986\n",
      "2025-09-07 20:22:39,211 - INFO - 473 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:39,214 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:39,223 - INFO - --------------------\n",
      "\n",
      "474/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:22:45,423 - INFO - All types `lr` of epoch 474: {'lr/param_group0': 0.0001263191853817472, 'lr/param_group1': 0.0001263191853817472, 'lr/param_group2': 0.0001263191853817472, 'lr/param_group3': 0.0001263191853817472}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:45,427 - INFO - epoch 474: train loss 0.043524558983605216\n",
      "2025-09-07 20:22:45,436 - INFO - 474 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:45,446 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:45,449 - INFO - --------------------\n",
      "\n",
      "475/800: 100%|██████████| 216/216 [00:06<00:00, 35.58it/s]\n",
      "2025-09-07 20:22:51,722 - INFO - All types `lr` of epoch 475: {'lr/param_group0': 0.00012581156857064755, 'lr/param_group1': 0.00012581156857064755, 'lr/param_group2': 0.00012581156857064755, 'lr/param_group3': 0.00012581156857064755}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:51,726 - INFO - epoch 475: train loss 0.04373660568078911\n",
      "2025-09-07 20:22:51,735 - INFO - 475 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:51,746 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:51,756 - INFO - --------------------\n",
      "\n",
      "476/800: 100%|██████████| 216/216 [00:06<00:00, 35.92it/s]\n",
      "2025-09-07 20:22:57,972 - INFO - All types `lr` of epoch 476: {'lr/param_group0': 0.00012530455609363898, 'lr/param_group1': 0.00012530455609363898, 'lr/param_group2': 0.00012530455609363898, 'lr/param_group3': 0.00012530455609363898}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:22:57,976 - INFO - epoch 476: train loss 0.04375874911676402\n",
      "2025-09-07 20:22:57,986 - INFO - 476 epochs completed!\n",
      "\n",
      "2025-09-07 20:22:57,989 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:22:57,998 - INFO - --------------------\n",
      "\n",
      "477/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:23:04,211 - INFO - All types `lr` of epoch 477: {'lr/param_group0': 0.00012479815576948097, 'lr/param_group1': 0.00012479815576948097, 'lr/param_group2': 0.00012479815576948097, 'lr/param_group3': 0.00012479815576948097}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:04,216 - INFO - epoch 477: train loss 0.04350635806029594\n",
      "2025-09-07 20:23:04,227 - INFO - 477 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:04,230 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:04,240 - INFO - --------------------\n",
      "\n",
      "478/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:23:10,458 - INFO - All types `lr` of epoch 478: {'lr/param_group0': 0.0001242923754074931, 'lr/param_group1': 0.0001242923754074931, 'lr/param_group2': 0.0001242923754074931, 'lr/param_group3': 0.0001242923754074931}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:10,462 - INFO - epoch 478: train loss 0.04380516380209614\n",
      "2025-09-07 20:23:10,472 - INFO - 478 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:10,475 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:10,484 - INFO - --------------------\n",
      "\n",
      "479/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:23:16,645 - INFO - All types `lr` of epoch 479: {'lr/param_group0': 0.00012378722280743408, 'lr/param_group1': 0.00012378722280743408, 'lr/param_group2': 0.00012378722280743408, 'lr/param_group3': 0.00012378722280743408}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:16,658 - INFO - epoch 479: train loss 0.04340527718886733\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.53it/s]\n",
      "2025-09-07 20:23:18,156 - INFO - epoch 479: val loss 0.05921889262066947\n",
      "2025-09-07 20:23:18,170 - INFO - 479 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:23:18,184 - INFO - 479 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:18,188 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:18,197 - INFO - --------------------\n",
      "\n",
      "480/800: 100%|██████████| 216/216 [00:06<00:00, 35.92it/s]\n",
      "2025-09-07 20:23:24,418 - INFO - All types `lr` of epoch 480: {'lr/param_group0': 0.00012328270575938215, 'lr/param_group1': 0.00012328270575938215, 'lr/param_group2': 0.00012328270575938215, 'lr/param_group3': 0.00012328270575938215}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:24,430 - INFO - epoch 480: train loss 0.043610296522577606\n",
      "2025-09-07 20:23:24,440 - INFO - 480 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:24,444 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:24,453 - INFO - --------------------\n",
      "\n",
      "481/800: 100%|██████████| 216/216 [00:06<00:00, 35.99it/s]\n",
      "2025-09-07 20:23:30,653 - INFO - All types `lr` of epoch 481: {'lr/param_group0': 0.00012277883204361403, 'lr/param_group1': 0.00012277883204361403, 'lr/param_group2': 0.00012277883204361403, 'lr/param_group3': 0.00012277883204361403}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:30,666 - INFO - epoch 481: train loss 0.043865891828857084\n",
      "2025-09-07 20:23:30,676 - INFO - 481 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:30,680 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:30,689 - INFO - --------------------\n",
      "\n",
      "482/800: 100%|██████████| 216/216 [00:06<00:00, 35.88it/s]\n",
      "2025-09-07 20:23:36,907 - INFO - All types `lr` of epoch 482: {'lr/param_group0': 0.00012227560943048584, 'lr/param_group1': 0.00012227560943048584, 'lr/param_group2': 0.00012227560943048584, 'lr/param_group3': 0.00012227560943048584}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:36,919 - INFO - epoch 482: train loss 0.043417039706751155\n",
      "2025-09-07 20:23:36,929 - INFO - 482 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:36,933 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:36,942 - INFO - --------------------\n",
      "\n",
      "483/800: 100%|██████████| 216/216 [00:06<00:00, 35.88it/s]\n",
      "2025-09-07 20:23:43,173 - INFO - All types `lr` of epoch 483: {'lr/param_group0': 0.00012177304568031289, 'lr/param_group1': 0.00012177304568031289, 'lr/param_group2': 0.00012177304568031289, 'lr/param_group3': 0.00012177304568031289}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:43,177 - INFO - epoch 483: train loss 0.043477823216192146\n",
      "2025-09-07 20:23:43,188 - INFO - 483 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:43,198 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:43,201 - INFO - --------------------\n",
      "\n",
      "484/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:23:49,398 - INFO - All types `lr` of epoch 484: {'lr/param_group0': 0.0001212711485432498, 'lr/param_group1': 0.0001212711485432498, 'lr/param_group2': 0.0001212711485432498, 'lr/param_group3': 0.0001212711485432498}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:49,410 - INFO - epoch 484: train loss 0.04358992020220116\n",
      "2025-09-07 20:23:49,421 - INFO - 484 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:49,425 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:49,434 - INFO - --------------------\n",
      "\n",
      "485/800: 100%|██████████| 216/216 [00:06<00:00, 35.69it/s]\n",
      "2025-09-07 20:23:55,696 - INFO - All types `lr` of epoch 485: {'lr/param_group0': 0.0001207699257591714, 'lr/param_group1': 0.0001207699257591714, 'lr/param_group2': 0.0001207699257591714, 'lr/param_group3': 0.0001207699257591714}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:23:55,700 - INFO - epoch 485: train loss 0.043514292790657945\n",
      "2025-09-07 20:23:55,710 - INFO - 485 epochs completed!\n",
      "\n",
      "2025-09-07 20:23:55,721 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:23:55,724 - INFO - --------------------\n",
      "\n",
      "486/800: 100%|██████████| 216/216 [00:06<00:00, 35.60it/s]\n",
      "2025-09-07 20:24:01,997 - INFO - All types `lr` of epoch 486: {'lr/param_group0': 0.0001202693850575529, 'lr/param_group1': 0.0001202693850575529, 'lr/param_group2': 0.0001202693850575529, 'lr/param_group3': 0.0001202693850575529}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:02,001 - INFO - epoch 486: train loss 0.043293290961257835\n",
      "2025-09-07 20:24:02,011 - INFO - 486 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:02,014 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:02,023 - INFO - --------------------\n",
      "\n",
      "487/800: 100%|██████████| 216/216 [00:05<00:00, 36.46it/s]\n",
      "2025-09-07 20:24:08,151 - INFO - All types `lr` of epoch 487: {'lr/param_group0': 0.00011976953415735127, 'lr/param_group1': 0.00011976953415735127, 'lr/param_group2': 0.00011976953415735127, 'lr/param_group3': 0.00011976953415735127}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:08,164 - INFO - epoch 487: train loss 0.04338229795986855\n",
      "2025-09-07 20:24:08,176 - INFO - 487 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:08,186 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:08,196 - INFO - --------------------\n",
      "\n",
      "488/800: 100%|██████████| 216/216 [00:05<00:00, 36.01it/s]\n",
      "2025-09-07 20:24:14,388 - INFO - All types `lr` of epoch 488: {'lr/param_group0': 0.00011927038076688566, 'lr/param_group1': 0.00011927038076688566, 'lr/param_group2': 0.00011927038076688566, 'lr/param_group3': 0.00011927038076688566}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:14,401 - INFO - epoch 488: train loss 0.04357647102464129\n",
      "2025-09-07 20:24:14,405 - INFO - 488 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:14,414 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:14,424 - INFO - --------------------\n",
      "\n",
      "489/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:24:20,625 - INFO - All types `lr` of epoch 489: {'lr/param_group0': 0.00011877193258371889, 'lr/param_group1': 0.00011877193258371889, 'lr/param_group2': 0.00011877193258371889, 'lr/param_group3': 0.00011877193258371889}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:20,638 - INFO - epoch 489: train loss 0.043550848167527606\n",
      "2025-09-07 20:24:20,641 - INFO - 489 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:20,651 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:20,661 - INFO - --------------------\n",
      "\n",
      "490/800: 100%|██████████| 216/216 [00:06<00:00, 35.83it/s]\n",
      "2025-09-07 20:24:26,874 - INFO - All types `lr` of epoch 490: {'lr/param_group0': 0.00011827419729453843, 'lr/param_group1': 0.00011827419729453843, 'lr/param_group2': 0.00011827419729453843, 'lr/param_group3': 0.00011827419729453843}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:26,886 - INFO - epoch 490: train loss 0.04345830757584837\n",
      "2025-09-07 20:24:26,889 - INFO - 490 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:26,898 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:26,908 - INFO - --------------------\n",
      "\n",
      "491/800: 100%|██████████| 216/216 [00:05<00:00, 36.27it/s]\n",
      "2025-09-07 20:24:33,047 - INFO - All types `lr` of epoch 491: {'lr/param_group0': 0.00011777718257503828, 'lr/param_group1': 0.00011777718257503828, 'lr/param_group2': 0.00011777718257503828, 'lr/param_group3': 0.00011777718257503828}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:33,059 - INFO - epoch 491: train loss 0.043525870251296846\n",
      "2025-09-07 20:24:33,070 - INFO - 491 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:33,074 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:33,083 - INFO - --------------------\n",
      "\n",
      "492/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:24:39,380 - INFO - All types `lr` of epoch 492: {'lr/param_group0': 0.00011728089608980029, 'lr/param_group1': 0.00011728089608980029, 'lr/param_group2': 0.00011728089608980029, 'lr/param_group3': 0.00011728089608980029}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:39,393 - INFO - epoch 492: train loss 0.04329313330904201\n",
      "2025-09-07 20:24:39,403 - INFO - 492 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:39,407 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:39,417 - INFO - --------------------\n",
      "\n",
      "493/800: 100%|██████████| 216/216 [00:05<00:00, 36.51it/s]\n",
      "2025-09-07 20:24:45,528 - INFO - All types `lr` of epoch 493: {'lr/param_group0': 0.00011678534549217586, 'lr/param_group1': 0.00011678534549217586, 'lr/param_group2': 0.00011678534549217586, 'lr/param_group3': 0.00011678534549217586}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:45,541 - INFO - epoch 493: train loss 0.04333029966801405\n",
      "2025-09-07 20:24:45,545 - INFO - 493 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:45,555 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:45,564 - INFO - --------------------\n",
      "\n",
      "494/800: 100%|██████████| 216/216 [00:05<00:00, 36.11it/s]\n",
      "2025-09-07 20:24:51,736 - INFO - All types `lr` of epoch 494: {'lr/param_group0': 0.00011629053842416835, 'lr/param_group1': 0.00011629053842416835, 'lr/param_group2': 0.00011629053842416835, 'lr/param_group3': 0.00011629053842416835}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:51,748 - INFO - epoch 494: train loss 0.04349344765284547\n",
      "2025-09-07 20:24:51,759 - INFO - 494 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:51,762 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:51,772 - INFO - --------------------\n",
      "\n",
      "495/800: 100%|██████████| 216/216 [00:05<00:00, 36.81it/s]\n",
      "2025-09-07 20:24:57,850 - INFO - All types `lr` of epoch 495: {'lr/param_group0': 0.00011579648251631477, 'lr/param_group1': 0.00011579648251631477, 'lr/param_group2': 0.00011579648251631477, 'lr/param_group3': 0.00011579648251631477}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:24:57,854 - INFO - epoch 495: train loss 0.04340178897190425\n",
      "2025-09-07 20:24:57,864 - INFO - 495 epochs completed!\n",
      "\n",
      "2025-09-07 20:24:57,873 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:24:57,877 - INFO - --------------------\n",
      "\n",
      "496/800: 100%|██████████| 216/216 [00:06<00:00, 35.96it/s]\n",
      "2025-09-07 20:25:04,088 - INFO - All types `lr` of epoch 496: {'lr/param_group0': 0.0001153031853875685, 'lr/param_group1': 0.0001153031853875685, 'lr/param_group2': 0.0001153031853875685, 'lr/param_group3': 0.0001153031853875685}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:04,093 - INFO - epoch 496: train loss 0.04335917758375958\n",
      "2025-09-07 20:25:04,103 - INFO - 496 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:04,113 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:04,116 - INFO - --------------------\n",
      "\n",
      "497/800: 100%|██████████| 216/216 [00:05<00:00, 36.03it/s]\n",
      "2025-09-07 20:25:10,304 - INFO - All types `lr` of epoch 497: {'lr/param_group0': 0.00011481065464518133, 'lr/param_group1': 0.00011481065464518133, 'lr/param_group2': 0.00011481065464518133, 'lr/param_group3': 0.00011481065464518133}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:10,316 - INFO - epoch 497: train loss 0.04334582914425819\n",
      "2025-09-07 20:25:10,320 - INFO - 497 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:10,330 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:10,340 - INFO - --------------------\n",
      "\n",
      "498/800: 100%|██████████| 216/216 [00:06<00:00, 35.74it/s]\n",
      "2025-09-07 20:25:16,571 - INFO - All types `lr` of epoch 498: {'lr/param_group0': 0.00011431889788458679, 'lr/param_group1': 0.00011431889788458679, 'lr/param_group2': 0.00011431889788458679, 'lr/param_group3': 0.00011431889788458679}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:16,584 - INFO - epoch 498: train loss 0.04349667292640165\n",
      "2025-09-07 20:25:16,589 - INFO - 498 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:16,599 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:16,609 - INFO - --------------------\n",
      "\n",
      "499/800: 100%|██████████| 216/216 [00:05<00:00, 36.21it/s]\n",
      "2025-09-07 20:25:22,761 - INFO - All types `lr` of epoch 499: {'lr/param_group0': 0.00011382792268928234, 'lr/param_group1': 0.00011382792268928234, 'lr/param_group2': 0.00011382792268928234, 'lr/param_group3': 0.00011382792268928234}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:22,774 - INFO - epoch 499: train loss 0.04323183370892097\n",
      "2025-09-07 20:25:22,778 - INFO - 499 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:22,787 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:22,797 - INFO - --------------------\n",
      "\n",
      "500/800: 100%|██████████| 216/216 [00:06<00:00, 35.76it/s]\n",
      "2025-09-07 20:25:29,029 - INFO - All types `lr` of epoch 500: {'lr/param_group0': 0.00011333773663071288, 'lr/param_group1': 0.00011333773663071288, 'lr/param_group2': 0.00011333773663071288, 'lr/param_group3': 0.00011333773663071288}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:29,042 - INFO - epoch 500: train loss 0.04324811903966798\n",
      "2025-09-07 20:25:29,047 - INFO - 500 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:29,057 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:29,067 - INFO - --------------------\n",
      "\n",
      "501/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:25:35,227 - INFO - All types `lr` of epoch 501: {'lr/param_group0': 0.00011284834726815384, 'lr/param_group1': 0.00011284834726815384, 'lr/param_group2': 0.00011284834726815384, 'lr/param_group3': 0.00011284834726815384}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:35,240 - INFO - epoch 501: train loss 0.04310482117795834\n",
      "2025-09-07 20:25:35,251 - INFO - 501 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:35,254 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:35,264 - INFO - --------------------\n",
      "\n",
      "502/800: 100%|██████████| 216/216 [00:06<00:00, 35.64it/s]\n",
      "2025-09-07 20:25:41,522 - INFO - All types `lr` of epoch 502: {'lr/param_group0': 0.00011235976214859457, 'lr/param_group1': 0.00011235976214859457, 'lr/param_group2': 0.00011235976214859457, 'lr/param_group3': 0.00011235976214859457}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:41,526 - INFO - epoch 502: train loss 0.04326866287738085\n",
      "2025-09-07 20:25:41,536 - INFO - 502 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:41,539 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:41,549 - INFO - --------------------\n",
      "\n",
      "503/800: 100%|██████████| 216/216 [00:05<00:00, 36.26it/s]\n",
      "2025-09-07 20:25:47,708 - INFO - All types `lr` of epoch 503: {'lr/param_group0': 0.00011187198880662204, 'lr/param_group1': 0.00011187198880662204, 'lr/param_group2': 0.00011187198880662204, 'lr/param_group3': 0.00011187198880662204}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:47,723 - INFO - epoch 503: train loss 0.04339177915136571\n",
      "2025-09-07 20:25:47,734 - INFO - 503 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:47,744 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:47,753 - INFO - --------------------\n",
      "\n",
      "504/800: 100%|██████████| 216/216 [00:06<00:00, 35.98it/s]\n",
      "2025-09-07 20:25:53,959 - INFO - All types `lr` of epoch 504: {'lr/param_group0': 0.00011138503476430459, 'lr/param_group1': 0.00011138503476430459, 'lr/param_group2': 0.00011138503476430459, 'lr/param_group3': 0.00011138503476430459}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:25:53,974 - INFO - epoch 504: train loss 0.04326512685252561\n",
      "2025-09-07 20:25:53,986 - INFO - 504 epochs completed!\n",
      "\n",
      "2025-09-07 20:25:53,997 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:25:54,007 - INFO - --------------------\n",
      "\n",
      "505/800: 100%|██████████| 216/216 [00:05<00:00, 36.22it/s]\n",
      "2025-09-07 20:26:00,170 - INFO - All types `lr` of epoch 505: {'lr/param_group0': 0.00011089890753107597, 'lr/param_group1': 0.00011089890753107597, 'lr/param_group2': 0.00011089890753107597, 'lr/param_group3': 0.00011089890753107597}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:00,174 - INFO - epoch 505: train loss 0.043082721893572144\n",
      "2025-09-07 20:26:00,187 - INFO - 505 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:00,198 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:00,201 - INFO - --------------------\n",
      "\n",
      "506/800: 100%|██████████| 216/216 [00:05<00:00, 36.03it/s]\n",
      "2025-09-07 20:26:06,396 - INFO - All types `lr` of epoch 506: {'lr/param_group0': 0.00011041361460361944, 'lr/param_group1': 0.00011041361460361944, 'lr/param_group2': 0.00011041361460361944, 'lr/param_group3': 0.00011041361460361944}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:06,400 - INFO - epoch 506: train loss 0.04298734147515562\n",
      "2025-09-07 20:26:06,410 - INFO - 506 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:06,420 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:06,424 - INFO - --------------------\n",
      "\n",
      "507/800: 100%|██████████| 216/216 [00:06<00:00, 35.68it/s]\n",
      "2025-09-07 20:26:12,687 - INFO - All types `lr` of epoch 507: {'lr/param_group0': 0.00010992916346575227, 'lr/param_group1': 0.00010992916346575227, 'lr/param_group2': 0.00010992916346575227, 'lr/param_group3': 0.00010992916346575227}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:12,691 - INFO - epoch 507: train loss 0.04302120933102237\n",
      "2025-09-07 20:26:12,701 - INFO - 507 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:12,711 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:12,714 - INFO - --------------------\n",
      "\n",
      "508/800: 100%|██████████| 216/216 [00:06<00:00, 36.00it/s]\n",
      "2025-09-07 20:26:18,919 - INFO - All types `lr` of epoch 508: {'lr/param_group0': 0.00010944556158831031, 'lr/param_group1': 0.00010944556158831031, 'lr/param_group2': 0.00010944556158831031, 'lr/param_group3': 0.00010944556158831031}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:18,923 - INFO - epoch 508: train loss 0.043029359403859685\n",
      "2025-09-07 20:26:18,933 - INFO - 508 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:18,944 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:18,947 - INFO - --------------------\n",
      "\n",
      "509/800: 100%|██████████| 216/216 [00:06<00:00, 35.72it/s]\n",
      "2025-09-07 20:26:25,191 - INFO - All types `lr` of epoch 509: {'lr/param_group0': 0.00010896281642903281, 'lr/param_group1': 0.00010896281642903281, 'lr/param_group2': 0.00010896281642903281, 'lr/param_group3': 0.00010896281642903281}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:25,205 - INFO - epoch 509: train loss 0.04326770226988527\n",
      "2025-09-07 20:26:25,209 - INFO - 509 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:25,219 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:25,229 - INFO - --------------------\n",
      "\n",
      "510/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:26:31,384 - INFO - All types `lr` of epoch 510: {'lr/param_group0': 0.00010848093543244716, 'lr/param_group1': 0.00010848093543244716, 'lr/param_group2': 0.00010848093543244716, 'lr/param_group3': 0.00010848093543244716}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:31,397 - INFO - epoch 510: train loss 0.04297279970099529\n",
      "2025-09-07 20:26:31,408 - INFO - 510 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:31,412 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:31,422 - INFO - --------------------\n",
      "\n",
      "511/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:26:37,635 - INFO - All types `lr` of epoch 511: {'lr/param_group0': 0.00010799992602975469, 'lr/param_group1': 0.00010799992602975469, 'lr/param_group2': 0.00010799992602975469, 'lr/param_group3': 0.00010799992602975469}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:37,648 - INFO - epoch 511: train loss 0.042958084097201074\n",
      "2025-09-07 20:26:37,659 - INFO - 511 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:37,663 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:37,672 - INFO - --------------------\n",
      "\n",
      "512/800: 100%|██████████| 216/216 [00:05<00:00, 36.06it/s]\n",
      "2025-09-07 20:26:43,864 - INFO - All types `lr` of epoch 512: {'lr/param_group0': 0.00010751979563871518, 'lr/param_group1': 0.00010751979563871518, 'lr/param_group2': 0.00010751979563871518, 'lr/param_group3': 0.00010751979563871518}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:43,877 - INFO - epoch 512: train loss 0.04288465686625353\n",
      "2025-09-07 20:26:43,881 - INFO - 512 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:43,892 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:43,902 - INFO - --------------------\n",
      "\n",
      "513/800: 100%|██████████| 216/216 [00:06<00:00, 35.57it/s]\n",
      "2025-09-07 20:26:50,174 - INFO - All types `lr` of epoch 513: {'lr/param_group0': 0.00010704055166353338, 'lr/param_group1': 0.00010704055166353338, 'lr/param_group2': 0.00010704055166353338, 'lr/param_group3': 0.00010704055166353338}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:50,178 - INFO - epoch 513: train loss 0.04322223191115039\n",
      "2025-09-07 20:26:50,188 - INFO - 513 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:50,198 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:50,201 - INFO - --------------------\n",
      "\n",
      "514/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:26:56,379 - INFO - All types `lr` of epoch 514: {'lr/param_group0': 0.00010656220149474412, 'lr/param_group1': 0.00010656220149474412, 'lr/param_group2': 0.00010656220149474412, 'lr/param_group3': 0.00010656220149474412}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:26:56,391 - INFO - epoch 514: train loss 0.043147702839363505\n",
      "2025-09-07 20:26:56,396 - INFO - 514 epochs completed!\n",
      "\n",
      "2025-09-07 20:26:56,406 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:26:56,418 - INFO - --------------------\n",
      "\n",
      "515/800: 100%|██████████| 216/216 [00:06<00:00, 35.72it/s]\n",
      "2025-09-07 20:27:02,664 - INFO - All types `lr` of epoch 515: {'lr/param_group0': 0.00010608475250909883, 'lr/param_group1': 0.00010608475250909883, 'lr/param_group2': 0.00010608475250909883, 'lr/param_group3': 0.00010608475250909883}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:02,679 - INFO - epoch 515: train loss 0.042871834227332366\n",
      "2025-09-07 20:27:02,691 - INFO - 515 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:02,701 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:02,711 - INFO - --------------------\n",
      "\n",
      "516/800: 100%|██████████| 216/216 [00:05<00:00, 36.72it/s]\n",
      "2025-09-07 20:27:08,798 - INFO - All types `lr` of epoch 516: {'lr/param_group0': 0.00010560821206945143, 'lr/param_group1': 0.00010560821206945143, 'lr/param_group2': 0.00010560821206945143, 'lr/param_group3': 0.00010560821206945143}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:08,812 - INFO - epoch 516: train loss 0.04302682946608574\n",
      "2025-09-07 20:27:08,824 - INFO - 516 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:08,834 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:08,845 - INFO - --------------------\n",
      "\n",
      "517/800: 100%|██████████| 216/216 [00:05<00:00, 36.16it/s]\n",
      "2025-09-07 20:27:15,030 - INFO - All types `lr` of epoch 517: {'lr/param_group0': 0.00010513258752464505, 'lr/param_group1': 0.00010513258752464505, 'lr/param_group2': 0.00010513258752464505, 'lr/param_group3': 0.00010513258752464505}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:15,034 - INFO - epoch 517: train loss 0.04302805929479224\n",
      "2025-09-07 20:27:15,044 - INFO - 517 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:15,047 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:15,057 - INFO - --------------------\n",
      "\n",
      "518/800: 100%|██████████| 216/216 [00:05<00:00, 36.10it/s]\n",
      "2025-09-07 20:27:21,259 - INFO - All types `lr` of epoch 518: {'lr/param_group0': 0.00010465788620939863, 'lr/param_group1': 0.00010465788620939863, 'lr/param_group2': 0.00010465788620939863, 'lr/param_group3': 0.00010465788620939863}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:21,263 - INFO - epoch 518: train loss 0.04293177049193117\n",
      "2025-09-07 20:27:21,274 - INFO - 518 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:21,277 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:21,287 - INFO - --------------------\n",
      "\n",
      "519/800: 100%|██████████| 216/216 [00:05<00:00, 36.27it/s]\n",
      "2025-09-07 20:27:27,463 - INFO - All types `lr` of epoch 519: {'lr/param_group0': 0.00010418411544419354, 'lr/param_group1': 0.00010418411544419354, 'lr/param_group2': 0.00010418411544419354, 'lr/param_group3': 0.00010418411544419354}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:27,476 - INFO - epoch 519: train loss 0.0431247686587826\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.14it/s]\n",
      "2025-09-07 20:27:28,963 - INFO - epoch 519: val loss 0.05894779344951665\n",
      "2025-09-07 20:27:28,977 - INFO - 519 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:27:28,992 - INFO - 519 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:28,997 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:29,007 - INFO - --------------------\n",
      "\n",
      "520/800: 100%|██████████| 216/216 [00:05<00:00, 37.45it/s]\n",
      "2025-09-07 20:27:34,975 - INFO - All types `lr` of epoch 520: {'lr/param_group0': 0.00010371128253516117, 'lr/param_group1': 0.00010371128253516117, 'lr/param_group2': 0.00010371128253516117, 'lr/param_group3': 0.00010371128253516117}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:34,988 - INFO - epoch 520: train loss 0.043081245902511806\n",
      "2025-09-07 20:27:34,999 - INFO - 520 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:35,003 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:35,013 - INFO - --------------------\n",
      "\n",
      "521/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:27:41,197 - INFO - All types `lr` of epoch 521: {'lr/param_group0': 0.00010323939477396981, 'lr/param_group1': 0.00010323939477396981, 'lr/param_group2': 0.00010323939477396981, 'lr/param_group3': 0.00010323939477396981}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:41,201 - INFO - epoch 521: train loss 0.04316928841311623\n",
      "2025-09-07 20:27:41,212 - INFO - 521 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:41,222 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:41,226 - INFO - --------------------\n",
      "\n",
      "522/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:27:47,408 - INFO - All types `lr` of epoch 522: {'lr/param_group0': 0.0001027684594377126, 'lr/param_group1': 0.0001027684594377126, 'lr/param_group2': 0.0001027684594377126, 'lr/param_group3': 0.0001027684594377126}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:47,421 - INFO - epoch 522: train loss 0.043070509270937356\n",
      "2025-09-07 20:27:47,432 - INFO - 522 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:47,436 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:47,446 - INFO - --------------------\n",
      "\n",
      "523/800: 100%|██████████| 216/216 [00:05<00:00, 36.61it/s]\n",
      "2025-09-07 20:27:53,561 - INFO - All types `lr` of epoch 523: {'lr/param_group0': 0.00010229848378879482, 'lr/param_group1': 0.00010229848378879482, 'lr/param_group2': 0.00010229848378879482, 'lr/param_group3': 0.00010229848378879482}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:27:53,566 - INFO - epoch 523: train loss 0.042729118976880004\n",
      "2025-09-07 20:27:53,576 - INFO - 523 epochs completed!\n",
      "\n",
      "2025-09-07 20:27:53,587 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:27:53,591 - INFO - --------------------\n",
      "\n",
      "524/800: 100%|██████████| 216/216 [00:06<00:00, 33.93it/s]\n",
      "2025-09-07 20:28:00,169 - INFO - All types `lr` of epoch 524: {'lr/param_group0': 0.00010182947507482261, 'lr/param_group1': 0.00010182947507482261, 'lr/param_group2': 0.00010182947507482261, 'lr/param_group3': 0.00010182947507482261}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:00,173 - INFO - epoch 524: train loss 0.04284613125923055\n",
      "2025-09-07 20:28:00,184 - INFO - 524 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:00,194 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:00,198 - INFO - --------------------\n",
      "\n",
      "525/800: 100%|██████████| 216/216 [00:06<00:00, 34.67it/s]\n",
      "2025-09-07 20:28:06,634 - INFO - All types `lr` of epoch 525: {'lr/param_group0': 0.00010136144052849031, 'lr/param_group1': 0.00010136144052849031, 'lr/param_group2': 0.00010136144052849031, 'lr/param_group3': 0.00010136144052849031}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:06,638 - INFO - epoch 525: train loss 0.04259851028176921\n",
      "2025-09-07 20:28:06,648 - INFO - 525 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:06,659 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:06,663 - INFO - --------------------\n",
      "\n",
      "526/800: 100%|██████████| 216/216 [00:05<00:00, 36.43it/s]\n",
      "2025-09-07 20:28:12,794 - INFO - All types `lr` of epoch 526: {'lr/param_group0': 0.00010089438736746967, 'lr/param_group1': 0.00010089438736746967, 'lr/param_group2': 0.00010089438736746967, 'lr/param_group3': 0.00010089438736746967}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:12,807 - INFO - epoch 526: train loss 0.04302923310617054\n",
      "2025-09-07 20:28:12,818 - INFO - 526 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:12,822 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:12,832 - INFO - --------------------\n",
      "\n",
      "527/800: 100%|██████████| 216/216 [00:06<00:00, 36.00it/s]\n",
      "2025-09-07 20:28:19,036 - INFO - All types `lr` of epoch 527: {'lr/param_group0': 0.00010042832279429834, 'lr/param_group1': 0.00010042832279429834, 'lr/param_group2': 0.00010042832279429834, 'lr/param_group3': 0.00010042832279429834}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:19,048 - INFO - epoch 527: train loss 0.042862133433421455\n",
      "2025-09-07 20:28:19,061 - INFO - 527 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:19,072 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:19,083 - INFO - --------------------\n",
      "\n",
      "528/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:28:25,281 - INFO - All types `lr` of epoch 528: {'lr/param_group0': 9.996325399626841e-05, 'lr/param_group1': 9.996325399626841e-05, 'lr/param_group2': 9.996325399626841e-05, 'lr/param_group3': 9.996325399626841e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:25,294 - INFO - epoch 528: train loss 0.04286166323624827\n",
      "2025-09-07 20:28:25,298 - INFO - 528 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:25,308 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:25,319 - INFO - --------------------\n",
      "\n",
      "529/800: 100%|██████████| 216/216 [00:06<00:00, 35.70it/s]\n",
      "2025-09-07 20:28:31,560 - INFO - All types `lr` of epoch 529: {'lr/param_group0': 9.949918814531617e-05, 'lr/param_group1': 9.949918814531617e-05, 'lr/param_group2': 9.949918814531617e-05, 'lr/param_group3': 9.949918814531617e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:31,575 - INFO - epoch 529: train loss 0.042760283013598785\n",
      "2025-09-07 20:28:31,587 - INFO - 529 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:31,613 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:31,628 - INFO - --------------------\n",
      "\n",
      "530/800: 100%|██████████| 216/216 [00:05<00:00, 36.01it/s]\n",
      "2025-09-07 20:28:37,828 - INFO - All types `lr` of epoch 530: {'lr/param_group0': 9.903613239791105e-05, 'lr/param_group1': 9.903613239791105e-05, 'lr/param_group2': 9.903613239791105e-05, 'lr/param_group3': 9.903613239791105e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:37,841 - INFO - epoch 530: train loss 0.042770445778000134\n",
      "2025-09-07 20:28:37,844 - INFO - 530 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:37,854 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:37,864 - INFO - --------------------\n",
      "\n",
      "531/800: 100%|██████████| 216/216 [00:05<00:00, 36.17it/s]\n",
      "2025-09-07 20:28:44,026 - INFO - All types `lr` of epoch 531: {'lr/param_group0': 9.857409389494557e-05, 'lr/param_group1': 9.857409389494557e-05, 'lr/param_group2': 9.857409389494557e-05, 'lr/param_group3': 9.857409389494557e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:44,038 - INFO - epoch 531: train loss 0.0429075646766082\n",
      "2025-09-07 20:28:44,049 - INFO - 531 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:44,053 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:44,063 - INFO - --------------------\n",
      "\n",
      "532/800: 100%|██████████| 216/216 [00:05<00:00, 36.20it/s]\n",
      "2025-09-07 20:28:50,233 - INFO - All types `lr` of epoch 532: {'lr/param_group0': 9.811307976162497e-05, 'lr/param_group1': 9.811307976162497e-05, 'lr/param_group2': 9.811307976162497e-05, 'lr/param_group3': 9.811307976162497e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:50,246 - INFO - epoch 532: train loss 0.04264288523268921\n",
      "2025-09-07 20:28:50,257 - INFO - 532 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:50,261 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:50,272 - INFO - --------------------\n",
      "\n",
      "533/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:28:56,476 - INFO - All types `lr` of epoch 533: {'lr/param_group0': 9.765309710735754e-05, 'lr/param_group1': 9.765309710735754e-05, 'lr/param_group2': 9.765309710735754e-05, 'lr/param_group3': 9.765309710735754e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:28:56,489 - INFO - epoch 533: train loss 0.04262519836494768\n",
      "2025-09-07 20:28:56,500 - INFO - 533 epochs completed!\n",
      "\n",
      "2025-09-07 20:28:56,504 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:28:56,514 - INFO - --------------------\n",
      "\n",
      "534/800: 100%|██████████| 216/216 [00:05<00:00, 36.11it/s]\n",
      "2025-09-07 20:29:02,697 - INFO - All types `lr` of epoch 534: {'lr/param_group0': 9.719415302564469e-05, 'lr/param_group1': 9.719415302564469e-05, 'lr/param_group2': 9.719415302564469e-05, 'lr/param_group3': 9.719415302564469e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:02,710 - INFO - epoch 534: train loss 0.0424672109592292\n",
      "2025-09-07 20:29:02,721 - INFO - 534 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:02,725 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:02,735 - INFO - --------------------\n",
      "\n",
      "535/800: 100%|██████████| 216/216 [00:06<00:00, 35.70it/s]\n",
      "2025-09-07 20:29:08,990 - INFO - All types `lr` of epoch 535: {'lr/param_group0': 9.673625459397203e-05, 'lr/param_group1': 9.673625459397203e-05, 'lr/param_group2': 9.673625459397203e-05, 'lr/param_group3': 9.673625459397203e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:09,004 - INFO - epoch 535: train loss 0.04258190392068139\n",
      "2025-09-07 20:29:09,008 - INFO - 535 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:09,019 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:09,030 - INFO - --------------------\n",
      "\n",
      "536/800: 100%|██████████| 216/216 [00:05<00:00, 36.56it/s]\n",
      "2025-09-07 20:29:15,130 - INFO - All types `lr` of epoch 536: {'lr/param_group0': 9.627940887369988e-05, 'lr/param_group1': 9.627940887369988e-05, 'lr/param_group2': 9.627940887369988e-05, 'lr/param_group3': 9.627940887369988e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:15,142 - INFO - epoch 536: train loss 0.04298444230247427\n",
      "2025-09-07 20:29:15,154 - INFO - 536 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:15,158 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:15,169 - INFO - --------------------\n",
      "\n",
      "537/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:29:21,321 - INFO - All types `lr` of epoch 537: {'lr/param_group0': 9.58236229099542e-05, 'lr/param_group1': 9.58236229099542e-05, 'lr/param_group2': 9.58236229099542e-05, 'lr/param_group3': 9.58236229099542e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:21,325 - INFO - epoch 537: train loss 0.04281464529534181\n",
      "2025-09-07 20:29:21,336 - INFO - 537 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:21,347 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:21,351 - INFO - --------------------\n",
      "\n",
      "538/800: 100%|██████████| 216/216 [00:05<00:00, 36.66it/s]\n",
      "2025-09-07 20:29:27,443 - INFO - All types `lr` of epoch 538: {'lr/param_group0': 9.536890373151859e-05, 'lr/param_group1': 9.536890373151859e-05, 'lr/param_group2': 9.536890373151859e-05, 'lr/param_group3': 9.536890373151859e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:27,458 - INFO - epoch 538: train loss 0.042415268581222604\n",
      "2025-09-07 20:29:27,462 - INFO - 538 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:27,473 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:27,484 - INFO - --------------------\n",
      "\n",
      "539/800: 100%|██████████| 216/216 [00:05<00:00, 37.35it/s]\n",
      "2025-09-07 20:29:33,451 - INFO - All types `lr` of epoch 539: {'lr/param_group0': 9.491525835072511e-05, 'lr/param_group1': 9.491525835072511e-05, 'lr/param_group2': 9.491525835072511e-05, 'lr/param_group3': 9.491525835072511e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:33,465 - INFO - epoch 539: train loss 0.04254267870069102\n",
      "2025-09-07 20:29:33,470 - INFO - 539 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:33,480 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:33,492 - INFO - --------------------\n",
      "\n",
      "540/800: 100%|██████████| 216/216 [00:06<00:00, 32.94it/s]\n",
      "2025-09-07 20:29:40,241 - INFO - All types `lr` of epoch 540: {'lr/param_group0': 9.446269376334689e-05, 'lr/param_group1': 9.446269376334689e-05, 'lr/param_group2': 9.446269376334689e-05, 'lr/param_group3': 9.446269376334689e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:40,254 - INFO - epoch 540: train loss 0.04280668840295187\n",
      "2025-09-07 20:29:40,266 - INFO - 540 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:40,270 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:40,280 - INFO - --------------------\n",
      "\n",
      "541/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:29:46,470 - INFO - All types `lr` of epoch 541: {'lr/param_group0': 9.401121694848957e-05, 'lr/param_group1': 9.401121694848957e-05, 'lr/param_group2': 9.401121694848957e-05, 'lr/param_group3': 9.401121694848957e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:46,474 - INFO - epoch 541: train loss 0.04252942558377981\n",
      "2025-09-07 20:29:46,485 - INFO - 541 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:46,497 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:46,509 - INFO - --------------------\n",
      "\n",
      "542/800: 100%|██████████| 216/216 [00:05<00:00, 36.10it/s]\n",
      "2025-09-07 20:29:52,689 - INFO - All types `lr` of epoch 542: {'lr/param_group0': 9.356083486848426e-05, 'lr/param_group1': 9.356083486848426e-05, 'lr/param_group2': 9.356083486848426e-05, 'lr/param_group3': 9.356083486848426e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:52,704 - INFO - epoch 542: train loss 0.04237201790911732\n",
      "2025-09-07 20:29:52,716 - INFO - 542 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:52,727 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:52,737 - INFO - --------------------\n",
      "\n",
      "543/800: 100%|██████████| 216/216 [00:05<00:00, 37.42it/s]\n",
      "2025-09-07 20:29:58,709 - INFO - All types `lr` of epoch 543: {'lr/param_group0': 9.31115544687797e-05, 'lr/param_group1': 9.31115544687797e-05, 'lr/param_group2': 9.31115544687797e-05, 'lr/param_group3': 9.31115544687797e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:29:58,724 - INFO - epoch 543: train loss 0.0423735363960818\n",
      "2025-09-07 20:29:58,736 - INFO - 543 epochs completed!\n",
      "\n",
      "2025-09-07 20:29:58,747 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:29:58,757 - INFO - --------------------\n",
      "\n",
      "544/800: 100%|██████████| 216/216 [00:05<00:00, 36.30it/s]\n",
      "2025-09-07 20:30:04,907 - INFO - All types `lr` of epoch 544: {'lr/param_group0': 9.266338267783539e-05, 'lr/param_group1': 9.266338267783539e-05, 'lr/param_group2': 9.266338267783539e-05, 'lr/param_group3': 9.266338267783539e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:04,922 - INFO - epoch 544: train loss 0.042748085102411335\n",
      "2025-09-07 20:30:04,934 - INFO - 544 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:04,945 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:04,956 - INFO - --------------------\n",
      "\n",
      "545/800: 100%|██████████| 216/216 [00:05<00:00, 36.12it/s]\n",
      "2025-09-07 20:30:11,143 - INFO - All types `lr` of epoch 545: {'lr/param_group0': 9.221632640701495e-05, 'lr/param_group1': 9.221632640701495e-05, 'lr/param_group2': 9.221632640701495e-05, 'lr/param_group3': 9.221632640701495e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:11,156 - INFO - epoch 545: train loss 0.04263186209869606\n",
      "2025-09-07 20:30:11,160 - INFO - 545 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:11,170 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:11,181 - INFO - --------------------\n",
      "\n",
      "546/800: 100%|██████████| 216/216 [00:05<00:00, 36.24it/s]\n",
      "2025-09-07 20:30:17,332 - INFO - All types `lr` of epoch 546: {'lr/param_group0': 9.177039255047894e-05, 'lr/param_group1': 9.177039255047894e-05, 'lr/param_group2': 9.177039255047894e-05, 'lr/param_group3': 9.177039255047894e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:17,338 - INFO - epoch 546: train loss 0.04260316360051985\n",
      "2025-09-07 20:30:17,350 - INFO - 546 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:17,353 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:17,363 - INFO - --------------------\n",
      "\n",
      "547/800: 100%|██████████| 216/216 [00:06<00:00, 35.63it/s]\n",
      "2025-09-07 20:30:23,635 - INFO - All types `lr` of epoch 547: {'lr/param_group0': 9.132558798507915e-05, 'lr/param_group1': 9.132558798507915e-05, 'lr/param_group2': 9.132558798507915e-05, 'lr/param_group3': 9.132558798507915e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:23,647 - INFO - epoch 547: train loss 0.04254763161211654\n",
      "2025-09-07 20:30:23,651 - INFO - 547 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:23,662 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:23,674 - INFO - --------------------\n",
      "\n",
      "548/800: 100%|██████████| 216/216 [00:05<00:00, 39.25it/s]\n",
      "2025-09-07 20:30:29,379 - INFO - All types `lr` of epoch 548: {'lr/param_group0': 9.088191957025219e-05, 'lr/param_group1': 9.088191957025219e-05, 'lr/param_group2': 9.088191957025219e-05, 'lr/param_group3': 9.088191957025219e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:29,383 - INFO - epoch 548: train loss 0.04223181314214512\n",
      "2025-09-07 20:30:29,394 - INFO - 548 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:29,397 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:29,407 - INFO - --------------------\n",
      "\n",
      "549/800: 100%|██████████| 216/216 [00:06<00:00, 35.80it/s]\n",
      "2025-09-07 20:30:35,645 - INFO - All types `lr` of epoch 549: {'lr/param_group0': 9.043939414791393e-05, 'lr/param_group1': 9.043939414791393e-05, 'lr/param_group2': 9.043939414791393e-05, 'lr/param_group3': 9.043939414791393e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:35,650 - INFO - epoch 549: train loss 0.04249086707002587\n",
      "2025-09-07 20:30:35,663 - INFO - 549 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:35,674 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:35,679 - INFO - --------------------\n",
      "\n",
      "550/800: 100%|██████████| 216/216 [00:06<00:00, 35.87it/s]\n",
      "2025-09-07 20:30:41,906 - INFO - All types `lr` of epoch 550: {'lr/param_group0': 8.999801854235368e-05, 'lr/param_group1': 8.999801854235368e-05, 'lr/param_group2': 8.999801854235368e-05, 'lr/param_group3': 8.999801854235368e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:41,918 - INFO - epoch 550: train loss 0.042456831541602257\n",
      "2025-09-07 20:30:41,930 - INFO - 550 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:41,934 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:41,945 - INFO - --------------------\n",
      "\n",
      "551/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:30:48,120 - INFO - All types `lr` of epoch 551: {'lr/param_group0': 8.955779956012945e-05, 'lr/param_group1': 8.955779956012945e-05, 'lr/param_group2': 8.955779956012945e-05, 'lr/param_group3': 8.955779956012945e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:48,132 - INFO - epoch 551: train loss 0.04242346046009549\n",
      "2025-09-07 20:30:48,143 - INFO - 551 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:48,147 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:48,158 - INFO - --------------------\n",
      "\n",
      "552/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:30:54,380 - INFO - All types `lr` of epoch 552: {'lr/param_group0': 8.911874398996233e-05, 'lr/param_group1': 8.911874398996233e-05, 'lr/param_group2': 8.911874398996233e-05, 'lr/param_group3': 8.911874398996233e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:30:54,385 - INFO - epoch 552: train loss 0.04250824209992533\n",
      "2025-09-07 20:30:54,396 - INFO - 552 epochs completed!\n",
      "\n",
      "2025-09-07 20:30:54,407 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:30:54,411 - INFO - --------------------\n",
      "\n",
      "553/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 20:31:00,592 - INFO - All types `lr` of epoch 553: {'lr/param_group0': 8.868085860263254e-05, 'lr/param_group1': 8.868085860263254e-05, 'lr/param_group2': 8.868085860263254e-05, 'lr/param_group3': 8.868085860263254e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:00,605 - INFO - epoch 553: train loss 0.04257688671350479\n",
      "2025-09-07 20:31:00,609 - INFO - 553 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:00,620 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:00,631 - INFO - --------------------\n",
      "\n",
      "554/800: 100%|██████████| 216/216 [00:06<00:00, 35.98it/s]\n",
      "2025-09-07 20:31:06,824 - INFO - All types `lr` of epoch 554: {'lr/param_group0': 8.824415015087436e-05, 'lr/param_group1': 8.824415015087436e-05, 'lr/param_group2': 8.824415015087436e-05, 'lr/param_group3': 8.824415015087436e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:06,836 - INFO - epoch 554: train loss 0.04260295626052\n",
      "2025-09-07 20:31:06,841 - INFO - 554 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:06,852 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:06,863 - INFO - --------------------\n",
      "\n",
      "555/800: 100%|██████████| 216/216 [00:05<00:00, 36.33it/s]\n",
      "2025-09-07 20:31:13,007 - INFO - All types `lr` of epoch 555: {'lr/param_group0': 8.78086253692723e-05, 'lr/param_group1': 8.78086253692723e-05, 'lr/param_group2': 8.78086253692723e-05, 'lr/param_group3': 8.78086253692723e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:13,011 - INFO - epoch 555: train loss 0.04228883503970725\n",
      "2025-09-07 20:31:13,022 - INFO - 555 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:13,034 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:13,038 - INFO - --------------------\n",
      "\n",
      "556/800: 100%|██████████| 216/216 [00:05<00:00, 36.28it/s]\n",
      "2025-09-07 20:31:19,188 - INFO - All types `lr` of epoch 556: {'lr/param_group0': 8.737429097415736e-05, 'lr/param_group1': 8.737429097415736e-05, 'lr/param_group2': 8.737429097415736e-05, 'lr/param_group3': 8.737429097415736e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:19,201 - INFO - epoch 556: train loss 0.04205295412490765\n",
      "2025-09-07 20:31:19,213 - INFO - 556 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:19,217 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:19,228 - INFO - --------------------\n",
      "\n",
      "557/800: 100%|██████████| 216/216 [00:06<00:00, 34.98it/s]\n",
      "2025-09-07 20:31:25,607 - INFO - All types `lr` of epoch 557: {'lr/param_group0': 8.694115366350314e-05, 'lr/param_group1': 8.694115366350314e-05, 'lr/param_group2': 8.694115366350314e-05, 'lr/param_group3': 8.694115366350314e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:25,621 - INFO - epoch 557: train loss 0.04250353995572637\n",
      "2025-09-07 20:31:25,626 - INFO - 557 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:25,636 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:25,647 - INFO - --------------------\n",
      "\n",
      "558/800: 100%|██████████| 216/216 [00:06<00:00, 35.55it/s]\n",
      "2025-09-07 20:31:31,917 - INFO - All types `lr` of epoch 558: {'lr/param_group0': 8.650922011682289e-05, 'lr/param_group1': 8.650922011682289e-05, 'lr/param_group2': 8.650922011682289e-05, 'lr/param_group3': 8.650922011682289e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:31,930 - INFO - epoch 558: train loss 0.04227361878104232\n",
      "2025-09-07 20:31:31,941 - INFO - 558 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:31,946 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:31,956 - INFO - --------------------\n",
      "\n",
      "559/800: 100%|██████████| 216/216 [00:05<00:00, 36.85it/s]\n",
      "2025-09-07 20:31:38,019 - INFO - All types `lr` of epoch 559: {'lr/param_group0': 8.607849699506603e-05, 'lr/param_group1': 8.607849699506603e-05, 'lr/param_group2': 8.607849699506603e-05, 'lr/param_group3': 8.607849699506603e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:38,032 - INFO - epoch 559: train loss 0.04213184057907374\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.72it/s]\n",
      "2025-09-07 20:31:39,531 - INFO - epoch 559: val loss 0.05866995522821391\n",
      "2025-09-07 20:31:39,546 - INFO - 559 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:31:39,555 - INFO - 559 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:39,567 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:39,579 - INFO - --------------------\n",
      "\n",
      "560/800: 100%|██████████| 216/216 [00:05<00:00, 36.19it/s]\n",
      "2025-09-07 20:31:45,747 - INFO - All types `lr` of epoch 560: {'lr/param_group0': 8.564899094051614e-05, 'lr/param_group1': 8.564899094051614e-05, 'lr/param_group2': 8.564899094051614e-05, 'lr/param_group3': 8.564899094051614e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:45,752 - INFO - epoch 560: train loss 0.042210887358696374\n",
      "2025-09-07 20:31:45,763 - INFO - 560 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:45,766 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:45,777 - INFO - --------------------\n",
      "\n",
      "561/800: 100%|██████████| 216/216 [00:05<00:00, 36.75it/s]\n",
      "2025-09-07 20:31:51,864 - INFO - All types `lr` of epoch 561: {'lr/param_group0': 8.522070857668772e-05, 'lr/param_group1': 8.522070857668772e-05, 'lr/param_group2': 8.522070857668772e-05, 'lr/param_group3': 8.522070857668772e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:51,868 - INFO - epoch 561: train loss 0.042483678363539557\n",
      "2025-09-07 20:31:51,881 - INFO - 561 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:51,892 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:51,896 - INFO - --------------------\n",
      "\n",
      "562/800: 100%|██████████| 216/216 [00:06<00:00, 35.86it/s]\n",
      "2025-09-07 20:31:58,133 - INFO - All types `lr` of epoch 562: {'lr/param_group0': 8.479365650822478e-05, 'lr/param_group1': 8.479365650822478e-05, 'lr/param_group2': 8.479365650822478e-05, 'lr/param_group3': 8.479365650822478e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:31:58,137 - INFO - epoch 562: train loss 0.04222173454170978\n",
      "2025-09-07 20:31:58,148 - INFO - 562 epochs completed!\n",
      "\n",
      "2025-09-07 20:31:58,160 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:31:58,164 - INFO - --------------------\n",
      "\n",
      "563/800: 100%|██████████| 216/216 [00:05<00:00, 39.74it/s]\n",
      "2025-09-07 20:32:03,800 - INFO - All types `lr` of epoch 563: {'lr/param_group0': 8.436784132079843e-05, 'lr/param_group1': 8.436784132079843e-05, 'lr/param_group2': 8.436784132079843e-05, 'lr/param_group3': 8.436784132079843e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:03,817 - INFO - epoch 563: train loss 0.042445016300512686\n",
      "2025-09-07 20:32:03,829 - INFO - 563 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:03,841 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:03,852 - INFO - --------------------\n",
      "\n",
      "564/800: 100%|██████████| 216/216 [00:05<00:00, 36.31it/s]\n",
      "2025-09-07 20:32:10,007 - INFO - All types `lr` of epoch 564: {'lr/param_group0': 8.394326958100565e-05, 'lr/param_group1': 8.394326958100565e-05, 'lr/param_group2': 8.394326958100565e-05, 'lr/param_group3': 8.394326958100565e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:10,011 - INFO - epoch 564: train loss 0.04232734600426974\n",
      "2025-09-07 20:32:10,022 - INFO - 564 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:10,033 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:10,037 - INFO - --------------------\n",
      "\n",
      "565/800: 100%|██████████| 216/216 [00:06<00:00, 35.72it/s]\n",
      "2025-09-07 20:32:16,293 - INFO - All types `lr` of epoch 565: {'lr/param_group0': 8.351994783626786e-05, 'lr/param_group1': 8.351994783626786e-05, 'lr/param_group2': 8.351994783626786e-05, 'lr/param_group3': 8.351994783626786e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:16,298 - INFO - epoch 565: train loss 0.04238183223814876\n",
      "2025-09-07 20:32:16,309 - INFO - 565 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:16,320 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:16,324 - INFO - --------------------\n",
      "\n",
      "566/800: 100%|██████████| 216/216 [00:06<00:00, 35.77it/s]\n",
      "2025-09-07 20:32:22,567 - INFO - All types `lr` of epoch 566: {'lr/param_group0': 8.309788261473002e-05, 'lr/param_group1': 8.309788261473002e-05, 'lr/param_group2': 8.309788261473002e-05, 'lr/param_group3': 8.309788261473002e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:22,580 - INFO - epoch 566: train loss 0.04222755032350068\n",
      "2025-09-07 20:32:22,592 - INFO - 566 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:22,596 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:22,607 - INFO - --------------------\n",
      "\n",
      "567/800: 100%|██████████| 216/216 [00:06<00:00, 35.88it/s]\n",
      "2025-09-07 20:32:28,834 - INFO - All types `lr` of epoch 567: {'lr/param_group0': 8.267708042516003e-05, 'lr/param_group1': 8.267708042516003e-05, 'lr/param_group2': 8.267708042516003e-05, 'lr/param_group3': 8.267708042516003e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:28,847 - INFO - epoch 567: train loss 0.04234436394094869\n",
      "2025-09-07 20:32:28,858 - INFO - 567 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:28,862 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:28,873 - INFO - --------------------\n",
      "\n",
      "568/800: 100%|██████████| 216/216 [00:06<00:00, 35.81it/s]\n",
      "2025-09-07 20:32:35,108 - INFO - All types `lr` of epoch 568: {'lr/param_group0': 8.225754775684815e-05, 'lr/param_group1': 8.225754775684815e-05, 'lr/param_group2': 8.225754775684815e-05, 'lr/param_group3': 8.225754775684815e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:35,122 - INFO - epoch 568: train loss 0.042383934940314956\n",
      "2025-09-07 20:32:35,126 - INFO - 568 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:35,137 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:35,148 - INFO - --------------------\n",
      "\n",
      "569/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:32:41,354 - INFO - All types `lr` of epoch 569: {'lr/param_group0': 8.183929107950716e-05, 'lr/param_group1': 8.183929107950716e-05, 'lr/param_group2': 8.183929107950716e-05, 'lr/param_group3': 8.183929107950716e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:41,367 - INFO - epoch 569: train loss 0.04211313325773786\n",
      "2025-09-07 20:32:41,379 - INFO - 569 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:41,384 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:41,394 - INFO - --------------------\n",
      "\n",
      "570/800: 100%|██████████| 216/216 [00:05<00:00, 36.10it/s]\n",
      "2025-09-07 20:32:47,583 - INFO - All types `lr` of epoch 570: {'lr/param_group0': 8.142231684317237e-05, 'lr/param_group1': 8.142231684317237e-05, 'lr/param_group2': 8.142231684317237e-05, 'lr/param_group3': 8.142231684317237e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:47,596 - INFO - epoch 570: train loss 0.0422806421260315\n",
      "2025-09-07 20:32:47,601 - INFO - 570 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:47,613 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:47,625 - INFO - --------------------\n",
      "\n",
      "571/800: 100%|██████████| 216/216 [00:06<00:00, 35.95it/s]\n",
      "2025-09-07 20:32:53,834 - INFO - All types `lr` of epoch 571: {'lr/param_group0': 8.100663147810245e-05, 'lr/param_group1': 8.100663147810245e-05, 'lr/param_group2': 8.100663147810245e-05, 'lr/param_group3': 8.100663147810245e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:32:53,839 - INFO - epoch 571: train loss 0.042012694412497456\n",
      "2025-09-07 20:32:53,851 - INFO - 571 epochs completed!\n",
      "\n",
      "2025-09-07 20:32:53,864 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:32:53,876 - INFO - --------------------\n",
      "\n",
      "572/800: 100%|██████████| 216/216 [00:06<00:00, 35.92it/s]\n",
      "2025-09-07 20:33:00,089 - INFO - All types `lr` of epoch 572: {'lr/param_group0': 8.05922413946798e-05, 'lr/param_group1': 8.05922413946798e-05, 'lr/param_group2': 8.05922413946798e-05, 'lr/param_group3': 8.05922413946798e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:00,103 - INFO - epoch 572: train loss 0.04195684203188176\n",
      "2025-09-07 20:33:00,106 - INFO - 572 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:00,117 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:00,128 - INFO - --------------------\n",
      "\n",
      "573/800: 100%|██████████| 216/216 [00:06<00:00, 35.85it/s]\n",
      "2025-09-07 20:33:06,344 - INFO - All types `lr` of epoch 573: {'lr/param_group0': 8.017915298331224e-05, 'lr/param_group1': 8.017915298331224e-05, 'lr/param_group2': 8.017915298331224e-05, 'lr/param_group3': 8.017915298331224e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:06,360 - INFO - epoch 573: train loss 0.04213210031459177\n",
      "2025-09-07 20:33:06,373 - INFO - 573 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:06,384 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:06,396 - INFO - --------------------\n",
      "\n",
      "574/800: 100%|██████████| 216/216 [00:06<00:00, 35.89it/s]\n",
      "2025-09-07 20:33:12,635 - INFO - All types `lr` of epoch 574: {'lr/param_group0': 7.9767372614334e-05, 'lr/param_group1': 7.9767372614334e-05, 'lr/param_group2': 7.9767372614334e-05, 'lr/param_group3': 7.9767372614334e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:12,647 - INFO - epoch 574: train loss 0.042109525521044376\n",
      "2025-09-07 20:33:12,658 - INFO - 574 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:12,669 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:12,673 - INFO - --------------------\n",
      "\n",
      "575/800: 100%|██████████| 216/216 [00:05<00:00, 36.10it/s]\n",
      "2025-09-07 20:33:18,857 - INFO - All types `lr` of epoch 575: {'lr/param_group0': 7.935690663790787e-05, 'lr/param_group1': 7.935690663790787e-05, 'lr/param_group2': 7.935690663790787e-05, 'lr/param_group3': 7.935690663790787e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:18,872 - INFO - epoch 575: train loss 0.042051295956803694\n",
      "2025-09-07 20:33:18,877 - INFO - 575 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:18,888 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:18,899 - INFO - --------------------\n",
      "\n",
      "576/800: 100%|██████████| 216/216 [00:05<00:00, 36.26it/s]\n",
      "2025-09-07 20:33:25,051 - INFO - All types `lr` of epoch 576: {'lr/param_group0': 7.894776138392688e-05, 'lr/param_group1': 7.894776138392688e-05, 'lr/param_group2': 7.894776138392688e-05, 'lr/param_group3': 7.894776138392688e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:25,063 - INFO - epoch 576: train loss 0.042198936058277334\n",
      "2025-09-07 20:33:25,075 - INFO - 576 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:25,079 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:25,090 - INFO - --------------------\n",
      "\n",
      "577/800: 100%|██████████| 216/216 [00:05<00:00, 37.41it/s]\n",
      "2025-09-07 20:33:31,073 - INFO - All types `lr` of epoch 577: {'lr/param_group0': 7.853994316191703e-05, 'lr/param_group1': 7.853994316191703e-05, 'lr/param_group2': 7.853994316191703e-05, 'lr/param_group3': 7.853994316191703e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:31,077 - INFO - epoch 577: train loss 0.04202553788544955\n",
      "2025-09-07 20:33:31,089 - INFO - 577 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:31,100 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:31,104 - INFO - --------------------\n",
      "\n",
      "578/800: 100%|██████████| 216/216 [00:05<00:00, 36.90it/s]\n",
      "2025-09-07 20:33:37,163 - INFO - All types `lr` of epoch 578: {'lr/param_group0': 7.813345826093983e-05, 'lr/param_group1': 7.813345826093983e-05, 'lr/param_group2': 7.813345826093983e-05, 'lr/param_group3': 7.813345826093983e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:37,167 - INFO - epoch 578: train loss 0.0420585279352963\n",
      "2025-09-07 20:33:37,179 - INFO - 578 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:37,190 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:37,194 - INFO - --------------------\n",
      "\n",
      "579/800: 100%|██████████| 216/216 [00:06<00:00, 35.69it/s]\n",
      "2025-09-07 20:33:43,457 - INFO - All types `lr` of epoch 579: {'lr/param_group0': 7.77283129494952e-05, 'lr/param_group1': 7.77283129494952e-05, 'lr/param_group2': 7.77283129494952e-05, 'lr/param_group3': 7.77283129494952e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:43,462 - INFO - epoch 579: train loss 0.042025849430097476\n",
      "2025-09-07 20:33:43,474 - INFO - 579 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:43,485 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:43,489 - INFO - --------------------\n",
      "\n",
      "580/800: 100%|██████████| 216/216 [00:06<00:00, 35.66it/s]\n",
      "2025-09-07 20:33:49,750 - INFO - All types `lr` of epoch 580: {'lr/param_group0': 7.73245134754252e-05, 'lr/param_group1': 7.73245134754252e-05, 'lr/param_group2': 7.73245134754252e-05, 'lr/param_group3': 7.73245134754252e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:49,763 - INFO - epoch 580: train loss 0.04191753026787882\n",
      "2025-09-07 20:33:49,776 - INFO - 580 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:49,780 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:49,791 - INFO - --------------------\n",
      "\n",
      "581/800: 100%|██████████| 216/216 [00:06<00:00, 35.56it/s]\n",
      "2025-09-07 20:33:56,074 - INFO - All types `lr` of epoch 581: {'lr/param_group0': 7.692206606581705e-05, 'lr/param_group1': 7.692206606581705e-05, 'lr/param_group2': 7.692206606581705e-05, 'lr/param_group3': 7.692206606581705e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:33:56,088 - INFO - epoch 581: train loss 0.04195636892001386\n",
      "2025-09-07 20:33:56,093 - INFO - 581 epochs completed!\n",
      "\n",
      "2025-09-07 20:33:56,105 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:33:56,116 - INFO - --------------------\n",
      "\n",
      "582/800: 100%|██████████| 216/216 [00:06<00:00, 35.26it/s]\n",
      "2025-09-07 20:34:02,448 - INFO - All types `lr` of epoch 582: {'lr/param_group0': 7.652097692690782e-05, 'lr/param_group1': 7.652097692690782e-05, 'lr/param_group2': 7.652097692690782e-05, 'lr/param_group3': 7.652097692690782e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:02,453 - INFO - epoch 582: train loss 0.041978331110267726\n",
      "2025-09-07 20:34:02,464 - INFO - 582 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:02,476 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:02,480 - INFO - --------------------\n",
      "\n",
      "583/800: 100%|██████████| 216/216 [00:06<00:00, 35.95it/s]\n",
      "2025-09-07 20:34:08,702 - INFO - All types `lr` of epoch 583: {'lr/param_group0': 7.612125224398804e-05, 'lr/param_group1': 7.612125224398804e-05, 'lr/param_group2': 7.612125224398804e-05, 'lr/param_group3': 7.612125224398804e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:08,707 - INFO - epoch 583: train loss 0.04211091579593442\n",
      "2025-09-07 20:34:08,718 - INFO - 583 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:08,730 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:08,734 - INFO - --------------------\n",
      "\n",
      "584/800: 100%|██████████| 216/216 [00:05<00:00, 36.04it/s]\n",
      "2025-09-07 20:34:14,924 - INFO - All types `lr` of epoch 584: {'lr/param_group0': 7.572289818130699e-05, 'lr/param_group1': 7.572289818130699e-05, 'lr/param_group2': 7.572289818130699e-05, 'lr/param_group3': 7.572289818130699e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:14,937 - INFO - epoch 584: train loss 0.04196238873043546\n",
      "2025-09-07 20:34:14,949 - INFO - 584 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:14,953 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:14,965 - INFO - --------------------\n",
      "\n",
      "585/800: 100%|██████████| 216/216 [00:06<00:00, 35.70it/s]\n",
      "2025-09-07 20:34:21,209 - INFO - All types `lr` of epoch 585: {'lr/param_group0': 7.532592088197697e-05, 'lr/param_group1': 7.532592088197697e-05, 'lr/param_group2': 7.532592088197697e-05, 'lr/param_group3': 7.532592088197697e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:21,223 - INFO - epoch 585: train loss 0.042223691267685756\n",
      "2025-09-07 20:34:21,226 - INFO - 585 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:21,237 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:21,248 - INFO - --------------------\n",
      "\n",
      "586/800: 100%|██████████| 216/216 [00:06<00:00, 35.86it/s]\n",
      "2025-09-07 20:34:27,461 - INFO - All types `lr` of epoch 586: {'lr/param_group0': 7.493032646787906e-05, 'lr/param_group1': 7.493032646787906e-05, 'lr/param_group2': 7.493032646787906e-05, 'lr/param_group3': 7.493032646787906e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:27,477 - INFO - epoch 586: train loss 0.04191263232173191\n",
      "2025-09-07 20:34:27,490 - INFO - 586 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:27,503 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:27,514 - INFO - --------------------\n",
      "\n",
      "587/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:34:33,809 - INFO - All types `lr` of epoch 587: {'lr/param_group0': 7.453612103956846e-05, 'lr/param_group1': 7.453612103956846e-05, 'lr/param_group2': 7.453612103956846e-05, 'lr/param_group3': 7.453612103956846e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:33,821 - INFO - epoch 587: train loss 0.04203514499520814\n",
      "2025-09-07 20:34:33,833 - INFO - 587 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:33,838 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:33,849 - INFO - --------------------\n",
      "\n",
      "588/800: 100%|██████████| 216/216 [00:05<00:00, 37.10it/s]\n",
      "2025-09-07 20:34:39,879 - INFO - All types `lr` of epoch 588: {'lr/param_group0': 7.41433106761806e-05, 'lr/param_group1': 7.41433106761806e-05, 'lr/param_group2': 7.41433106761806e-05, 'lr/param_group3': 7.41433106761806e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:39,893 - INFO - epoch 588: train loss 0.041878556798177737\n",
      "2025-09-07 20:34:39,898 - INFO - 588 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:39,910 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:39,922 - INFO - --------------------\n",
      "\n",
      "589/800: 100%|██████████| 216/216 [00:06<00:00, 35.77it/s]\n",
      "2025-09-07 20:34:46,161 - INFO - All types `lr` of epoch 589: {'lr/param_group0': 7.375190143533715e-05, 'lr/param_group1': 7.375190143533715e-05, 'lr/param_group2': 7.375190143533715e-05, 'lr/param_group3': 7.375190143533715e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:46,174 - INFO - epoch 589: train loss 0.041858123132476104\n",
      "2025-09-07 20:34:46,179 - INFO - 589 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:46,191 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:46,203 - INFO - --------------------\n",
      "\n",
      "590/800: 100%|██████████| 216/216 [00:05<00:00, 36.05it/s]\n",
      "2025-09-07 20:34:52,400 - INFO - All types `lr` of epoch 590: {'lr/param_group0': 7.336189935305285e-05, 'lr/param_group1': 7.336189935305285e-05, 'lr/param_group2': 7.336189935305285e-05, 'lr/param_group3': 7.336189935305285e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:52,404 - INFO - epoch 590: train loss 0.04186458237193249\n",
      "2025-09-07 20:34:52,416 - INFO - 590 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:52,428 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:52,432 - INFO - --------------------\n",
      "\n",
      "591/800: 100%|██████████| 216/216 [00:06<00:00, 35.96it/s]\n",
      "2025-09-07 20:34:58,657 - INFO - All types `lr` of epoch 591: {'lr/param_group0': 7.297331044364226e-05, 'lr/param_group1': 7.297331044364226e-05, 'lr/param_group2': 7.297331044364226e-05, 'lr/param_group3': 7.297331044364226e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:34:58,662 - INFO - epoch 591: train loss 0.04171280862970485\n",
      "2025-09-07 20:34:58,673 - INFO - 591 epochs completed!\n",
      "\n",
      "2025-09-07 20:34:58,685 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:34:58,690 - INFO - --------------------\n",
      "\n",
      "592/800: 100%|██████████| 216/216 [00:06<00:00, 35.69it/s]\n",
      "2025-09-07 20:35:04,947 - INFO - All types `lr` of epoch 592: {'lr/param_group0': 7.258614069962701e-05, 'lr/param_group1': 7.258614069962701e-05, 'lr/param_group2': 7.258614069962701e-05, 'lr/param_group3': 7.258614069962701e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:04,961 - INFO - epoch 592: train loss 0.04165226186591166\n",
      "2025-09-07 20:35:04,974 - INFO - 592 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:04,978 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:04,990 - INFO - --------------------\n",
      "\n",
      "593/800: 100%|██████████| 216/216 [00:05<00:00, 36.23it/s]\n",
      "2025-09-07 20:35:11,168 - INFO - All types `lr` of epoch 593: {'lr/param_group0': 7.220039609164358e-05, 'lr/param_group1': 7.220039609164358e-05, 'lr/param_group2': 7.220039609164358e-05, 'lr/param_group3': 7.220039609164358e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:11,182 - INFO - epoch 593: train loss 0.04177368004564886\n",
      "2025-09-07 20:35:11,187 - INFO - 593 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:11,199 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:11,212 - INFO - --------------------\n",
      "\n",
      "594/800: 100%|██████████| 216/216 [00:06<00:00, 35.15it/s]\n",
      "2025-09-07 20:35:17,564 - INFO - All types `lr` of epoch 594: {'lr/param_group0': 7.181608256835098e-05, 'lr/param_group1': 7.181608256835098e-05, 'lr/param_group2': 7.181608256835098e-05, 'lr/param_group3': 7.181608256835098e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:17,568 - INFO - epoch 594: train loss 0.041949946243591885\n",
      "2025-09-07 20:35:17,580 - INFO - 594 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:17,594 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:17,607 - INFO - --------------------\n",
      "\n",
      "595/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:35:23,897 - INFO - All types `lr` of epoch 595: {'lr/param_group0': 7.143320605633917e-05, 'lr/param_group1': 7.143320605633917e-05, 'lr/param_group2': 7.143320605633917e-05, 'lr/param_group3': 7.143320605633917e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:23,911 - INFO - epoch 595: train loss 0.041886855089278134\n",
      "2025-09-07 20:35:23,915 - INFO - 595 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:23,926 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:23,939 - INFO - --------------------\n",
      "\n",
      "596/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 20:35:30,123 - INFO - All types `lr` of epoch 596: {'lr/param_group0': 7.105177246003757e-05, 'lr/param_group1': 7.105177246003757e-05, 'lr/param_group2': 7.105177246003757e-05, 'lr/param_group3': 7.105177246003757e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:30,139 - INFO - epoch 596: train loss 0.04166876709226657\n",
      "2025-09-07 20:35:30,153 - INFO - 596 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:30,165 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:30,177 - INFO - --------------------\n",
      "\n",
      "597/800: 100%|██████████| 216/216 [00:06<00:00, 35.97it/s]\n",
      "2025-09-07 20:35:36,406 - INFO - All types `lr` of epoch 597: {'lr/param_group0': 7.067178766162413e-05, 'lr/param_group1': 7.067178766162413e-05, 'lr/param_group2': 7.067178766162413e-05, 'lr/param_group3': 7.067178766162413e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:36,418 - INFO - epoch 597: train loss 0.04173123896880834\n",
      "2025-09-07 20:35:36,430 - INFO - 597 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:36,434 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:36,446 - INFO - --------------------\n",
      "\n",
      "598/800: 100%|██████████| 216/216 [00:06<00:00, 35.52it/s]\n",
      "2025-09-07 20:35:42,739 - INFO - All types `lr` of epoch 598: {'lr/param_group0': 7.029325752093448e-05, 'lr/param_group1': 7.029325752093448e-05, 'lr/param_group2': 7.029325752093448e-05, 'lr/param_group3': 7.029325752093448e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:42,752 - INFO - epoch 598: train loss 0.041754480813526444\n",
      "2025-09-07 20:35:42,764 - INFO - 598 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:42,769 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:42,781 - INFO - --------------------\n",
      "\n",
      "599/800: 100%|██████████| 216/216 [00:06<00:00, 35.67it/s]\n",
      "2025-09-07 20:35:49,043 - INFO - All types `lr` of epoch 599: {'lr/param_group0': 6.991618787537162e-05, 'lr/param_group1': 6.991618787537162e-05, 'lr/param_group2': 6.991618787537162e-05, 'lr/param_group3': 6.991618787537162e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:49,057 - INFO - epoch 599: train loss 0.041637685581075924\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.15it/s]\n",
      "2025-09-07 20:35:50,547 - INFO - epoch 599: val loss 0.05929036183213746\n",
      "2025-09-07 20:35:50,562 - INFO - 599 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:35:50,662 - INFO - epoch 599 has been saved\n",
      "2025-09-07 20:35:50,999 - INFO - 599 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:51,017 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:51,030 - INFO - --------------------\n",
      "\n",
      "600/800: 100%|██████████| 216/216 [00:06<00:00, 35.72it/s]\n",
      "2025-09-07 20:35:57,271 - INFO - All types `lr` of epoch 600: {'lr/param_group0': 6.954058453981608e-05, 'lr/param_group1': 6.954058453981608e-05, 'lr/param_group2': 6.954058453981608e-05, 'lr/param_group3': 6.954058453981608e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:35:57,284 - INFO - epoch 600: train loss 0.04173035571282661\n",
      "2025-09-07 20:35:57,296 - INFO - 600 epochs completed!\n",
      "\n",
      "2025-09-07 20:35:57,301 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:35:57,313 - INFO - --------------------\n",
      "\n",
      "601/800: 100%|██████████| 216/216 [00:05<00:00, 36.24it/s]\n",
      "2025-09-07 20:36:03,479 - INFO - All types `lr` of epoch 601: {'lr/param_group0': 6.916645330653582e-05, 'lr/param_group1': 6.916645330653582e-05, 'lr/param_group2': 6.916645330653582e-05, 'lr/param_group3': 6.916645330653582e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:03,492 - INFO - epoch 601: train loss 0.04207905544037068\n",
      "2025-09-07 20:36:03,505 - INFO - 601 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:03,509 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:03,520 - INFO - --------------------\n",
      "\n",
      "602/800: 100%|██████████| 216/216 [00:05<00:00, 36.38it/s]\n",
      "2025-09-07 20:36:09,649 - INFO - All types `lr` of epoch 602: {'lr/param_group0': 6.879379994509727e-05, 'lr/param_group1': 6.879379994509727e-05, 'lr/param_group2': 6.879379994509727e-05, 'lr/param_group3': 6.879379994509727e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:09,664 - INFO - epoch 602: train loss 0.041699438355863094\n",
      "2025-09-07 20:36:09,677 - INFO - 602 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:09,689 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:09,701 - INFO - --------------------\n",
      "\n",
      "603/800: 100%|██████████| 216/216 [00:06<00:00, 35.93it/s]\n",
      "2025-09-07 20:36:15,932 - INFO - All types `lr` of epoch 603: {'lr/param_group0': 6.84226302022763e-05, 'lr/param_group1': 6.84226302022763e-05, 'lr/param_group2': 6.84226302022763e-05, 'lr/param_group3': 6.84226302022763e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:15,936 - INFO - epoch 603: train loss 0.04152032432870732\n",
      "2025-09-07 20:36:15,948 - INFO - 603 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:15,952 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:15,963 - INFO - --------------------\n",
      "\n",
      "604/800: 100%|██████████| 216/216 [00:05<00:00, 36.05it/s]\n",
      "2025-09-07 20:36:22,164 - INFO - All types `lr` of epoch 604: {'lr/param_group0': 6.805294980196951e-05, 'lr/param_group1': 6.805294980196951e-05, 'lr/param_group2': 6.805294980196951e-05, 'lr/param_group3': 6.805294980196951e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:22,178 - INFO - epoch 604: train loss 0.04179720371892607\n",
      "2025-09-07 20:36:22,181 - INFO - 604 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:22,193 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:22,205 - INFO - --------------------\n",
      "\n",
      "605/800: 100%|██████████| 216/216 [00:07<00:00, 30.82it/s]\n",
      "2025-09-07 20:36:29,420 - INFO - All types `lr` of epoch 605: {'lr/param_group0': 6.768476444510594e-05, 'lr/param_group1': 6.768476444510594e-05, 'lr/param_group2': 6.768476444510594e-05, 'lr/param_group3': 6.768476444510594e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:29,425 - INFO - epoch 605: train loss 0.041778222692233545\n",
      "2025-09-07 20:36:29,437 - INFO - 605 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:29,449 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:29,453 - INFO - --------------------\n",
      "\n",
      "606/800: 100%|██████████| 216/216 [00:06<00:00, 35.54it/s]\n",
      "2025-09-07 20:36:35,735 - INFO - All types `lr` of epoch 606: {'lr/param_group0': 6.731807980955936e-05, 'lr/param_group1': 6.731807980955936e-05, 'lr/param_group2': 6.731807980955936e-05, 'lr/param_group3': 6.731807980955936e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:35,748 - INFO - epoch 606: train loss 0.04162025449935485\n",
      "2025-09-07 20:36:35,761 - INFO - 606 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:35,766 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:35,777 - INFO - --------------------\n",
      "\n",
      "607/800: 100%|██████████| 216/216 [00:06<00:00, 35.81it/s]\n",
      "2025-09-07 20:36:42,020 - INFO - All types `lr` of epoch 607: {'lr/param_group0': 6.69529015500603e-05, 'lr/param_group1': 6.69529015500603e-05, 'lr/param_group2': 6.69529015500603e-05, 'lr/param_group3': 6.69529015500603e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:42,034 - INFO - epoch 607: train loss 0.041794012455890574\n",
      "2025-09-07 20:36:42,039 - INFO - 607 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:42,050 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:42,062 - INFO - --------------------\n",
      "\n",
      "608/800: 100%|██████████| 216/216 [00:06<00:00, 35.81it/s]\n",
      "2025-09-07 20:36:48,287 - INFO - All types `lr` of epoch 608: {'lr/param_group0': 6.658923529810944e-05, 'lr/param_group1': 6.658923529810944e-05, 'lr/param_group2': 6.658923529810944e-05, 'lr/param_group3': 6.658923529810944e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:48,301 - INFO - epoch 608: train loss 0.0416909071823789\n",
      "2025-09-07 20:36:48,306 - INFO - 608 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:48,318 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:48,330 - INFO - --------------------\n",
      "\n",
      "609/800: 100%|██████████| 216/216 [00:06<00:00, 35.52it/s]\n",
      "2025-09-07 20:36:54,606 - INFO - All types `lr` of epoch 609: {'lr/param_group0': 6.622708666189018e-05, 'lr/param_group1': 6.622708666189018e-05, 'lr/param_group2': 6.622708666189018e-05, 'lr/param_group3': 6.622708666189018e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:36:54,620 - INFO - epoch 609: train loss 0.04162447785751687\n",
      "2025-09-07 20:36:54,635 - INFO - 609 epochs completed!\n",
      "\n",
      "2025-09-07 20:36:54,648 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:36:54,661 - INFO - --------------------\n",
      "\n",
      "610/800: 100%|██████████| 216/216 [00:06<00:00, 35.45it/s]\n",
      "2025-09-07 20:37:00,959 - INFO - All types `lr` of epoch 610: {'lr/param_group0': 6.586646122618242e-05, 'lr/param_group1': 6.586646122618242e-05, 'lr/param_group2': 6.586646122618242e-05, 'lr/param_group3': 6.586646122618242e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:00,975 - INFO - epoch 610: train loss 0.04159719205495936\n",
      "2025-09-07 20:37:00,988 - INFO - 610 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:01,001 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:01,013 - INFO - --------------------\n",
      "\n",
      "611/800: 100%|██████████| 216/216 [00:05<00:00, 36.09it/s]\n",
      "2025-09-07 20:37:07,223 - INFO - All types `lr` of epoch 611: {'lr/param_group0': 6.550736455227665e-05, 'lr/param_group1': 6.550736455227665e-05, 'lr/param_group2': 6.550736455227665e-05, 'lr/param_group3': 6.550736455227665e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:07,228 - INFO - epoch 611: train loss 0.0417112839339232\n",
      "2025-09-07 20:37:07,240 - INFO - 611 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:07,243 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:07,254 - INFO - --------------------\n",
      "\n",
      "612/800: 100%|██████████| 216/216 [00:06<00:00, 35.64it/s]\n",
      "2025-09-07 20:37:13,521 - INFO - All types `lr` of epoch 612: {'lr/param_group0': 6.514980217788766e-05, 'lr/param_group1': 6.514980217788766e-05, 'lr/param_group2': 6.514980217788766e-05, 'lr/param_group3': 6.514980217788766e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:13,535 - INFO - epoch 612: train loss 0.04158793227678096\n",
      "2025-09-07 20:37:13,540 - INFO - 612 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:13,552 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:13,563 - INFO - --------------------\n",
      "\n",
      "613/800: 100%|██████████| 216/216 [00:06<00:00, 35.50it/s]\n",
      "2025-09-07 20:37:19,852 - INFO - All types `lr` of epoch 613: {'lr/param_group0': 6.47937796170697e-05, 'lr/param_group1': 6.47937796170697e-05, 'lr/param_group2': 6.47937796170697e-05, 'lr/param_group3': 6.47937796170697e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:19,857 - INFO - epoch 613: train loss 0.04146970177276267\n",
      "2025-09-07 20:37:19,869 - INFO - 613 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:19,882 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:19,886 - INFO - --------------------\n",
      "\n",
      "614/800: 100%|██████████| 216/216 [00:06<00:00, 35.77it/s]\n",
      "2025-09-07 20:37:26,146 - INFO - All types `lr` of epoch 614: {'lr/param_group0': 6.443930236013102e-05, 'lr/param_group1': 6.443930236013102e-05, 'lr/param_group2': 6.443930236013102e-05, 'lr/param_group3': 6.443930236013102e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:26,151 - INFO - epoch 614: train loss 0.04147798559386973\n",
      "2025-09-07 20:37:26,163 - INFO - 614 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:26,175 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:26,180 - INFO - --------------------\n",
      "\n",
      "615/800: 100%|██████████| 216/216 [00:06<00:00, 35.83it/s]\n",
      "2025-09-07 20:37:32,418 - INFO - All types `lr` of epoch 615: {'lr/param_group0': 6.408637587354946e-05, 'lr/param_group1': 6.408637587354946e-05, 'lr/param_group2': 6.408637587354946e-05, 'lr/param_group3': 6.408637587354946e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:32,431 - INFO - epoch 615: train loss 0.04144228843075258\n",
      "2025-09-07 20:37:32,445 - INFO - 615 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:32,449 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:32,461 - INFO - --------------------\n",
      "\n",
      "616/800: 100%|██████████| 216/216 [00:06<00:00, 35.74it/s]\n",
      "2025-09-07 20:37:38,716 - INFO - All types `lr` of epoch 616: {'lr/param_group0': 6.373500559988796e-05, 'lr/param_group1': 6.373500559988796e-05, 'lr/param_group2': 6.373500559988796e-05, 'lr/param_group3': 6.373500559988796e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:38,730 - INFO - epoch 616: train loss 0.04155514297868918\n",
      "2025-09-07 20:37:38,735 - INFO - 616 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:38,747 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:38,759 - INFO - --------------------\n",
      "\n",
      "617/800: 100%|██████████| 216/216 [00:06<00:00, 35.79it/s]\n",
      "2025-09-07 20:37:44,990 - INFO - All types `lr` of epoch 617: {'lr/param_group0': 6.338519695771089e-05, 'lr/param_group1': 6.338519695771089e-05, 'lr/param_group2': 6.338519695771089e-05, 'lr/param_group3': 6.338519695771089e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:45,004 - INFO - epoch 617: train loss 0.04166344554956864\n",
      "2025-09-07 20:37:45,009 - INFO - 617 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:45,021 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:45,034 - INFO - --------------------\n",
      "\n",
      "618/800: 100%|██████████| 216/216 [00:06<00:00, 35.56it/s]\n",
      "2025-09-07 20:37:51,313 - INFO - All types `lr` of epoch 618: {'lr/param_group0': 6.30369553415002e-05, 'lr/param_group1': 6.30369553415002e-05, 'lr/param_group2': 6.30369553415002e-05, 'lr/param_group3': 6.30369553415002e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:51,318 - INFO - epoch 618: train loss 0.04151912143936864\n",
      "2025-09-07 20:37:51,331 - INFO - 618 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:51,343 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:51,348 - INFO - --------------------\n",
      "\n",
      "619/800: 100%|██████████| 216/216 [00:06<00:00, 35.51it/s]\n",
      "2025-09-07 20:37:57,648 - INFO - All types `lr` of epoch 619: {'lr/param_group0': 6.269028612157242e-05, 'lr/param_group1': 6.269028612157242e-05, 'lr/param_group2': 6.269028612157242e-05, 'lr/param_group3': 6.269028612157242e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:37:57,653 - INFO - epoch 619: train loss 0.04124588226140649\n",
      "2025-09-07 20:37:57,665 - INFO - 619 epochs completed!\n",
      "\n",
      "2025-09-07 20:37:57,669 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:37:57,681 - INFO - --------------------\n",
      "\n",
      "620/800: 100%|██████████| 216/216 [00:06<00:00, 35.91it/s]\n",
      "2025-09-07 20:38:03,907 - INFO - All types `lr` of epoch 620: {'lr/param_group0': 6.234519464399581e-05, 'lr/param_group1': 6.234519464399581e-05, 'lr/param_group2': 6.234519464399581e-05, 'lr/param_group3': 6.234519464399581e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:03,920 - INFO - epoch 620: train loss 0.041402317186886514\n",
      "2025-09-07 20:38:03,924 - INFO - 620 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:03,936 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:03,949 - INFO - --------------------\n",
      "\n",
      "621/800: 100%|██████████| 216/216 [00:06<00:00, 35.50it/s]\n",
      "2025-09-07 20:38:10,230 - INFO - All types `lr` of epoch 621: {'lr/param_group0': 6.200168623050778e-05, 'lr/param_group1': 6.200168623050778e-05, 'lr/param_group2': 6.200168623050778e-05, 'lr/param_group3': 6.200168623050778e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:10,235 - INFO - epoch 621: train loss 0.04151147948922934\n",
      "2025-09-07 20:38:10,247 - INFO - 621 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:10,260 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:10,265 - INFO - --------------------\n",
      "\n",
      "622/800: 100%|██████████| 216/216 [00:06<00:00, 35.46it/s]\n",
      "2025-09-07 20:38:16,563 - INFO - All types `lr` of epoch 622: {'lr/param_group0': 6.165976617843312e-05, 'lr/param_group1': 6.165976617843312e-05, 'lr/param_group2': 6.165976617843312e-05, 'lr/param_group3': 6.165976617843312e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:16,577 - INFO - epoch 622: train loss 0.04121855613603084\n",
      "2025-09-07 20:38:16,590 - INFO - 622 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:16,595 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:16,607 - INFO - --------------------\n",
      "\n",
      "623/800: 100%|██████████| 216/216 [00:06<00:00, 35.68it/s]\n",
      "2025-09-07 20:38:22,875 - INFO - All types `lr` of epoch 623: {'lr/param_group0': 6.131943976060184e-05, 'lr/param_group1': 6.131943976060184e-05, 'lr/param_group2': 6.131943976060184e-05, 'lr/param_group3': 6.131943976060184e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:22,890 - INFO - epoch 623: train loss 0.041468911028156676\n",
      "2025-09-07 20:38:22,895 - INFO - 623 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:22,907 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:22,919 - INFO - --------------------\n",
      "\n",
      "624/800: 100%|██████████| 216/216 [00:06<00:00, 35.69it/s]\n",
      "2025-09-07 20:38:29,168 - INFO - All types `lr` of epoch 624: {'lr/param_group0': 6.098071222526847e-05, 'lr/param_group1': 6.098071222526847e-05, 'lr/param_group2': 6.098071222526847e-05, 'lr/param_group3': 6.098071222526847e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:29,183 - INFO - epoch 624: train loss 0.04148177602500827\n",
      "2025-09-07 20:38:29,188 - INFO - 624 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:29,200 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:29,214 - INFO - --------------------\n",
      "\n",
      "625/800: 100%|██████████| 216/216 [00:06<00:00, 35.35it/s]\n",
      "2025-09-07 20:38:35,520 - INFO - All types `lr` of epoch 625: {'lr/param_group0': 6.0643588796030495e-05, 'lr/param_group1': 6.0643588796030495e-05, 'lr/param_group2': 6.0643588796030495e-05, 'lr/param_group3': 6.0643588796030495e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:35,535 - INFO - epoch 625: train loss 0.04142654166315441\n",
      "2025-09-07 20:38:35,540 - INFO - 625 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:35,552 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:35,564 - INFO - --------------------\n",
      "\n",
      "626/800: 100%|██████████| 216/216 [00:06<00:00, 35.48it/s]\n",
      "2025-09-07 20:38:41,863 - INFO - All types `lr` of epoch 626: {'lr/param_group0': 6.030807467174835e-05, 'lr/param_group1': 6.030807467174835e-05, 'lr/param_group2': 6.030807467174835e-05, 'lr/param_group3': 6.030807467174835e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:41,868 - INFO - epoch 626: train loss 0.04132461647882506\n",
      "2025-09-07 20:38:41,880 - INFO - 626 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:41,892 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:41,897 - INFO - --------------------\n",
      "\n",
      "627/800: 100%|██████████| 216/216 [00:06<00:00, 35.89it/s]\n",
      "2025-09-07 20:38:48,117 - INFO - All types `lr` of epoch 627: {'lr/param_group0': 5.9974175026464796e-05, 'lr/param_group1': 5.9974175026464796e-05, 'lr/param_group2': 5.9974175026464796e-05, 'lr/param_group3': 5.9974175026464796e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:48,130 - INFO - epoch 627: train loss 0.04125913863794671\n",
      "2025-09-07 20:38:48,143 - INFO - 627 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:48,148 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:48,160 - INFO - --------------------\n",
      "\n",
      "628/800: 100%|██████████| 216/216 [00:06<00:00, 35.38it/s]\n",
      "2025-09-07 20:38:54,474 - INFO - All types `lr` of epoch 628: {'lr/param_group0': 5.964189500932548e-05, 'lr/param_group1': 5.964189500932548e-05, 'lr/param_group2': 5.964189500932548e-05, 'lr/param_group3': 5.964189500932548e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:38:54,488 - INFO - epoch 628: train loss 0.04136376025983029\n",
      "2025-09-07 20:38:54,493 - INFO - 628 epochs completed!\n",
      "\n",
      "2025-09-07 20:38:54,505 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:38:54,508 - INFO - --------------------\n",
      "\n",
      "629/800: 100%|██████████| 216/216 [00:06<00:00, 35.64it/s]\n",
      "2025-09-07 20:39:00,783 - INFO - All types `lr` of epoch 629: {'lr/param_group0': 5.9311239744499286e-05, 'lr/param_group1': 5.9311239744499286e-05, 'lr/param_group2': 5.9311239744499286e-05, 'lr/param_group3': 5.9311239744499286e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:00,788 - INFO - epoch 629: train loss 0.041259932624935\n",
      "2025-09-07 20:39:00,800 - INFO - 629 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:00,804 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:00,816 - INFO - --------------------\n",
      "\n",
      "630/800: 100%|██████████| 216/216 [00:06<00:00, 35.80it/s]\n",
      "2025-09-07 20:39:07,075 - INFO - All types `lr` of epoch 630: {'lr/param_group0': 5.898221433109941e-05, 'lr/param_group1': 5.898221433109941e-05, 'lr/param_group2': 5.898221433109941e-05, 'lr/param_group3': 5.898221433109941e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:07,089 - INFO - epoch 630: train loss 0.04135802514092238\n",
      "2025-09-07 20:39:07,093 - INFO - 630 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:07,105 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:07,118 - INFO - --------------------\n",
      "\n",
      "631/800: 100%|██████████| 216/216 [00:06<00:00, 33.39it/s]\n",
      "2025-09-07 20:39:13,786 - INFO - All types `lr` of epoch 631: {'lr/param_group0': 5.8654823843104824e-05, 'lr/param_group1': 5.8654823843104824e-05, 'lr/param_group2': 5.8654823843104824e-05, 'lr/param_group3': 5.8654823843104824e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:13,799 - INFO - epoch 631: train loss 0.04122845769894344\n",
      "2025-09-07 20:39:13,812 - INFO - 631 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:13,816 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:13,828 - INFO - --------------------\n",
      "\n",
      "632/800: 100%|██████████| 216/216 [00:06<00:00, 35.90it/s]\n",
      "2025-09-07 20:39:20,052 - INFO - All types `lr` of epoch 632: {'lr/param_group0': 5.832907332928177e-05, 'lr/param_group1': 5.832907332928177e-05, 'lr/param_group2': 5.832907332928177e-05, 'lr/param_group3': 5.832907332928177e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:20,067 - INFO - epoch 632: train loss 0.0414261971945288\n",
      "2025-09-07 20:39:20,072 - INFO - 632 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:20,085 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:20,097 - INFO - --------------------\n",
      "\n",
      "633/800: 100%|██████████| 216/216 [00:06<00:00, 35.29it/s]\n",
      "2025-09-07 20:39:26,413 - INFO - All types `lr` of epoch 633: {'lr/param_group0': 5.800496781310625e-05, 'lr/param_group1': 5.800496781310625e-05, 'lr/param_group2': 5.800496781310625e-05, 'lr/param_group3': 5.800496781310625e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:26,427 - INFO - epoch 633: train loss 0.04122523080419611\n",
      "2025-09-07 20:39:26,432 - INFO - 633 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:26,444 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:26,457 - INFO - --------------------\n",
      "\n",
      "634/800: 100%|██████████| 216/216 [00:06<00:00, 35.63it/s]\n",
      "2025-09-07 20:39:32,728 - INFO - All types `lr` of epoch 634: {'lr/param_group0': 5.7682512292686124e-05, 'lr/param_group1': 5.7682512292686124e-05, 'lr/param_group2': 5.7682512292686124e-05, 'lr/param_group3': 5.7682512292686124e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:32,733 - INFO - epoch 634: train loss 0.04120564783267953\n",
      "2025-09-07 20:39:32,748 - INFO - 634 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:32,761 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:32,766 - INFO - --------------------\n",
      "\n",
      "635/800: 100%|██████████| 216/216 [00:05<00:00, 36.00it/s]\n",
      "2025-09-07 20:39:38,969 - INFO - All types `lr` of epoch 635: {'lr/param_group0': 5.736171174068453e-05, 'lr/param_group1': 5.736171174068453e-05, 'lr/param_group2': 5.736171174068453e-05, 'lr/param_group3': 5.736171174068453e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:38,983 - INFO - epoch 635: train loss 0.04122576971227924\n",
      "2025-09-07 20:39:38,997 - INFO - 635 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:39,002 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:39,015 - INFO - --------------------\n",
      "\n",
      "636/800: 100%|██████████| 216/216 [00:05<00:00, 36.02it/s]\n",
      "2025-09-07 20:39:45,228 - INFO - All types `lr` of epoch 636: {'lr/param_group0': 5.704257110424275e-05, 'lr/param_group1': 5.704257110424275e-05, 'lr/param_group2': 5.704257110424275e-05, 'lr/param_group3': 5.704257110424275e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:45,242 - INFO - epoch 636: train loss 0.041181117934347304\n",
      "2025-09-07 20:39:45,254 - INFO - 636 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:45,259 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:45,271 - INFO - --------------------\n",
      "\n",
      "637/800: 100%|██████████| 216/216 [00:06<00:00, 34.71it/s]\n",
      "2025-09-07 20:39:51,703 - INFO - All types `lr` of epoch 637: {'lr/param_group0': 5.672509530490431e-05, 'lr/param_group1': 5.672509530490431e-05, 'lr/param_group2': 5.672509530490431e-05, 'lr/param_group3': 5.672509530490431e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:51,717 - INFO - epoch 637: train loss 0.04131672896996692\n",
      "2025-09-07 20:39:51,722 - INFO - 637 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:51,735 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:51,739 - INFO - --------------------\n",
      "\n",
      "638/800: 100%|██████████| 216/216 [00:06<00:00, 35.47it/s]\n",
      "2025-09-07 20:39:58,046 - INFO - All types `lr` of epoch 638: {'lr/param_group0': 5.640928923853859e-05, 'lr/param_group1': 5.640928923853859e-05, 'lr/param_group2': 5.640928923853859e-05, 'lr/param_group3': 5.640928923853859e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:39:58,051 - INFO - epoch 638: train loss 0.04110166821973743\n",
      "2025-09-07 20:39:58,063 - INFO - 638 epochs completed!\n",
      "\n",
      "2025-09-07 20:39:58,067 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:39:58,080 - INFO - --------------------\n",
      "\n",
      "639/800: 100%|██████████| 216/216 [00:06<00:00, 35.05it/s]\n",
      "2025-09-07 20:40:04,460 - INFO - All types `lr` of epoch 639: {'lr/param_group0': 5.609515777526597e-05, 'lr/param_group1': 5.609515777526597e-05, 'lr/param_group2': 5.609515777526597e-05, 'lr/param_group3': 5.609515777526597e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:04,465 - INFO - epoch 639: train loss 0.0414001501372291\n",
      "100%|██████████| 54/54 [00:01<00:00, 41.91it/s]\n",
      "2025-09-07 20:40:05,965 - INFO - epoch 639: val loss 0.059341697574213696\n",
      "2025-09-07 20:40:05,980 - INFO - 639 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:40:05,998 - INFO - 639 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:06,003 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:06,015 - INFO - --------------------\n",
      "\n",
      "640/800: 100%|██████████| 216/216 [00:06<00:00, 34.74it/s]\n",
      "2025-09-07 20:40:12,456 - INFO - All types `lr` of epoch 640: {'lr/param_group0': 5.57827057593821e-05, 'lr/param_group1': 5.57827057593821e-05, 'lr/param_group2': 5.57827057593821e-05, 'lr/param_group3': 5.57827057593821e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:12,461 - INFO - epoch 640: train loss 0.04153695571477766\n",
      "2025-09-07 20:40:12,474 - INFO - 640 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:12,487 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:12,492 - INFO - --------------------\n",
      "\n",
      "641/800: 100%|██████████| 216/216 [00:06<00:00, 35.56it/s]\n",
      "2025-09-07 20:40:18,772 - INFO - All types `lr` of epoch 641: {'lr/param_group0': 5.54719380092836e-05, 'lr/param_group1': 5.54719380092836e-05, 'lr/param_group2': 5.54719380092836e-05, 'lr/param_group3': 5.54719380092836e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:18,785 - INFO - epoch 641: train loss 0.04111192408190281\n",
      "2025-09-07 20:40:18,799 - INFO - 641 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:18,804 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:18,817 - INFO - --------------------\n",
      "\n",
      "642/800: 100%|██████████| 216/216 [00:06<00:00, 34.40it/s]\n",
      "2025-09-07 20:40:25,323 - INFO - All types `lr` of epoch 642: {'lr/param_group0': 5.516285931739377e-05, 'lr/param_group1': 5.516285931739377e-05, 'lr/param_group2': 5.516285931739377e-05, 'lr/param_group3': 5.516285931739377e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:25,328 - INFO - epoch 642: train loss 0.041231470199784744\n",
      "2025-09-07 20:40:25,341 - INFO - 642 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:25,354 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:25,359 - INFO - --------------------\n",
      "\n",
      "643/800: 100%|██████████| 216/216 [00:06<00:00, 35.00it/s]\n",
      "2025-09-07 20:40:31,748 - INFO - All types `lr` of epoch 643: {'lr/param_group0': 5.485547445008817e-05, 'lr/param_group1': 5.485547445008817e-05, 'lr/param_group2': 5.485547445008817e-05, 'lr/param_group3': 5.485547445008817e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:31,762 - INFO - epoch 643: train loss 0.04100257408356777\n",
      "2025-09-07 20:40:31,775 - INFO - 643 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:31,780 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:31,792 - INFO - --------------------\n",
      "\n",
      "644/800: 100%|██████████| 216/216 [00:06<00:00, 34.78it/s]\n",
      "2025-09-07 20:40:38,200 - INFO - All types `lr` of epoch 644: {'lr/param_group0': 5.454978814762184e-05, 'lr/param_group1': 5.454978814762184e-05, 'lr/param_group2': 5.454978814762184e-05, 'lr/param_group3': 5.454978814762184e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:38,214 - INFO - epoch 644: train loss 0.04131546031890644\n",
      "2025-09-07 20:40:38,218 - INFO - 644 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:38,230 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:38,242 - INFO - --------------------\n",
      "\n",
      "645/800: 100%|██████████| 216/216 [00:06<00:00, 35.27it/s]\n",
      "2025-09-07 20:40:44,567 - INFO - All types `lr` of epoch 645: {'lr/param_group0': 5.424580512405564e-05, 'lr/param_group1': 5.424580512405564e-05, 'lr/param_group2': 5.424580512405564e-05, 'lr/param_group3': 5.424580512405564e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:44,584 - INFO - epoch 645: train loss 0.041066278910471335\n",
      "2025-09-07 20:40:44,598 - INFO - 645 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:44,611 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:44,622 - INFO - --------------------\n",
      "\n",
      "646/800: 100%|██████████| 216/216 [00:06<00:00, 34.90it/s]\n",
      "2025-09-07 20:40:51,021 - INFO - All types `lr` of epoch 646: {'lr/param_group0': 5.3943530067183914e-05, 'lr/param_group1': 5.3943530067183914e-05, 'lr/param_group2': 5.3943530067183914e-05, 'lr/param_group3': 5.3943530067183914e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:51,035 - INFO - epoch 646: train loss 0.04110223034189807\n",
      "2025-09-07 20:40:51,048 - INFO - 646 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:51,053 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:51,065 - INFO - --------------------\n",
      "\n",
      "647/800: 100%|██████████| 216/216 [00:06<00:00, 35.38it/s]\n",
      "2025-09-07 20:40:57,383 - INFO - All types `lr` of epoch 647: {'lr/param_group0': 5.364296763846192e-05, 'lr/param_group1': 5.364296763846192e-05, 'lr/param_group2': 5.364296763846192e-05, 'lr/param_group3': 5.364296763846192e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:40:57,398 - INFO - epoch 647: train loss 0.04127283413308086\n",
      "2025-09-07 20:40:57,403 - INFO - 647 epochs completed!\n",
      "\n",
      "2025-09-07 20:40:57,416 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:40:57,428 - INFO - --------------------\n",
      "\n",
      "648/800: 100%|██████████| 216/216 [00:06<00:00, 35.36it/s]\n",
      "2025-09-07 20:41:03,747 - INFO - All types `lr` of epoch 648: {'lr/param_group0': 5.334412247293417e-05, 'lr/param_group1': 5.334412247293417e-05, 'lr/param_group2': 5.334412247293417e-05, 'lr/param_group3': 5.334412247293417e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:03,752 - INFO - epoch 648: train loss 0.04119309548426558\n",
      "2025-09-07 20:41:03,764 - INFO - 648 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:03,777 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:03,782 - INFO - --------------------\n",
      "\n",
      "649/800: 100%|██████████| 216/216 [00:06<00:00, 35.52it/s]\n",
      "2025-09-07 20:41:10,072 - INFO - All types `lr` of epoch 649: {'lr/param_group0': 5.304699917916273e-05, 'lr/param_group1': 5.304699917916273e-05, 'lr/param_group2': 5.304699917916273e-05, 'lr/param_group3': 5.304699917916273e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:10,086 - INFO - epoch 649: train loss 0.041086343099811566\n",
      "2025-09-07 20:41:10,099 - INFO - 649 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:10,104 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:10,117 - INFO - --------------------\n",
      "\n",
      "650/800: 100%|██████████| 216/216 [00:06<00:00, 35.76it/s]\n",
      "2025-09-07 20:41:16,374 - INFO - All types `lr` of epoch 650: {'lr/param_group0': 5.275160233915644e-05, 'lr/param_group1': 5.275160233915644e-05, 'lr/param_group2': 5.275160233915644e-05, 'lr/param_group3': 5.275160233915644e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:16,388 - INFO - epoch 650: train loss 0.041169987267090216\n",
      "2025-09-07 20:41:16,394 - INFO - 650 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:16,406 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:16,418 - INFO - --------------------\n",
      "\n",
      "651/800: 100%|██████████| 216/216 [00:06<00:00, 34.53it/s]\n",
      "2025-09-07 20:41:22,871 - INFO - All types `lr` of epoch 651: {'lr/param_group0': 5.245793650829983e-05, 'lr/param_group1': 5.245793650829983e-05, 'lr/param_group2': 5.245793650829983e-05, 'lr/param_group3': 5.245793650829983e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:22,885 - INFO - epoch 651: train loss 0.041042270983948755\n",
      "2025-09-07 20:41:22,890 - INFO - 651 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:22,902 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:22,915 - INFO - --------------------\n",
      "\n",
      "652/800: 100%|██████████| 216/216 [00:06<00:00, 35.14it/s]\n",
      "2025-09-07 20:41:29,272 - INFO - All types `lr` of epoch 652: {'lr/param_group0': 5.216600621528354e-05, 'lr/param_group1': 5.216600621528354e-05, 'lr/param_group2': 5.216600621528354e-05, 'lr/param_group3': 5.216600621528354e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:29,277 - INFO - epoch 652: train loss 0.04116786483468281\n",
      "2025-09-07 20:41:29,290 - INFO - 652 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:29,305 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:29,319 - INFO - --------------------\n",
      "\n",
      "653/800: 100%|██████████| 216/216 [00:06<00:00, 34.34it/s]\n",
      "2025-09-07 20:41:35,820 - INFO - All types `lr` of epoch 653: {'lr/param_group0': 5.1875815962033584e-05, 'lr/param_group1': 5.1875815962033584e-05, 'lr/param_group2': 5.1875815962033584e-05, 'lr/param_group3': 5.1875815962033584e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:35,834 - INFO - epoch 653: train loss 0.0410360112544839\n",
      "2025-09-07 20:41:35,838 - INFO - 653 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:35,850 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:35,864 - INFO - --------------------\n",
      "\n",
      "654/800: 100%|██████████| 216/216 [00:06<00:00, 35.96it/s]\n",
      "2025-09-07 20:41:42,071 - INFO - All types `lr` of epoch 654: {'lr/param_group0': 5.158737022364283e-05, 'lr/param_group1': 5.158737022364283e-05, 'lr/param_group2': 5.158737022364283e-05, 'lr/param_group3': 5.158737022364283e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:42,085 - INFO - epoch 654: train loss 0.041185081039589864\n",
      "2025-09-07 20:41:42,089 - INFO - 654 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:42,102 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:42,115 - INFO - --------------------\n",
      "\n",
      "655/800: 100%|██████████| 216/216 [00:07<00:00, 30.81it/s]\n",
      "2025-09-07 20:41:49,329 - INFO - All types `lr` of epoch 655: {'lr/param_group0': 5.13006734483013e-05, 'lr/param_group1': 5.13006734483013e-05, 'lr/param_group2': 5.13006734483013e-05, 'lr/param_group3': 5.13006734483013e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:49,344 - INFO - epoch 655: train loss 0.040890493619911095\n",
      "2025-09-07 20:41:49,350 - INFO - 655 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:49,363 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:49,376 - INFO - --------------------\n",
      "\n",
      "656/800: 100%|██████████| 216/216 [00:06<00:00, 35.16it/s]\n",
      "2025-09-07 20:41:55,721 - INFO - All types `lr` of epoch 656: {'lr/param_group0': 5.1015730057227974e-05, 'lr/param_group1': 5.1015730057227974e-05, 'lr/param_group2': 5.1015730057227974e-05, 'lr/param_group3': 5.1015730057227974e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:41:55,744 - INFO - epoch 656: train loss 0.041056932519293494\n",
      "2025-09-07 20:41:55,759 - INFO - 656 epochs completed!\n",
      "\n",
      "2025-09-07 20:41:55,764 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:41:55,777 - INFO - --------------------\n",
      "\n",
      "657/800: 100%|██████████| 216/216 [00:06<00:00, 35.16it/s]\n",
      "2025-09-07 20:42:02,139 - INFO - All types `lr` of epoch 657: {'lr/param_group0': 5.073254444460235e-05, 'lr/param_group1': 5.073254444460235e-05, 'lr/param_group2': 5.073254444460235e-05, 'lr/param_group3': 5.073254444460235e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:02,154 - INFO - epoch 657: train loss 0.04124080727773684\n",
      "2025-09-07 20:42:02,159 - INFO - 657 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:02,171 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:02,185 - INFO - --------------------\n",
      "\n",
      "658/800: 100%|██████████| 216/216 [00:06<00:00, 34.72it/s]\n",
      "2025-09-07 20:42:08,605 - INFO - All types `lr` of epoch 658: {'lr/param_group0': 5.0451120977497e-05, 'lr/param_group1': 5.0451120977497e-05, 'lr/param_group2': 5.0451120977497e-05, 'lr/param_group3': 5.0451120977497e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:08,620 - INFO - epoch 658: train loss 0.041138133586004925\n",
      "2025-09-07 20:42:08,625 - INFO - 658 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:08,638 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:08,650 - INFO - --------------------\n",
      "\n",
      "659/800: 100%|██████████| 216/216 [00:06<00:00, 35.47it/s]\n",
      "2025-09-07 20:42:14,935 - INFO - All types `lr` of epoch 659: {'lr/param_group0': 5.0171463995809844e-05, 'lr/param_group1': 5.0171463995809844e-05, 'lr/param_group2': 5.0171463995809844e-05, 'lr/param_group3': 5.0171463995809844e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:14,951 - INFO - epoch 659: train loss 0.040944739124151294\n",
      "2025-09-07 20:42:14,964 - INFO - 659 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:14,969 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:14,982 - INFO - --------------------\n",
      "\n",
      "660/800: 100%|██████████| 216/216 [00:06<00:00, 34.76it/s]\n",
      "2025-09-07 20:42:21,407 - INFO - All types `lr` of epoch 660: {'lr/param_group0': 4.989357781219757e-05, 'lr/param_group1': 4.989357781219757e-05, 'lr/param_group2': 4.989357781219757e-05, 'lr/param_group3': 4.989357781219757e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:21,423 - INFO - epoch 660: train loss 0.04094707446724728\n",
      "2025-09-07 20:42:21,428 - INFO - 660 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:21,440 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:21,444 - INFO - --------------------\n",
      "\n",
      "661/800: 100%|██████████| 216/216 [00:06<00:00, 34.77it/s]\n",
      "2025-09-07 20:42:27,864 - INFO - All types `lr` of epoch 661: {'lr/param_group0': 4.961746671200878e-05, 'lr/param_group1': 4.961746671200878e-05, 'lr/param_group2': 4.961746671200878e-05, 'lr/param_group3': 4.961746671200878e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:27,877 - INFO - epoch 661: train loss 0.04101557541569626\n",
      "2025-09-07 20:42:27,881 - INFO - 661 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:27,894 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:27,907 - INFO - --------------------\n",
      "\n",
      "662/800: 100%|██████████| 216/216 [00:06<00:00, 35.09it/s]\n",
      "2025-09-07 20:42:34,260 - INFO - All types `lr` of epoch 662: {'lr/param_group0': 4.934313495321831e-05, 'lr/param_group1': 4.934313495321831e-05, 'lr/param_group2': 4.934313495321831e-05, 'lr/param_group3': 4.934313495321831e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:34,265 - INFO - epoch 662: train loss 0.04085798861665858\n",
      "2025-09-07 20:42:34,279 - INFO - 662 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:34,293 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:34,298 - INFO - --------------------\n",
      "\n",
      "663/800: 100%|██████████| 216/216 [00:06<00:00, 35.02it/s]\n",
      "2025-09-07 20:42:40,676 - INFO - All types `lr` of epoch 663: {'lr/param_group0': 4.907058676636118e-05, 'lr/param_group1': 4.907058676636118e-05, 'lr/param_group2': 4.907058676636118e-05, 'lr/param_group3': 4.907058676636118e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:40,689 - INFO - epoch 663: train loss 0.04092224288938774\n",
      "2025-09-07 20:42:40,703 - INFO - 663 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:40,708 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:40,721 - INFO - --------------------\n",
      "\n",
      "664/800: 100%|██████████| 216/216 [00:06<00:00, 34.91it/s]\n",
      "2025-09-07 20:42:47,125 - INFO - All types `lr` of epoch 664: {'lr/param_group0': 4.87998263544676e-05, 'lr/param_group1': 4.87998263544676e-05, 'lr/param_group2': 4.87998263544676e-05, 'lr/param_group3': 4.87998263544676e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:47,139 - INFO - epoch 664: train loss 0.0410982763601674\n",
      "2025-09-07 20:42:47,153 - INFO - 664 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:47,158 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:47,170 - INFO - --------------------\n",
      "\n",
      "665/800: 100%|██████████| 216/216 [00:06<00:00, 35.25it/s]\n",
      "2025-09-07 20:42:53,525 - INFO - All types `lr` of epoch 665: {'lr/param_group0': 4.853085789299809e-05, 'lr/param_group1': 4.853085789299809e-05, 'lr/param_group2': 4.853085789299809e-05, 'lr/param_group3': 4.853085789299809e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:53,530 - INFO - epoch 665: train loss 0.0408197740368821\n",
      "2025-09-07 20:42:53,543 - INFO - 665 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:53,556 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:53,561 - INFO - --------------------\n",
      "\n",
      "666/800: 100%|██████████| 216/216 [00:05<00:00, 36.53it/s]\n",
      "2025-09-07 20:42:59,692 - INFO - All types `lr` of epoch 666: {'lr/param_group0': 4.8263685529779036e-05, 'lr/param_group1': 4.8263685529779036e-05, 'lr/param_group2': 4.8263685529779036e-05, 'lr/param_group3': 4.8263685529779036e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:42:59,698 - INFO - epoch 666: train loss 0.04090214748349455\n",
      "2025-09-07 20:42:59,711 - INFO - 666 epochs completed!\n",
      "\n",
      "2025-09-07 20:42:59,725 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:42:59,729 - INFO - --------------------\n",
      "\n",
      "667/800: 100%|██████████| 216/216 [00:06<00:00, 34.79it/s]\n",
      "2025-09-07 20:43:06,148 - INFO - All types `lr` of epoch 667: {'lr/param_group0': 4.799831338493886e-05, 'lr/param_group1': 4.799831338493886e-05, 'lr/param_group2': 4.799831338493886e-05, 'lr/param_group3': 4.799831338493886e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:06,163 - INFO - epoch 667: train loss 0.040933905617782367\n",
      "2025-09-07 20:43:06,177 - INFO - 667 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:06,181 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:06,195 - INFO - --------------------\n",
      "\n",
      "668/800: 100%|██████████| 216/216 [00:06<00:00, 34.23it/s]\n",
      "2025-09-07 20:43:12,724 - INFO - All types `lr` of epoch 668: {'lr/param_group0': 4.773474555084416e-05, 'lr/param_group1': 4.773474555084416e-05, 'lr/param_group2': 4.773474555084416e-05, 'lr/param_group3': 4.773474555084416e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:12,739 - INFO - epoch 668: train loss 0.040841378875214746\n",
      "2025-09-07 20:43:12,744 - INFO - 668 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:12,757 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:12,770 - INFO - --------------------\n",
      "\n",
      "669/800: 100%|██████████| 216/216 [00:06<00:00, 34.63it/s]\n",
      "2025-09-07 20:43:19,203 - INFO - All types `lr` of epoch 669: {'lr/param_group0': 4.7472986092037136e-05, 'lr/param_group1': 4.7472986092037136e-05, 'lr/param_group2': 4.7472986092037136e-05, 'lr/param_group3': 4.7472986092037136e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:19,217 - INFO - epoch 669: train loss 0.0409034816203294\n",
      "2025-09-07 20:43:19,231 - INFO - 669 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:19,236 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:19,249 - INFO - --------------------\n",
      "\n",
      "670/800: 100%|██████████| 216/216 [00:06<00:00, 34.11it/s]\n",
      "2025-09-07 20:43:25,775 - INFO - All types `lr` of epoch 670: {'lr/param_group0': 4.7213039045172406e-05, 'lr/param_group1': 4.7213039045172406e-05, 'lr/param_group2': 4.7213039045172406e-05, 'lr/param_group3': 4.7213039045172406e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:25,792 - INFO - epoch 670: train loss 0.041042005832962414\n",
      "2025-09-07 20:43:25,807 - INFO - 670 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:25,820 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:25,833 - INFO - --------------------\n",
      "\n",
      "671/800: 100%|██████████| 216/216 [00:06<00:00, 35.00it/s]\n",
      "2025-09-07 20:43:32,232 - INFO - All types `lr` of epoch 671: {'lr/param_group0': 4.695490841895497e-05, 'lr/param_group1': 4.695490841895497e-05, 'lr/param_group2': 4.695490841895497e-05, 'lr/param_group3': 4.695490841895497e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:32,238 - INFO - epoch 671: train loss 0.040751736197206706\n",
      "2025-09-07 20:43:32,251 - INFO - 671 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:32,254 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:32,267 - INFO - --------------------\n",
      "\n",
      "672/800: 100%|██████████| 216/216 [00:06<00:00, 34.89it/s]\n",
      "2025-09-07 20:43:38,694 - INFO - All types `lr` of epoch 672: {'lr/param_group0': 4.6698598194078404e-05, 'lr/param_group1': 4.6698598194078404e-05, 'lr/param_group2': 4.6698598194078404e-05, 'lr/param_group3': 4.6698598194078404e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:38,700 - INFO - epoch 672: train loss 0.040777396910858375\n",
      "2025-09-07 20:43:38,714 - INFO - 672 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:38,727 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:38,732 - INFO - --------------------\n",
      "\n",
      "673/800: 100%|██████████| 216/216 [00:06<00:00, 34.63it/s]\n",
      "2025-09-07 20:43:45,172 - INFO - All types `lr` of epoch 673: {'lr/param_group0': 4.644411232316354e-05, 'lr/param_group1': 4.644411232316354e-05, 'lr/param_group2': 4.644411232316354e-05, 'lr/param_group3': 4.644411232316354e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:45,186 - INFO - epoch 673: train loss 0.04098056870754118\n",
      "2025-09-07 20:43:45,191 - INFO - 673 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:45,204 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:45,218 - INFO - --------------------\n",
      "\n",
      "674/800: 100%|██████████| 216/216 [00:06<00:00, 34.22it/s]\n",
      "2025-09-07 20:43:51,732 - INFO - All types `lr` of epoch 674: {'lr/param_group0': 4.619145473069721e-05, 'lr/param_group1': 4.619145473069721e-05, 'lr/param_group2': 4.619145473069721e-05, 'lr/param_group3': 4.619145473069721e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:51,747 - INFO - epoch 674: train loss 0.04106085259398377\n",
      "2025-09-07 20:43:51,760 - INFO - 674 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:51,765 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:51,778 - INFO - --------------------\n",
      "\n",
      "675/800: 100%|██████████| 216/216 [00:06<00:00, 35.49it/s]\n",
      "2025-09-07 20:43:58,080 - INFO - All types `lr` of epoch 675: {'lr/param_group0': 4.594062931297203e-05, 'lr/param_group1': 4.594062931297203e-05, 'lr/param_group2': 4.594062931297203e-05, 'lr/param_group3': 4.594062931297203e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:43:58,095 - INFO - epoch 675: train loss 0.04102253934575452\n",
      "2025-09-07 20:43:58,100 - INFO - 675 epochs completed!\n",
      "\n",
      "2025-09-07 20:43:58,113 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:43:58,126 - INFO - --------------------\n",
      "\n",
      "676/800: 100%|██████████| 216/216 [00:06<00:00, 34.72it/s]\n",
      "2025-09-07 20:44:04,557 - INFO - All types `lr` of epoch 676: {'lr/param_group0': 4.569163993802637e-05, 'lr/param_group1': 4.569163993802637e-05, 'lr/param_group2': 4.569163993802637e-05, 'lr/param_group3': 4.569163993802637e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:04,562 - INFO - epoch 676: train loss 0.04086927966111236\n",
      "2025-09-07 20:44:04,576 - INFO - 676 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:04,589 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:04,594 - INFO - --------------------\n",
      "\n",
      "677/800: 100%|██████████| 216/216 [00:06<00:00, 34.62it/s]\n",
      "2025-09-07 20:44:11,043 - INFO - All types `lr` of epoch 677: {'lr/param_group0': 4.5444490445584326e-05, 'lr/param_group1': 4.5444490445584326e-05, 'lr/param_group2': 4.5444490445584326e-05, 'lr/param_group3': 4.5444490445584326e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:11,058 - INFO - epoch 677: train loss 0.04088025567708192\n",
      "2025-09-07 20:44:11,064 - INFO - 677 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:11,076 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:11,080 - INFO - --------------------\n",
      "\n",
      "678/800: 100%|██████████| 216/216 [00:06<00:00, 34.28it/s]\n",
      "2025-09-07 20:44:17,600 - INFO - All types `lr` of epoch 678: {'lr/param_group0': 4.51991846469968e-05, 'lr/param_group1': 4.51991846469968e-05, 'lr/param_group2': 4.51991846469968e-05, 'lr/param_group3': 4.51991846469968e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:17,605 - INFO - epoch 678: train loss 0.040715881864781735\n",
      "2025-09-07 20:44:17,619 - INFO - 678 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:17,623 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:17,636 - INFO - --------------------\n",
      "\n",
      "679/800: 100%|██████████| 216/216 [00:06<00:00, 34.04it/s]\n",
      "2025-09-07 20:44:24,192 - INFO - All types `lr` of epoch 679: {'lr/param_group0': 4.4955726325182574e-05, 'lr/param_group1': 4.4955726325182574e-05, 'lr/param_group2': 4.4955726325182574e-05, 'lr/param_group3': 4.4955726325182574e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:24,196 - INFO - epoch 679: train loss 0.04069919803145307\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.31it/s]\n",
      "2025-09-07 20:44:25,691 - INFO - epoch 679: val loss 0.05925626921708937\n",
      "2025-09-07 20:44:25,697 - INFO - 679 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:44:25,714 - INFO - 679 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:25,728 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:25,733 - INFO - --------------------\n",
      "\n",
      "680/800: 100%|██████████| 216/216 [00:06<00:00, 33.44it/s]\n",
      "2025-09-07 20:44:32,411 - INFO - All types `lr` of epoch 680: {'lr/param_group0': 4.471411923457034e-05, 'lr/param_group1': 4.471411923457034e-05, 'lr/param_group2': 4.471411923457034e-05, 'lr/param_group3': 4.471411923457034e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:32,417 - INFO - epoch 680: train loss 0.04100283797554396\n",
      "2025-09-07 20:44:32,431 - INFO - 680 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:32,444 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:32,449 - INFO - --------------------\n",
      "\n",
      "681/800: 100%|██████████| 216/216 [00:06<00:00, 34.22it/s]\n",
      "2025-09-07 20:44:38,962 - INFO - All types `lr` of epoch 681: {'lr/param_group0': 4.447436710104019e-05, 'lr/param_group1': 4.447436710104019e-05, 'lr/param_group2': 4.447436710104019e-05, 'lr/param_group3': 4.447436710104019e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:38,976 - INFO - epoch 681: train loss 0.04081987979373446\n",
      "2025-09-07 20:44:38,990 - INFO - 681 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:38,995 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:39,009 - INFO - --------------------\n",
      "\n",
      "682/800: 100%|██████████| 216/216 [00:06<00:00, 34.75it/s]\n",
      "2025-09-07 20:44:45,442 - INFO - All types `lr` of epoch 682: {'lr/param_group0': 4.4236473621866655e-05, 'lr/param_group1': 4.4236473621866655e-05, 'lr/param_group2': 4.4236473621866655e-05, 'lr/param_group3': 4.4236473621866655e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:45,457 - INFO - epoch 682: train loss 0.040933232495768204\n",
      "2025-09-07 20:44:45,463 - INFO - 682 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:45,477 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:45,491 - INFO - --------------------\n",
      "\n",
      "683/800: 100%|██████████| 216/216 [00:06<00:00, 34.23it/s]\n",
      "2025-09-07 20:44:52,012 - INFO - All types `lr` of epoch 683: {'lr/param_group0': 4.400044246566136e-05, 'lr/param_group1': 4.400044246566136e-05, 'lr/param_group2': 4.400044246566136e-05, 'lr/param_group3': 4.400044246566136e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:52,018 - INFO - epoch 683: train loss 0.04068404805191137\n",
      "2025-09-07 20:44:52,031 - INFO - 683 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:52,035 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:52,048 - INFO - --------------------\n",
      "\n",
      "684/800: 100%|██████████| 216/216 [00:06<00:00, 33.76it/s]\n",
      "2025-09-07 20:44:58,677 - INFO - All types `lr` of epoch 684: {'lr/param_group0': 4.376627727231688e-05, 'lr/param_group1': 4.376627727231688e-05, 'lr/param_group2': 4.376627727231688e-05, 'lr/param_group3': 4.376627727231688e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:44:58,682 - INFO - epoch 684: train loss 0.040636488460694196\n",
      "2025-09-07 20:44:58,696 - INFO - 684 epochs completed!\n",
      "\n",
      "2025-09-07 20:44:58,700 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:44:58,712 - INFO - --------------------\n",
      "\n",
      "685/800: 100%|██████████| 216/216 [00:06<00:00, 33.77it/s]\n",
      "2025-09-07 20:45:05,329 - INFO - All types `lr` of epoch 685: {'lr/param_group0': 4.3533981652950115e-05, 'lr/param_group1': 4.3533981652950115e-05, 'lr/param_group2': 4.3533981652950115e-05, 'lr/param_group3': 4.3533981652950115e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:05,343 - INFO - epoch 685: train loss 0.040997629433318424\n",
      "2025-09-07 20:45:05,347 - INFO - 685 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:05,360 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:05,374 - INFO - --------------------\n",
      "\n",
      "686/800: 100%|██████████| 216/216 [00:06<00:00, 35.60it/s]\n",
      "2025-09-07 20:45:11,636 - INFO - All types `lr` of epoch 686: {'lr/param_group0': 4.330355918984681e-05, 'lr/param_group1': 4.330355918984681e-05, 'lr/param_group2': 4.330355918984681e-05, 'lr/param_group3': 4.330355918984681e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:11,651 - INFO - epoch 686: train loss 0.04079861861343185\n",
      "2025-09-07 20:45:11,665 - INFO - 686 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:11,670 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:11,683 - INFO - --------------------\n",
      "\n",
      "687/800: 100%|██████████| 216/216 [00:05<00:00, 37.14it/s]\n",
      "2025-09-07 20:45:17,711 - INFO - All types `lr` of epoch 687: {'lr/param_group0': 4.307501343640647e-05, 'lr/param_group1': 4.307501343640647e-05, 'lr/param_group2': 4.307501343640647e-05, 'lr/param_group3': 4.307501343640647e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:17,724 - INFO - epoch 687: train loss 0.04067139525000972\n",
      "2025-09-07 20:45:17,738 - INFO - 687 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:17,743 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:17,756 - INFO - --------------------\n",
      "\n",
      "688/800: 100%|██████████| 216/216 [00:06<00:00, 34.52it/s]\n",
      "2025-09-07 20:45:24,235 - INFO - All types `lr` of epoch 688: {'lr/param_group0': 4.2848347917087366e-05, 'lr/param_group1': 4.2848347917087366e-05, 'lr/param_group2': 4.2848347917087366e-05, 'lr/param_group3': 4.2848347917087366e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:24,249 - INFO - epoch 688: train loss 0.040905214897874326\n",
      "2025-09-07 20:45:24,255 - INFO - 688 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:24,268 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:24,282 - INFO - --------------------\n",
      "\n",
      "689/800: 100%|██████████| 216/216 [00:06<00:00, 34.91it/s]\n",
      "2025-09-07 20:45:30,673 - INFO - All types `lr` of epoch 689: {'lr/param_group0': 4.262356612735212e-05, 'lr/param_group1': 4.262356612735212e-05, 'lr/param_group2': 4.262356612735212e-05, 'lr/param_group3': 4.262356612735212e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:30,689 - INFO - epoch 689: train loss 0.040726694002471586\n",
      "2025-09-07 20:45:30,695 - INFO - 689 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:30,708 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:30,722 - INFO - --------------------\n",
      "\n",
      "690/800: 100%|██████████| 216/216 [00:06<00:00, 33.88it/s]\n",
      "2025-09-07 20:45:37,298 - INFO - All types `lr` of epoch 690: {'lr/param_group0': 4.240067153361401e-05, 'lr/param_group1': 4.240067153361401e-05, 'lr/param_group2': 4.240067153361401e-05, 'lr/param_group3': 4.240067153361401e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:37,312 - INFO - epoch 690: train loss 0.04078595257467694\n",
      "2025-09-07 20:45:37,327 - INFO - 690 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:37,332 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:37,345 - INFO - --------------------\n",
      "\n",
      "691/800: 100%|██████████| 216/216 [00:06<00:00, 34.61it/s]\n",
      "2025-09-07 20:45:43,810 - INFO - All types `lr` of epoch 691: {'lr/param_group0': 4.217966757318344e-05, 'lr/param_group1': 4.217966757318344e-05, 'lr/param_group2': 4.217966757318344e-05, 'lr/param_group3': 4.217966757318344e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:43,824 - INFO - epoch 691: train loss 0.04057017508549271\n",
      "2025-09-07 20:45:43,830 - INFO - 691 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:43,844 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:43,858 - INFO - --------------------\n",
      "\n",
      "692/800: 100%|██████████| 216/216 [00:06<00:00, 33.46it/s]\n",
      "2025-09-07 20:45:50,524 - INFO - All types `lr` of epoch 692: {'lr/param_group0': 4.196055765421488e-05, 'lr/param_group1': 4.196055765421488e-05, 'lr/param_group2': 4.196055765421488e-05, 'lr/param_group3': 4.196055765421488e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:50,529 - INFO - epoch 692: train loss 0.040613450661853505\n",
      "2025-09-07 20:45:50,543 - INFO - 692 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:50,557 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:50,562 - INFO - --------------------\n",
      "\n",
      "693/800: 100%|██████████| 216/216 [00:07<00:00, 28.73it/s]\n",
      "2025-09-07 20:45:58,307 - INFO - All types `lr` of epoch 693: {'lr/param_group0': 4.1743345155654305e-05, 'lr/param_group1': 4.1743345155654305e-05, 'lr/param_group2': 4.1743345155654305e-05, 'lr/param_group3': 4.1743345155654305e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:45:58,312 - INFO - epoch 693: train loss 0.04070912879305305\n",
      "2025-09-07 20:45:58,326 - INFO - 693 epochs completed!\n",
      "\n",
      "2025-09-07 20:45:58,329 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:45:58,342 - INFO - --------------------\n",
      "\n",
      "694/800: 100%|██████████| 216/216 [00:06<00:00, 34.66it/s]\n",
      "2025-09-07 20:46:04,806 - INFO - All types `lr` of epoch 694: {'lr/param_group0': 4.152803342718716e-05, 'lr/param_group1': 4.152803342718716e-05, 'lr/param_group2': 4.152803342718716e-05, 'lr/param_group3': 4.152803342718716e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:04,812 - INFO - epoch 694: train loss 0.0407032798803239\n",
      "2025-09-07 20:46:04,825 - INFO - 694 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:04,839 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:04,844 - INFO - --------------------\n",
      "\n",
      "695/800: 100%|██████████| 216/216 [00:06<00:00, 34.12it/s]\n",
      "2025-09-07 20:46:11,388 - INFO - All types `lr` of epoch 695: {'lr/param_group0': 4.131462578918664e-05, 'lr/param_group1': 4.131462578918664e-05, 'lr/param_group2': 4.131462578918664e-05, 'lr/param_group3': 4.131462578918664e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:11,402 - INFO - epoch 695: train loss 0.04055662703251949\n",
      "2025-09-07 20:46:11,417 - INFO - 695 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:11,422 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:11,436 - INFO - --------------------\n",
      "\n",
      "696/800: 100%|██████████| 216/216 [00:06<00:00, 34.60it/s]\n",
      "2025-09-07 20:46:17,897 - INFO - All types `lr` of epoch 696: {'lr/param_group0': 4.110312553266255e-05, 'lr/param_group1': 4.110312553266255e-05, 'lr/param_group2': 4.110312553266255e-05, 'lr/param_group3': 4.110312553266255e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:17,912 - INFO - epoch 696: train loss 0.04066288236666609\n",
      "2025-09-07 20:46:17,918 - INFO - 696 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:17,932 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:17,945 - INFO - --------------------\n",
      "\n",
      "697/800: 100%|██████████| 216/216 [00:06<00:00, 34.26it/s]\n",
      "2025-09-07 20:46:24,464 - INFO - All types `lr` of epoch 697: {'lr/param_group0': 4.089353591921042e-05, 'lr/param_group1': 4.089353591921042e-05, 'lr/param_group2': 4.089353591921042e-05, 'lr/param_group3': 4.089353591921042e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:24,469 - INFO - epoch 697: train loss 0.04051378964343005\n",
      "2025-09-07 20:46:24,483 - INFO - 697 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:24,497 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:24,502 - INFO - --------------------\n",
      "\n",
      "698/800: 100%|██████████| 216/216 [00:06<00:00, 34.05it/s]\n",
      "2025-09-07 20:46:31,054 - INFO - All types `lr` of epoch 698: {'lr/param_group0': 4.0685860180961474e-05, 'lr/param_group1': 4.0685860180961474e-05, 'lr/param_group2': 4.0685860180961474e-05, 'lr/param_group3': 4.0685860180961474e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:31,069 - INFO - epoch 698: train loss 0.04066896241986089\n",
      "2025-09-07 20:46:31,083 - INFO - 698 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:31,088 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:31,101 - INFO - --------------------\n",
      "\n",
      "699/800: 100%|██████████| 216/216 [00:06<00:00, 33.99it/s]\n",
      "2025-09-07 20:46:37,674 - INFO - All types `lr` of epoch 699: {'lr/param_group0': 4.048010152053238e-05, 'lr/param_group1': 4.048010152053238e-05, 'lr/param_group2': 4.048010152053238e-05, 'lr/param_group3': 4.048010152053238e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:37,690 - INFO - epoch 699: train loss 0.04062763874039606\n",
      "2025-09-07 20:46:37,695 - INFO - 699 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:37,710 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:37,723 - INFO - --------------------\n",
      "\n",
      "700/800: 100%|██████████| 216/216 [00:06<00:00, 34.22it/s]\n",
      "2025-09-07 20:46:44,244 - INFO - All types `lr` of epoch 700: {'lr/param_group0': 4.02762631109763e-05, 'lr/param_group1': 4.02762631109763e-05, 'lr/param_group2': 4.02762631109763e-05, 'lr/param_group3': 4.02762631109763e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:44,261 - INFO - epoch 700: train loss 0.04081681448345383\n",
      "2025-09-07 20:46:44,277 - INFO - 700 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:44,291 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:44,305 - INFO - --------------------\n",
      "\n",
      "701/800: 100%|██████████| 216/216 [00:06<00:00, 33.82it/s]\n",
      "2025-09-07 20:46:50,930 - INFO - All types `lr` of epoch 701: {'lr/param_group0': 4.007434809573361e-05, 'lr/param_group1': 4.007434809573361e-05, 'lr/param_group2': 4.007434809573361e-05, 'lr/param_group3': 4.007434809573361e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:50,936 - INFO - epoch 701: train loss 0.040614529961237204\n",
      "2025-09-07 20:46:50,950 - INFO - 701 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:50,954 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:50,967 - INFO - --------------------\n",
      "\n",
      "702/800: 100%|██████████| 216/216 [00:06<00:00, 34.08it/s]\n",
      "2025-09-07 20:46:57,524 - INFO - All types `lr` of epoch 702: {'lr/param_group0': 3.987435958858371e-05, 'lr/param_group1': 3.987435958858371e-05, 'lr/param_group2': 3.987435958858371e-05, 'lr/param_group3': 3.987435958858371e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:46:57,529 - INFO - epoch 702: train loss 0.040774485303295985\n",
      "2025-09-07 20:46:57,543 - INFO - 702 epochs completed!\n",
      "\n",
      "2025-09-07 20:46:57,556 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:46:57,562 - INFO - --------------------\n",
      "\n",
      "703/800: 100%|██████████| 216/216 [00:06<00:00, 34.01it/s]\n",
      "2025-09-07 20:47:04,131 - INFO - All types `lr` of epoch 703: {'lr/param_group0': 3.967630067359668e-05, 'lr/param_group1': 3.967630067359668e-05, 'lr/param_group2': 3.967630067359668e-05, 'lr/param_group3': 3.967630067359668e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:04,147 - INFO - epoch 703: train loss 0.040657939216880885\n",
      "2025-09-07 20:47:04,152 - INFO - 703 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:04,166 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:04,179 - INFO - --------------------\n",
      "\n",
      "704/800: 100%|██████████| 216/216 [00:06<00:00, 33.78it/s]\n",
      "2025-09-07 20:47:10,784 - INFO - All types `lr` of epoch 704: {'lr/param_group0': 3.948017440508605e-05, 'lr/param_group1': 3.948017440508605e-05, 'lr/param_group2': 3.948017440508605e-05, 'lr/param_group3': 3.948017440508605e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:10,799 - INFO - epoch 704: train loss 0.04044978589647346\n",
      "2025-09-07 20:47:10,814 - INFO - 704 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:10,819 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:10,833 - INFO - --------------------\n",
      "\n",
      "705/800: 100%|██████████| 216/216 [00:06<00:00, 33.81it/s]\n",
      "2025-09-07 20:47:17,452 - INFO - All types `lr` of epoch 705: {'lr/param_group0': 3.928598380756151e-05, 'lr/param_group1': 3.928598380756151e-05, 'lr/param_group2': 3.928598380756151e-05, 'lr/param_group3': 3.928598380756151e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:17,458 - INFO - epoch 705: train loss 0.04047941050871655\n",
      "2025-09-07 20:47:17,472 - INFO - 705 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:17,486 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:17,491 - INFO - --------------------\n",
      "\n",
      "706/800: 100%|██████████| 216/216 [00:06<00:00, 33.63it/s]\n",
      "2025-09-07 20:47:24,131 - INFO - All types `lr` of epoch 706: {'lr/param_group0': 3.90937318756823e-05, 'lr/param_group1': 3.90937318756823e-05, 'lr/param_group2': 3.90937318756823e-05, 'lr/param_group3': 3.90937318756823e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:24,146 - INFO - epoch 706: train loss 0.04063341668289569\n",
      "2025-09-07 20:47:24,161 - INFO - 706 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:24,166 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:24,180 - INFO - --------------------\n",
      "\n",
      "707/800: 100%|██████████| 216/216 [00:06<00:00, 35.43it/s]\n",
      "2025-09-07 20:47:30,506 - INFO - All types `lr` of epoch 707: {'lr/param_group0': 3.8903421574211e-05, 'lr/param_group1': 3.8903421574211e-05, 'lr/param_group2': 3.8903421574211e-05, 'lr/param_group3': 3.8903421574211e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:30,512 - INFO - epoch 707: train loss 0.040377321342627205\n",
      "2025-09-07 20:47:30,525 - INFO - 707 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:30,539 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:30,544 - INFO - --------------------\n",
      "\n",
      "708/800: 100%|██████████| 216/216 [00:06<00:00, 34.25it/s]\n",
      "2025-09-07 20:47:37,062 - INFO - All types `lr` of epoch 708: {'lr/param_group0': 3.871505583796788e-05, 'lr/param_group1': 3.871505583796788e-05, 'lr/param_group2': 3.871505583796788e-05, 'lr/param_group3': 3.871505583796788e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:37,077 - INFO - epoch 708: train loss 0.040458199050691396\n",
      "2025-09-07 20:47:37,094 - INFO - 708 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:37,109 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:37,124 - INFO - --------------------\n",
      "\n",
      "709/800: 100%|██████████| 216/216 [00:06<00:00, 35.06it/s]\n",
      "2025-09-07 20:47:43,496 - INFO - All types `lr` of epoch 709: {'lr/param_group0': 3.8528637571785705e-05, 'lr/param_group1': 3.8528637571785705e-05, 'lr/param_group2': 3.8528637571785705e-05, 'lr/param_group3': 3.8528637571785705e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:43,510 - INFO - epoch 709: train loss 0.04058736329898238\n",
      "2025-09-07 20:47:43,514 - INFO - 709 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:43,528 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:43,542 - INFO - --------------------\n",
      "\n",
      "710/800: 100%|██████████| 216/216 [00:06<00:00, 33.85it/s]\n",
      "2025-09-07 20:47:50,132 - INFO - All types `lr` of epoch 710: {'lr/param_group0': 3.834416965046464e-05, 'lr/param_group1': 3.834416965046464e-05, 'lr/param_group2': 3.834416965046464e-05, 'lr/param_group3': 3.834416965046464e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:50,138 - INFO - epoch 710: train loss 0.04056934817452674\n",
      "2025-09-07 20:47:50,152 - INFO - 710 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:50,155 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:50,169 - INFO - --------------------\n",
      "\n",
      "711/800: 100%|██████████| 216/216 [00:06<00:00, 34.10it/s]\n",
      "2025-09-07 20:47:56,735 - INFO - All types `lr` of epoch 711: {'lr/param_group0': 3.816165491872828e-05, 'lr/param_group1': 3.816165491872828e-05, 'lr/param_group2': 3.816165491872828e-05, 'lr/param_group3': 3.816165491872828e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:47:56,740 - INFO - epoch 711: train loss 0.04061588025824339\n",
      "2025-09-07 20:47:56,754 - INFO - 711 epochs completed!\n",
      "\n",
      "2025-09-07 20:47:56,768 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:47:56,773 - INFO - --------------------\n",
      "\n",
      "712/800: 100%|██████████| 216/216 [00:06<00:00, 33.82it/s]\n",
      "2025-09-07 20:48:03,370 - INFO - All types `lr` of epoch 712: {'lr/param_group0': 3.798109619117954e-05, 'lr/param_group1': 3.798109619117954e-05, 'lr/param_group2': 3.798109619117954e-05, 'lr/param_group3': 3.798109619117954e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:03,386 - INFO - epoch 712: train loss 0.040572295172346964\n",
      "2025-09-07 20:48:03,401 - INFO - 712 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:03,406 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:03,420 - INFO - --------------------\n",
      "\n",
      "713/800: 100%|██████████| 216/216 [00:06<00:00, 33.79it/s]\n",
      "2025-09-07 20:48:10,036 - INFO - All types `lr` of epoch 713: {'lr/param_group0': 3.780249625225743e-05, 'lr/param_group1': 3.780249625225743e-05, 'lr/param_group2': 3.780249625225743e-05, 'lr/param_group3': 3.780249625225743e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:10,052 - INFO - epoch 713: train loss 0.04047835354382793\n",
      "2025-09-07 20:48:10,058 - INFO - 713 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:10,071 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:10,085 - INFO - --------------------\n",
      "\n",
      "714/800: 100%|██████████| 216/216 [00:06<00:00, 34.13it/s]\n",
      "2025-09-07 20:48:16,613 - INFO - All types `lr` of epoch 714: {'lr/param_group0': 3.76258578561939e-05, 'lr/param_group1': 3.76258578561939e-05, 'lr/param_group2': 3.76258578561939e-05, 'lr/param_group3': 3.76258578561939e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:16,627 - INFO - epoch 714: train loss 0.040498997498717576\n",
      "2025-09-07 20:48:16,642 - INFO - 714 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:16,647 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:16,661 - INFO - --------------------\n",
      "\n",
      "715/800: 100%|██████████| 216/216 [00:06<00:00, 33.97it/s]\n",
      "2025-09-07 20:48:23,240 - INFO - All types `lr` of epoch 715: {'lr/param_group0': 3.7451183726971446e-05, 'lr/param_group1': 3.7451183726971446e-05, 'lr/param_group2': 3.7451183726971446e-05, 'lr/param_group3': 3.7451183726971446e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:23,256 - INFO - epoch 715: train loss 0.0406076525406981\n",
      "2025-09-07 20:48:23,262 - INFO - 715 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:23,276 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:23,291 - INFO - --------------------\n",
      "\n",
      "716/800: 100%|██████████| 216/216 [00:06<00:00, 34.01it/s]\n",
      "2025-09-07 20:48:29,844 - INFO - All types `lr` of epoch 716: {'lr/param_group0': 3.727847655828138e-05, 'lr/param_group1': 3.727847655828138e-05, 'lr/param_group2': 3.727847655828138e-05, 'lr/param_group3': 3.727847655828138e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:29,858 - INFO - epoch 716: train loss 0.04071411523209126\n",
      "2025-09-07 20:48:29,876 - INFO - 716 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:29,892 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:29,907 - INFO - --------------------\n",
      "\n",
      "717/800: 100%|██████████| 216/216 [00:06<00:00, 33.68it/s]\n",
      "2025-09-07 20:48:36,543 - INFO - All types `lr` of epoch 717: {'lr/param_group0': 3.7107739013481794e-05, 'lr/param_group1': 3.7107739013481794e-05, 'lr/param_group2': 3.7107739013481794e-05, 'lr/param_group3': 3.7107739013481794e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:36,549 - INFO - epoch 717: train loss 0.04048188879258103\n",
      "2025-09-07 20:48:36,563 - INFO - 717 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:36,567 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:36,582 - INFO - --------------------\n",
      "\n",
      "718/800: 100%|██████████| 216/216 [00:06<00:00, 33.75it/s]\n",
      "2025-09-07 20:48:43,210 - INFO - All types `lr` of epoch 718: {'lr/param_group0': 3.6938973725556896e-05, 'lr/param_group1': 3.6938973725556896e-05, 'lr/param_group2': 3.6938973725556896e-05, 'lr/param_group3': 3.6938973725556896e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:43,214 - INFO - epoch 718: train loss 0.040662546573137795\n",
      "2025-09-07 20:48:43,228 - INFO - 718 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:43,243 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:43,248 - INFO - --------------------\n",
      "\n",
      "719/800: 100%|██████████| 216/216 [00:06<00:00, 34.11it/s]\n",
      "2025-09-07 20:48:49,801 - INFO - All types `lr` of epoch 719: {'lr/param_group0': 3.6772183297076105e-05, 'lr/param_group1': 3.6772183297076105e-05, 'lr/param_group2': 3.6772183297076105e-05, 'lr/param_group3': 3.6772183297076105e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:49,816 - INFO - epoch 719: train loss 0.04044695683168592\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.67it/s]\n",
      "2025-09-07 20:48:51,303 - INFO - epoch 719: val loss 0.05939491962393125\n",
      "2025-09-07 20:48:51,319 - INFO - 719 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:48:51,338 - INFO - 719 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:51,343 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:51,357 - INFO - --------------------\n",
      "\n",
      "720/800: 100%|██████████| 216/216 [00:06<00:00, 34.07it/s]\n",
      "2025-09-07 20:48:57,927 - INFO - All types `lr` of epoch 720: {'lr/param_group0': 3.6607370300154245e-05, 'lr/param_group1': 3.6607370300154245e-05, 'lr/param_group2': 3.6607370300154245e-05, 'lr/param_group3': 3.6607370300154245e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:48:57,933 - INFO - epoch 720: train loss 0.0403419256520768\n",
      "2025-09-07 20:48:57,947 - INFO - 720 epochs completed!\n",
      "\n",
      "2025-09-07 20:48:57,961 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:48:57,966 - INFO - --------------------\n",
      "\n",
      "721/800: 100%|██████████| 216/216 [00:06<00:00, 34.02it/s]\n",
      "2025-09-07 20:49:04,526 - INFO - All types `lr` of epoch 721: {'lr/param_group0': 3.644453727641163e-05, 'lr/param_group1': 3.644453727641163e-05, 'lr/param_group2': 3.644453727641163e-05, 'lr/param_group3': 3.644453727641163e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:04,540 - INFO - epoch 721: train loss 0.04062581408975853\n",
      "2025-09-07 20:49:04,555 - INFO - 721 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:04,560 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:04,575 - INFO - --------------------\n",
      "\n",
      "722/800: 100%|██████████| 216/216 [00:06<00:00, 34.98it/s]\n",
      "2025-09-07 20:49:10,970 - INFO - All types `lr` of epoch 722: {'lr/param_group0': 3.6283686736934834e-05, 'lr/param_group1': 3.6283686736934834e-05, 'lr/param_group2': 3.6283686736934834e-05, 'lr/param_group3': 3.6283686736934834e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:10,986 - INFO - epoch 722: train loss 0.04040051393072914\n",
      "2025-09-07 20:49:11,002 - INFO - 722 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:11,017 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:11,032 - INFO - --------------------\n",
      "\n",
      "723/800: 100%|██████████| 216/216 [00:06<00:00, 34.10it/s]\n",
      "2025-09-07 20:49:17,572 - INFO - All types `lr` of epoch 723: {'lr/param_group0': 3.612482116223822e-05, 'lr/param_group1': 3.612482116223822e-05, 'lr/param_group2': 3.612482116223822e-05, 'lr/param_group3': 3.612482116223822e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:17,589 - INFO - epoch 723: train loss 0.0403934218575833\n",
      "2025-09-07 20:49:17,605 - INFO - 723 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:17,620 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:17,633 - INFO - --------------------\n",
      "\n",
      "724/800: 100%|██████████| 216/216 [00:06<00:00, 34.33it/s]\n",
      "2025-09-07 20:49:24,161 - INFO - All types `lr` of epoch 724: {'lr/param_group0': 3.596794300222545e-05, 'lr/param_group1': 3.596794300222545e-05, 'lr/param_group2': 3.596794300222545e-05, 'lr/param_group3': 3.596794300222545e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:24,167 - INFO - epoch 724: train loss 0.04052258427772257\n",
      "2025-09-07 20:49:24,182 - INFO - 724 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:24,186 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:24,200 - INFO - --------------------\n",
      "\n",
      "725/800: 100%|██████████| 216/216 [00:06<00:00, 35.35it/s]\n",
      "2025-09-07 20:49:30,541 - INFO - All types `lr` of epoch 725: {'lr/param_group0': 3.581305467615184e-05, 'lr/param_group1': 3.581305467615184e-05, 'lr/param_group2': 3.581305467615184e-05, 'lr/param_group3': 3.581305467615184e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:30,556 - INFO - epoch 725: train loss 0.040440972756456445\n",
      "2025-09-07 20:49:30,559 - INFO - 725 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:30,573 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:30,587 - INFO - --------------------\n",
      "\n",
      "726/800: 100%|██████████| 216/216 [00:06<00:00, 33.98it/s]\n",
      "2025-09-07 20:49:37,144 - INFO - All types `lr` of epoch 726: {'lr/param_group0': 3.566015857258689e-05, 'lr/param_group1': 3.566015857258689e-05, 'lr/param_group2': 3.566015857258689e-05, 'lr/param_group3': 3.566015857258689e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:37,150 - INFO - epoch 726: train loss 0.04053593977113013\n",
      "2025-09-07 20:49:37,165 - INFO - 726 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:37,179 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:37,184 - INFO - --------------------\n",
      "\n",
      "727/800: 100%|██████████| 216/216 [00:06<00:00, 34.60it/s]\n",
      "2025-09-07 20:49:43,638 - INFO - All types `lr` of epoch 727: {'lr/param_group0': 3.550925704937779e-05, 'lr/param_group1': 3.550925704937779e-05, 'lr/param_group2': 3.550925704937779e-05, 'lr/param_group3': 3.550925704937779e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:43,643 - INFO - epoch 727: train loss 0.040473372054596744\n",
      "2025-09-07 20:49:43,657 - INFO - 727 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:43,671 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:43,676 - INFO - --------------------\n",
      "\n",
      "728/800: 100%|██████████| 216/216 [00:06<00:00, 34.80it/s]\n",
      "2025-09-07 20:49:50,081 - INFO - All types `lr` of epoch 728: {'lr/param_group0': 3.5360352433612696e-05, 'lr/param_group1': 3.5360352433612696e-05, 'lr/param_group2': 3.5360352433612696e-05, 'lr/param_group3': 3.5360352433612696e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:50,096 - INFO - epoch 728: train loss 0.04024809152232828\n",
      "2025-09-07 20:49:50,101 - INFO - 728 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:50,115 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:50,129 - INFO - --------------------\n",
      "\n",
      "729/800: 100%|██████████| 216/216 [00:06<00:00, 34.69it/s]\n",
      "2025-09-07 20:49:56,562 - INFO - All types `lr` of epoch 729: {'lr/param_group0': 3.5213447021584886e-05, 'lr/param_group1': 3.5213447021584886e-05, 'lr/param_group2': 3.5213447021584886e-05, 'lr/param_group3': 3.5213447021584886e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:49:56,567 - INFO - epoch 729: train loss 0.0402747837619649\n",
      "2025-09-07 20:49:56,582 - INFO - 729 epochs completed!\n",
      "\n",
      "2025-09-07 20:49:56,596 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:49:56,601 - INFO - --------------------\n",
      "\n",
      "730/800: 100%|██████████| 216/216 [00:04<00:00, 44.03it/s]\n",
      "2025-09-07 20:50:01,718 - INFO - All types `lr` of epoch 730: {'lr/param_group0': 3.5068543078757614e-05, 'lr/param_group1': 3.5068543078757614e-05, 'lr/param_group2': 3.5068543078757614e-05, 'lr/param_group3': 3.5068543078757614e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:01,723 - INFO - epoch 730: train loss 0.04039772620631589\n",
      "2025-09-07 20:50:01,734 - INFO - 730 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:01,746 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:01,750 - INFO - --------------------\n",
      "\n",
      "731/800: 100%|██████████| 216/216 [00:04<00:00, 48.06it/s]\n",
      "2025-09-07 20:50:06,428 - INFO - All types `lr` of epoch 731: {'lr/param_group0': 3.49256428397289e-05, 'lr/param_group1': 3.49256428397289e-05, 'lr/param_group2': 3.49256428397289e-05, 'lr/param_group3': 3.49256428397289e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:06,442 - INFO - epoch 731: train loss 0.04033912287128193\n",
      "2025-09-07 20:50:06,446 - INFO - 731 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:06,457 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:06,469 - INFO - --------------------\n",
      "\n",
      "732/800: 100%|██████████| 216/216 [00:06<00:00, 35.42it/s]\n",
      "2025-09-07 20:50:12,742 - INFO - All types `lr` of epoch 732: {'lr/param_group0': 3.478474850819728e-05, 'lr/param_group1': 3.478474850819728e-05, 'lr/param_group2': 3.478474850819728e-05, 'lr/param_group3': 3.478474850819728e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:12,757 - INFO - epoch 732: train loss 0.04033571252323411\n",
      "2025-09-07 20:50:12,761 - INFO - 732 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:12,775 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:12,789 - INFO - --------------------\n",
      "\n",
      "733/800: 100%|██████████| 216/216 [00:06<00:00, 33.36it/s]\n",
      "2025-09-07 20:50:19,463 - INFO - All types `lr` of epoch 733: {'lr/param_group0': 3.4645862256927505e-05, 'lr/param_group1': 3.4645862256927505e-05, 'lr/param_group2': 3.4645862256927505e-05, 'lr/param_group3': 3.4645862256927505e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:19,468 - INFO - epoch 733: train loss 0.04045194434002042\n",
      "2025-09-07 20:50:19,482 - INFO - 733 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:19,497 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:19,503 - INFO - --------------------\n",
      "\n",
      "734/800: 100%|██████████| 216/216 [00:05<00:00, 39.87it/s]\n",
      "2025-09-07 20:50:25,134 - INFO - All types `lr` of epoch 734: {'lr/param_group0': 3.45089862277175e-05, 'lr/param_group1': 3.45089862277175e-05, 'lr/param_group2': 3.45089862277175e-05, 'lr/param_group3': 3.45089862277175e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:25,149 - INFO - epoch 734: train loss 0.040374728799280196\n",
      "2025-09-07 20:50:25,153 - INFO - 734 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:25,168 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:25,182 - INFO - --------------------\n",
      "\n",
      "735/800: 100%|██████████| 216/216 [00:06<00:00, 33.62it/s]\n",
      "2025-09-07 20:50:31,822 - INFO - All types `lr` of epoch 735: {'lr/param_group0': 3.4374122531364924e-05, 'lr/param_group1': 3.4374122531364924e-05, 'lr/param_group2': 3.4374122531364924e-05, 'lr/param_group3': 3.4374122531364924e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:31,827 - INFO - epoch 735: train loss 0.04063085140660405\n",
      "2025-09-07 20:50:31,842 - INFO - 735 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:31,846 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:31,860 - INFO - --------------------\n",
      "\n",
      "736/800: 100%|██████████| 216/216 [00:06<00:00, 33.59it/s]\n",
      "2025-09-07 20:50:38,524 - INFO - All types `lr` of epoch 736: {'lr/param_group0': 3.4241273247634785e-05, 'lr/param_group1': 3.4241273247634785e-05, 'lr/param_group2': 3.4241273247634785e-05, 'lr/param_group3': 3.4241273247634785e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:38,530 - INFO - epoch 736: train loss 0.040492665212325474\n",
      "2025-09-07 20:50:38,545 - INFO - 736 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:38,559 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:38,565 - INFO - --------------------\n",
      "\n",
      "737/800: 100%|██████████| 216/216 [00:06<00:00, 33.41it/s]\n",
      "2025-09-07 20:50:45,240 - INFO - All types `lr` of epoch 737: {'lr/param_group0': 3.411044042522739e-05, 'lr/param_group1': 3.411044042522739e-05, 'lr/param_group2': 3.411044042522739e-05, 'lr/param_group3': 3.411044042522739e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:45,255 - INFO - epoch 737: train loss 0.04039410862174851\n",
      "2025-09-07 20:50:45,261 - INFO - 737 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:45,276 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:45,290 - INFO - --------------------\n",
      "\n",
      "738/800: 100%|██████████| 216/216 [00:06<00:00, 33.51it/s]\n",
      "2025-09-07 20:50:51,954 - INFO - All types `lr` of epoch 738: {'lr/param_group0': 3.398162608174677e-05, 'lr/param_group1': 3.398162608174677e-05, 'lr/param_group2': 3.398162608174677e-05, 'lr/param_group3': 3.398162608174677e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:51,959 - INFO - epoch 738: train loss 0.04044285902960433\n",
      "2025-09-07 20:50:51,974 - INFO - 738 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:51,989 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:51,994 - INFO - --------------------\n",
      "\n",
      "739/800: 100%|██████████| 216/216 [00:06<00:00, 35.44it/s]\n",
      "2025-09-07 20:50:58,308 - INFO - All types `lr` of epoch 739: {'lr/param_group0': 3.385483220366937e-05, 'lr/param_group1': 3.385483220366937e-05, 'lr/param_group2': 3.385483220366937e-05, 'lr/param_group3': 3.385483220366937e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:50:58,325 - INFO - epoch 739: train loss 0.04037555965974375\n",
      "2025-09-07 20:50:58,331 - INFO - 739 epochs completed!\n",
      "\n",
      "2025-09-07 20:50:58,347 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:50:58,362 - INFO - --------------------\n",
      "\n",
      "740/800: 100%|██████████| 216/216 [00:06<00:00, 32.80it/s]\n",
      "2025-09-07 20:51:05,177 - INFO - All types `lr` of epoch 740: {'lr/param_group0': 3.373006074631366e-05, 'lr/param_group1': 3.373006074631366e-05, 'lr/param_group2': 3.373006074631366e-05, 'lr/param_group3': 3.373006074631366e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:05,183 - INFO - epoch 740: train loss 0.04053110234370386\n",
      "2025-09-07 20:51:05,197 - INFO - 740 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:05,212 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:05,217 - INFO - --------------------\n",
      "\n",
      "741/800: 100%|██████████| 216/216 [00:06<00:00, 33.18it/s]\n",
      "2025-09-07 20:51:11,939 - INFO - All types `lr` of epoch 741: {'lr/param_group0': 3.3607313633809894e-05, 'lr/param_group1': 3.3607313633809894e-05, 'lr/param_group2': 3.3607313633809894e-05, 'lr/param_group3': 3.3607313633809894e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:11,954 - INFO - epoch 741: train loss 0.04056278688626157\n",
      "2025-09-07 20:51:11,969 - INFO - 741 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:11,975 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:11,990 - INFO - --------------------\n",
      "\n",
      "742/800: 100%|██████████| 216/216 [00:06<00:00, 33.68it/s]\n",
      "2025-09-07 20:51:18,630 - INFO - All types `lr` of epoch 742: {'lr/param_group0': 3.348659275907031e-05, 'lr/param_group1': 3.348659275907031e-05, 'lr/param_group2': 3.348659275907031e-05, 'lr/param_group3': 3.348659275907031e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:18,646 - INFO - epoch 742: train loss 0.04015551186684105\n",
      "2025-09-07 20:51:18,652 - INFO - 742 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:18,666 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:18,670 - INFO - --------------------\n",
      "\n",
      "743/800: 100%|██████████| 216/216 [00:06<00:00, 33.25it/s]\n",
      "2025-09-07 20:51:25,387 - INFO - All types `lr` of epoch 743: {'lr/param_group0': 3.336789998376028e-05, 'lr/param_group1': 3.336789998376028e-05, 'lr/param_group2': 3.336789998376028e-05, 'lr/param_group3': 3.336789998376028e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:25,394 - INFO - epoch 743: train loss 0.04034980786619363\n",
      "2025-09-07 20:51:25,417 - INFO - 743 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:25,421 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:25,435 - INFO - --------------------\n",
      "\n",
      "744/800: 100%|██████████| 216/216 [00:06<00:00, 33.41it/s]\n",
      "2025-09-07 20:51:32,127 - INFO - All types `lr` of epoch 744: {'lr/param_group0': 3.3251237138269095e-05, 'lr/param_group1': 3.3251237138269095e-05, 'lr/param_group2': 3.3251237138269095e-05, 'lr/param_group3': 3.3251237138269095e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:32,143 - INFO - epoch 744: train loss 0.04027864204167768\n",
      "2025-09-07 20:51:32,147 - INFO - 744 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:32,161 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:32,176 - INFO - --------------------\n",
      "\n",
      "745/800: 100%|██████████| 216/216 [00:06<00:00, 33.42it/s]\n",
      "2025-09-07 20:51:38,861 - INFO - All types `lr` of epoch 745: {'lr/param_group0': 3.313660602168222e-05, 'lr/param_group1': 3.313660602168222e-05, 'lr/param_group2': 3.313660602168222e-05, 'lr/param_group3': 3.313660602168222e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:38,876 - INFO - epoch 745: train loss 0.04034095136793675\n",
      "2025-09-07 20:51:38,891 - INFO - 745 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:38,897 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:38,912 - INFO - --------------------\n",
      "\n",
      "746/800: 100%|██████████| 216/216 [00:06<00:00, 33.87it/s]\n",
      "2025-09-07 20:51:45,516 - INFO - All types `lr` of epoch 746: {'lr/param_group0': 3.302400840175328e-05, 'lr/param_group1': 3.302400840175328e-05, 'lr/param_group2': 3.302400840175328e-05, 'lr/param_group3': 3.302400840175328e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:45,522 - INFO - epoch 746: train loss 0.04019703883332787\n",
      "2025-09-07 20:51:45,536 - INFO - 746 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:45,551 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:45,557 - INFO - --------------------\n",
      "\n",
      "747/800: 100%|██████████| 216/216 [00:06<00:00, 33.48it/s]\n",
      "2025-09-07 20:51:52,228 - INFO - All types `lr` of epoch 747: {'lr/param_group0': 3.291344601487679e-05, 'lr/param_group1': 3.291344601487679e-05, 'lr/param_group2': 3.291344601487679e-05, 'lr/param_group3': 3.291344601487679e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:52,244 - INFO - epoch 747: train loss 0.040266894131760905\n",
      "2025-09-07 20:51:52,260 - INFO - 747 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:52,265 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:52,279 - INFO - --------------------\n",
      "\n",
      "748/800: 100%|██████████| 216/216 [00:06<00:00, 33.22it/s]\n",
      "2025-09-07 20:51:59,010 - INFO - All types `lr` of epoch 748: {'lr/param_group0': 3.280492056606162e-05, 'lr/param_group1': 3.280492056606162e-05, 'lr/param_group2': 3.280492056606162e-05, 'lr/param_group3': 3.280492056606162e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:51:59,026 - INFO - epoch 748: train loss 0.040427172349558935\n",
      "2025-09-07 20:51:59,032 - INFO - 748 epochs completed!\n",
      "\n",
      "2025-09-07 20:51:59,046 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:51:59,061 - INFO - --------------------\n",
      "\n",
      "749/800: 100%|██████████| 216/216 [00:06<00:00, 33.53it/s]\n",
      "2025-09-07 20:52:05,702 - INFO - All types `lr` of epoch 749: {'lr/param_group0': 3.2698433728904406e-05, 'lr/param_group1': 3.2698433728904406e-05, 'lr/param_group2': 3.2698433728904406e-05, 'lr/param_group3': 3.2698433728904406e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:05,717 - INFO - epoch 749: train loss 0.04019360794444327\n",
      "2025-09-07 20:52:05,733 - INFO - 749 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:05,738 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:05,752 - INFO - --------------------\n",
      "\n",
      "750/800: 100%|██████████| 216/216 [00:06<00:00, 33.72it/s]\n",
      "2025-09-07 20:52:12,379 - INFO - All types `lr` of epoch 750: {'lr/param_group0': 3.2593987145563884e-05, 'lr/param_group1': 3.2593987145563884e-05, 'lr/param_group2': 3.2593987145563884e-05, 'lr/param_group3': 3.2593987145563884e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:12,394 - INFO - epoch 750: train loss 0.040311083335567405\n",
      "2025-09-07 20:52:12,400 - INFO - 750 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:12,414 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:12,418 - INFO - --------------------\n",
      "\n",
      "751/800: 100%|██████████| 216/216 [00:06<00:00, 33.05it/s]\n",
      "2025-09-07 20:52:19,181 - INFO - All types `lr` of epoch 751: {'lr/param_group0': 3.2491582426735595e-05, 'lr/param_group1': 3.2491582426735595e-05, 'lr/param_group2': 3.2491582426735595e-05, 'lr/param_group3': 3.2491582426735595e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:19,186 - INFO - epoch 751: train loss 0.040224957590301834\n",
      "2025-09-07 20:52:19,201 - INFO - 751 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:19,205 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:19,219 - INFO - --------------------\n",
      "\n",
      "752/800: 100%|██████████| 216/216 [00:06<00:00, 33.51it/s]\n",
      "2025-09-07 20:52:25,885 - INFO - All types `lr` of epoch 752: {'lr/param_group0': 3.239122115162701e-05, 'lr/param_group1': 3.239122115162701e-05, 'lr/param_group2': 3.239122115162701e-05, 'lr/param_group3': 3.239122115162701e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:25,901 - INFO - epoch 752: train loss 0.040261252490044745\n",
      "2025-09-07 20:52:25,905 - INFO - 752 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:25,919 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:25,934 - INFO - --------------------\n",
      "\n",
      "753/800: 100%|██████████| 216/216 [00:06<00:00, 33.45it/s]\n",
      "2025-09-07 20:52:32,593 - INFO - All types `lr` of epoch 753: {'lr/param_group0': 3.2292904867933134e-05, 'lr/param_group1': 3.2292904867933134e-05, 'lr/param_group2': 3.2292904867933134e-05, 'lr/param_group3': 3.2292904867933134e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:32,608 - INFO - epoch 753: train loss 0.0406056349683139\n",
      "2025-09-07 20:52:32,623 - INFO - 753 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:32,629 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:32,643 - INFO - --------------------\n",
      "\n",
      "754/800: 100%|██████████| 216/216 [00:06<00:00, 33.74it/s]\n",
      "2025-09-07 20:52:39,264 - INFO - All types `lr` of epoch 754: {'lr/param_group0': 3.2196635091812664e-05, 'lr/param_group1': 3.2196635091812664e-05, 'lr/param_group2': 3.2196635091812664e-05, 'lr/param_group3': 3.2196635091812664e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:39,279 - INFO - epoch 754: train loss 0.04041559801057533\n",
      "2025-09-07 20:52:39,294 - INFO - 754 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:39,300 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:39,314 - INFO - --------------------\n",
      "\n",
      "755/800: 100%|██████████| 216/216 [00:06<00:00, 32.81it/s]\n",
      "2025-09-07 20:52:46,137 - INFO - All types `lr` of epoch 755: {'lr/param_group0': 3.2102413307864636e-05, 'lr/param_group1': 3.2102413307864636e-05, 'lr/param_group2': 3.2102413307864636e-05, 'lr/param_group3': 3.2102413307864636e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:46,143 - INFO - epoch 755: train loss 0.04020186677506125\n",
      "2025-09-07 20:52:46,158 - INFO - 755 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:46,172 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:46,178 - INFO - --------------------\n",
      "\n",
      "756/800: 100%|██████████| 216/216 [00:06<00:00, 33.16it/s]\n",
      "2025-09-07 20:52:52,913 - INFO - All types `lr` of epoch 756: {'lr/param_group0': 3.20102409691055e-05, 'lr/param_group1': 3.20102409691055e-05, 'lr/param_group2': 3.20102409691055e-05, 'lr/param_group3': 3.20102409691055e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:52,928 - INFO - epoch 756: train loss 0.04012257809302321\n",
      "2025-09-07 20:52:52,944 - INFO - 756 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:52,950 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:52,964 - INFO - --------------------\n",
      "\n",
      "757/800: 100%|██████████| 216/216 [00:06<00:00, 33.24it/s]\n",
      "2025-09-07 20:52:59,704 - INFO - All types `lr` of epoch 757: {'lr/param_group0': 3.192011949694678e-05, 'lr/param_group1': 3.192011949694678e-05, 'lr/param_group2': 3.192011949694678e-05, 'lr/param_group3': 3.192011949694678e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:52:59,709 - INFO - epoch 757: train loss 0.04005954354242594\n",
      "2025-09-07 20:52:59,725 - INFO - 757 epochs completed!\n",
      "\n",
      "2025-09-07 20:52:59,741 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:52:59,747 - INFO - --------------------\n",
      "\n",
      "758/800: 100%|██████████| 216/216 [00:06<00:00, 33.12it/s]\n",
      "2025-09-07 20:53:06,487 - INFO - All types `lr` of epoch 758: {'lr/param_group0': 3.1832050281173095e-05, 'lr/param_group1': 3.1832050281173095e-05, 'lr/param_group2': 3.1832050281173095e-05, 'lr/param_group3': 3.1832050281173095e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:06,504 - INFO - epoch 758: train loss 0.04010972813530653\n",
      "2025-09-07 20:53:06,510 - INFO - 758 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:06,525 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:06,529 - INFO - --------------------\n",
      "\n",
      "759/800: 100%|██████████| 216/216 [00:06<00:00, 33.04it/s]\n",
      "2025-09-07 20:53:13,286 - INFO - All types `lr` of epoch 759: {'lr/param_group0': 3.174603467992064e-05, 'lr/param_group1': 3.174603467992064e-05, 'lr/param_group2': 3.174603467992064e-05, 'lr/param_group3': 3.174603467992064e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:13,302 - INFO - epoch 759: train loss 0.04017233462245376\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.16it/s]\n",
      "2025-09-07 20:53:14,788 - INFO - epoch 759: val loss 0.059784676810657536\n",
      "2025-09-07 20:53:14,805 - INFO - 759 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:53:14,815 - INFO - 759 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:14,830 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:14,845 - INFO - --------------------\n",
      "\n",
      "760/800: 100%|██████████| 216/216 [00:06<00:00, 32.74it/s]\n",
      "2025-09-07 20:53:21,640 - INFO - All types `lr` of epoch 760: {'lr/param_group0': 3.1662074019656394e-05, 'lr/param_group1': 3.1662074019656394e-05, 'lr/param_group2': 3.1662074019656394e-05, 'lr/param_group3': 3.1662074019656394e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:21,656 - INFO - epoch 760: train loss 0.03996292939754548\n",
      "2025-09-07 20:53:21,671 - INFO - 760 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:21,677 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:21,692 - INFO - --------------------\n",
      "\n",
      "761/800: 100%|██████████| 216/216 [00:06<00:00, 32.44it/s]\n",
      "2025-09-07 20:53:28,584 - INFO - All types `lr` of epoch 761: {'lr/param_group0': 3.158016959515763e-05, 'lr/param_group1': 3.158016959515763e-05, 'lr/param_group2': 3.158016959515763e-05, 'lr/param_group3': 3.158016959515763e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:28,591 - INFO - epoch 761: train loss 0.040200017064947774\n",
      "2025-09-07 20:53:28,608 - INFO - 761 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:28,624 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:28,630 - INFO - --------------------\n",
      "\n",
      "762/800: 100%|██████████| 216/216 [00:06<00:00, 32.84it/s]\n",
      "2025-09-07 20:53:35,421 - INFO - All types `lr` of epoch 762: {'lr/param_group0': 3.150032266949188e-05, 'lr/param_group1': 3.150032266949188e-05, 'lr/param_group2': 3.150032266949188e-05, 'lr/param_group3': 3.150032266949188e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:35,436 - INFO - epoch 762: train loss 0.04006627519373541\n",
      "2025-09-07 20:53:35,443 - INFO - 762 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:35,458 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:35,473 - INFO - --------------------\n",
      "\n",
      "763/800: 100%|██████████| 216/216 [00:06<00:00, 32.85it/s]\n",
      "2025-09-07 20:53:42,252 - INFO - All types `lr` of epoch 763: {'lr/param_group0': 3.142253447399751e-05, 'lr/param_group1': 3.142253447399751e-05, 'lr/param_group2': 3.142253447399751e-05, 'lr/param_group3': 3.142253447399751e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:42,267 - INFO - epoch 763: train loss 0.040249621581838084\n",
      "2025-09-07 20:53:42,286 - INFO - 763 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:42,302 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:42,318 - INFO - --------------------\n",
      "\n",
      "764/800: 100%|██████████| 216/216 [00:06<00:00, 32.93it/s]\n",
      "2025-09-07 20:53:49,101 - INFO - All types `lr` of epoch 764: {'lr/param_group0': 3.1346806208264727e-05, 'lr/param_group1': 3.1346806208264727e-05, 'lr/param_group2': 3.1346806208264727e-05, 'lr/param_group3': 3.1346806208264727e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:49,107 - INFO - epoch 764: train loss 0.04020485721735491\n",
      "2025-09-07 20:53:49,122 - INFO - 764 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:49,126 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:49,142 - INFO - --------------------\n",
      "\n",
      "765/800: 100%|██████████| 216/216 [00:06<00:00, 33.73it/s]\n",
      "2025-09-07 20:53:55,772 - INFO - All types `lr` of epoch 765: {'lr/param_group0': 3.127313904011709e-05, 'lr/param_group1': 3.127313904011709e-05, 'lr/param_group2': 3.127313904011709e-05, 'lr/param_group3': 3.127313904011709e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:53:55,788 - INFO - epoch 765: train loss 0.040194674826192635\n",
      "2025-09-07 20:53:55,792 - INFO - 765 epochs completed!\n",
      "\n",
      "2025-09-07 20:53:55,807 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:53:55,822 - INFO - --------------------\n",
      "\n",
      "766/800: 100%|██████████| 216/216 [00:06<00:00, 32.92it/s]\n",
      "2025-09-07 20:54:02,585 - INFO - All types `lr` of epoch 766: {'lr/param_group0': 3.120153410559342e-05, 'lr/param_group1': 3.120153410559342e-05, 'lr/param_group2': 3.120153410559342e-05, 'lr/param_group3': 3.120153410559342e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:02,600 - INFO - epoch 766: train loss 0.0400397466685347\n",
      "2025-09-07 20:54:02,616 - INFO - 766 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:02,621 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:02,636 - INFO - --------------------\n",
      "\n",
      "767/800: 100%|██████████| 216/216 [00:06<00:00, 33.03it/s]\n",
      "2025-09-07 20:54:09,396 - INFO - All types `lr` of epoch 767: {'lr/param_group0': 3.113199250893041e-05, 'lr/param_group1': 3.113199250893041e-05, 'lr/param_group2': 3.113199250893041e-05, 'lr/param_group3': 3.113199250893041e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:09,414 - INFO - epoch 767: train loss 0.040274037375908206\n",
      "2025-09-07 20:54:09,421 - INFO - 767 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:09,436 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:09,452 - INFO - --------------------\n",
      "\n",
      "768/800: 100%|██████████| 216/216 [00:06<00:00, 32.25it/s]\n",
      "2025-09-07 20:54:16,350 - INFO - All types `lr` of epoch 768: {'lr/param_group0': 3.10645153225455e-05, 'lr/param_group1': 3.10645153225455e-05, 'lr/param_group2': 3.10645153225455e-05, 'lr/param_group3': 3.10645153225455e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:16,365 - INFO - epoch 768: train loss 0.04018046555143816\n",
      "2025-09-07 20:54:16,381 - INFO - 768 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:16,387 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:16,402 - INFO - --------------------\n",
      "\n",
      "769/800: 100%|██████████| 216/216 [00:06<00:00, 32.29it/s]\n",
      "2025-09-07 20:54:23,317 - INFO - All types `lr` of epoch 769: {'lr/param_group0': 3.099910358702037e-05, 'lr/param_group1': 3.099910358702037e-05, 'lr/param_group2': 3.099910358702037e-05, 'lr/param_group3': 3.099910358702037e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:23,323 - INFO - epoch 769: train loss 0.0401752354680664\n",
      "2025-09-07 20:54:23,338 - INFO - 769 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:23,354 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:23,359 - INFO - --------------------\n",
      "\n",
      "770/800: 100%|██████████| 216/216 [00:06<00:00, 32.29it/s]\n",
      "2025-09-07 20:54:30,262 - INFO - All types `lr` of epoch 770: {'lr/param_group0': 3.093575831108491e-05, 'lr/param_group1': 3.093575831108491e-05, 'lr/param_group2': 3.093575831108491e-05, 'lr/param_group3': 3.093575831108491e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:30,279 - INFO - epoch 770: train loss 0.04010896683084192\n",
      "2025-09-07 20:54:30,285 - INFO - 770 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:30,300 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:30,315 - INFO - --------------------\n",
      "\n",
      "771/800: 100%|██████████| 216/216 [00:06<00:00, 33.10it/s]\n",
      "2025-09-07 20:54:37,059 - INFO - All types `lr` of epoch 771: {'lr/param_group0': 3.087448047160169e-05, 'lr/param_group1': 3.087448047160169e-05, 'lr/param_group2': 3.087448047160169e-05, 'lr/param_group3': 3.087448047160169e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:37,065 - INFO - epoch 771: train loss 0.03997834549388952\n",
      "2025-09-07 20:54:37,080 - INFO - 771 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:37,085 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:37,100 - INFO - --------------------\n",
      "\n",
      "772/800: 100%|██████████| 216/216 [00:06<00:00, 33.25it/s]\n",
      "2025-09-07 20:54:43,814 - INFO - All types `lr` of epoch 772: {'lr/param_group0': 3.0815271013550735e-05, 'lr/param_group1': 3.0815271013550735e-05, 'lr/param_group2': 3.0815271013550735e-05, 'lr/param_group3': 3.0815271013550735e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:43,833 - INFO - epoch 772: train loss 0.04028678309448339\n",
      "2025-09-07 20:54:43,851 - INFO - 772 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:43,867 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:43,882 - INFO - --------------------\n",
      "\n",
      "773/800: 100%|██████████| 216/216 [00:06<00:00, 32.79it/s]\n",
      "2025-09-07 20:54:50,709 - INFO - All types `lr` of epoch 773: {'lr/param_group0': 3.0758130850015115e-05, 'lr/param_group1': 3.0758130850015115e-05, 'lr/param_group2': 3.0758130850015115e-05, 'lr/param_group3': 3.0758130850015115e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:50,725 - INFO - epoch 773: train loss 0.04021567954785294\n",
      "2025-09-07 20:54:50,731 - INFO - 773 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:50,745 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:50,760 - INFO - --------------------\n",
      "\n",
      "774/800: 100%|██████████| 216/216 [00:07<00:00, 30.72it/s]\n",
      "2025-09-07 20:54:57,988 - INFO - All types `lr` of epoch 774: {'lr/param_group0': 3.07030608621669e-05, 'lr/param_group1': 3.07030608621669e-05, 'lr/param_group2': 3.07030608621669e-05, 'lr/param_group3': 3.07030608621669e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:54:58,015 - INFO - epoch 774: train loss 0.04012231551179731\n",
      "2025-09-07 20:54:58,040 - INFO - 774 epochs completed!\n",
      "\n",
      "2025-09-07 20:54:58,049 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:54:58,073 - INFO - --------------------\n",
      "\n",
      "775/800: 100%|██████████| 216/216 [00:06<00:00, 31.97it/s]\n",
      "2025-09-07 20:55:05,128 - INFO - All types `lr` of epoch 775: {'lr/param_group0': 3.065006189925344e-05, 'lr/param_group1': 3.065006189925344e-05, 'lr/param_group2': 3.065006189925344e-05, 'lr/param_group3': 3.065006189925344e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:05,134 - INFO - epoch 775: train loss 0.04011056720520611\n",
      "2025-09-07 20:55:05,149 - INFO - 775 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:05,165 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:05,171 - INFO - --------------------\n",
      "\n",
      "776/800: 100%|██████████| 216/216 [00:06<00:00, 32.99it/s]\n",
      "2025-09-07 20:55:11,934 - INFO - All types `lr` of epoch 776: {'lr/param_group0': 3.059913477858418e-05, 'lr/param_group1': 3.059913477858418e-05, 'lr/param_group2': 3.059913477858418e-05, 'lr/param_group3': 3.059913477858418e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:11,949 - INFO - epoch 776: train loss 0.040240254943017605\n",
      "2025-09-07 20:55:11,966 - INFO - 776 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:11,971 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:11,987 - INFO - --------------------\n",
      "\n",
      "777/800: 100%|██████████| 216/216 [00:06<00:00, 33.26it/s]\n",
      "2025-09-07 20:55:18,709 - INFO - All types `lr` of epoch 777: {'lr/param_group0': 3.055028028551846e-05, 'lr/param_group1': 3.055028028551846e-05, 'lr/param_group2': 3.055028028551846e-05, 'lr/param_group3': 3.055028028551846e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:18,725 - INFO - epoch 777: train loss 0.04016435736169418\n",
      "2025-09-07 20:55:18,732 - INFO - 777 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:18,746 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:18,762 - INFO - --------------------\n",
      "\n",
      "778/800: 100%|██████████| 216/216 [00:06<00:00, 33.12it/s]\n",
      "2025-09-07 20:55:25,485 - INFO - All types `lr` of epoch 778: {'lr/param_group0': 3.0503499173452928e-05, 'lr/param_group1': 3.0503499173452928e-05, 'lr/param_group2': 3.0503499173452928e-05, 'lr/param_group3': 3.0503499173452928e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:25,500 - INFO - epoch 778: train loss 0.04028851354356717\n",
      "2025-09-07 20:55:25,519 - INFO - 778 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:25,536 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:25,551 - INFO - --------------------\n",
      "\n",
      "779/800: 100%|██████████| 216/216 [00:06<00:00, 32.36it/s]\n",
      "2025-09-07 20:55:32,444 - INFO - All types `lr` of epoch 779: {'lr/param_group0': 3.0458792163810207e-05, 'lr/param_group1': 3.0458792163810207e-05, 'lr/param_group2': 3.0458792163810207e-05, 'lr/param_group3': 3.0458792163810207e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:32,450 - INFO - epoch 779: train loss 0.0401793234222741\n",
      "2025-09-07 20:55:32,466 - INFO - 779 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:32,470 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:32,485 - INFO - --------------------\n",
      "\n",
      "780/800: 100%|██████████| 216/216 [00:06<00:00, 32.92it/s]\n",
      "2025-09-07 20:55:39,274 - INFO - All types `lr` of epoch 780: {'lr/param_group0': 3.0416159946027707e-05, 'lr/param_group1': 3.0416159946027707e-05, 'lr/param_group2': 3.0416159946027707e-05, 'lr/param_group3': 3.0416159946027707e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:39,278 - INFO - epoch 780: train loss 0.04016226823269217\n",
      "2025-09-07 20:55:39,294 - INFO - 780 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:39,310 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:39,316 - INFO - --------------------\n",
      "\n",
      "781/800: 100%|██████████| 216/216 [00:06<00:00, 32.28it/s]\n",
      "2025-09-07 20:55:46,223 - INFO - All types `lr` of epoch 781: {'lr/param_group0': 3.0375603177546958e-05, 'lr/param_group1': 3.0375603177546958e-05, 'lr/param_group2': 3.0375603177546958e-05, 'lr/param_group3': 3.0375603177546958e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:46,239 - INFO - epoch 781: train loss 0.0402240927365643\n",
      "2025-09-07 20:55:46,254 - INFO - 781 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:46,260 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:46,275 - INFO - --------------------\n",
      "\n",
      "782/800: 100%|██████████| 216/216 [00:06<00:00, 32.48it/s]\n",
      "2025-09-07 20:55:53,158 - INFO - All types `lr` of epoch 782: {'lr/param_group0': 3.0337122483803534e-05, 'lr/param_group1': 3.0337122483803534e-05, 'lr/param_group2': 3.0337122483803534e-05, 'lr/param_group3': 3.0337122483803534e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:55:53,175 - INFO - epoch 782: train loss 0.04020933296393465\n",
      "2025-09-07 20:55:53,181 - INFO - 782 epochs completed!\n",
      "\n",
      "2025-09-07 20:55:53,196 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:55:53,211 - INFO - --------------------\n",
      "\n",
      "783/800: 100%|██████████| 216/216 [00:06<00:00, 32.61it/s]\n",
      "2025-09-07 20:56:00,033 - INFO - All types `lr` of epoch 783: {'lr/param_group0': 3.0300718458217278e-05, 'lr/param_group1': 3.0300718458217278e-05, 'lr/param_group2': 3.0300718458217278e-05, 'lr/param_group3': 3.0300718458217278e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:00,049 - INFO - epoch 783: train loss 0.04022059084295675\n",
      "2025-09-07 20:56:00,065 - INFO - 783 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:00,071 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:00,086 - INFO - --------------------\n",
      "\n",
      "784/800: 100%|██████████| 216/216 [00:06<00:00, 33.37it/s]\n",
      "2025-09-07 20:56:06,787 - INFO - All types `lr` of epoch 784: {'lr/param_group0': 3.0266391662183322e-05, 'lr/param_group1': 3.0266391662183322e-05, 'lr/param_group2': 3.0266391662183322e-05, 'lr/param_group3': 3.0266391662183322e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:06,803 - INFO - epoch 784: train loss 0.0401123427544479\n",
      "2025-09-07 20:56:06,809 - INFO - 784 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:06,825 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:06,842 - INFO - --------------------\n",
      "\n",
      "785/800: 100%|██████████| 216/216 [00:06<00:00, 32.79it/s]\n",
      "2025-09-07 20:56:13,641 - INFO - All types `lr` of epoch 785: {'lr/param_group0': 3.023414262506332e-05, 'lr/param_group1': 3.023414262506332e-05, 'lr/param_group2': 3.023414262506332e-05, 'lr/param_group3': 3.023414262506332e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:13,657 - INFO - epoch 785: train loss 0.04001425696467912\n",
      "2025-09-07 20:56:13,673 - INFO - 785 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:13,679 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:13,694 - INFO - --------------------\n",
      "\n",
      "786/800: 100%|██████████| 216/216 [00:06<00:00, 32.42it/s]\n",
      "2025-09-07 20:56:20,583 - INFO - All types `lr` of epoch 786: {'lr/param_group0': 3.0203971844177353e-05, 'lr/param_group1': 3.0203971844177353e-05, 'lr/param_group2': 3.0203971844177353e-05, 'lr/param_group3': 3.0203971844177353e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:20,589 - INFO - epoch 786: train loss 0.04015957634827053\n",
      "2025-09-07 20:56:20,605 - INFO - 786 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:20,609 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:20,624 - INFO - --------------------\n",
      "\n",
      "787/800: 100%|██████████| 216/216 [00:06<00:00, 32.79it/s]\n",
      "2025-09-07 20:56:27,438 - INFO - All types `lr` of epoch 787: {'lr/param_group0': 3.0175879784796188e-05, 'lr/param_group1': 3.0175879784796188e-05, 'lr/param_group2': 3.0175879784796188e-05, 'lr/param_group3': 3.0175879784796188e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:27,454 - INFO - epoch 787: train loss 0.04002362496599003\n",
      "2025-09-07 20:56:27,458 - INFO - 787 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:27,473 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:27,489 - INFO - --------------------\n",
      "\n",
      "788/800: 100%|██████████| 216/216 [00:06<00:00, 32.15it/s]\n",
      "2025-09-07 20:56:34,409 - INFO - All types `lr` of epoch 788: {'lr/param_group0': 3.0149866880134044e-05, 'lr/param_group1': 3.0149866880134044e-05, 'lr/param_group2': 3.0149866880134044e-05, 'lr/param_group3': 3.0149866880134044e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:34,425 - INFO - epoch 788: train loss 0.0401715308048383\n",
      "2025-09-07 20:56:34,442 - INFO - 788 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:34,448 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:34,463 - INFO - --------------------\n",
      "\n",
      "789/800: 100%|██████████| 216/216 [00:06<00:00, 32.60it/s]\n",
      "2025-09-07 20:56:41,329 - INFO - All types `lr` of epoch 789: {'lr/param_group0': 3.012593353134217e-05, 'lr/param_group1': 3.012593353134217e-05, 'lr/param_group2': 3.012593353134217e-05, 'lr/param_group3': 3.012593353134217e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:41,336 - INFO - epoch 789: train loss 0.04009535046363318\n",
      "2025-09-07 20:56:41,351 - INFO - 789 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:41,367 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:41,373 - INFO - --------------------\n",
      "\n",
      "790/800: 100%|██████████| 216/216 [00:06<00:00, 32.59it/s]\n",
      "2025-09-07 20:56:48,218 - INFO - All types `lr` of epoch 790: {'lr/param_group0': 3.010408010750237e-05, 'lr/param_group1': 3.010408010750237e-05, 'lr/param_group2': 3.010408010750237e-05, 'lr/param_group3': 3.010408010750237e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:48,234 - INFO - epoch 790: train loss 0.04015910508180106\n",
      "2025-09-07 20:56:48,250 - INFO - 790 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:48,256 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:48,271 - INFO - --------------------\n",
      "\n",
      "791/800: 100%|██████████| 216/216 [00:06<00:00, 32.65it/s]\n",
      "2025-09-07 20:56:55,109 - INFO - All types `lr` of epoch 791: {'lr/param_group0': 3.008430694562156e-05, 'lr/param_group1': 3.008430694562156e-05, 'lr/param_group2': 3.008430694562156e-05, 'lr/param_group3': 3.008430694562156e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:56:55,125 - INFO - epoch 791: train loss 0.03995782481851401\n",
      "2025-09-07 20:56:55,141 - INFO - 791 epochs completed!\n",
      "\n",
      "2025-09-07 20:56:55,147 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:56:55,162 - INFO - --------------------\n",
      "\n",
      "792/800: 100%|██████████| 216/216 [00:06<00:00, 33.07it/s]\n",
      "2025-09-07 20:57:01,917 - INFO - All types `lr` of epoch 792: {'lr/param_group0': 3.006661435062623e-05, 'lr/param_group1': 3.006661435062623e-05, 'lr/param_group2': 3.006661435062623e-05, 'lr/param_group3': 3.006661435062623e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:01,933 - INFO - epoch 792: train loss 0.040097625356995396\n",
      "2025-09-07 20:57:01,940 - INFO - 792 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:01,955 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:01,971 - INFO - --------------------\n",
      "\n",
      "793/800: 100%|██████████| 216/216 [00:06<00:00, 32.42it/s]\n",
      "2025-09-07 20:57:08,834 - INFO - All types `lr` of epoch 793: {'lr/param_group0': 3.0051002595358154e-05, 'lr/param_group1': 3.0051002595358154e-05, 'lr/param_group2': 3.0051002595358154e-05, 'lr/param_group3': 3.0051002595358154e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:08,850 - INFO - epoch 793: train loss 0.04009060406436523\n",
      "2025-09-07 20:57:08,866 - INFO - 793 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:08,872 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:08,886 - INFO - --------------------\n",
      "\n",
      "794/800: 100%|██████████| 216/216 [00:06<00:00, 32.15it/s]\n",
      "2025-09-07 20:57:15,840 - INFO - All types `lr` of epoch 794: {'lr/param_group0': 3.003747192056992e-05, 'lr/param_group1': 3.003747192056992e-05, 'lr/param_group2': 3.003747192056992e-05, 'lr/param_group3': 3.003747192056992e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:15,846 - INFO - epoch 794: train loss 0.04019592148769233\n",
      "2025-09-07 20:57:15,862 - INFO - 794 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:15,866 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:15,881 - INFO - --------------------\n",
      "\n",
      "795/800: 100%|██████████| 216/216 [00:06<00:00, 32.71it/s]\n",
      "2025-09-07 20:57:22,708 - INFO - All types `lr` of epoch 795: {'lr/param_group0': 3.0026022534921256e-05, 'lr/param_group1': 3.0026022534921256e-05, 'lr/param_group2': 3.0026022534921256e-05, 'lr/param_group3': 3.0026022534921256e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:22,727 - INFO - epoch 795: train loss 0.040181404997215224\n",
      "2025-09-07 20:57:22,745 - INFO - 795 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:22,761 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:22,776 - INFO - --------------------\n",
      "\n",
      "796/800: 100%|██████████| 216/216 [00:06<00:00, 32.30it/s]\n",
      "2025-09-07 20:57:29,704 - INFO - All types `lr` of epoch 796: {'lr/param_group0': 3.001665461497582e-05, 'lr/param_group1': 3.001665461497582e-05, 'lr/param_group2': 3.001665461497582e-05, 'lr/param_group3': 3.001665461497582e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:29,720 - INFO - epoch 796: train loss 0.04002837876409844\n",
      "2025-09-07 20:57:29,726 - INFO - 796 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:29,741 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:29,757 - INFO - --------------------\n",
      "\n",
      "797/800: 100%|██████████| 216/216 [00:06<00:00, 32.31it/s]\n",
      "2025-09-07 20:57:36,651 - INFO - All types `lr` of epoch 797: {'lr/param_group0': 3.0009368305198555e-05, 'lr/param_group1': 3.0009368305198555e-05, 'lr/param_group2': 3.0009368305198555e-05, 'lr/param_group3': 3.0009368305198555e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:36,667 - INFO - epoch 797: train loss 0.040188666329615645\n",
      "2025-09-07 20:57:36,684 - INFO - 797 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:36,690 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:36,705 - INFO - --------------------\n",
      "\n",
      "798/800: 100%|██████████| 216/216 [00:05<00:00, 36.60it/s]\n",
      "2025-09-07 20:57:42,833 - INFO - All types `lr` of epoch 798: {'lr/param_group0': 3.0004163717953378e-05, 'lr/param_group1': 3.0004163717953378e-05, 'lr/param_group2': 3.0004163717953378e-05, 'lr/param_group3': 3.0004163717953378e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:42,850 - INFO - epoch 798: train loss 0.04009737065751796\n",
      "2025-09-07 20:57:42,856 - INFO - 798 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:42,871 - INFO - --------------------\n",
      "\n",
      "2025-09-07 20:57:42,887 - INFO - --------------------\n",
      "\n",
      "799/800: 100%|██████████| 216/216 [00:06<00:00, 32.32it/s]\n",
      "2025-09-07 20:57:49,802 - INFO - All types `lr` of epoch 799: {'lr/param_group0': 3.000104093350145e-05, 'lr/param_group1': 3.000104093350145e-05, 'lr/param_group2': 3.000104093350145e-05, 'lr/param_group3': 3.000104093350145e-05}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-07 20:57:49,808 - INFO - epoch 799: train loss 0.0400788652262202\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.78it/s]\n",
      "2025-09-07 20:57:51,303 - INFO - epoch 799: val loss 0.059519419653548136\n",
      "2025-09-07 20:57:51,310 - INFO - 799 epoch vae reconstruct images complete!\n",
      "2025-09-07 20:57:51,425 - INFO - epoch 799 has been saved\n",
      "2025-09-07 20:57:51,685 - INFO - 799 epochs completed!\n",
      "\n",
      "2025-09-07 20:57:51,695 - INFO - --------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vae_trainer = VAETrainer([encoder, decoder], dataset, vae_cfg)\n",
    "vae_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
