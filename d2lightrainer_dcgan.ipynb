{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f15d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb60e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 100, ngf: int = 64, channels: int = 3):\n",
    "        super().__init__()\n",
    "        # input Z => project to 4x4 feature map\n",
    "        self.net = nn.Sequential(\n",
    "            # input z: (N, latent_dim, 1, 1) after unsqueeze\n",
    "            nn.ConvTranspose2d(latent_dim, ngf * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size: (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 8x8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 16x16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 32x32\n",
    "            nn.ConvTranspose2d(ngf, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # output: channels x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z: (N, latent_dim)\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414a0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf: int = 64, channels: int = 3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # input: channels x 64 x 64\n",
    "            nn.Conv2d(channels, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # final: 4x4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            # output is (N,1,1,1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out.view(-1, 1).squeeze(1)  # (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76688d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, image_num=-1):\n",
    "        # Collects image file paths from the root directory, limited to `image_num` images.\n",
    "        self.image_paths = sorted(\n",
    "            [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)\n",
    "             if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        )[:image_num]  # Limit to the first `image_num` images\n",
    "        self.transform = transform # Transformation to apply to images\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the number of images in the dataset.\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Loads an image by index, converts it to RGB, and applies transformations if provided.\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Since no actual labels, return 0 as dummy labels\n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f442fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pipeline for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Randomly applies a horizontal flip with 40% probability.\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ], p=0.4),  \n",
    "    transforms.ToTensor(), # Converts image to a PyTorch tensor.\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                         std=(0.5, 0.5, 0.5)), # Normalizes using mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12941d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(root_dir=\"/datasets/delkon/dm_data\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca15c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2lightrainer.UnsupervisedLearning.DCGAN.trainer_config import DCGANTrainerConfig\n",
    "from d2lightrainer.UnsupervisedLearning.DCGAN.trainer import DCGANTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f05fd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_cfg = DCGANTrainerConfig()\n",
    "new_param_dict = {\"device\": 3, \"save_dir\": \"runs_test\", \"batch_size\": 16, \"nominal_batch_size\": 64}\n",
    "dcgan_cfg.update(**new_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d32090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 23:54:22,818 - INFO - Using GPU: 3\n",
      "2025-09-08 23:54:22,823 - INFO - 'generator optimizer:' Adam(lr=0.0003, momentum=0.5) with parameter groups 4 weight(decay=0.0), 0 weight(decay=0.0), 5 weight(decay=0.0), 4 bias(decay=0.0)\n",
      "2025-09-08 23:54:22,825 - INFO - 'discriminator optimizer:' Adam(lr=0.0003, momentum=0.5) with parameter groups 3 weight(decay=0.0), 0 weight(decay=1.0000000000000002e-06), 5 weight(decay=0.0001), 3 bias(decay=0.0)\n",
      "2025-09-08 23:54:22,939 - INFO - --------------------\n",
      "\n",
      "0/200: 100%|██████████| 269/269 [00:07<00:00, 33.99it/s]\n",
      "2025-09-08 23:54:30,976 - INFO - Generator: all types `lr` of epoch 0: {'lr/param_group0': np.float64(0.0005402230483271375), 'lr/param_group1': np.float64(5.977695167286245e-05), 'lr/param_group2': np.float64(5.977695167286245e-05), 'lr/param_group3': np.float64(5.977695167286245e-05)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-08 23:54:30,976 - INFO - epoch 0: generator train loss 0.45553079697556215\n",
      "2025-09-08 23:54:30,977 - INFO - Discriminator: all types `lr` of epoch 0: {'lr/param_group0': np.float64(0.00045055762081784383), 'lr/param_group1': np.float64(0.00014944237918215612), 'lr/param_group2': np.float64(0.00014944237918215612), 'lr/param_group3': np.float64(0.00014944237918215612)}\n",
      "- lr/param_group0: regular weights (full weight decay applied)\n",
      "- lr/param_group1: batchnorm and logit_scale parameters (no weight decay)\n",
      "- lr/param_group2: embedding layer weights (smaller weight decay)\n",
      "- lr/param_group3: bias parameters (no weight decay)\n",
      "2025-09-08 23:54:30,977 - INFO - epoch 0: discriminator train loss 0.7107139723340818\n",
      "2025-09-08 23:54:30,979 - INFO - 0 epochs forward process completed!\n",
      "\n",
      "2025-09-08 23:54:30,980 - INFO - --------------------\n",
      "\n",
      "2025-09-08 23:54:30,980 - INFO - --------------------\n",
      "\n",
      "1/200:  46%|████▌     | 124/269 [00:03<00:03, 37.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dcgan_trainer = DCGANTrainer([generator, discriminator], dataset, dcgan_cfg)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdcgan_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UniversityWorks/d2lightrainer/UnsupervisedLearning/DCGAN/trainer.py:328\u001b[39m, in \u001b[36mDCGANTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[38;5;28mself\u001b[39m._optimizer_step(\u001b[38;5;28mself\u001b[39m.optimizer_d, model_choice=\u001b[33m\"\u001b[39m\u001b[33mdiscriminator\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    324\u001b[39m         last_opt_step_d = current_num_iter\n\u001b[32m    326\u001b[39m     pbar.set_description(\n\u001b[32m    327\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.current_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# (GB) GPU memory util\u001b[39;00m\n\u001b[32m    329\u001b[39m     )\n\u001b[32m    331\u001b[39m lr_g = {\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr/param_group\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: param_group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.optimizer_g.param_groups)}\n\u001b[32m    332\u001b[39m lr_d = {\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr/param_group\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: param_group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m k, param_group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.optimizer_d.param_groups)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UniversityWorks/d2lightrainer/UnsupervisedLearning/DCGAN/trainer.py:412\u001b[39m, in \u001b[36mDCGANTrainer.get_memory\u001b[39m\u001b[34m(self, fraction)\u001b[39m\n\u001b[32m    410\u001b[39m memory, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m     memory = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmemory_reserved\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fraction:\n\u001b[32m    414\u001b[39m         total = torch.cuda.get_device_properties(\u001b[38;5;28mself\u001b[39m.device).total_memory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/cuda/memory.py:575\u001b[39m, in \u001b[36mmemory_reserved\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmemory_reserved\u001b[39m(device: \u001b[33m\"\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    564\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the current GPU memory managed by the caching allocator in bytes for a given device.\u001b[39;00m\n\u001b[32m    565\u001b[39m \n\u001b[32m    566\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m \u001b[33;03m        management.\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmemory_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mreserved_bytes.all.current\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/cuda/memory.py:327\u001b[39m, in \u001b[36mmemory_stats\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    325\u001b[39m stats = memory_stats_as_nested_dict(device=device)\n\u001b[32m    326\u001b[39m _recurse_add_to_result(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, stats)\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collections.OrderedDict(result)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dcgan_trainer = DCGANTrainer([generator, discriminator], dataset, dcgan_cfg)\n",
    "dcgan_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
