{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d4dc5",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77faa627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, dir, classes):\n",
    "        if isinstance(dir, str):\n",
    "            dir = Path(dir)\n",
    "        subjects = [os.path.splitext(file)[0] for file in os.listdir(dir) \n",
    "                    if not file.startswith(\".\")]\n",
    "        print(subjects)\n",
    "        print(f\"Scanning all npz files in the {dir}\")\n",
    "        with Pool() as p:\n",
    "            result = list(\n",
    "                tqdm(\n",
    "                    p.imap(partial(self.load_npz_data, dir=dir, classes=classes), subjects), \n",
    "                    total=len(subjects), \n",
    "                    bar_format=\"{l_bar}{bar:10}{r_bar}\"\n",
    "                )\n",
    "            )\n",
    "        # print(result)\n",
    "        _, ch, n_times = result[0][0].shape\n",
    "        self.raw_data = np.array([row[0] for row in result]).reshape(-1, ch, n_times)\n",
    "        self.label = np.array([row[1] for row in result]).reshape(-1).astype(np.int64)\n",
    "        self.data = self.scale_data(self.raw_data)\n",
    "        self.data = np.expand_dims(self.data, axis=1).astype(np.float32)\n",
    "        # print(self.data.dtype, self.label.dtype)\n",
    "        self.len = len(self.label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data)[idx], torch.from_numpy(self.label)[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def load_npz_data(subject, dir, classes):\n",
    "        data = []\n",
    "        if isinstance(dir, str):\n",
    "            dir = Path(dir)\n",
    "        npz_fpath = dir / (subject + \".npz\")\n",
    "        # print(npz_fpath)\n",
    "        item = np.load(npz_fpath)[\"event_datas\"]\n",
    "        bs, ch, n_times = item.shape\n",
    "        data.append(item)\n",
    "        label = np.repeat(np.arange(classes), repeats=bs / classes)\n",
    "        return [np.array(data).reshape(-1, ch, n_times), label]\n",
    "    \n",
    "    def scale_data(self, raw_data):\n",
    "        for i in range(len(raw_data)):\n",
    "            raw_data[i, ...] = preprocessing.scale(raw_data[i, ...], axis=1)\n",
    "        return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(dir=Path(\"./train_course/npz_data\"), classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a25973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopad(k, p=None, d=1):\n",
    "    if d > 1:\n",
    "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k] # actual kernel size\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k] # auto-pad\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e890b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, \n",
    "                 g=1, d=1, act=True, has_bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), \n",
    "                              groups=g, dilation=d, bias=has_bias)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.SiLU() if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "    def forward_fuse(self, x):\n",
    "        self.act(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98955e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dWithConstraint(nn.Conv2d):\n",
    "    def __init__(self, *args, max_norm=1.0, **kwargs):\n",
    "        self.max_norm = max_norm\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.weight.data = torch.renorm(\n",
    "            self.weight.data, p=2, dim=0, maxnorm=self.max_norm\n",
    "        )\n",
    "        return super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4094e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvWithConstraint(nn.Module):\n",
    "    def __init__(self, c1, c2, k=1, max_norm=1.0, \n",
    "                 s=1, p=None, g=1, d=1, act=True, has_bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = Conv2dWithConstraint(c1, c2, k, max_norm=max_norm, stride=s, \n",
    "                                         padding=autopad(k, p, d), groups=g, dilation=d, \n",
    "                                         bias=has_bias)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.SiLU() if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def forward_fuse(self, x):\n",
    "        return self.act(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bcad38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWConvWithConstraint(ConvWithConstraint):\n",
    "    def __init__(self, c1, c2, max_norm=1.0, k=1, act=True, s=1, p=0, d=1):\n",
    "        super().__init__(c1, c2, k, max_norm=max_norm, s=s, p=p, g=math.gcd(c1, c2), d=d, act=act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b10e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv(nn.Module):\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, \n",
    "                 d=1, act=True, has_bias=True):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(c1, c1, k, stride=s, padding=autopad(k, p, d), \n",
    "                            dilation=d, groups=c1, bias=has_bias)\n",
    "        self.pw = nn.Conv2d(c1, c2, 1, stride=s, bias=has_bias)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "\n",
    "        self.act = nn.SiLU() if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.pw(self.dw(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4ccfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithConstraint(nn.Linear):\n",
    "    def __init__(self, *args, max_norm=1.0, **kwargs):\n",
    "        self.max_norm = max_norm\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data = torch.renorm(\n",
    "            self.weight.data, p=2, dim=0, maxnorm=self.max_norm\n",
    "        )\n",
    "        return super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d497657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temporal_conv = Conv(1, 8, (1, 31))\n",
    "        self.spatial_conv = DWConvWithConstraint(8, 16, 2., (64, 1))\n",
    "        self.separable_conv = SeparableConv(16, 16, (1, 15))\n",
    "\n",
    "        self.linear = LinearWithConstraint(256, 8, 0.5)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d((1, 4))\n",
    "        self.dropout = nn.Dropout(0.65)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial_conv(self.temporal_conv(x))\n",
    "        x = self.dropout(self.avg_pool(x))\n",
    "        x = self.separable_conv(x)\n",
    "        x = self.dropout(self.avg_pool(x))\n",
    "        return self.linear(self.flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet = EEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2lightrainer.SupervisedLearning.trainer_config import CLSTrainerConfig\n",
    "from d2lightrainer.SupervisedLearning.trainer import CLSTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_cfg = CLSTrainerConfig()\n",
    "new_param_dict = {\"batch_size\": 32, \"nominal_batch_size\": 64, \"save_dir\": \"runs_eeg\"}\n",
    "cls_cfg.update(**new_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_trainer = CLSTrainer(eegnet, dataset, cls_cfg)\n",
    "cls_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
